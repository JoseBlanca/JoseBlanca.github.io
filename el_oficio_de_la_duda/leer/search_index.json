[["front_matter.html", "El oficio de la duda Sobre el libro", " El oficio de la duda Jose Blanca Sobre el libro El oficio de la duda Jose Blanca Version: cef64e1c2e0f378121b3a122850c813e8d82ed48 Fecha: 3-12-2021 ©2021, Jose Blanca. Algunos derechos reservados. Excepto cuando se indique lo contrario, esta obra está bajo una licencia CC BY-NC-SA 4.0. (https://creativecommons.org/licenses/by-nc-sa/4.0/deed.es) Usted es libre de: Compartir — copiar y redistribuir el material en cualquier medio o formato Adaptar — remezclar, transformar y construir a partir del material El licenciante no puede revocar estas libertades en tanto usted siga los términos de la licencia bajo los siguientes términos: Atribución — Usted debe dar crédito de manera adecuada, brindar un enlace a la licencia, e indicar si se han realizado cambios. Puede hacerlo en cualquier forma razonable, pero no de forma tal que sugiera que usted o su uso tienen el apoyo del licenciante. NoComercial — Usted no puede hacer uso del material con propósitos comerciales. CompartirIgual — Si remezcla, transforma o crea a partir del material, debe distribuir su contribución bajo la la misma licencia del original. No hay restricciones adicionales — No puede aplicar términos legales ni medidas tecnológicas que restrinjan legalmente a otras a hacer cualquier uso permitido por la licencia. Avisos: No tiene que cumplir con la licencia para elementos del material en el dominio público o cuando su uso esté permitido por una excepción o limitación aplicable. No se dan garantías. La licencia podría no darle todos los permisos que necesita para el uso que tenga previsto. Por ejemplo, otros derechos como publicidad, privacidad, o derechos morales pueden limitar la forma en que utilice el material. "],["dedicatoria.html", "Dedicatoria", " Dedicatoria A mi madre, que, a pesar de nacer con las cartas en contra, siempre ha valorado el conocimiento. "],["prefacio.html", "Prefacio", " Prefacio A principios de los 80 en mi barrio los jóvenes morían por la heroína, pero había otros mundos. Mi barrio nunca fue mi mundo. Una noche de julio de 1982,1 un señor de cabello imposible y voz cautivadora se asomó a la tele y dijo: “El Cosmos es todo lo que es, lo que fue o lo que será. La contemplación del Cosmos nos perturba. Sentimos un hormigueo en la espina dorsal, un nudo en la garganta, una vaga sensación, como un recuerdo lejano en el que nos precipitamos al vacío. Sabemos que nos estamos acercando al mayor de los misterios”. Así empezaba Cosmos, la serie de Carl Sagan en la que muchos encontramos nuestro hogar. Mi barrio era el cosmos y yo debía conocerlo. Nuestro maestro, durante 13 semanas, nos fue explicando cual había sido nuestro origen. Nos contó que los átomos que nos componen habían sido forjados en colosales explosiones, en el Big Bang y en el corazón de las estrellas. Mucho más tarde, en un pequeño planeta a las afueras de la galaxia, un proceso de copia y selección se puso en marcha, un proceso ciego y extremadamente lento, pero que millones de años más tarde acabó por dar lugar a unos ojos capaces de mirar asombrados al cosmos que los había alumbrado. En aquel momento yo entendí más bien poco, tenía 9 años, pero me quedé fascinado, el cosmos no sólo era extraño, era mucho más extraño de lo que jamás pudimos soñar. La Tierra se mueve a 30 kilómetros por segundo alrededor del Sol y dentro de una gota de agua hay mundos microscópicos llenos de vida. El cosmos es un lugar encantado. Lewis Carroll intentó lanzar a Alicia a un mundo extraño, pero tanto el mundo de Alicia, como el descrito por cualquier mito precientífico, palidecen frente a la profunda extrañeza de la realidad; la imaginación humana es muy provinciana. Dijo Sócrates, antes de que sus vecinos lo condenasen a muerte, que la vida sin reflexión no merece la pena. Probablemente exageraba, pero tengo claro que la mía me sabría a poco sin la pasión por aprender sobre el cosmos y sobre nuestro pequeño papel en él. Gracias a Carl Sagan ahora sabía que no estaba solo y sabía cuál era mi hogar. Además, el conocimiento no es sólo apasionante, es el fundamento de las aplicaciones tecnológicas que hacen posible que miles de millones de seres humanos habiten el planeta. Mira a tu alrededor, ¿hay algo de lo que te rodea que no haya sido creado por la tecnología? ¿La ropa que vistes, la tinta del libro que lees? Intenta señalar algo que no haya sido afectado por la tecnología. Vivimos en un mundo complejo e interrelacionado que debe más a Galileo y Edison que a cualquier político. Nuestra dependencia de la tecnología no es opcional. Sin la medicina actual muchos habríamos muerto ya. ¿Quién no tiene a un familiar o un amigo diabético dependiente de la insulina transgénica? Sin agricultura altamente productiva habría mucha más hambre. En los últimos 50 años la población mundial se ha doblado,2 pero también lo ha hecho la productividad media de los campos de arroz, uno de los alimentos básicos de la humanidad,3 llegando a ser de 4 toneladas por hectárea en el año 2000.4 Cuando la roya de la patata destruyó las cosechas irlandesas entre 1845 y 1849 un millón de personas murió y otro millón tuvo que emigrar.5 Sin embargo, desde hace unos años, lo que más me llama la atención no tiene tanto que ver con el conocimiento que hemos acumulado, sino con el proceso que lo ha generado. ¿Cómo hemos llegado a saber lo que sabemos? ¿Cómo debemos determinar qué es razonable creer y qué no? Nuestra maquinaria cognitiva evolucionó para resolver problemas relacionados con la supervivencia en la sabana, pero, a pesar de las limitaciones que impone la adaptación a un entorno tan específico, hemos conseguido averiguar que el secreto de la vida reside en el apareamiento químico de cuatro moléculas, los cuatro nucleótidos que componen el ADN. ¿Cómo ha podido un mono desnudo y engreído dar el salto de la sabana a las estrellas? ¿Habrá conocimientos que estarán por siempre más allá de lo que nuestro cerebro provinciano será capaz de comprender? Podría pensarse que como investigador profesional tal vez debería tener claro cómo funciona la ciencia, cuáles son sus fortalezas y sus límites, pero lo cierto es que cuando me pregunté por el proceso que yo mismo seguía en el laboratorio de genética, mis ideas fueron muy vagas. No fui capaz de detallar en qué consistía dicho método, ni de comparar sus virtudes y limitaciones con otras aproximaciones. A pesar de lo que podría pensarse, los científicos solemos tener un conocimiento muy superficial sobre estas cuestiones. Afortunadamente, existe un área del conocimiento que tiene como objetivo entender la actividad científica: la filosofía de la ciencia.6 Dado mi desconocimiento probablemente no sea yo la persona más adecuada para tratar de explicar estas cuestiones en un libro. No soy un experto ni en filosofía ni en historia de la ciencia y temo cometer un error en cada frase. La filosofía debe practicarse con un rigor lógico que, por desgracia, yo no podré alcanzar. Si he decidido intentarlo, a pesar de todo, es por tratar de facilitar el acceso a estos temas a otros lectores interesados. Hay un gran número de textos que tratan estas cuestiones, pero muy pocos que me parezcan accesibles para el principiante. Casi todos asumen un conocimiento previo de la filosofía de la ciencia o, al menos, de la filosofía en general. Una posible ventaja de mi falta de experiencia es que tengo algo más fresco el camino que he recorrido, así como los principales obstáculos que he encontrado. Espero que esto compense el riesgo que conlleva mi inexperiencia. Además, aunque trataré siempre de mostrar las tesis de las diferentes escuelas filosóficas con justicia, el lector hará bien en recordar que en un texto como este es imposible evitar que transcienda el punto de vista de quien compila el material. Al escribir tengo en mente a distintos posibles lectores. En primer lugar, pienso en un ciudadano consciente del papel crucial que el conocimiento científico y técnico tienen en nuestra sociedad. Si queremos tener las mejores opciones para solucionar los problemas a los que nos enfrentamos, como el cambio climático o futuras pandemias, debemos entender las fortalezas y las debilidades del proceso científico y de nuestro proceso individual de adquisición de conocimiento. ¿Es la llamada agricultura ecológica el mejor modo de minimizar el impacto ambiental de la generación de alimentos? ¿Debemos fomentar el uso de la energía nuclear para paliar el cambio climático o debemos limitar su uso dados sus riesgos? Responder racionalmente a estas preguntas exige algo más que mero conocimiento, requiere evaluar su proceso de generación. Cuando decidimos utilizar la medicina convencional o sustituirla por alguno de sus sucedáneos estamos tomando una posición filosófica. Al considerar como válida sólo la medicina que ha sido consensuada por los expertos estamos aceptando el consenso científico como la mejor aproximación al conocimiento de la realidad. Aunque dados los terribles errores del pasado, como el de la talidomida7 o las injerencias de la industria farmacéutica en la investigación sanitaria,8 ¿qué confianza merece ese consenso? Es cierto que debemos dudar y cuestionar, pero la pregunta clave es cuánto. Veremos que, dadas unas evidencias, un pensador racional, en principio, debería albergar un grado de confianza determinado. Creer que cualquier conclusión obtenida por la comunidad científica se mantendrá sin variación en el futuro es irracional, pero no lo es menos desconfiar de la eficacia del calendario estándar de vacunas. En algunos sectores de la sociedad la desconfianza en los expertos y la credulidad con que se aceptan las afirmaciones de los charlatanes es tan alta que es posible incluso vender una terapia basada en ambientadores llenos de mierda tratada con imanes9 o afirmar, mientras mueren miles de personas al día, que no existe el virus que las está matando. Esto no debería suceder en un mundo cuyo progreso está estrechamente ligado al avance tecnológico y que haría bien en recordar los ideales ilustrados. Al parecer amplios sectores sociales han olvidado las conclusiones fundamentales de nuestros maestros más racionales. A lo largo de la historia los filósofos y los científicos, desde Aristóteles a Ioannidis, un fuerte crítico del inadecuado uso de la estadística en la ciencia actual,10 se han esforzado por mejorar el proceso de generación de conocimiento y si aspiramos a ser racionales deberíamos considerar sus recomendaciones y sus avisos, tanto al evaluar el consenso científico como en nuestra vida cotidiana. No somos tan racionales como creemos, y conocer las fortalezas y las debilidades de nuestro pensamiento nos ayuda a no ser engañados. Aprender a razonar disciplinadamente requirió el esfuerzo de muchos pensadores a lo largo de la historia, pensar sistemáticamente no es espontáneo ni intuitivo, hemos de esforzarnos para aprender y hemos de entrenarnos para que esta disciplina se convierta en hábito. Si tuviese que elegir preservar uno sólo de los resultados conseguidos por la ciencia no elegiría ningún conocimiento concreto sino las lecciones sobre cómo debemos generarlos. El proceso es más relevante que cualquier conclusión. Otro posible lector que tengo en mente es un compañero del movimiento escéptico. De ellos he aprendido mucho, especialmente sobre las debilidades del pensamiento humano. Los escépticos contemporáneos persiguen la difusión del pensamiento racional y, por lo tanto, tienen en muy buena consideración el proceso científico. De hecho, en algunas ocasiones, tengo la impresión de que el escéptico típico suele tener a la comunidad científica en mejor consideración que yo mismo, que la observo desde dentro. Por último, recomendaría a mis compañeros científicos que hiciesen el esfuerzo de acercarse a la filosofía de la ciencia. Sin embargo, asumo que este consejo sorprenderá a muchos. Entre los científicos es común encontrar actitudes que abarcan desde la indiferencia hasta la hostilidad. Hay quien considera que la filosofía es una especie de preciencia, un conjunto de especulaciones de sillón que deben ser abandonadas una vez que un área de conocimiento madura y se convierte en científica. Stephen Hawking declaró muerta a la filosofía, y lo hizo, precisamente, después de enumerar una lista de cuestiones filosóficas, como cuál es la naturaleza de la realidad o si es necesario postular un creador del universo.11 Neil deGrasse Tyson ha llegado a afirmar que estudiar filosofía puede estropearte. Si esto es cierto, yo estoy más allá de toda redención posible, no sólo he leído sobre filosofía, sino que, gracias a lo que he aprendido, ahora creo entender mejor mi trabajo como científico. Richard Feynman, uno de mis héroes, dijo una vez: La filosofía de la ciencia es tan útil para un científico como la ornitología para un pájaro. En realidad, esta actitud es difícil de justificar si pensamos que la ciencia se desarrolla dentro de un marco filosófico concreto determinado por sus asunciones y sus métodos y que el mismo Feynman dedicó muchas páginas a hablar sobre cómo debía hacerse la ciencia de calidad. La aproximación científica asume que existen modos mejores y peores de obtener conocimiento, que hay estándares que deben seguirse y ésta es una cuestión filosófica. No se puede hacer ciencia sin estar haciendo a la vez filosofía. La filosofía y la ciencia están inevitablemente entrelazadas, tanto que no es trivial delimitarlas. Además, no podemos elegir hacer o no hacer filosofía, sólo si la filosofía que estamos haciendo es buena o mala.12 Incluso si eres un científico que cree que lo que haces poco tiene que ver con la filosofía deberías entender las críticas filosóficas lo suficiente como para poder defenderte de ellas y, al hacerlo, habrás entrado de lleno en terreno filosófico. Si no reflexionas sobre las razones filosóficas de tu quehacer puede que, en realidad, estés asumiendo una filosofía poco desarrollada y fácilmente criticable. Además, Feynman era muy consciente de que los pájaros nacen siendo pájaros, pero los humanos no nacen siendo científicos, deben aprender. Hay quien piensa que los niños son científicos natos. Nada más absurdo. Aristóteles, uno de los pensadores más profundos de la historia, dedicó un gran esfuerzo a reflexionar sobre cómo debía estudiarse el cosmos y, sin embargo, desde la perspectiva de la ciencia moderna debemos considerar su enorme contribución como un simple paso más. Si el pensamiento científico es intuitivo, ¿cómo es que este inmenso filósofo, profundamente preocupado por la cuestión de cómo hemos de estudiar el cosmos, no llegó a dar con las claves posteriores? El problema es que el pensamiento científico dista mucho de ser intuitivo. Decimos que la ciencia debe basarse en las evidencias, pero Galileo, a pesar de que sus sentidos le indicaban lo contrario, estaba seguro de que la Tierra se movía. A pesar de esto, el pensamiento científico no es esencialmente distinto del intuitivo, ambos se sustentan sobre la percepción y sobre los mismos tipos de inferencias elementales, la única diferencia es que el científico debe ser mucho más sistemático y crítico. El científico necesita reflexionar sobre cómo proceder en sus investigaciones y esto es en parte metodología científica y en parte filosofía de la ciencia. Einstein pensaba que era precisamente esa perspectiva filosófica la que distinguía al técnico del verdadero científico.13 Conocer el alcance y las limitaciones de nuestra aproximación al estudio del cosmos puede ayudarnos a hacer buena ciencia y, muy especialmente, nos ayuda a no caer en un exceso de confianza. Los científicos suelen aprender a hacer ciencia practicando junto a sus maestros. Aprendemos más junto a la máquina del café, conversando con nuestros maestros y compañeros, que en cursos formales y, al ser una gran parte de esta transmisión implícita, no es común que seamos capaces de explicar con precisión las reglas del juego. Nos parecemos al ciclista que sabe mantener el equilibrio, pero no es capaz de explicar cómo lo hace. Tal vez este proceso de aprendizaje se pueda mejorar haciendo más explícitos los modos de razonar, las asunciones filosóficas y las limitaciones que conllevan. Resulta curioso que intelectuales como Hawking, Tyson o Laurence Krauss, que se abstendrían de criticar áreas de la ciencia que desconocen, se atrevan a hacer afirmaciones tan equivocadas sobre un área de conocimiento, la filosofía de la ciencia, que, claramente, desconocen.14 Tal vez parte del problema radique en el problema de imagen que tiene la filosofía: son muchos los que piensan que los filósofos son una especie de gurús completamente alejados de la realidad15 y, además, es cierto que hay mucha filosofía absurda. Veremos, por ejemplo, que hay filósofos que han llegado a afirmar que la ciencia no es metodológicamente distinta del vudú. Sin embargo, sería un error muy serio creer que estas estupideces son compartidas por una parte significativa de los filósofos de la ciencia actuales. Incluso es cierto que entre los filósofos que se ocupan de otras áreas sí se pueden encontrar actitudes muy negativas frente a la actividad científica.16 Pero hemos de recordar que la filosofía es un área de conocimiento muy amplia, que abarca desde regiones cercanas a la literatura a disciplinas indistinguibles de la lógica y las matemáticas. Al primer estilo de hacer filosofía, al que practicaban Sartre, Camus o Derrida, se le suele llamar continental y al segundo, el ejercido por Russell, Carnap o Popper, se le denomina analítico. Ambas aproximaciones suelen estar asociadas a la reflexión sobre problemáticas muy distintas: es habitual que un filósofo continental estudie las consecuencias de la falta de sentido transcendente en lo humano, mientras que la epistemología es un tema que se presta más a un tratamiento analítico. Los filósofos de la ciencia suelen pertenecer a la corriente analítica y se caracterizan por razonar muy rigurosamente sobre temas que, frecuentemente, pueden parecer muy alejados de nuestra vida cotidiana. Además, suelen presentar sus conclusiones de un modo muy sobrio al que es difícil aproximarse, mientras que los filósofos continentales suelen escribir de forma más accesible sobre temas de interés social. Los filósofos analíticos llegan a tener preocupaciones que, a primera vista, pueden parecer muy extrañas. Bertrand Russell, uno de los fundadores de la aproximación analítica, se propuso en sus Principia Mathematica establecer unas bases lógicas sólidas para las matemáticas; estaba preocupado por la justificación lógica de que 1 más 1 fuesen 2. James Laydyman, uno de los filósofos de la ciencia contemporáneos más reputados, ha dedicado muchas páginas a evaluar si podemos considerar la existencia de los entes comunes, como los gatos, como suficientemente justificada. Estos asuntos más técnicos no suelen comentarse fuera de los círculos filosóficos profesionales, lo cual contribuye a que sean los filósofos continentales los más escuchados en los medios de comunicación generalistas, a pesar de que, en muchas ocasiones, a largo plazo, el precio del pan ha acabado dependiendo de esas complicadas discusiones técnicas. Es más sencillo discutir en la radio sobre el papel de la mujer en la sociedad que sobre las limitaciones de la justificación lógica de la aritmética. Incluso aunque aprender filosofía no tuviese ninguna otra utilidad, sólo el hecho de que nos sirve como escudo para defendernos de la gran cantidad de mala filosofía que puebla tanto la sociedad general como el mundo académico ya haría que mereciese la pena. A pesar de esto, sería injusto culpar exclusivamente a los continentales del problema de imagen que la filosofía tiene entre los científicos. Los propios filósofos de la ciencia también han sido responsables, sobre todo en los años 70 y 80, de este alejamiento. En la segunda mitad del siglo XX la filosofía de la ciencia sufrió una profunda crisis, que le ha permitido madurar y de la que los científicos tenemos mucho que aprender, pero que, por un tiempo, la llevó por caminos excesivamente críticos con el proceso científico. A principios del siglo XX, el positivismo lógico, la corriente mayoritaria en aquella época, consideraba a la ciencia como un ejemplo de pensamiento racional. Sin embargo, esta visión optimista fue severamente cuestionada en los años 50 y 60. Se concluyó que los resultados científicos dependen, en parte, de las dinámicas sociales internas de la comunidad científica y no sólo, como se había asumido hasta entonces, de las evidencias y la lógica. Esta es la época de los famosos paradigmas de Kuhn y del vudú. Algunos, en vez de limitarse a recomendar cautela a los científicos, concluyeron que la ciencia era una mera construcción social sin una relación especial con la realidad. Fueron este tipo de afirmaciones las que alejaron a los científicos, creando una ruptura que muchos, hoy en día, perciben como natural, pero que es muy reciente. En la generación anterior, Bohr y Einstein eran perfectamente conscientes de estar haciendo filosofía. Por fortuna, a pesar de lo que afirmasen los filósofos y sociólogos más enajenados, las manzanas siguieron cayendo con la misma aceleración y los aviones siguieron cruzando los océanos diariamente, no tuvimos que cambiarlos por alfombras mágicas. De modo que las posiciones filosóficas acabaron madurando y se llegó a un equilibrio entre el optimismo positivista y el pesimismo de algunos de los seguidores de Kuhn. Hoy en día, tengo la impresión de que somos los científicos los que más tenemos que aprender. Los filósofos de la ciencia con los que me he cruzado tienen un conocimiento profundo sobre el proceder científico y son conscientes de que hay problemas serios en las comunidades científicas debidos a las dinámicas sociales, mientras que los científicos con los que trabajo son, en muchos casos, ajenos a estos peligros y, en demasiados casos, se sienten tentados de maquillar sus conclusiones para hacerlas más atractivas y de aligerar las críticas para no buscarse enemigos entre los científicos más reconocidos; cayendo así en los comportamientos que criticaron los sociólogos y los filósofos en los 70 y 80. Dado que pienso tratar temas filosóficos relacionados con la ciencia, alguien podría pensar que también discutiré las evidentes implicaciones éticas de la ciencia y la tecnología, pero no lo haré. No es que piense que todas las aplicaciones del conocimiento sean positivas. Defender eso sería absurdo incluso aunque Hiroshima y Nagasaki no fuesen más que horrores de una distopia imaginada. El conocimiento tiene consecuencias, algunas positivas y otras negativas, algunas esperables y otras inesperadas y esto tiene claras implicaciones morales para los investigadores. Como nos recordaron los revolucionarios franceses y el tío de Spiderman: “Un gran poder conlleva una gran responsabilidad”17. Además, es necesario evaluar la moralidad, no sólo de las posibles consecuencias de las aplicaciones tecnológicas, sino de los propios métodos utilizados para obtener el conocimiento científico y tecnológico. A veces los científicos han hecho experimentos claramente inmorales, como los médicos de Alabama que engañaron a enfermos de sífilis diciéndoles que estaban siendo tratados cuando, en realidad, eran el grupo control sin tratamiento.18 Es necesario hacer una evaluación ética de las metodologías utilizadas en las investigaciones y para ello se han creado los mecanismos institucionales correspondientes. Sin embargo, yo no trataré estos temas, no porque carezcan de interés, sino porque me he centrado en aprender sobre los aspectos más relacionados con la epistemología, con la justificación del conocimiento, con la lógica y las evidencias, y los temas éticos constituyen un área suficientemente diferenciada y compleja como para merecer otras obras. Mi objetivo es hacer una introducción y, por lo tanto, no asumiré ningún conocimiento filosófico previo. Sin embargo, este ánimo introductorio no implica que vaya a simplificar demasiado los temas tratados. Mi intención es que introductorio no implique superficial. Siempre trataré de comenzar explicando las cuestiones básicas, pero a partir de ahí, poco a poco pretendo tratar los temas más complejos, por lo que no renunciaré a hacer un análisis profundo ni a utilizar terminología técnica. Además, conviene que tengáis en cuenta que es muy probable que algunos matices se me escapen, al fin y al cabo no soy un filósofo, sino un científico interesado por el tema. Para hacer este camino más sencillo pretendo aprovecharme del desarrollo histórico de las ideas. Las propuestas filosóficas actuales son fruto de un desarrollo que ha ido, paulatinamente, refinando las respuestas iniciales. Por lo tanto, una presentación cronológica puede aproximarnos paulatinamente a las matizadas posiciones actuales. Sin embargo, que se vaya a utilizar la historia con un ánimo pedagógico no implica que pretenda, en modo alguno, escribir una historia de la filosofía. Si bien es cierto que la historia del pensamiento, descrita a grandes rasgos, puede facilitar la comprensión, no es menos cierto, que si intentamos estudiarla con más profundidad, dada su complejidad, nos enredaremos con mil detalles que acabaron por no ser relevantes. La aproximación histórica será sólo un medio, un instrumento subordinado a la pedagogía.19 Además, aunque el hilo general siga un desarrollo aproximadamente temporal desde la antigüedad hasta la modernidad, la organización del texto será, principalmente, temática, por lo que iré saltando hacia adelante y hacia atrás en el tiempo. El texto estará compuesto por varias secciones que, tal vez, puedan interesar a distintos lectores en distinto grado y que pueden ser leídas independientemente. Aunque si se opta por saltarse alguna de ellas, es importante tener en cuenta que las secciones posteriores asumirán un conocimiento de las cuestiones básicas tratadas en las anteriores. Los capítulos incluidos en Antes del principio tratarán sobre el problema de cómo surge la capacidad de conocer, sobre las limitaciones del razonamiento humano y sobre la diferencia entre la ciencia y la tecnología. A continuación, en El triunfo de la razón, discutiremos qué es la filosofía, cuál es su relación con la ciencia y algunas cuestiones epistemológicas elementales como, por ejemplo, qué es el conocimiento. En Hechos, modernos y reaccionarios hablaremos sobre las características de la ciencia moderna y sobre las reacciones, tanto positivas como negativas, que suscitó su aparición en la sociedad. En La pérdida de la inocencia trataremos sobre las limitaciones de la aproximación científica. Espero que esta sección apacigüe un tanto el optimismo de los defensores más fervientes de la aproximación científica. Esta sería, además, la sección en la que, probablemente, comenzaría un libro sobre filosofía de la ciencia más habitual que asumiese un conocimiento previo sobre los fundamentos de la epistemología y del proceder científico. Por último, en Verdad y metafísica haremos una incursión en terrenos más metafísicos y en Bayesianismo en los avances más recientes en inferencia bayesiana. Cada capítulo termina con un breve resumen de las ideas que considero más relevante. Esto puede ser utilizado por los lectores para limitar su lectura a algún capítulo concreto. El libro termina con un resumen final que, espero, integre los distintos hilos en una visión conjunta. Cuentan que Odín tenía un hambre voraz de conocimiento y que estaba dispuesto a hacer grandes sacrificios para conseguirlo. En una ocasión se adentró en la guarida de Mímir el gigante protector de las fuentes de la sabiduría, situadas en las raíces de Yggdrasil, el árbol de la vida. Odín pidió beber de la fuente y Mímir le exigió un ojo a cambio, precio que Odín, siempre hambriento, estuvo dispuesto a pagar.20 Yo no tengo el conocimiento de un gigante mitológico, ni siquiera el de un experto y, aunque lo tuviese, no exigiría un ojo como pago. Pero no quiero engañar a nadie, aunque considero que el estudio de la obtención y la justificación del conocimiento son temas apasionantes y de gran relevancia social, aviso que pretendo dedicar bastantes líneas a evaluar si nuestras creencias relativas a la existencia de los gatos y de que sus piruetas están regidas por la fuerza de la gravedad están suficientemente justificadas. No será necesario pagar con un ojo, pero, tal vez, sí se requiera algo de atención y puede que un pequeño esfuerzo. "],["antes_del_principio_part.html", "Antes del principio", " Antes del principio "],["origen_evolucion_y_conocimiento.html", "1 Origen, evolución y conocimiento 1.1 Vida y propósito 1.2 Cristales, copia y evolución 1.3 La selección acumula información sobre el entorno 1.4 La evolución funciona a pesar de su ineficiencia 1.5 La experiencia es más eficiente 1.6 Evolución cultural 1.7 Metacognición: aprendiendo sobre aprender 1.8 Resumen", " 1 Origen, evolución y conocimiento En el principio no fue la palabra, durante eones no hubo ni palabras ni vida en el cosmos, tan sólo un desierto infinito. Y, por supuesto, sin seres mínimamente complejos, tampoco había ni conocedores ni conocimiento; para conocer se requiere un sujeto que posea unos mecanismos que le permitan generar, acumular y transmitir conocimiento. Del mismo modo que la vida surge a partir de la vida, tampoco hay generación espontánea en el conocimiento, no se puede empezar a conocer desde cero, se requieren unas bases mínimas sobre las que empezar a construir. Sin embargo, en este inmenso desierto regido por las simples leyes de la física y la química, tras miles de millones de años de esterilidad, y gracias a un proceso dolorosamente lento e ineficiente, terminó por surgir, al menos, un oasis; el cosmos alumbró vida y con ella las primeras formas de conocimiento. 1.1 Vida y propósito La vida es un fenómeno peculiar, medra en la fina línea que separa el orden del caos, una frontera caracterizada por una constante huida del equilibrio, y para conseguirlo necesita acumular conocimiento sobre la estructura del cosmos.21 Es común asociar la vida al equilibrio, pero es un error, lo que convierte a la vida en un fenómeno enigmático e interesante es, precisamente, su huida del equilibrio.22 Un sistema aislado que haya alcanzado el equilibrio permanecerá inmóvil e inerte para siempre, pero un ser vivo no se encuentra en equilibrio, actúa sobre su entorno para conseguir sobrevivir y cuando deja de tomar ese papel activo muere. Esta característica es tan esencial que los astrónomos consideran que la detección de una atmósfera alejada del equilibrio químico es una posible evidencia de vida. El equilibrio está relacionado con una magnitud física denominada entropía. La segunda ley de la termodinámica dicta que en un sistema aislado la entropía tenderá a aumentar hasta llegar al equilibrio, que se caracteriza por ser el estado de máxima entropía. Sin embargo, los seres vivos huyen de este estado de máxima entropía, de la muerte. La entropía se describió en el siglo XIX como una medida del trabajo que podía ser extraído de una fuente de energía. Hay energías de mejor y peor calidad, algunas permiten realizar más trabajo que otras. Por ejemplo, el carbón contiene energía química de buena calidad, de baja entropía, que nos permite mover una locomotora. Una vez la locomotora ha llegado a su destino, quemando el carbón, la cantidad de energía del sistema completo no ha variado, la energía se conserva. En este caso, la energía que contenía el carbón se ha convertido en calor. Lo que sí ha variado es que esta forma final que ha adoptado la energía, el calor dispersado en el ambiente, tiene una mayor entropía, es de menor calidad y no nos permite realizar trabajo. Los seres vivos debemos buscar fuentes de energía de buena calidad, es decir, de baja entropía, para poder realizar los trabajos necesarios para continuar viviendo. Un gato digiere alimentos que contienen energía química con baja entropía y, como la locomotora, realiza trabajo útil, se mueve, se reproduce y piensa, a costa de transformar esa energía química en calor, aumentando así la entropía. Sin embargo, aunque la termodinámica y la química de las locomotoras y los gatos sean muy similares, parece existir una diferencia fundamental entre ambos. El gato está animado, tiene un propósito: conseguir alimentos para mantenerse vivo, y sabe cómo aprovechar la estructura del rincón de universo que le rodea para conseguirlo. El gato interviene en el cosmos, no es un simple sujeto pasivo. La locomotora, en cambio, es un ser inerte y abandonada a su suerte llegará al equilibrio sin hacer nada por evitarlo. Esta es una diferencia fundamental entre los seres vivos y los inertes. No obstante, a pesar de la importancia de esta diferencia no encontraremos una sustancia vital, una energía propia exclusiva de los seres vivos que explique este comportamiento, la química y la termodinámica de ambos tipos de sistemas son muy similares. Para que el cosmos haya generado seres vivos con propósitos y con conocimiento para llevarlos a cabo se requieren dos elementos. En primer lugar, debe disponerse de una fuente de energía de alta calidad, en nuestro caso el Sol, mientras que el segundo ingrediente es un éxito reproductivo relacionado con algunas de las características heredadas. Es decir, se necesita selección natural. Los gatos, por ejemplo, cumplen estos requisitos, se reproducen con pequeñas modificaciones heredables y su éxito reproductivo depende de estas diferencias, por lo tanto, su especie evoluciona por selección. Esto hace que poco a poco vayan adaptándose al ambiente que ocupan, que su genoma acumule el conocimiento requerido para explorar el entorno más eficientemente. Tanto el propósito como el conocimiento pueden surgir gracias a este proceso sencillo, pero inexorable, que caracteriza a los sistemas que se reproducen, se copian, con eficacias dependientes de sus características heredables. 1.2 Cristales, copia y evolución Pero si los sistemas más sencillos capaces de reproducirse fuesen tan complejos como un gato, el cosmos no habría podido alumbrar vida alguna. Un gato es demasiado complejo, el salto desde la química más simple habría sido un abismo insalvable. Por fortuna, existen sistemas mucho más sencillos que también pueden reproducirse. Los cristales, no el vidrio, sino los verdaderos cristales, son estructuras altamente ordenadas. Son ejemplos clásicos de estructuras cristalinas, por ejemplo, los pequeños cubitos que forman la sal de mesa. Estos cubitos están compuestos por millones de átomos de cloro y sodio ordenados según un patrón fijo. Cada átomo de sodio está rodeado por 6 átomos de cloro y, a su vez, cada átomo de cloro está rodeado por 6 átomos de sodio. Esto da lugar a una estructura cristalina con una simetría cúbica en la que hay filas con millones de átomos de cloro y sodio alternados. Los cristales tienen simetrías equivalentes a las que se generan al cubrir con azulejos una superficie. Cada granito de sal es el resultado de esta ordenación y se formará siempre que tengamos una disolución acuosa con suficientes iones de sodio y cloro disueltos en ella. En principio, podría parecer que este proceso de cristalización tiene poco que ver con la reproducción de los seres vivos, pero en realidad son dos procesos químicamente muy similares. La maquinaria que encierra la información para crear un gato también es una especie de cristal, una estructura química ordenada,23 y la copia del material genético puede considerarse como una forma sofisticada de cristalización. El ácido desoxirribonucleico, el ADN, es una molécula, que, como los cristales de sal, está formado por unidades repetidas. En el caso del ADN las unidades, los nucleótidos, se repiten formando una estructura lineal en vez de una estructura tridimensional como la que hemos descrito para la sal de mesa, pero esta no es una diferencia esencial. Lo relevante es que en el ADN cada posición puede estar ocupada indistintamente por cuatro elementos, los cuatro nucleótidos: adenina (A), citosina (C), guanina (G) y timina (T). Cualquiera de ellos puede formar uno de los eslabones de la cadena de ADN sin que se altere su estructura. Sin embargo, la sal común no es tan versátil, el patrón debe ser siempre el mismo: cloro, sodio, cloro, sodio, cloro, sodio, etcétera. La sal es la esencia del aburrimiento químico, mientras que el ADN es un cristal aperiódico de secuencia variable. Erwin Schrödinger, basándose en las capacidades de transmisión de la información genética de los seres vivos, antes de que se conociese la estructura del ADN, hizo esta predicción extraordinariamente lúcida: el material genético debía ser un cristal aperiódico,24 y acertó. El ADN tiene una misma estructura molecular, la doble cadena, independientemente de su secuencia de nucleótidos. Esto es algo que la sal común no puede hacer y es, precisamente, en esta diferencia donde radica su capacidad de almacenar información. Sin embargo, este es sólo el primer truco químico, el segundo es el apareamiento de las bases, una característica que permite que el material genético se copie y que los seres vivos se reproduzcan. En 1952 el químico Erwin Chargaff observó una relación entre las cantidades de A, C, T y G presentes en el ADN de la mayoría de los seres vivos: normalmente, hay tantas adeninas como timinas y tantas citosinas como guaninas. Ésta fue la pista fundamental que permitió a Watson y Crick proponer que la adenina debía aparearse siempre con una timina y la citosina con una guanina. Es así como se compone la doble cadena. Cada una de las dos cadenas es un cristal aperiódico y debido al apareamiento de A con T y C con G la información de una sola de las cadenas es suficiente para generar la otra. Es así como se copia la información genética. Aunque es cierto que en las células actuales el proceso de copia del ADN es muy complejo, en esencia, no es muy diferente de una cristalización y lo fundamental es que, gracias a los cristales aperiódicos, no necesitamos más que química para explicar el almacenamiento y la copia de la información genética. 1.3 La selección acumula información sobre el entorno Sin embargo, hay algo que la simple química no parece capaz de explicar. En el genoma del gato, en su secuencia de nucleótidos, está contenida la información sobre cómo construir sus sensibles oídos y sus afiladas garras y sobre cómo interaccionar con el entorno para conseguir huir del equilibrio químico, pero ¿de dónde surgen estas capacidades? Es aquí donde entra en escena la evolución, la responsable de acumular ese conocimiento. Existen moléculas de ADN con distintas secuencias de nucleótidos. Esta diversidad puede surgir, por ejemplo, por errores en la copia del ADN. El resultado es que en una población de individuos siempre existirá una cierta diversidad genética generada por esos errores. Estas mutaciones, estos cambios, no ocurren porque sean ventajosos, porque favorezcan el éxito reproductivo, sino que se dan al azar. De hecho, en muchos casos, no afectarán a ninguna función y, la mayoría de las veces, cuando lo hagan no incrementarán las posibilidades de reproducción del individuo, sino que las perjudicarán. Pero que las mutaciones sean aleatorias no implica que la evolución lo sea, ya que la selección natural no lo es. La variación genética es sólo el material de partida. No todos los organismos se reproducen con la misma eficacia y el éxito reproductivo de un individuo depende, al menos en parte, de la secuencia de sus genes. Con el tiempo, el material genético que se reproduce con mayor dificultad acabará por desaparecer en favor del que se reproduce más eficientemente. Lo que funciona se queda, se selecciona, y lo que falla se desecha. Esta es la esencia del constraste de hipótesis biológico. El material de partida, las mutaciones, es informe y caótico, pero el resultado no lo es puesto que se elimina lo que no encaja. En esto consiste la selección, en recordar lo que funciona y olvidar lo deletéreo. Esta es la clave de la creación del propósito y de la acumulación de conocimiento en los procesos biológicos. Imaginemos que una mutación hace que una molécula se reproduzca más fácilmente porque gracias a ella captura más fácilmente los nucleótidos que hay dispersos en el ambiente. En este caso, podríamos decir que la molécula ha aprendido a capturar mejor los nucleótidos para satisfacer su propósito de copia. De hecho, esta es la fuente original de propósito en el cosmos y para satisfacer ese propósito el material genético ha acabado codificando habilidades que le permiten explotar aspectos estables, regularidades, del cosmos. La información es la clave y la selección natural es el mecanismo que la va acumulando a lo largo de una serie ininterrumpida de generaciones que se remonta al principio de la vida misma. Esta es la información con la que se construyen los mecanismos que rigen el desarrollo de criaturas tan intrincadas como un colibrí o un gato, la información que les permite responder y explotar el medio que habitan. Cada variación exitosa encierra un pequeño detalle sobre la estructura del entorno que rodea al ser vivo, de modo que, al ir acumulándolas, la información genética, de algún modo, va capturando distintas regularidades de ese entorno. Esto es lo que permite al colibrí y al gato aprovecharse del entorno para reproducirse más eficientemente. Una característica presente en cualquier conocimiento relativo al universo, no sólo el generado por la selección natural, es que siempre involucra una correlación entre dos sistemas físicos, uno el conocido y otro el conocedor. Por ejemplo, nuestro cerebro es un sistema físico que conoce y lo hace porque refleja una parte del entorno que le rodea, del objeto conocido. Cuando veo a mi gata sobre la mesa lo que está sucediendo es que dentro de mi cerebro se ha formado una percepción que refleja una realidad externa. Además, el modelo creado en mi mente, al reflejar aspectos del mundo externo, puede utilizarse para intervenir sobre él con el objetivo de obtener un resultado. Por ejemplo, puedo alargar la mano y acariciar el gato. Llegados a este punto, merece la pena hacer un aviso. Los filósofos no suelen hablar del conocimiento en estos términos. La definición clásica propone que el conocimiento es una creencia verdadera y justificada. Es decir, es algo que creemos, que se corresponde con lo que existe realmente en el universo y que somos capaces de justificar mediante evidencias y lógica. Según la definición clásica sé que las manzanas caen con un movimiento acelerado porque es algo que creo y porque puedo mostrar evidencias experimentales de que efectivamente las manzanas que hay fuera de mi cabeza se comportan de ese modo. Esta es una definición que, aunque es muy razonable, excluye el conocimiento implícito, por ejemplo el conocimiento que permite actuar a los animales; mi gata, según la definición clásica, aunque puede saltar para subir a la mesa, no sabría nada sobre la gravedad porque no es capaz de hacer explícitas sus habilidades. Además, en la definición clásica no se hace énfasis en que el sistema que tiene la creencia sea físico o no y, aunque podríamos relacionar la correlación entre el sistema conocedor y el conocido con las nociones de correspondencia y verdad y la acción exitosa con la justificación, la definición clásica, como veremos, requiere que la creencia sea explícita. El genoma del gato no es el primer ejemplo que suele acudir a la cabeza de un epistemólogo cuando piensa en conocimiento. El genoma puede dirigir la construcción de un oído excelente y de unas garras certeras, pero no puede explicarnos cómo lo hace. Ni tan siquiera los genetistas que llevan décadas estudiándolo son capaces de darnos los detalles del proceso. El genoma no se puede leer como un libro de instrucciones o como los planos de un arquitecto. La mayoría de autores prefiere que la definición de conocimiento marque las diferencias entre las capacidades implícitas que poseen los gatos o nuestros sistemas perceptivos y las creencias explícitas de nuestros sistemas cognitivos y reservan el término “conocimiento” sólo para lo explícito. Esta posición me parece muy defendible, aunque, en el fondo, estaríamos discutiendo simplemente sobre qué etiquetas poner a unos conceptos y otros. Tal vez, podría reservarse el término conocimiento para lo explícito y saberes para lo implícito. En cualquier caso, el proceso de acumulación de conocimiento por selección no sólo es válido para la evolución biológica, también puede describir, hasta cierto punto, el desarrollo científico. La clave del progreso científico radica en disponer de un proceso de evaluación de hipótesis que nos permita separar el grano de la paja. Cuando Kekulé, uno de los grandes químicos del XIX, dijo haber soñado la estructura del benceno a nadie le preocupó excesivamente que afirmase haber utilizado este extravagante método de generación de hipótesis, porque lo más relevante para el avance científico es que se disponga de mecanismos de justificación de hipótesis. Lo fundamental es que la estructura de Kekulé describía las evidencias experimentales adecuadamente, que se correspondía con la realidad, que se hubiese generado en un sueño era secundario. 1.4 La evolución funciona a pesar de su ineficiencia El mecanismo que permite a la evolución acumular conocimiento es sencillo, variación heredable y selección. El truco consiste en recordar sólo lo que ha funcionado en el pasado, de este modo consigue transformar el ruido generado por la mutación aleatoria en señal.25 Este proceso genera diseño, pero lo hace de un modo muy distinto al que utilizaría un diseñador. Mientras un ingeniero predice cómo funcionarán distintas ideas alternativas en el futuro, la selección se limita a volver a aplicar lo que funcionó en el pasado.26 Por ambos mecanismos pueden generarse sistemas capaces de cumplir una función, pero en el caso de la evolución, basada en la variación aleatoria, en el ruido, el proceso es muy ineficiente y requiere mucho tiempo. Por fortuna, si algo le sobra al cosmos es tiempo, el universo no es impaciente. Sin embargo, en el caso de la ciencia, si queremos que avance con eficiencia, deberemos preocuparnos por tener un mecanismo de generación de hipótesis más eficaz que las ensoñaciones de Kekulé. El genoma del gato se escribió solo, a base de acumular errores, que, de vez en cuando, producían mejoras en las opciones que tenían los antepasados de los gatos actuales, pero la inmensa mayoría de las secuencias genéticas que se probaron desaparecieron, sólo unas pocas, muy pocas, han llegado a nuestros días. La evolución biológica no funciona porque sea inteligente, sino más bien al contrario, funciona a pesar de estar basada en un mecanismo de generación de la variación, la mutación, absolutamente ineficiente, absurdo y cruel.27 Es común pensar que los ecosistemas estables están caracterizados por una relación mutuamente beneficiosa entre la Tierra y sus habitantes que permite que las especies puedan sobrevivir y reproducirse. En una encuesta a estudiantes de ecología sólo un tercio fue capaz de reconocer la terrible verdad: la mayor parte de los seres vivos mueren sin descendencia.28 En este, como en muchos otros casos, quienes mejor describen la realidad son los periódicos satíricos: The Onion (la cebolla) publicó un artículo explicando que el grotesco asesino, la selección natural, se había cebado con los más jóvenes y los más débiles, el artículo se titulaba “La selección natural mata, en su día más sangriento, 38 cuatrillones de organismos.”29 Mi tesis doctoral la hice estudiando un gen, la frataxina, que al estropearse produce una enfermedad devastadora, la ataxia de Friedreich. La proteína codificada por el gen tiene un papel fundamental en la célula y cuando no puede producirse el resultado es una debilidad muscular extrema que suele terminar en una muerte prematura. Estos son los efectos típicos de generar mutaciones al azar: el sufrimiento y la muerte. El sistema, dado el tiempo suficiente, termina por generar conocimiento, pero lo hace a costa de los individuos. Este gen, la frataxina, es muy antiguo, lo compartimos con otras muchas formas de vida, que incluyen no sólo a otros animales sino incluso a las bacterias. Si comparamos las secuencias del gen en humanos y en bacterias encontraremos regiones que no han variado en los últimos dos mil millones de años. Esto no se debe a que no hayan aparecido mutaciones en estas regiones durante esta inmensidad de tiempo, sino que todos y cada uno de los infortunados portadores de esas mutaciones pagaron el precio. Durante dos mil millones de años cada humano, cada gato, cada hongo, cada bacteria que tuvo la desgracia de tener una mutación equivocada en las regiones clave de ese gen sufrió el mismo destino que todavía hoy pagan los niños afectados. La selección natural es inmisericorde, es capaz de acumular diseño, pero su crueldad es inabarcable: más de dos mil millones de años de muertes para mantener una proteína implicada en el control de la concentración del hierro en la célula. Un diseñador con una inteligencia mínima podría habernos ahorrado una cantidad inmensa de sufrimiento. Daniel Dennett, uno de los filósofos actuales más conocidos, en La peligrosa idea de Darwin, una obra dedicada a analizar las implicaciones filosóficas de la evolución, propuso una clasificación de los seres vivos en función de su tipo de aprendizaje30 31. En esta clasificación definió a los seres darwinianos como aquellos que nacen con las habilidades que la selección natural ha acumulado en sus genes, pero son incapaces de aprender nada más durante sus vidas.32 Un virus es un ejemplo de ser darwiniano puro. Todo el conocimiento que alberga sobre sus huéspedes ha sido acumulado por la selección. Como acabamos de comentar, la limitación de este tipo de aprendizaje radica en su lentitud. El genoma acumula conocimiento, pero lo hace a una velocidad glacial. Un individuo concreto tendrá una estrategia particular para resolver un problema, la que le dicte su genética, pero si esa estrategia falla, continuará dándose cabezazos contra la pared hasta el final de los tiempos sin que se plantee hacer las cosas de otro modo. 1.5 La experiencia es más eficiente Dennett propone en su clasificación un segundo tipo de seres, los skinnerianos. Estos son mucho más versátiles puesto que nacen con una habilidad muy especial, son capaces de ajustar su comportamiento en función de la experiencia acumulada a lo largo de sus vidas.33 Se diferencian de los darwinianos en que, cuando se enfrenten a una situación por segunda vez, tienen en cuenta el resultado de sus acciones en el pasado. Los skinnerianos disponen de un repertorio de posibles respuestas ante un problema y de entre éstas seleccionan una. Si la respuesta funciona tenderán a repetirla, si falla procurarán evitarla. Este aprendizaje les permite extraer información del entorno para mejorar su eficacia durante el tiempo que duran sus vidas. La mayor parte de los seres vivos del planeta, incluso algunos de apariencia muy humilde, son skinnerianos. La liebre de mar, Aplysia, es un molusco que se utiliza como modelo en el estudio del aprendizaje. Aplysia no se caracteriza por su extraordinaria inteligencia, sino por todo lo contrario, tiene un sistema neuronal muy limitado. Pero a pesar de su simplicidad es capaz de aprender. La novedad en Aplysia, y en el resto de seres skinnerianos, es que la selección natural ha creado en estos organismos un mecanismo capaz de aprender de sus aciertos y de sus errores algo que los darwinianos no podían hacer. Es decir, el material genético de Aplysia no sólo posee información sobre cómo es el mundo, sino que, además, incluye información sobre cómo aprender sobre el mundo. Antes de continuar me gustaría aclarar un detalle de la clasificación propuesta por Dennett que podría inducir a confusión, las distintas categorías no son excluyentes. No debe pensarse que los darwinianos aprenden nuevas habilidades mediante selección natural, pero el resto no, esto sería un error. Los skinnerianos, así como todos los que describiremos a continuación, también evolucionan por selección natural. Tampoco debemos pensar que la ventaja conferida por la versatilidad del comportamiento de los seres skinnerianos hace que todos los seres darwinanos queden obsoletos. Esa versatilidad tiene un coste. Aplysia está obligada a construir durante su desarrollo, y a mantener a lo largo de su vida, un mecanismo de aprendizaje y esto conlleva un gasto de energía. El precio a pagar no es insignificante y esta complejidad sólo puede permitirse si los beneficios son suficientes. En un mundo con recursos limitados una estrategia más frugal también puede ser ventajosa. Aplysia ha elegido, o mejor dicho, la selección natural ha elegido por ella, invertir parte de los recursos disponibles en crear un sistema neuronal capaz de aprender. Esos recursos ya no podrán invertirse en la reproducción y mientras que Aplysia se lo piensa los darwinianos se multiplican. Desde nuestra perspectiva cefalocéntrica podría parecernos que la evolución debería apostar siempre por la inteligencia, pero eso no es así. Ten muchos hijos y muere idiota es una alternativa válida en muchos nichos ecológicos. De hecho, la inmensa mayoría de seres vivos del planeta son unicelulares y, por lo tanto, carecen de sistema nervioso. La capacidad de aprendizaje de los skinnerianos es de una gran utilidad y casi todos los animales la utilizamos, pero no es una panacea. Imaginemos que un animal skinneriano se enfrenta al reto de cruzar una carretera. La clave está en cómo decidir cuándo cruzar con seguridad. La estrategia del skinneriano es cruzar varias veces y aprender de la experiencia. No es difícil imaginar que el encuentro con el primer camión limitará severamente el éxito de esta estrategia. El precio de una equivocación puede ser fatal. Sin embargo, los pollos hacen algo mucho más sofisticado: miran antes de cruzar. El pollo crea dentro de su cabeza un modelo de la carretera y del camión y puede representar en este teatro mental el resultado de sus acciones antes de llevarlas a cabo. A estas criaturas Dennett las denomina popperianas porque son capaces de pretestear sus comportamientos pudiendo hacer que “mueran sus hipótesis en vez de ellos.”34 El skinneriano hace pruebas y pregunta al universo por el resultado, el popperiano puede preguntar por el resultado al mapa del universo que tiene dentro de su cabeza. El filósofo Willard Van Orman Quine también propuso que la evolución debe de haber hecho que nuestros sistemas cognitivos reflejen la estructura del mundo externo porque creer en algo cierto confiere un mayor éxito reproductivo que creer en algo falso.35 Pero, de nuevo, debemos tener en cuenta los costes asociados. Estos mapas, estas representaciones, requieren una gran capacidad cognitiva. Los informáticos que trabajan en inteligencia artificial han aprendido que diseñar inteligencias capaces de cruzar carreteras es mucho más complicado que hacer ordenadores que ganen al ajedrez. En el caso de sistemas neuronales algo más complejos es aún más fácil apreciar la magnitud de estos costes. El cerebro humano requiere el 20% de la energía que consumimos, a pesar de que representa sólo un 2% de nuestra masa.36 Por otro lado, no debemos asumir que los modelos mentales del popperiano han de ser completamente fieles en todos sus detalles, de hecho, tal cosa es imposible, tan solo deben parecerse lo suficiente a la realidad como para que los ensayos que se lleven a cabo en ellos tiendan a dar unos resultados lo suficientemente buenos como para compensar el coste de haberlos construido. Los sistemas de creación de representaciones del entorno estarán adaptados a nuestras necesidades y limitados por su coste. El pollo no necesita saber cómo funciona el motor del coche, sólo requiere saber que hay un objeto de un cierto tamaño que viene a una cierta velocidad e imaginar el resultado de cruzarse en su camino. Por otro lado, los seres humanos no vemos en infrarrojo o en ultravioleta ni detectamos átomos. Si un sistema es demasiado costoso comparado con el beneficio obtenido la selección lo descartará. La selección no favorece la aparición de seres perfectos, sino de seres capaces de sobrevivir y, además, dado que la perfección es demasiado cara acabamos obteniendo seres que son un poco mejores que sus vecinos, pero no mucho más. Como comentaremos al hablar sobre ciencia moderna, la ciencia, en muchas ocasiones procede de un modo análogo, crea modelos simplificados del mundo externo. Por ejemplo, Galileo nos pidió que al evaluar su física olvidásemos el rozamiento. A este camino lo denominaremos aproximación de la vaca esférica. Por último, Dennett propone incluir a los seres humanos en una nueva categoría, la de los seres gregorianos. Además de aprender de la experiencia somos capaces de hacer algo muy poderoso, transmitir lo que hemos aprendido. Los pollos y los gatos aprenden durante sus vidas, pero cuando mueren la siguiente generación tiene que volver a empezar, su conocimiento no se acumula.37 Cada pollo debe aprender las mismas cosas por sí mismo cometiendo los mismos errores que otros pollos han cometido en el pasado. Aprender es caro y aprovechar la experiencia de los demás puede ahorrarnos muchos disgustos. Disponer del conocimiento acumulado por los que nos precedieron es un modo muy económico de obtener conocimiento, por eso tenemos escuelas. El único ejemplo de organismos fuertemente gregorianos que conocemos en el universo somos nosotros, los seres humanos, y la herramienta clave es el lenguaje. El lenguaje nos permite transmitir y reutilizar el conocimiento. Además, los seres humanos no sólo utilizamos el lenguaje, sino que lo hacemos con fruición. El documentalista David Attenborough nos describió como comunicadores compulsivos. Los seres humanos adoramos las palabras, las historias y los cuentos. Si quieres enganchar a un gato dale de comer, si quieres que un humano te ame: cuéntale cuentos. Nuestra forma de entender el mundo y de transmitir ese entendimiento está profundamente entrelazada con las historias que nos hemos venido contando desde que, durante las largas noches, nos acurrucábamos con nuestro clan junto a la hoguera para guarnecernos del frío. Además, a lo largo del tiempo, hemos creado tecnologías que nos permiten compartir nuestras ideas cada vez con más individuos y esto ha tenido una gran repercusión, tanto en la cantidad de información disponible como en la estructura de nuestras sociedades. La escritura nació junto a la civilización. La civilización es impensable sin letras y números. Más tarde, la invención de la imprenta de Gutenberg se asoció a la transición de la Edad Media a la Moderna y sin la participación de los medios de comunicación masivos, la radio y la televisión, sería difícil entender el siglo XX, del mismo modo que el XXI no puede comprenderse sin la irrupción de internet. 1.6 Evolución cultural La comunicación cambia radicalmente las reglas del juego, el lenguaje no es sólo una herramienta poderosa, crea un nuevo territorio en el que aparecen nuevos fenómenos. Richard Dawkins en El gen egoísta introdujo el concepto de meme: las ideas se copian de cerebro en cerebro. Estas ideas pueden surgir por una diversidad de mecanismos: pueden aparecer por errores en la transmisión, como en el juego infantil del teléfono loco, por modificación deliberada, como la que hace un ingeniero al cambiar un diseño, o por la creación de una mentira interesada. Para un ser social las mentiras son un arma más. En cualquier caso, tenemos variación heredable, ideas que se copian de mente en mente, y tasas de transmisión diferenciales, los ingredientes básicos de los procesos evolutivos. Las tecnologías, por ejemplo la forja de los metales, han evolucionado. Solemos pensar en la tecnología en función de sus manifestaciones materiales, por ejemplo, una espada de acero es un objeto tecnológico, pero una tecnología es, ante todo, un conjunto de ideas sobre cómo modificar el mundo material o social. Estas ideas a medida que van siendo transmitidas de mente en mente pueden ir acumulando cambios seleccionables. Un herrero transmite su conocimiento a su aprendiz y éste, a su vez, lo transmitirá a su aprendiz cuando, con el tiempo, se convierta en maestro. Pero puede que antes de hacerlo, durante su largo oficio, haga algún pequeño cambio, un cambio que en el futuro podrá tener éxito o no. Para que exista selección lo único que se requiere es reproducción diferencial entre las distintas versiones y ésta puede darse sin que las modificaciones seleccionadas tengan utilidad alguna para los humanos que las transmiten, puede que algunas historias se transmitan mejor que otras, simplemente, por ser más llamativas o más memorables. En este caso nuestras mentes pasan a ser el universo en el que medrarán unas ideas u otras. Dennett ha propuesto que las religiones evolucionan y que las ideas que las forman pueden seleccionarse incluso aunque no sean beneficiosas para los seres humanos, tan sólo deben estar especialmente bien adaptadas a transmitirse entre las mentes que las albergan.38 Sin embargo, por muy relevante que sea el parecido entre la evolución de los memes y la de los genes no debemos forzar la analogía y concluir que el cambio cultural es idéntico al biológico. Nuestros cerebros pueden modificar las ideas deliberadamente. Pueden, además, con mucha facilidad, mezclar ideas. Hace 35.000 años en el valle del río Lone en Alemania alguien unió las ideas de humano y de león y esculpió un humano con cabeza de león.39 El nacimiento de esta idea no se lo debemos a mutaciones aleatorias, sino a la capacidad que tiene nuestra mente de jugar con las representaciones que alberga sobre el mundo. Al parecer hace 35.000 años ya éramos capaces de jugar con el pensamiento abstracto. Sin embargo, aunque la creación de esta idea es bastante diferente del proceso evolutivo que hemos descrito, su supervivencia probablemente sí se la debemos a un proceso de selección. Al escultor la fusión de lo humano y de lo animal debió de parecerle lo bastante atractiva como para dedicarle el gran esfuerzo que supuso esculpirla en marfil con las limitadas herramientas disponibles en el paleolítico. Mucho tiempo después seguimos haciendo lo mismo, este texto que estoy escribiendo es el resultado de fusionar ideas provenientes de cientos de pensadores. 1.7 Metacognición: aprendiendo sobre aprender Finalmente, Dennett propuso un último tipo de seres, las criaturas científicas. Estos organismos, a diferencia de los gregorianos, pueden reflexionar sobre los propios métodos de aprendizaje y esto les permite crear nuevos, sofisticados y sistemáticos métodos de adquisición de conocimiento. No se trata simplemente de acumular ideas, sino de aprender a evaluar los métodos de creación de estas ideas en función de su éxito. Además, estos seres pueden aplicar estos métodos sistemáticamente creando de este modo poderosas herramientas lógicas, matemáticas y observacionales. Sin embargo, estas capacidades no son innatas, nacemos gregorianos, pero sólo con esfuerzo podemos llegar a convertirnos en científicos. Mientras no consigamos grabarlas en nuestro genoma, cada generación estará obligada a aprender de nuevo estas metodologías, estas formas de razonar. Los mecanismos cognitivos que operan por defecto en nuestra mente nos definen como meros comunicadores compulsivos susceptibles de caer bajo el influjo de ideas que no han sido cuestionadas, pero con esfuerzo podemos llegar a razonar sistemáticamente tomando el control de qué ideas merecen ser tomadas en serio y cuáles deben ser desechadas. Para conseguirlo debemos adoptar y, si es posible mejorar, los métodos que durante generaciones los pensadores anteriores han ido puliendo, aquellos que han demostrado ser más eficientes a la hora de crear conocimiento sobre el mundo. Es este esfuerzo el que hace posible que un mono surgido hace apenas 200 000 años en la sabana, un instante para la evolución, sea capaz de soñar con el cosmos y es un esfuerzo que compartimos con una inmensa cadena de pensadores que nos une a los burócratas sumerios que inventaron la escritura, a Tales, a Aristóteles y Galileo. 1.8 Resumen Tanto la vida como el conocimiento comparten una aparente paradoja: necesitan de una semilla. ¿Cómo es posible entonces comenzar el proceso de generación de conocimiento o de vida? La respuesta es la selección, la evolución por medio de la selección natural es capaz de crear, partiendo de sistemas no biológicos, organismos capaces de disponer de suficiente información sobre el mundo como para poder explotarlo con éxito. La selección incorpora en el genoma de los organismos, aunque sea de un modo implícito, información sobre la estructura del mundo externo y esto le ha permitido, incluso, crear no sólo los primeros saberes, sino los primeros mecanismos de aprendizaje. La selección no requiere de ninguna inteligencia, funciona, simplemente, porque el mundo externo elige aquellos organismos que se desenvuelven mejor. Si existe una forma de comprobar distintos candidatos a conocimiento podremos aprender. Como veremos, los filósofos de la ciencia distinguen entre descubrimiento y justificación. En la evolución biológica el descubrimiento es azaroso, pero la justificación de ese conocimiento es implacable, o funciona y se conserva o no funciona y se elimina. La limitación de este mecanismo de acumulación de conocimiento reside en su ineficiencia, pero la propia evolución implementó una alternativa, organismos que podían aprender, adaptar su comportamiento al entorno, durante el corto periodo de sus vidas, e incluso dio con seres aún más eficientes aún, capaces de aprender utilizando modelos mentales del mundo que les rodeaba y de transmitir lo aprendido. "],["evolucion_tecnologia_y_civilizacion.html", "2 Evolución, tecnología y civilización 2.1 Hijos de Prometeo 2.2 Semilla, río, imperio 2.3 Carne y harina 2.4 Genes domésticos 2.5 Metal civilizado 2.6 Burócratas civilizados 2.7 Reyes, ríos y mes 2.8 No era ciencia 2.9 Evolución cultural 2.10 Del barro al scriptorium 2.11 Espacios evolutivos 2.12 No tengas compasión, busca la realidad 2.13 Resumen", " 2 Evolución, tecnología y civilización 2.1 Hijos de Prometeo Somos hijos de Prometeo, sin tecnología no seríamos. El reconocimiento de nuestra dependencia tecnológica viene de lejos; en la academia de Platón había un altar dedicado a Prometeo y, mucho antes aún, los sumerios, los fundadores de la primera civilización, asumieron que sin estos conocimientos el progreso no era posible. Evidentemente, por tecnología, en este caso, no estoy refiriéndome sólo al último teléfono, en Eridú, la primera ciudad, no había cobertura. Son tecnología el conjunto de conocimientos que nos permiten manipular el entorno que nos rodea. Este es, además, el aspecto clave que diferencia a la ciencia de la tecnología: mientras que el objetivo de la ciencia es comprender el mundo externo, el de la tecnología es modificarlo. La tecnología manipula, la ciencia comprende. Según la Biblia Abel era pastor y Caín agricultor, pero esto no es cierto. Las invenciones del cultivo y la ganadería son relativamente recientes, durante la mayor parte de la historia, los seres humanos, como los otros grandes primates, no cultivaban ni pastoreaban, sino que eran cazadores-recolectores.40 Los cazadores-recolectores tenían acceso a ecosistemas con una productividad de alimentos que, comparada con la posterior riqueza agrícola, era bastante baja. Esta limitada disponibilidad de comida hacía que sus densidades de población fuesen modestas y que, en la mayor parte de los casos, viviesen una vida nómada en perpetua persecución del sustento.41 Esto plantea una cuestión, ¿cómo pudieron desarrollar las culturas antiguas las tecnologías que requerían si no disponían de conocimiento científico ni de la capacidad de generar conocimiento sistemático de ningún tipo? 2.2 Semilla, río, imperio Hace unos 15 000 años, el largo invierno que había padecido el planeta se tomó un descanso, el clima cambió y entramos en la dilatada primavera que hemos disfrutado desde entonces. Estas condiciones climáticas más suaves posibilitaron la práctica de la agricultura y algunos grupos de cazadores-recolectores comenzaron una transición gradual hacia un nuevo modo de vida, el neolítico.42 Este cambio ocurrió independientemente en distintas culturas localizadas en diferentes regiones del Oriente próximo, la India, África, Asia y América y en cada una de ellas tuvo lugar en tiempos muy distintos que abarcan, principalmente, desde el 10.000 a. C. al 3.000 a. C..43 El ejemplo más antiguo se encuentra en el llamado creciente fértil, las estribaciones de los montes que rodean Mesopotamia.44 Es allí, a orillas del Éufrates, cerca de la actual Alepo, donde se encuentra el yacimiento arqueológico neolítico más antiguo conocido, Abu Hureyra.45 Abu Hureyra se fundó hace unos 13 000 años, estuvo habitada durante 2500 y su población llegó a ser de unos 6000 habitantes. Fueron estas gentes neolíticas las que dieron el primer paso hacia la modernidad, realizando un cambio que diferenció su modo de vida del de los cazadores-recolectores que les habían precedido. En los poblados neolíticos, como en nuestros pueblos actuales, vivían en casas, disponían de utensilios de barro cocido, cultivaban y pastoreaban.46 Sin embargo, no hemos de pensar que esta profunda transformación fue instantánea; requirió un largo periodo. Además, los nuevos granjeros no abandonaron inmediatamente la caza y la recolección de las especies silvestres, sino que la simultanearon con el cultivo durante milenios.47 La abundancia de recursos generada por el cultivo y la ganadería no sólo favoreció el asentamiento de las poblaciones, sino que permitió que su tamaño aumentase paulatinamente. Mientras que al principio eran pequeños poblados con unas docenas de casas, tres milenios después se habían convertido en incipientes ciudades,48 que poco a poco continuaron creciendo hasta levantar grandes palacios y templos.49 Esta nueva revolución, la urbana, comenzó alrededor de 3500 a. C. y no lo hizo en las fértiles faldas de las montañas que habían cultivado los primeros pueblos neolíticos, sino a sus pies, en el corazón de Mesopotamia, en la agostada llanura aluvial dominada por el Tigris y el Éufrates. En paralelo, aunque algo más tarde, esta transición hacia la ciudad y la civilización ocurrió también, independientemente, en al menos otros dos lugares: China (1800 a. C.) y Mesoamérica (300 a. C.). Las ciudades se diferencian de los pueblos por tener una mayor densidad de población y, por lo tanto, requieren de más recursos. Su aparición en estos lugares y periodos concretos no fue casual, sino que fue propiciada por una serie de mejoras agrícolas que se habían ido acumulando desde el inicio del neolítico. A lo largo de los milenios la agricultura de subsistencia inicial se había ido transformando en una producción más intensiva, en la que el arado y el buey habían sustituido a la azada neolítica y los valles habían ido acumulando infraestructuras hidrológicas que permitían regar grandes y productivas extensiones.50 Esta asociación entre civilización, llanuras aluviales y regadío fue común en las civilizaciones antiguas de Mesopotamia, China, Egipto e India. No es casual que los antiguos egipcios llamasen a su país Kemet, la tierra negra, ya que eran conscientes de que debían su sustento al oscuro limo del Nilo que fertilizaba sus campos año tras año.51 Aunque, dado que a los jeroglíficos con los que describían su reino, a las sílabas Kemet, que aparecían en sus logogramas, solían añadir las correspondientes a ciudad o canal de riego, tal vez, unas traducciones más completas pudiesen ser La civilización de la tierra negra o El regadío de la tierra negra. El aumento de los recursos no sólo afectó a la densidad de población, sino también, y muy especialmente, a la estructura social. Los grupos de cazadores-recolectores eran bastante igualitarios, había líderes, pero no alcaldes o reyes.52 La riqueza acumulada no era mucha, los recursos eran limitados y, además, al ser nómadas, cualquier patrimonio debía ser acarreado de un lugar para otro, lo cual limitaba la acumulación de bienes y las diferencias sociales. Sin embargo, una vez que se empezó a cultivar y las tribus se establecieron, las nuevas estructuras sociales representaron un cambio profundo. En los asentamientos estables sí podían acumularse objetos y excedentes agrícolas y, además, los agricultores pasaron a estar mucho más interesados en la propiedad de la tierra, pues de poco sirve sembrar y atender un campo si no vas a disfrutar la propiedad de su fruto. Estos cambios, junto a las crecientes densidades de población, impulsaron la aparición de nuevas formas de gobierno. Inicialmente, las bandas de cazadores-recolectores se transformaron en tribus compuestas por varios clanes familiares,53 que poco a poco fueron sustituyéndose por jefaturas en las que un jefe gobernaba entre 5000 y 20 000 personas.54 En las jefaturas la estructura social era mucho más rígida que la de las primeras tribus, en ellas cada miembro tenía un lugar en la jerarquía que determinaba su riqueza y su poder55 y este estatus, en muchos casos, era hereditario. Estas diferencias se hicieron aún más profundas durante la revolución urbana. Según los sumerios, Jushur fue el primer rey y, aunque no se sabe hasta qué punto esta figura es real, lo que sí parece claro es que alrededor de 2900 a. C., en Mesopotamia, los jefes habían acumulado suficiente poder político y económico como para que pudiesen ser considerados verdaderos reyes. China experimentó un desarrollo social paralelo. En la dinastía Shang, a partir del 1700 a. C., la propiedad de toda la tierra estaba asignada al emperador. La revolución urbana, además de reyes, propició la aparición de otra institución social: la esclavitud.56 Los cambios que sustentaron el neolítico y la revolución urbana, igual que los muy posteriores de la revolución industrial, no fueron solamente culturales y las causas de estas transformaciones fueron fundamentalmente tecnológicas.57 Fueron el cultivo y la ganadería los que posibilitaron que primero se fundasen los pueblos y que, más tarde, se construyesen las ciudades. Debería ser trivial asumir que las civilizaciones no pueden sostenerse, ni las antiguas ni las contemporáneas, sin alimentos suficientes. Esto es algo que los antiguos mayas ya parecían tener claro. Según su mitología los dioses intentaron crear seres humanos en distintas ocasiones, primero con barro y luego con madera, pero fracasaron. No fue hasta que se sirvieron del maíz cuando consiguieron por fin crear verdaderos humanos. Todavía actualmente sus descendientes deben el 60% de las calorías que consumen a este cereal.58 Estas revoluciones representan, además, un rubicón tecnológico; una vez el tamaño de la población depende de la agricultura, una posible vuelta a un mundo anterior implica una catástrofe monstruosa. Nuestra dependencia de la tecnología es crítica. Solomon Epstein, el personaje de la serie de ciencia ficción La expansión, dice, al reflexionar sobre el motor espacial que ha desarrollado, y que cambiará nuestro papel en el sistema solar para siempre, que lo maravilloso y lo terrible de la tecnología es que lo cambia todo. Yo comparto esa opinión, aunque, pensando en cómo vivimos hoy en día y en cómo se vivía en el paleolítico, yo pondría más el énfasis en lo maravilloso que en lo terrible. 2.3 Carne y harina Es posible que a alguien le pueda llamar la atención que yo insista en hablar de tecnología para referirme a prácticas agrícolas neolíticas o sumerias. Creo que parte de esta sorpresa puede deberse, en última instancia, a la actual abundancia de alimentos. Sospecho que los protagonistas de esas revoluciones eran más conscientes de estas cuestiones y así lo reflejaron en algunos de sus mes. Los sumerios denominaban me a cualquiera de las costumbres o tecnologías que, según ellos, hacían posible la civilización.59 Entre otros, eran mes: la soberanía, las artes, la música, la calidad de héroe, la justicia, el arte de trabajar la madera, el oficio del herrero, la ley o la prostitución. Resulta evidente que la cultura sumeria y la nuestra tienen algunas pintorescas diferencias, no en vano han pasado 5500 años. Pero, en cualquier caso, ellos celebraban en su cultura aquello que hacía posible su mundo, y esta es una lección que no deberíamos olvidar. La ganadería fue una de las primeras innovaciones neolíticas. Una cabra es una excelente fuente de carne, leche, queso, fibra, piel, grasa y fertilizante. Sin la domesticación del ganado habría sido más difícil dejar de ser cazadores-recolectores, aunque, curiosamente, la primera domesticación, la del perro, fue la única paleolítica. En el oriente próximo, durante el neolítico, se domesticaron cuatro especies clave: las ovejas, las cabras, los cerdos y el ganado vacuno.60 Las primeras plantas en domesticarse, también en el oriente próximo, fueron varios cereales: cebada, trigo y centeno. Los cereales pasaron a ser la fuente principal de energía y se convirtieron en el sustento de la mayoría de las grandes civilizaciones de la antigüedad. En Mesopotamia fue el trigo, en China el arroz y en Mesoamérica el maíz. La única excepción a los cereales fueron las patatas andinas. Además, todavía en la actualidad son estos mismos cultivos los que continúan aportando la mayoría de las calorías a los seres humanos.61 Tampoco es accidental que en los lugares que alumbraron la civilización dispusiesen también de legumbres domesticables. En Mesopotamia, en las mismas colinas que habitaban los antepasados del trigo y la cebada abundaban las lentejas silvestres62 y en China el arroz se cultivaba junto a la soja.63 La combinación de cereal y legumbre es muy recomendable nutricionalmente puesto que, mientras que los cereales son ricos en almidón, en calorías, las legumbres suelen tener más proteínas. Además, los seres humanos necesitamos consumir algunos aminoácidos esenciales que no podemos sintetizar y el consumo conjunto de cereales y legumbres facilita tener una dieta equilibrada.64 Por si esto fuese poco, la combinación de cereales y legumbres también es muy ventajosa agronómicamente. El cultivo de los cereales empobrece el suelo ya que requiere una gran cantidad de nitrógeno fijado, mientras que las legumbres están asociadas a bacterias capaces de fijar el nitrógeno atmosférico y, por lo tanto, su cultivo enriquece la tierra.65 Los agricultores sumerios o chinos no sabían nada sobre el triple enlace del nitrógeno atmosférico ni sobre la existencia de la nitrogenasa presente en las bacterias del género Rhizobium, pero sí fueron capaces de averiguar que la alternancia de cereales y leguminosas era muy ventajosa. 2.4 Genes domésticos Sin embargo, esta manipulación biotecnológica neolítica no fue la más profunda. Los animales y las plantas domésticas no son silvestres, están adaptados a vivir junto a nosotros. El adjetivo doméstico tiene su origen en la palabra latina domus, casa. La domesticación es el proceso de alteración genética mediante el cual una especie silvestre se adapta a nosotros. El perro es un ejemplo paradigmático de especie domesticada. En la naturaleza, antes de la aparición de los humanos no había perros, ni ovejas, ni cabras, ni cerdos, ni vacas, había lobos, muflones, cabras bezoares, jabalíes y uros y fue la selección artificial la que transformó a estos últimos en los domesticados. Esta modificación del acervo genético no requiere de un esfuerzo deliberado ni de un conocimiento de la genética subyacente, tan sólo es necesario que haya una selección continuada de los individuos más adaptados al entorno doméstico. Ni tan siquiera es imprescindible que esta presión selectiva sea ejercida por los seres humanos. Los ratones domésticos también son una especie doméstica, pero nadie pretendió crearla; simplemente, de entre los ratones silvestres, se seleccionaron aquellos que más se acercaban a los graneros neolíticos. Esos tenían más alimento y, por lo tanto, una mayor capacidad reproductiva. Se piensa que puede que los gatos también se auto-domesticasen sin intervención directa de los seres humanos al seguir la abundancia de ratones. Por supuesto, esta domesticación inconsciente no es tan eficiente como la mejora genética actual; los cambios que llevaron a cabo las gentes del neolítico requirieron milenios para crear variedades cultivables medianamente productivas. Estas alteraciones genéticas afectaron a la morfología y la fisiología de las especies domesticadas. En general los tamaños de los animales domésticos son menores que los de sus antepasados silvestres.66 La domesticación redujo muy especialmente el tamaño del cerebro, que como ya hemos comentado es un órgano que consume mucha energía,67 pero, sin embargo, mantuvo la cantidad de grasa corporal. Recientemente hemos conseguido encontrar algunas de las variantes genéticas que fueron seleccionadas para lograr estos cambios. Por ejemplo, en los caballos se seleccionó una mutación en el gen DMRT3 que, gracias a una alteración en el desarrollo de la espina vertebral, modifica su marcha haciendo que montarlo sea más sencillo.68 En las plantas también se alteraron varios caracteres fundamentales, por ejemplo, el desgranado de los cereales. La semilla es la herramienta que la planta utiliza para reproducirse, por lo que es natural que cuando la semilla está madura, la planta la deje caer. Esto es un problema para el agricultor ya que en un cultivo de cereales silvestres la mayoría de los granos maduros se perderán al caer al suelo mientras que la cosecha consistirá, principalmente, en granos verdes. Por fortuna, pudieron seleccionarse muy pronto variedades mutantes en las que las semillas no caían al madurar. De este modo los agricultores podían esperar a que madurasen la mayoría de los granos antes de cosechar sin temor a perderlos.69 Esta alteración selló una relación muy especial entre los agricultores y las plantas, puesto que, al no dejar caer sus semillas, estas variedades ya no pueden sobrevivir por sí mismas.70 Además, para producir frutos comestibles se seleccionaron otras mutaciones. Por ejemplo, en la almendra se seleccionó un cambio en un gen, un factor de transcripción, que hacía que no fuesen tóxicas.71 Algo muy similar a lo que ocurrió en las patatas. Los tubérculos de las plantas silvestres tienen concentraciones de alcaloides poco saludables, que se redujeron en las domesticadas. 2.5 Metal civilizado El otro gran éxito tecnológico del neolítico fue el barro cocido, la alfarería. Aunque se conocen algunas culturas paleolíticas productoras de cerámica, no fue hasta el neolítico cuando esta tecnología se adoptó con entusiasmo.72 Hay que tener en cuenta que las piezas de barro no son fáciles de transportar por grupos nómadas y, además, puede que el incentivo más importante para utilizarlas apareciese al tener cosechas de grano que almacenar.73 La alfarería fue desarrollada independientemente por numerosas culturas; lo que indica que, seguramente, no debe de ser difícil de inventar. Es razonable pensar que las primeras piezas se produjeron, simplemente, secando arcilla, silicatos hidratados, al Sol.74 Otro modo temprano, muy común, de cocer la cerámica era aprovechar los hornos con los que se hacía el pan amasado con las harinas de los nuevos cereales. Al principio estos hornos eran bastante simples, eran poco más que agujeros excavados en el suelo,75 pero la fundación de poblados estables incentivó la construcción de verdaderos hornos de ladrillo.76 Estos nuevos hornos terminarían convirtiéndose en una pieza clave de varias de las incipientes tecnologías químicas: la cerámica, el vidrio y los metales.77 El desarrollo de la metalurgia también se inició durante el neolítico, aunque, dado que el dominio de esta tecnología resultó ser más complejo, requirió miles de años de evolución hasta poder utilizarse para fabricar herramientas verdaderamente útiles. La mayoría de los metales no se encuentran en sus formas puras en la naturaleza. Las excepciones principales a esta norma la constituyen los metales preciosos, sobre todo el oro y la plata, algo de cobre y una mínima cantidad de hierro meteórico. Estos materiales llamaban la atención de nuestros antepasados. Con ellos se hacían adornos a base de calentarlos y martillearlos, pero eran tan escasos que nunca pasaron de tener un papel secundario durante el neolítico. La verdadera era de los metales tuvo que esperar a la revolución urbana y la civilización. El grueso de la metalurgia no hace uso de los raros depósitos de metales puros, sino de las menas metálicas. Una mena es un mineral, usualmente óxidos, sulfuros o silicatos, del que, mediante un proceso químico, puede extraerse un metal. La malaquita, por ejemplo, un mineral semiprecioso verde, es una mena de cobre. Además, conseguir extraer el metal a partir de la mena no es nada sencillo. Alrededor del 3000 a. C. los sumerios descubrieron que si calentaban ciertos minerales en presencia de carbón se obtenían pequeños fragmentos de cobre.78 Es probable que este descubrimiento fuese fortuito, casi todas las menas de cobre, estaño y hierro, en la antigüedad, antes de ser utilizadas para extraer metales, eran utilizadas como pigmentos.79 La malaquita, por ejemplo, se empleaba como cosmético y los óxidos de hierro como decoración para las paredes. Lo más probable es que alguien observase como un trozo de malaquita, tras caer al fuego, generaba una pepita de cobre.80 El proceso de fundición de los metales consiste, en esencia, en calentar la mena en una atmósfera reductora a una temperatura elevada para obtener un metal lo más puro posible. Por fortuna, como ya hemos comentado, desde el neolítico se disponía del equipamiento químico requerido para alcanzar las altas temperaturas necesarias: los hornos cerámicos.81 A pesar de estos avances, el cobre no pudo utilizarse para fabricar herramientas a gran escala hasta que alguien se dio cuenta de que si se añadía casiterita, una mena de estaño, a la mena del cobre, se obtenía un metal más duro, el bronce, que era capaz de mantener mejor el filo y que era más fácil de manipular puesto que fundía a una temperatura menor.82 Este fue el avance crucial que hizo posible que las civilizaciones entrasen en la edad del bronce. Durante siglos el bronce fue un material esencial para las grandes civilizaciones, aunque, con el tiempo, acabó siendo desplazado por el hierro, un metal mucho más abundante y útil, pero que requirió de un desarrollo tecnológico aún más complejo. Es posible que las menas de hierro se utilizasen al principio para facilitar la eliminación de la escoria durante la fundición del cobre.83 La escoria es el material sobrante en las fundiciones metálicas. Si alguien utiliza menas de hierro durante la fundición del bronce, entre la escoria se obtendrá pequeños fragmentos del nuevo metal: el hierro. El problema es que la fundición del hierro requiere temperaturas superiores a las del bronce,84 por lo que inicialmente lo que se obtenía no era hierro puro sino zamarra, una mezcla esponjosa de hierro y escoria de la que podía separarse el hierro a base de golpearla y recocerla. A este hierro se le denomina arrabio. Este avance representó un paso muy importante, pero no fue más que el primero de muchos. La dureza, maleabilidad y durabilidad de las aleaciones metálicas dependen, críticamente, tanto de su composición química, por ejemplo, de la cantidad de carbono que tenga el hierro, como de la historia de los tratamientos térmicos y mecánicos a los que hayan sido sometidas. Hasta el siglo VI a. C. no se consiguió desarrollar hornos capaces de alcanzar una temperatura suficiente como para fundir, para volver líquido, el hierro. El uso del verbo fundir en castellano es algo confuso porque se utiliza tanto para referirse al proceso de extracción del metal a partir de la mena como para describir la licuefacción de los metales. En inglés para la primera acepción se utiliza smelting, mientras que para la segunda el término es melting. De modo que durante siglos la fundición (smelting) del hierro fue común, pero las herramientas de hierro no podían crearse vertiendo hierro fundido (melted) en moldes. Este fue un avance que consiguió desarrollarse en China utilizando fuelles para introducir aire a presión en el horno, aumentando así la temperatura.85 De este modo se consiguió hacer herramientas utilizando moldes, pero esto creó un nuevo problema ya que este tratamiento altera la concentración de carbono de la aleación, un parámetro crucial. Los herreros romanos, por ejemplo, se dieron cuenta de que si las armas y los utensilios de hierro se trataban con carbón se obtenían filos mucho más duraderos, un proceso que denominamos carburización.86 En China fueron capaces de alcanzar un control aún mayor de la concentración final de carbono gracias al desarrollo de un complejo proceso siderúrgico. Aprendieron que si mezclaban el hierro forjado, que habían conseguido fundir en sus avanzados hornos y que tenía un bajo contenido en carbono, con arrabio, un hierro con una alta cantidad de carbono, y otras impurezas podían obtener una nueva aleación con unas propiedades maravillosas, el acero.87 Pero mucho antes de que se alcanzase este grado de excelencia metalúrgica, ya desde el desarrollo del bronce, la relevancia de las herramientas y las armas metálicas fue enorme.88 Antes de la invención de la fundición el uso de los metales se había limitado a los adornos y al arte.89 Ni siquiera cuando se dominó la fundición del cobre las herramientas comunes de piedra y madera fueron reemplazadas, el cobre es demasiado blando. Sin embargo, una vez los artesanos consiguieron fundir bronce el metal comenzó a sustituir a las herramientas de piedra y la madera.90 Aunque para que el bronce pudiese popularizarse las civilizaciones tuvieron que superar una complicación adicional debida a la geología. Salvo en contadas ocasiones, las menas de cobre y estaño se encuentran en regiones volcánicas que suelen estar bastante alejadas de las llanuras aluviales en las que las ciudades habían empezado a medrar.91 Este problema obligó a los reinos de la antigüedad a establecer extensas redes comerciales para adquirir mena metálica o a conseguir controlar grandes extensiones territoriales. Las menas de hierro, sin embargo, son mucho más comunes y accesibles, pero, en este caso, el factor limitante fue conseguir acumular el complejo conocimiento metalúrgico requerido. Se necesitaron siglos de evolución tecnológica desde el primer bronce hasta obtener el primer hierro. Eso sí, una vez se dominó la siderurgia, esta tecnología fue disruptiva. Con los nuevos arados de hierro se pudieron arar tierras más duras y los filos de las nuevas hoces facilitaron la cosecha. Este avance permitió mejorar la productividad agrícola. Incluso el comercio se vio afectado, con este nuevo metal se fabricaron clavos que permitieron construir barcos mayores y más capaces que convirtieron, por primera vez, el Mediterráneo en un área comercial globalizada.92 Además, como era de esperar, hubo aplicaciones bélicas. Asiria, equipada con espadas, cascos y lanzas de hierro, sembró el terror con unas armas más capaces y mucho más baratas de producir.93 El conocimiento siderúrgico se convirtió en una fuerza histórica de primer orden. Desde ese momento hasta la Edad Media no hubo nuevos avances tecnológicos tan revolucionarios como el dominio del hierro. 2.6 Burócratas civilizados Hasta este punto hemos estado hablando sobre algunos mes, conocimientos requeridos para la civilización, que actualmente asociamos con la tecnología, como la metalurgia, sin embargo, estos no fueron los únicos desarrollos sumerios. Para poder organizar las incipientes civilizaciones los escribas crearon dos nuevos mes que pocos, hoy en día, denominaríamos tecnologías: las matemáticas y la escritura. La propia burocracia fue otra de las nuevas ocupaciones surgidas con la civilización. Todos los estados tuvieron que dotarse de burócratas para organizarse.94 En Sumeria el rey gobernaba a través de los burócratas, muchos de ellos sacerdotes, que se encargaban, entre otras cosas, de distribuir las tierras y las cosechas. Durante el imperio Acadio, 2334 a. C. a 2192 a. C., estas burocracias llegaron a ser tan complejas, que fueron capaces de organizar a un millón de trabajadores, algo bastante notable para un imperio que sólo disponía de burros y tecnologías de la edad del bronce.95 China también se proveyó de una extraordinaria burocracia96 y para contratarla establecieron unas oposiciones cuyo temario permaneció sin alteraciones significativas durante 2000 años, hasta 1904.97 Y, como no podía ser de otro modo, desde el principio hubo acusaciones de abuso de poder por parte de estos nuevos estamentos. En Lagash, una ciudad sumeria, se decía que a quien realmente debías temer no era a tu señor o a tu rey, sino al recaudador de impuestos y que no había nada más seguro que la muerte y los impuestos.98 Además, estoy seguro de que estos problemas no se debían tan sólo al afán de beneficio personal de algunos de esos escribas, habría que considerar también las ineficiencias debidas al desconocimiento detallado de los complejos sistemas sociales que la burocracia pretende organizar. Este es un problema que todavía sufrimos hoy en día tanto en las instituciones públicas como privadas. Sin embargo, a pesar de estas críticas, debemos reconocer que los burócratas nos hicieron un enorme regalo: la escritura. Esta idea apareció algunos siglos antes del 3000 a. C.99 y es probablemente el legado más importante de Uruk, la cuna de la civilización. Las primeras anotaciones fueron modestas, no se hicieron para cantar grandes gestas o para reflexionar sobre la vida, el universo y todo lo demás, sino para dejar constancia de transacciones comerciales y ventas de tierras y para controlar inventarios.100 La mayoría de los escritos chinos y mesopotámicos estaban relacionados con la administración.101 El 85% de las tablillas cuneiformes de Uruk, recogen intercambios económicos.102 Sin emgargo, las consecuencias de las tecnologías son en muchos casos inesperadas, la tecnología lo cambia todo, y a pesar de este origen utilitario la escritura fue revolucionaria. Por primera vez la evanescente materia de nuestros sueños, preocupaciones y reflexiones pudo hacerse tangible en forma de incisiones en el barro. Nada volvió a ser igual. Fue entonces cuando comenzamos a documentar la historia103 y cuando nació la literatura. Aquel que todo lo vio, hasta los confines de la tierra, que todo lo experimentó, que vio lo oculto y que desveló lo velado, aquel que nos informó sobre el mundo antediluviano, llevó a cabo un largo viaje y cansado y derrengado, todo su afán grabó en una estela de piedra y en la llanura de Uruk un muro construyó… Este es el inicio de Gilgamesh, la obra épica más antigua conocida. Un texto en el que se nos insta a renunciar a la gloria vana, a disfrutar de una vida sencilla y a aceptar la muerte cuando nos llegue, algo a lo que, cuatro mil años después, no tenemos mucho más que añadir.104 Los sumerios, además, fueron los primeros en utilizar la recién creada escritura para alumbrar un nuevo me imprescindible para la organización social de cualquier civilización, la ley. Los primeros códigos legales conocidos, los de Ur-Nammu y Hammurabi, datan de alrededor del 2000 a. C.. Todas las culturas tienen formas de regular el conflicto, pero la ley está escrita y este hecho, que puede parecernos trivial, tiene consecuencias profundas, prácticamente metafísicas. A partir del momento en que las reglas están escritas, da la impresión de que quien castiga ya no es una persona: un juez, un anciano o un sabio, sino la ley misma. Por si todo esto nos pareciese poco, los sumerios también fueron pioneros en el desarrollo de otros mes, como la deuda, los bancos o las matemáticas. Es cierto que hay algunas evidencias de números y cuentas en el paleolítico, pero las matemáticas asociadas a la revolución urbana constituyen un fenómeno claramente diferenciado. Las evidencias matemáticas sumerias más antiguas, 3500 a. C., están unidas a la aparición de la escritura, y también son anotaciones comerciales.105 Sin embargo, a pesar de este humilde inicio, la transcendencia de este avance fue tan enorme que sus ecos todavía resuenan en nuestra vida diaria. Nuestros años tienen 12 meses, nuestros días 24 horas, nuestras horas 60 minutos y nuestros círculos 360 grados porque el sistema numérico sumerio estaba basado en el 6 y el 60.106 Herodoto, el historiador griego (484 a. C. a 425 a. C.) ya nos decía que el origen de las matemáticas estuvo ligado a las necesidades administrativas y prácticas.107 La aritmética era necesaria para hacer inventarios,108 para calcular transformaciones entre distintos sistemas de pesos y medidas,109 intereses bancarios, impuestos110 y divisiones de herencias y la geometría era imprescindible para los agrimensores, para delimitar superficies, por ejemplo, campos de cultivo, y para la construcción de los sistemas de riego y los edificios.111 Para organizar estas obras había que calcular el número de trabajadores, así como la cantidad de materiales necesarios.112 Una civilización no puede funcionar sin matemáticas y en algunos casos esas matemáticas llegaron a ser relativamente sofisticadas. Por ejemplo, la aproximación mesopotámica a pi era 3 y un octavo (3.125).113 2.7 Reyes, ríos y mes Espero haber aportado suficientes evidencias de que tanto el neolítico como la revolución urbana dependieron críticamente del conocimiento, y, muy especialmente, de la tecnología. De hecho, sin estas tecnologías la civilización, que requiere la vida en la ciudad, no es posible. Creo, además, que el conocimiento se convirtió en una fuerza histórica más. Es común que cuando los historiadores discuten sobre las causas del cambio histórico le presten una gran atención a la influencia de los grandes personajes y de las fuerzas económicas, pero me parece que estos no son los únicos factores que han de considerarse. Es indiscutible que nuestra historia sería muy distinta sin los 32 años de Alejandro Magno, pero el neolítico y la revolución urbana nos recuerdan que también debemos considerar la geografía y el conocimiento. Jared Diamond en Armas, gérmenes y acero explica cómo la biología, la geografía y el clima influyen en el desarrollo histórico. Aunque es evidente que no todo puede ser explicado por la geografía, (por ejemplo, las profundas diferencias entre Corea del Norte y del Sur no son atribuibles a factores geográficos), no es menos cierto que la causa de que los inuit no desarrollasen la agricultura del trigo no es cultural.114 Las culturas neolíticas sólo aparecieron en las regiones que presentaban las condiciones adecuadas, aquellas en las que había especies fáciles de domesticar y suelos altamente productivos.115 Además, aunque la historia no se repite del todo, al menos parece rimar. Distintas culturas tuvieron un desarrollo prácticamente paralelo116 y este hecho parece sugerir que los factores geográficos y tecnológicos fueron relevantes. Por ejemplo, en China y en Mesopotamia se desarrolló primero una agricultura básica, que dio lugar a pueblos neolíticos bastante igualitarios conocedores de la cerámica. Con el tiempo esta agricultura aumentó su productividad hasta ser capaz de sostener, en las llanuras aluviales, la aparición de las primeras ciudades, lo cual conllevó un incremento de la desigualdad y de la especialización que, a su vez, favoreció la aparición de diversos conocimientos y tecnologías que propiciaron un incremento de la complejidad social aún mayor. Este patrón se repitió, con algunos matices, en todas las grandes civilizaciones de la antigüedad: Mesopotamia, China, Egipto, el valle del Indo, Mesoamérica y la región andina. Que existan estas similitudes de los desarrollos históricos observados a vista de pájaro no implica que no hubiese diferencias regionales debidas a otros factores, especialmente si se tiene en cuenta el devenir histórico de periodos más cortos. Por ejemplo, no todas las culturas que habitaban áreas en las que las condiciones geográficas permitían el desarrollo de la agricultura iniciaron una transición independiente al neolítico.117 Aunque sí es cierto que las que no lo hicieron acabaron siendo reemplazadas por sus vecinos neolíticos.118 A pesar de esto no me gustaría que la descripción a vista de pájaro que he hecho del origen de las civilizaciones nos haga pensar que la historia ha seguido exactamente los mismos patrones en todos los lugares. La historia, al fin y al cabo, es la historia de las personas y, aunque es mucho lo que compartimos, no es desdeñable lo que pueden llegar a influir nuestras diferencias culturales. Además, nuestra ignorancia sobre los mundos del paleolítico, el neolítico y las primeras civilizaciones es enorme. He hablado sobre el neolítico como si de un barrio vecino y familiar se tratase, pero este es un lugar muy lejano del que todavía nos queda mucho por aprender. Una de las más recientes sorpresas ha sido Göbekli Tepe. Este es un sitio construido por cazadores-recolectores en el creciente fértil durante las primeras etapas neolíticas. Ante sus estructuras megalíticas uno no puede dejar de sentir un profundo asombro por la enormidad de la historia, a la vez que una extraña mezcla de cercanía y distancia con sus constructores. Actualmente desconocemos cómo miles de habitantes a caballo entre el paleolítico y el neolítico fueron capaces de organizarse para levantar unas descomunales estructuras de las que la mismísima Babilonia podría haberse sentido orgullosa miles de años después. Aun así, es evidente que durante el neolítico y la revolución urbana la tecnología se convirtió en una fuerza histórica de capital importancia. Sin tecnología ni la sangre de los linajes reales ni los políticos más diestros son capaces de crear y mantener civilizaciones. Además, la propia idea de progreso se convirtió en una fuerza histórica. Los sumerios eran conscientes de estar progresando, ellos mismos pensaban que Eridú era la primera ciudad de la historia, una opinión que, hoy en día, comparten muchos historiadores. Para los sumerios el progreso era más importante que la tradición.119 Los arquitectos de Eridú no solían restaurar edificios antiguos, preferían sustituirlos por otros mayores y más elaborados. En algunos casos llegaron a demoler y construir de nuevo hasta 11 veces en 10 siglos un mismo edificio, una vez cada 90 años.120 Desconozco si había voces opuestas a esta obsolescencia programada sumeria. Mientras que para los egipcios era importante que sus tumbas quedasen para siempre, para los sumerios el cambio era la única constante. Esta actitud ante el progreso también se reflejaba en su mitología. Enki era un dios sumerio que personificaba la fertilidad de las aguas de riego, la creatividad y la inteligencia121 y era, además, el protector de Eridú y de los mes.122 El propio concepto del me, conocimiento que hace posible la civilización, es otro signo de la actitud sumeria ante el progreso. Innana, posteriormente conocida como Ishtar, era la diosa del granero, el almacén comunal de las cosechas, de la fertilidad, de las relaciones sexuales y la guerra.123 Innana era además la diosa de las prostitutas. Los sumerios contraponían la sexualidad represora y la moralidad conservadora del campo a la de la ciudad, para ellos la civilización y el sexo estaban unidos.124 Innana habitaba Uruk y quería tener acceso a los mes para poder fundar una nueva ciudad, pero Enki no quería que los mes abandonasen el templo de Eridú. De modo que Innana trazó un plan para conseguirlos, decidió visitar a Enki, seducirlo y emborracharlo. Cuando Enki despertó después de la fiesta, se dio cuenta de que Innana le había robados los mes125 y envió tras ella a sus ministros, junto algunos monstruos protectores, pero todo fue en vano. La diosa consiguió huir con los mes a Uruk, liberándolos así para todos los sumerios y posibilitando que Uruk se convirtiese en una gran ciudad. Esta leyenda no debe hacernos pensar que, a pesar del ejemplo sumerio, la aceptación del progreso tecnológico implica necesariamente una predilección cultural por el cambio en otros ámbitos. En China, a pesar de desarrollar la tecnología tanto o más que en Mesopotamia, políticamente eran mucho más conservadores. La clave tal vez estribe en que esta defensa del progreso y del conocimiento no se limitaba a los mitos y las ceremonias, los gobernantes consideraban los mes como imprescindibles y financiaban su mantenimiento.126 Por ejemplo, el estado fomentaba la formación de escribas y sacerdotes profesionales conocedores de la escritura, las matemáticas, la ley, la medicina y la astrología.127 Tanto en Mesopotamia,128 como en Egipto129 y en China,130 había academias para formar estos profesionales y su prestigio social era muy elevado.131 Este reconocimiento del progreso neolítico y urbano tampoco implica que debamos asumir que todos los cambios fueron siempre positivos para la gente que los experimentó ni que el desarrollo fuese continuo e ininterrumpido. Los esqueletos de los primeros agricultores delatan que los cazadores-recolectores eran más altos, tenían mejores dientes y carecían de muchas enfermedades típicamente neolíticas.132 Los habitantes de los nuevos poblados tenían más tendencia a estar malnutridos, a padecer escorbuto, una deficiencia de vitamina C, raquitismo, por la falta de vitamina D, y anemia.133 La transición a la agricultura no sólo propició un aumento en el número de habitantes, sino también un empeoramiento de la salud. Había más comida, es cierto, pero menos diversa, y aparecieron nuevas enfermedades infecciosas debidas al aumento de las densidades de población y al estrecho contacto con los animales de granja, las ratas y los ratones.134 Los perros nos transmitieron la rabia, los gatos la toxoplasmosis, los caballos los resfriados, las vacas el tétanos, la difteria y la tuberculosis y los cerdos y los pollos la gripe.135 Además, aunque las ciudades, en la mayoría de los casos, estaban densamente pobladas, carecían de alcantarillado, lo que favorecía las epidemias.136 2.8 No era ciencia Otro error común es pensar que en las civilizaciones antiguas se practicaba la ciencia. Es indiscutible que estas civilizaciones tenían un amplio conocimiento tecnológico, pero la tecnología y la ciencia no están necesariamente relacionadas. El objetivo de la ciencia, a diferencia del de la tecnología, no es modificar el mundo sino comprenderlo. Incluso cuando el artesano o el ingeniero hacen uso de un conocimiento teórico, lo hacen para conseguir crear mejores herramientas o armas, las teorías no son más que medios con los que alcanzar un fin práctico. Es evidente que nuestro conocimiento científico actual favorece enormemente el desarrollo de la tecnología, pero como demuestran las tecnologías del mundo antiguo, no es imprescindible conocer la ciencia subyacente para desarrollar una tecnología. Actualmente solemos pensar en la tecnología como en una ciencia aplicada, pero esta íntima relación entre ambas disciplinas no existía antes de las revoluciones científica e industrial. Esta nueva aproximación tiene ventajas indudables; en el tiempo que a nosotros nos ha costado llegar desde la primera línea de ferrocarril a pisar la Luna, los sumerios apenas consiguieron mejorar sus aleaciones de bronce. Conocer la ciencia subyacente no es imprescindible para el desarrollo tecnológico, pero es muy conveniente. La ambición práctica del conocimiento antiguo se refleja, por ejemplo, en sus matemáticas, que estaban orientadas principalmente a solucionar problemas prácticos.137 Conocían la aritmética básica, cómo calcular intereses compuestos,138 cómo resolver ecuaciones lineales, así como algunas cuadráticas y cúbicas, cómo calcular hipotenusas de triángulos rectángulos y cómo calcular áreas y volúmenes de superficies y sólidos sencillos.139 Sin embargo, muy pocas veces los escribas que usaban esas matemáticas elementales se detenían a jugar con ellas más allá de lo estrictamente necesario.140 Sí que es cierto que las civilizaciones antiguas hicieron observaciones y desarrollaron catálogos astronómicos, una actividad que actualmente enmarcaríamos dentro de la ciencia, pero su interés también era práctico. Para ellos la astrología era un conocimiento aplicado, tan respetable como la medicina, y no distinguían entre astrología y astronomía. Además, estos catálogos astronómicos carecían de marco teórico alguno. Como veremos, hasta la Grecia clásica no hay constancia de que nadie propusiese una posible hipótesis que unificase las distintas observaciones astronómicas. Esto no implica que estas gentes no tuviesen una necesidad de explicar el cosmos; la tenían, y eran sus sacerdotes y sus mitos los que proporcionaban esas explicaciones. Pero ésta, por supuesto, no era una aproximación científica. Aunque es cierto que el objetivo de muchos de esos mitos era explicar fenómenos que hoy en día explica nuestra ciencia, y en este sentido los sacerdotes y nuestros científicos comparten objetivos, existe una diferencia fundamental entre ambas aproximaciones. Los sacerdotes proponían explicaciones, pero no había un esfuerzo colectivo de análisis sistemático. Hasta la Grecia clásica no aparecieron comunidades que practicasen la crítica sistemática racional tanto de las hipótesis sobre el funcionamiento del mundo natural como de cualquier otra propuesta, ya fuese ésta moral, política o, incluso, estética. Esto se refleja, por ejemplo, en los logros de los matemáticos griegos, que, a diferencia de los sumerios o los egipcios, sí consiguieron desarrollar la aproximación moderna a las matemáticas: la demostrativa. Cuando en secundaria se nos justifica el teorema de Pitágoras, el profesor no lo hace empíricamente, es decir, midiendo los lados de unos cuantos triángulos rectángulos y comprobando que, efectivamente, la relación entre la hipotenusa y los catetos se cumple. La justificación es demostrativa, se parte de unos axiomas elementales y a partir de ellos se demuestra, sin ningún lugar a dudas, mediante el uso de la lógica, que todos los triángulos construidos respetando esos axiomas cumplirán necesariamente el teorema deducido. Las matemáticas que crearon los pitagóricos ya eran nuestras matemáticas. Por supuesto que hoy en día se han demostrado muchos más teoremas, incluso existen ramas completas de las matemáticas que los griegos desconocían por completo, pero no es menos cierto que Euclides utiliza en Los elementos una aproximación axiomática, demostrativa, igual a la de cualquier curso de matemática avanzada actual. Los mesopotámicos, egipcios y chinos, sin embargo, no tenían nada remotamente parecido a una demostración deductiva que justificase sus conocimientos matemáticos.141 Los ingenieros babilonios sabían cual era la relación entre los catetos y la hipotenusa de los triángulos rectángulos, pero no conocían el teorema de Pitágoras, su conocimiento era meramente empírico y para justificarlo medían triángulos concretos. Nosotros también tenemos matemáticas aplicadas, pero los profesores de ingeniería no las justifican bajándose a la obra con una regla. 2.9 Evolución cultural Además, la aproximación al desarrollo tecnológico de los artesanos antiguos también era bastante diferente a la de los ingenieros actuales. La falta de conocimientos teóricos hacía que se avanzase por ensayo y error142 y, además, es muy dudoso que la comunidad artesanal babilónica emprendiese programas sistemáticos de desarrollo tecnológico. De modo que las civilizaciones antiguas consiguieron dominar tecnologías sofisticadas sin disponer de los conocimientos y aproximaciones sistemáticas que hoy en día nos ayudarían en la creación de nuevos perfumes, cristales, cosméticos, cerámicas o herramientas metálicas.143 Lo que estos artesanos nos enseñan es que es posible desarrollar tecnología incluso careciendo de conocimientos teóricos y de programas sistemáticos. Los agricultores averiguaron que la combinación de legumbres y cereales era positiva para el cultivo y para la alimentación, sin saber nada sobre las bacterias fijadoras de nitrógeno, y modificaron la genética de las plantas sin haber oído hablar de Mendel ni de genes y sin acometer análisis rigurosos. Los artesanos chinos que crearon acero no sabían química e ignoraban qué es un silicato metálico o una atmósfera reductora, ni siquiera sabían qué eran los elementos químicos, las aleaciones o la concentración de carbono. Dadas estas carencias la pregunta que cabe plantearse es: ¿Cómo consiguieron unos artesanos educados para seguir la tradición llegar a desarrollar tecnologías tan sofisticadas como la siderurgia? Creo que el proceso puede describirse como una evolución tecnológica en la que los cambios, incluso los introducidos por azar, son seleccionados en función del resultado final.144 Este es un proceso que, dado el tiempo necesario, pudo llegar a conseguir avances que ninguno de los artesanos involucrados pudo haber imaginado. De hecho, es precisamente el largo tiempo que requirieron estas mejoras uno de los indicios que parece sugerir que el proceso que los generó pudo ser evolutivo. Se necesitaron siglos para llegar desde las primeras pepitas de cobre de los hornos cerámicos neolíticos hasta las espadas de acero. Ya hemos comentado previamente cómo la selección natural puede hacer aparecer diseño en la biosfera sin la mediación de ningún diseñador. De un modo análogo, puede que la evolución cultural genere diseño sin que ninguna de las personas involucradas conozca los motivos profundos que hacen que ese diseño funcione. En este caso también sería aplicable la segunda ley de Orgel: la evolución es más inteligente que tú.145 La solución encontrada por estos procesos no es el resultado de la reflexión de ningún pensador concreto, sino de una multitud de pequeños cambios introducidos por innumerables artesanos.146 Recordemos que la evolución se dará siempre que haya variación heredable asociada a diferentes tasas de reproducción.147 En el caso de la artesanía, la transmisión de las ideas se da por el aprendizaje a partir de los maestros. Para que haya evolución no se requiere que esta transmisión sea completamente fiel, un aprendiz puede introducir cambios, lo que se necesita es que los descendientes de un artesano particular tiendan a parecerse más a este que a los demás.148 De hecho, si hay errores durante el aprendizaje estos jugarán el papel de la mutación en la transmisión del material genético, serán una fuente de variación, otro de los requisitos imprescindibles para que haya evolución. Por último, para que aparezca diseño es necesaria la selección, las distintas ideas, por ejemplo, las diferentes formas de forjar una espada, deben tener un éxito distinto, algunos artesanos deben ser reconocidos como mejores en virtud del resultado de su trabajo y se debe tender a que sean estos los más imitados. Lo que no es un requisito imprescindible para la evolución es que los mecanismos de generación de la variación dependan exclusivamente del azar. En principio, parece posible que las tecnologías antiguas hayan mejorado mediante procesos evolutivos, aunque conseguir evidencias directas de esto no es trivial. De hecho, esto no es fácil ni siquiera en el caso de la evolución biológica. No ha sido hasta la segunda mitad del siglo XX cuando los microbiólogos han podido observar y manipular la evolución biológica directamente. Lo más habitual es que la existencia de evolución biológica sea inferida a partir de evidencias paleontológicas o genéticas. En el caso de las técnicas artesanales, los conocimientos se transmitían oralmente y hemos de conformarnos con las evidencias materiales que los arqueólogos han recuperado, las ideas que las crearon se perdieron y debemos resignarnos a contar sólo con algunos de los resultados de la aplicación de esos conocimientos.149 Aunque sí hay algunas características que esperamos observar en los vestigios de un proceso evolutivo. La principal de ellas tal vez sea la continuidad. En la evolución biológica las mutaciones genéticas suelen ser pequeñas. No es esperable encontrar mutaciones beneficiosas que alteren mucho el fenotipo del individuo, los mutantes del profesor Xavier, el fundador de los X-men, no son biológicamente plausibles. Aunque también es cierto que esta es una característica un tanto arbitraria porque, ¿cuánto es “mucho”? Cualquier cambio implica un cierto salto, pero veremos que la descripción de un proceso como evolutivo deja de ser útil cuando estos saltos son arbitrariamente grandes y que fuera del mundo biológico, donde la variación no tiene por qué deberse exclusivamente al azar, la distinción entre procesos evolutivos y diseño dirigido o inteligente no es tan nítida como solemos asumir. Además, si en un proceso evolutivo ha habido selección, todas las etapas deben ser útiles. Esto pareció suceder en el caso de la metalurgia: la malaquita era útil por su color, el cobre como adorno, y el bronce, el arrabio, el hierro forjado y el acero como metales para herramientas. Por otro lado, si hay selección debe haber progreso, las soluciones encontradas deberían satisfacer cada vez mejor el propósito establecido por la selección. Por ejemplo, una vez que alguien consigue crear una espada de hierro capaz de vencer a una de bronce, estas últimas, con el tiempo, deberían ser reemplazadas. Esto también parece haber sucedido en el caso de la metalurgia y, como veremos a continuación, en la historia de los sistemas de escritura. Otra característica que suele observarse en los procesos evolutivos es la paulatina divergencia, en los detalles no esenciales, de distintos linajes creados a partir de un tronco común que poco a poco va dividiéndose. Esta es una característica que se observa incluso cuando la evolución es neutral, es decir, cuando no hay selección. Existen numerosos casos en los que la evolución cultural parece seguir este patrón de diversificaciones paulatinas. Por ejemplo, las lenguas van diferenciándose con el tiempo a partir de troncos comunes. Esto hace, por ejemplo, que existan lenguas germánicas, eslavas y latinas, que a su vez provienen de un tronco común más antiguo, el indoeuropeo. Finalmente, los procesos evolutivos, son capaces de llegar a las mismas soluciones independientemente en los mismos linajes, algo que hemos observado en la evolución de la agricultura y la metalurgia en Mesopotamia y China. 2.10 Del barro al scriptorium Los sistemas de escritura, como los metales, también sufrieron un desarrollo gradual,150 lo que sugiere un posible proceso evolutivo. Los primeros símbolos sumerios (3300 a. C.) se utilizaban para representar objetos almacenados. Estos símbolos eran pictográficos, se parecían a los objetos representados.151 Esta protoescritura no era capaz de consignar un lenguaje completo ya que, aunque se disponía de pictogramas para objetos y números no había forma de representar la sintaxis.152 Por ejemplo, no se podían distinguir el sujeto y el predicado. Con el tiempo estos pictogramas fueron cambiando. No es fácil hacer buenos dibujos utilizando tablillas de barro húmedo, de modo que los símbolos fueron haciéndose cada vez más estilizados y abstractos hasta perder el parecido con el objeto representado.153 En este momento, la relación entre los símbolos y los objetos representados pasó a ser arbitraria, como en nuestros sistemas de escritura modernos, en los que las palabras escritas no evocan en modo alguno a los objetos representados. La palabra “pato” no tiene ni pico ni plumas. Cuando la relación entre los objetos y su símbolo escrito es meramente convencional, los símbolos ya no se denominan pictogramas sino logogramas.154 La mayoría de los miles de símbolos de la escritura sumeria eran logogramas. En China la escritura también sufrió esta transición desde los primitivos pictogramas a los logogramas. No hay un acuerdo completo sobre hasta qué punto este proceso de creación de la escritura sumeria fue gradual, pero incluso aquellos que creen que el desarrollo fue más abrupto piensan que se necesitaron varios siglos para completarlo.155 Y, además, esta transición no constituyó más que el principio del camino. Durante siglos los símbolos representaron objetos, pero a nadie se le ocurrió que pudiesen servir también para codificar sonidos.156 El problema de los logogramas es que no permiten representar nombres propios o partículas gramaticales fácilmente,157 algo que sí pudo hacerse cuando los caracteres escritos pasaron a representar sonidos, cuando se convirtieron en fonogramas. Puede que los escribas creasen estos nuevos fonogramas asociando al símbolo logográfico el sonido de la palabra que solía representar.158 Este cambio fue muy significativo ya que permitió a los sumerios escribir completamente su lenguaje hablado,159 incluyendo no sólo los nombres propios sino otras palabras de más difícil representación como las preposiciones. Al parecer esta transición desde los logogramas a los fonogramas requirió, de nuevo, varios siglos160 y, de hecho, en el caso de la escritura cuneiforme, los logogramas nunca llegaron a abandonarse del todo.161 Alrededor de 1500 a. C. ya existían sistemas fonográficos puramente silábicos en los que cada sílaba estaba representada por un símbolo.162 Estos sistemas de escritura eran más sencillos que los anteriores, aunque no eran tan fáciles de aprender como el nuestro actual ya que para cada sílaba se requería un símbolo distinto. Por ejemplo, para representar: pa, pe, pi, po, pu necesitaríamos 5 fonogramas distintos. El siguiente avance se dio en Ugarit, una ciudad comercial mediterránea localizada en la actual Siria, alrededor del 1500 a. C.. Allí se desarrolló la primera escritura alfabética. Para crearla eliminaron las vocales, de modo que cada símbolo representaba un sonido consonántico y no una sílaba completa.163 Este nuevo sistema fue adoptado por los fenicios en 1100 a. C. y fueron ellos quienes lo popularizaron, convirtiéndose así en el origen de casi todas las escrituras alfabéticas actuales.164 Esta popularización dio lugar a la aparición de distintos linajes y sublinajes en los que diferentes alfabetos fueron modificándose y diversificándose a medida que se transmitían a lo largo de distintas tradiciones culturales. El alfabeto inicial se dividió en dos ramas, la semítica del norte y la del sur. La del sur acabaría generando el actual alfabeto etíope, mientras que la del norte se dividió a su vez en la subrama griega y en la aramea. De la griega descienden varios alfabetos contemporáneos: romano, griego y cirílico y de la aramea el hebreo, el árabe, el sirio y el mongol. Estas ramificaciones en distintas ramas y subramas, como he comentado, son típicas de los procesos evolutivos. Sin embargo, las consonantes ugaríticas tampoco fueron la última innovación. Este alfabeto y el fenicio sólo representaban consonantes, ls vcls había que inferirlas por el contexto.165 Fueron los griegos quienes añadieron nuevas letras para las vocales.166 La escritura hebrea antigua también carecía de vocales. No podemos estar seguros, por ejemplo, de cuál es la pronunciación original de Yahveh. Resulta curioso que el alfabeto elegido por quien inspiró el antiguo testamento, supuestamente el dios judío, no pudiese reflejar fielmente ni tan sólo el nombre de su propio dios. Pero tampoco fueron las vocales griegas el final del camino. Para Platón o Aristóteles leer era más difícil que para nosotros. La escritura de la Grecia clásica carecía de símbolos de puntuación y de espacios.167 De modo que La república de Platón fue escrita con todas las palabras y los párrafos seguidos, sin espacios, comas o puntos. Los espacios y los signos de puntuación fueron popularizándose gradualmente en el mundo clásico. Finalmente, en la Edad Media se desarrollaron las mayúsculas y las minúsculas a partir de las distintas modificaciones alfabéticas comunes en esa época. Podría pensarse que la elección de un sistema de escritura se debía a meras preferencias culturales y que no tenían ninguna consecuencia práctica, pero esto no es cierto. La escritura se desarrolló porque cumple unas funciones fundamentales: almacenar y transmitir información, y algunos de estos sistemas de escritura son mejores soluciones que otros. Es cierto que las civilizaciones mesopotámicas, tras siglos de desarrollo, consiguieron desarrollar sistemas completos, capaces de expresar cualquier idea, pero el esfuerzo que requería aprenderlos era muy superior al que exige nuestro alfabeto actual y eso tenía importantes implicaciones sociales. Los sistemas logográficos necesitan un gran número de caracteres, en China, en el periodo Han, llegaron a tener más de 9000 ideogramas, mientras que los sumerios más antiguos tenían unos 3000.168 Aprender a leer y a escribir era una tarea que requería años de estudio y entrenamiento,169 un esfuerzo que sólo podía hacer una pequeña parte de la población.170 Las escrituras mesopotámicas eran tan complejas que ni tan siquiera todos los escribas llegaban a comprenderlas por completo.171 Los jeroglíficos egipcios, sin embargo, que en gran parte eran silábicos, eran más fáciles de aprender. El escriba egipcio necesitaba menos tiempo que el sumerio para dominar su escritura.172 Esto hizo que más gente aprendiese a leer, se estima que entre el 2 y el 5 por ciento de la población estaba alfabetizada en Egipto frente al 0,5 o 1 por cien de Sumeria y China.173 La alfabetización aún progresó más con los sistemas alfabéticos. Se calcula que en la Atenas de Platón y Aristóteles entre un cuarto y la mitad de los ciudadanos masculinos adultos sabía leer.174 Este puede que fuese uno de los factores que posibilitaron la aparición de la filosofía clásica y, desde luego, debió de ser relevante en la democracia ateniense. Es difícil imaginar que una democracia pueda funcionar mientras la lectura de las leyes esté limitada a los escribas cercanos al poder. 2.11 Espacios evolutivos Es común pensar que las grandes creaciones culturales son regalos de algún genio, o como mucho, de un pequeño conjunto de creadores. Sin embargo, en la mayoría de los casos, esas creaciones son fruto de procesos muy complejos en las que intervienen un gran número de personas. La metalurgia y la escritura no parecen ser el resultado de un genio capaz de realizar un doble mortal en el espacio de posibles soluciones. Esto es algo habitual incluso en los descubrimientos actuales. Suele ser muy difícil adscribir un avance a una sola persona. ¿Calculó Avogadro la constante que lleva su nombre? ¿Escribió Maxwell las ecuaciones de Maxwell? ¿Descubrió Ohm la ley de Ohm? No, no y no. Aunque nos resulte más fácil o satisfactorio recordar la historia como una serie de grandes hitos alcanzados por personas geniales el proceso de desarrollo del conocimiento suele ser más comunitario que individual y más gradual que abrupto. Esta complejidad de los procesos de desarrollo hace que, aunque solamos nombrar los resultados finales en honor a un investigador, la realidad es que estas elecciones son un tanto arbitrarias. Tanto es así que el profesor Stephen Stigler propuso una ley según la cual ningún descubrimiento se termina nombrando en función de su descubridor original, una regla que, aunque lleva su nombre, fue propuesta anteriormente por el sociólogo Robert K. Merton.175 Sewall Wright, uno de los fundadores de la genética de poblaciones176 propuso el concepto de paisaje adaptativo, una idea que Richard Dawkins describe muy bien en su Relojero ciego. En el caso biológico este paisaje adaptativo sería un espacio abstracto compuesto por todas las posibles secuencias genéticas. Un individuo concreto ocuparía un punto en este espacio y una población sería un conjunto de puntos más o menos cercanos. Una forma de visualizar este espacio sería imaginar un plano, por ejemplo, una mesa. Cada punto de la mesa se correspondería con una secuencia genética distinta y un individuo estaría representado por el punto que le correspondiese según su genoma. Una población de individuos estaría representada por un conjunto de puntos cercanos, de secuencias similares, en este espacio. Además, en este espacio los descendientes de un individuo tenderán a ser puntos muy cercanos al original ya que sus secuencias serán muy similares a las de su progenitor. La evolución biológica consistiría en el movimiento a través de este espacio, es decir, del cambio de secuencias genéticas de los distintos individuos. Puede que, dado que también hay evolución sin selección, tal vez, fuese más conveniente referirse a este espacio como evolutivo en vez de, simplemente, adaptativo. En el caso de las tecnologías este espacio representaría el conjunto de todos los posibles métodos que alguien podría usar. Por ejemplo, todos los posibles métodos para crear herramientas metálicas. Cuando no hay selección, en la evolución neutral, todas las regiones de ese espacio serían equivalentes, sin embargo, al añadir selección, las distintas regiones del espacio evolutivo dejan de ser iguales. El plano que nos estábamos imaginando pasa a tener montañas y valles dependiendo de lo buenas que sean las soluciones propuestas. Un método especialmente eficaz estaría representado por una montaña especialmente alta, mientras que una solución estúpida y condenada al fracaso sería un pozo profundo. En el caso de la evolución neutral los puntos se mueven al azar por el espacio, pero si hay selección, si hay montañas, los puntos, con el tiempo, tenderán a ocupar posiciones cada vez más elevadas puesto que un punto en una posición más elevada tiene más descendencia que un punto localizado en un valle. Esto es precisamente lo que representa la altura, el éxito reproductivo, cuanto más alto esté un punto más descendencia tenderá a tener. Si nos acostumbramos a pensar de este modo, la evolución pasa a ser un conjunto de puntos que, poco a poco, va encontrando el modo de escalar esas montañas. Dawkins describió esta subida por el paisaje evolutivo en Escalando el monte improbable. Si pensamos en los distintos métodos metalúrgicos o en los diferentes sistemas de escritura como en puntos en un espacio evolutivo, lo que deberíamos observar con el tiempo es que esas soluciones propuestas, poco a poco, van escalando las montañas del paisaje, es decir, van siendo más adecuadas. Aunque conviene recordar que esta mejora no tiene por qué ser monotónica, siempre ascendiente, ni tiene que proceder con un ritmo continuo, algunos cambios se pueden demorar más que otros. Lo más probable es que ninguno de los escribas y artesanos involucrados tuviese una visión global de un proceso del que no eran más que una pequeña pieza. Sin embargo, si consideramos rangos de tiempo suficientemente amplios, tanto en la metalurgia como en la escritura, está claro que poco a poco se fueron obteniendo soluciones cada vez más adecuadas, cada vez más elevadas en el espacio evolutivo. La escritura era mejor en el sentido de que cada vez se podía representar el lenguaje con mayor fidelidad y en que se podía conseguir alfabetizar más personas con un esfuerzo menor. Y en la metalurgia las herramientas creadas por los herreros también estuvieron cada vez mejor adaptadas a las tareas que tenían encomendadas. Por ejemplo, los arados labraban más eficientemente el campo y las espadas eran más capaces de atravesar al enemigo. Esta mejora progresiva es una característica típica de los procesos evolutivos. Otros autores han planteado también la posibilidad de que la evolución fuese la responsable de algunos otros objetos tecnológicos como el sombrero de cowboy177 o las ratoneras.178 Llegados a este punto tal vez sea conveniente comentar algunas de las propuestas que distintos autores han hecho acerca de la evolución cultural y hacer algunas matizaciones. Tal vez la noción fundamental que comparten las distintas propuestas es que hay ideas que se imitan más que otras y que esta selección conlleva un aumento en la popularidad de algunas de ellas.179 Daniel Dennett defiende que las distintas ideas compiten en el entorno formado por nuestras mentes y que las que mejor se adaptan a ser copiadas por nuestros sistemas cognitivos, por ejemplo, las más memorables, son las que acaban teniendo un mayor éxito cultural.180 Dennett ha planteado que bastantes de los aspectos del fenómeno religioso pueden haber evolucionado para ser más contagiosos.181 Por ejemplo, una vez se implanta en una mente la idea de que no debe confiarse en los argumentos de quien no comparte nuestro sistema de creencias, esta idea protege a todas las otras ideas de ese sistema y la aísla de otras creencias alternativas, lo que termina por favorecer su copia. Esta no es exactamente la propuesta que yo he defendido respecto a la evolución de los mes. En estos casos existe un problema tecnológico y el éxito de copia depende de la medida en la que se consiga solucionar este problema, no del grado en el que la idea se adapte a la psicología humana. Lo que se creó en el caso de la metalurgia fueron mejores espadas, no mejores historias sobre cómo matar dragones. La propuesta de Dennett liga la selección a las características de nuestras mentes, algo que seguramente sucede en muchos casos, pero esta selección también puede ser debida al éxito tecnológico. Además, recordemos que puede haber evolución sin selección, que algunos aspectos pueden ser neutrales. Hay características que no influyen en el éxito reproductivo y, por lo tanto, la variación de su popularidad a lo largo del tiempo puede deberse simplemente al azar, para ellas el espacio evolutivo es plano, sus cambios en el espacio evolutivo son simples paseos aleatorios. A este fenómeno en biología se le denomina deriva. Esto es algo que puede haberle sucedido, hasta cierto punto, al cuento de caperucita roja. En distintos continentes existen distintas versiones del cuento.182 Algunos de los detalles que diferencian a estas versiones podrían haberse hecho populares en unos lugares y no en otros por azar. Incluso aunque asumiésemos un proceso puramente neutral la evolución acabaría creando diferentes versiones en distintos lugares a partir de una única versión original. Con esta explicación no quiero dar la impresión de que hay dos tipos de procesos evolutivos, aquellos en los que hay selección y aquellos en los que actúa la evolución neutral. La evolución neutral actuará siempre, es una consecuencia inevitable de que las poblaciones no tengan un tamaño infinito, y la selección puede ser más o menos intensa, por ejemplo, una cultura puede ser más o menos susceptible al ritmo de un cuento. En un espacio evolutivo siempre habrá un cierto movimiento debido al azar, independientemente de que este espacio sea completamente plano, tenga colinas suaves o se caracterice por elevadas montañas. Existen críticos de la evolución cultural que nos recuerdan que la cultura y la biología tienen características muy diferentes que merece la pena analizar. Una aparente diferencia entre la evolución biológica y la cultural es la distinta capacidad de mezcla que tienen los genes y las ideas. Mientras que los genes de los organismos suelen transmitirse verticalmente, de padres a hijos, y rara vez se mezclan entre ellos, las ideas culturales pueden transmitirse horizontalmente, entre individuos no emparentados, y pueden ser mezcladas en las cabezas de estos individuos para crear nuevas versiones.183 Sin embargo, esta mezcla no debe hacernos pensar que ya no tiene sentido hablar de evolución. De hecho, incluso en los seres vivos la información genética, a veces, también se transmite horizontalmente. Esto es muy común en las bacterias. Por ejemplo, la resistencia a los antibióticos es un problema grave, precisamente, porque la idea de la resistencia a antibióticos puede transferirse con facilidad incluso entre individuos de especies distintas. Aunque es cierto que incluso en el caso de las bacterias, el grado de mezcla del material genético es mucho menor del que puede darse con las ideas dentro de la mente de una persona, esta es una simple diferencia de grado. También podría pensarse que la clave que diferencia a los procesos evolutivos de los no evolutivos resida en el mecanismo de generación de las ideas. Puede que si las ideas apareciesen por simple azar debiésemos admitir que hay evolución, pero que no tenga sentido hablar de evolución cuando las soluciones son propuestas tras una deliberación consciente por parte de un ingeniero. En el primer caso, las nuevas ideas aparecerían por pequeñas modificaciones aleatorias a partir de las anteriores. En el espacio evolutivo los nuevos puntos aparecerán en una posición aleatoria cercana a la de sus antepasados. Sin embargo, en el caso de la deliberación consciente el ingeniero sería capaz de proponer una buena solución directamente, los nuevos puntos podrían aterrizar encima de las montañas del espacio evolutivo en una sola generación. En este caso el ingeniero estaría haciendo diseño dirigido. Estas dos formas de generar diseño, en principio, parecen absolutamente contrapuestas: evolución frente a diseño dirigido. El aprovechamiento del conocimiento teórico del ingeniero mediante la deliberación consciente le permite plantear nuevas soluciones que tenderán a ocupar posiciones más elevadas en el espacio evolutivo, mientras que, si los cambios se introducen al azar, por ejemplo, porque un trozo de malaquita cae en una hoguera, las nuevas ideas no tienen porqué funcionar mejor que las antiguas. Además, si el conocimiento del ingeniero es suficientemente profundo puede dar grandes saltos en el espacio evolutivo sin temor a caer en una región de malas soluciones. Un ingeniero puede aprender sobre ciencia de materiales y decidir añadir el carbono necesario para conseguir un acero óptimo. Gracias al conocimiento teórico el ingeniero es capaz de hacerse una idea aproximada de la estructura del espacio evolutivo y eso le capacita para pergeñar soluciones que en el espacio evolutivo tenderán a estar en posiciones más elevadas. Picasso dijo: yo no busco, yo encuentro.184 Quería decir que él no necesitaba ensayar distintas posibles soluciones para comprobar cuál de ellas funcionaba, simplemente su cabeza era capaz de encontrar la pepita de oro en ese inmenso espacio de posibles soluciones. Esta es prácticamente la definición del diseño dirigido, un tipo de creación que suele contraponerse a la evolución. Cuando hablamos sobre los seres popperianos dijimos que eran aquellos que podían ensayar posibles soluciones dentro de su mente gracias a los modelos que tenían del mundo externo y este es, precisamente, el secreto que les permite generar diseño dirigido. Darwin nos enseñó que para obtener diseño no era imprescindible tener comprensión alguna del problema que se está tratando de resolver, pero no cabe duda de que si disponemos del conocimiento adecuado el proceso puede acelerarse.185 Si los artesanos mesopotámicos hubiesen sabido qué es el carbono podrían haber explorado cómo su concentración influye en las propiedades del hierro y seguramente habrían logrado desarrollar acero. Uno de los motivos de que durante los siglos XVIII y el XIX el ritmo de desarrollo tecnológico aumentase vertiginosamente fue, precisamente, que los ingenieros se acercaron al conocimiento del mundo natural que los filósofos naturales y los científicos estaban generando.186 Si disponemos de un modelo del mundo lo suficientemente fiel como para reproducir dentro de nuestra mente la estructura aproximada del espacio evolutivo podemos dar grandes saltos en este espacio aterrizando directamente sobre las montañas. Gracias a esta capacidad hemos podido explorar regiones de este espacio a las que los pequeños cambios continuos de los artesanos no pudieron llevarnos. El aluminio es uno de los metales más comunes de la corteza terrestre y, actualmente, lo usamos para enrollar el kebab, pero ningún artesano babilonio o chino fue capaz jamás de conseguir aislarlo. A pesar de que su abundancia en la corteza terrestre es incluso mayor que la del hierro, ni tan siquiera se les ocurrió la posibilidad de que este increíble material pudiese existir. Otra lección que los ingenieros aprendieron de los científicos, incluso antes de que sus modelos del mundo les fuesen útiles, es que la exploración sistemática del espacio de posibles soluciones es más eficiente que la mera repetición de las recetas aprendidas de los maestros.187 La ingeniería es sistemática, la artesanía no. Para el artesano una posible alternativa consistiría en introducir grandes cambios en cada generación. De este modo podría dar grandes saltos en el espacio evolutivo. Sin embargo, esta estrategia suele fracasar ya que la inmensa mayoría del espacio evolutivo está ocupada por malas soluciones, las regiones montañosas suelen ser minúsculas. Si nos inventamos un nuevo método radicalmente distinto para extraer metales del que nos enseñó nuestro maestro sin saber nada sobre química, las probabilidades de que demos con una buena receta son prácticamente nulas. El artesano que no sabe sobre química debe limitarse a explorar el espacio de soluciones introduciendo pequeñas variaciones y comprobándolas en el mundo real, por ejemplo, forjando distintas espadas con distintos métodos y probando cuál de ellos resulta mejor. Pero el ingeniero es un ser popperiano que puede acelerar la búsqueda de soluciones haciendo que muchas de ellas mueran en su cabeza sin llegar a ensayarlas en el mundo real.188 Cuanto más precisos sean nuestros modelos del mundo, más efectivas pueden ser las manipulaciones de las ideas dentro de nuestras mentes y mayores podrán ser nuestros saltos en el espacio evolutivo. Es posible que hablar de evolución cuando nuestro conocimiento teórico sea suficiente como para crear diseño directamente dentro de nuestras cabezas sea poco útil, pero lo cierto es que evolución y diseño dirigido no son más que los dos extremos de un continuo, no existe una diferencia nítida entre ambos. Para que se genere diseño, lo fundamental es que el éxito reproductivo de la idea dependa de cómo de bueno sea su desempeño, no de cuál sea su origen. Además, lo más habitual es que nuestros modelos del mundo no sean lo suficientemente precisos como para reproducir fielmente la estructura completa del espacio de soluciones, recordemos que el mapa no es el territorio. Puede que nuestros modelos nos permitan proponer soluciones mejores que las que obtendríamos haciendo cambios al azar, como hace la mutación en los seres biológicos, pero esto no implica que seamos capaces de alcanzar de un solo salto las cimas de las montañas más altas del espacio evolutivo. Ningún ingeniero, ni siquiera utilizando aproximaciones sistemáticas, fue capaz de crear desde cero el avión comercial moderno. La propuesta de los hermanos Wright no se parecía, en absoluto, a los aparatos comerciales modernos que diariamente cruzan los océanos. Incluso Picasso mintió, o al menos exageró, al decir que él no buscaba. En realidad, hacía búsquedas sistemáticas, su proceso de creación pasaba por evaluar numerosos bocetos y ensayos hasta dar con una solución que le satisficiese.189 Que las nuevas soluciones que estamos creando sean mejores que las que haría el azar, que nuestros diseños sean parcialmente inteligentes, no implica que no estemos explorando el espacio evolutivo un poco a ciegas. Además, aunque puede que nuestros modelos nos permitan hacernos una idea del entorno cercano del espacio evolutivo, pero la niebla suele cubrir la lontananza. Puede, por ejemplo, que nuestros modelos sean lo suficientemente buenos para reproducir con una cierta fidelidad una región localizada del espacio de soluciones, pero que no seamos capaces de reproducir en nuestras cabezas la estructura de las regiones más alejadas de nuestra experiencia cotidiana. Veremos que Sócrates nos enseñó que definir un término complejo con precisión es muy difícil, incluso que puede que en la mayoría de los casos sea imposible. Pero tal vez, el ejercicio de tratar de definirlo sea útil incluso aunque no logremos alcanzar una buena definición con la que todo el mundo esté de acuerdo. Obtener una lista de características relevantes es también muy provechoso. En el caso de la evolución hay una característica necesaria: que la variación sea heredable. Si, además, hay selección, la evolución creará diseño. Por último, puede que la variación se genere completamente al azar, como en el caso de la evolución biológica, o que las nuevas ideas se creen de un modo más o menos inteligente. 2.12 No tengas compasión, busca la realidad En cualquier caso, la lección clave que debemos recordar es que: si queremos una respuesta a un problema, independientemente de cómo se llegue a la posible solución, debemos buscar el modo de contrastarla con la realidad, con esa parte del mundo que está fuera de nuestra mente. La evolución tecnológica, durante las revoluciones científica e industrial, se fue haciendo cada vez más deliberada, poco a poco el diseño se fue generando más dentro de nuestras mentes,190 y más sistemática, pero no hemos de olvidar que, al final, cualquier idea tiene que ser ensayada en el mundo real, fuera de nuestras cabezas, y si no funciona debe abandonarse. Veremos que este aspecto, esta distinción entre la generación del conocimiento y su justificación es, según los positivistas, una de las características claves del proceso científico. Esta propuesta positivista fue criticada y deberemos matizarla ya que, por desgracia, el éxito de las hipótesis científicas no puede depender exclusivamente de factores racionales, pero es una muy buena primera aproximación. Siguiendo la sencilla receta de repetir lo que ha funcionado en el pasado, pudimos avanzar en el espacio de soluciones y en unos miles de años varias culturas, independientemente, consiguieron acumular la tecnología necesaria para crear civilizaciones. Y para hacerlo no hizo falta esperar a conocer la química que hacía posible la forja de las espadas. Esta es una característica clave tanto en la tecnología como en la ciencia. Las espadas deben ser probadas en el campo de batalla y nuestras explicaciones sobre cómo funciona el mundo deben corresponderse con la realidad. Aunque en este aspecto la tecnología, como demuestran las civilizaciones antiguas, tiene ventaja frente a la ciencia. Alguien confundido por sus sesgos cognitivos puede inventar historias preciosas sobre cómo los dioses controlan las lluvias o sobre cómo se domesticó el tomate y, si tiene suficiente predicamento en su comunidad, puede que logre imponer esas historias durante un tiempo. Pero si su vida depende de una cota de malla y de una espada, los cuentos le servirán de poco, el acero no tiene misericordia, en la batalla o las espadas funcionan o mueres. La tecnología admite menos excusas que la ciencia, describir el mundo es más sufrido que manipularlo. 2.13 Resumen Desde el neolítico los seres humanos dependemos críticamente de la tecnología, especialmente de la agrícola y ganadera. Sin comida ni los pueblos ni las ciudades son posibles y, por supuesto, en nuestro mundo moderno esta dependencia ha aumentando sustancialmente en otros aspectos esenciales como la sanidad o las comunicaciones. En la actualidad tendemos a asociar ciencia y tecnología, pero la relación entre el estudio del mundo externo y su manipulación es bastante reciente. Las tecnologías antiguas fueron creadas mediante procesos evolutivos sin que nadie conociese la ciencia subyacente. Fue posible llegar a tener acero sin conocer nada sobre el papel del carbono en las aleaciones porque la justificación del resultado puede separarse del resultado y porque el primer aspecto es más crítico que el segundo. Si la espada corta, poco importa que el artesano no sepa cuál es la estructura cristalina del metal. Esto, además, crea las condiciones para poner en marcha la mejora evolutiva de las soluciones tecnológicas. Una vez disponemos de un modo que permita seleccionar de entre varias propuestas aquella más adecuada podemos esperar que, con el tiempo, las soluciones sean cada vez mejores. Esto no implica que el proceso de descubrimiento sea irrelevante. Los artesanos chinos consiguieron forjar acero, pero no se obtuvo aluminio hasta el siglo XIX. Conocer la química, tener un buen mapa del territorio subyacente, nos permite avanzar mucho más rápidamente. Este es uno de los factores que distinguen al ingeniero del artesano, el ingeniero, por ejemplo, tiene idea de la química subyacente y esto le permite proponer soluciones mucho más prometedoras que las creadas por el azaroso proceso de copia del artesano. Además, los ingenieros aprendieron junto a los científicos a ser sistemáticos, a explorar con mucho más cuidado el espacio de posibilidades. A estas mejoras, como veremos en breve, habría que añadir el uso de la lógica, la herramienta que nos permite explorar sistemáticamente la coherencia de nuestras ideas. "],["el_triunfo_de_la_razon_part.html", "El triunfo de la razón", " El triunfo de la razón "],["nace_la_filosofia.html", "3 Nace la filosofía 3.1 El giro axial 3.2 En un lugar llamado Mileto 3.3 Cosmos y logos 3.4 Logófagos 3.5 Asombro reverencial 3.6 Filosofía y religión 3.7 Libertad 3.8 Ágora, la comunidad racional 3.9 Recomendaciones racionales 3.10 La filosofía es pensamiento sistemático 3.11 Resumen", " 3 Nace la filosofía 3.1 El giro axial Alrededor del siglo VI a. C., en tres regiones tan distantes y tan diferentes como la India, China y Grecia, diversos pensadores comenzaron a evaluar con una seriedad inusual las creencias religiosas, los mitos, las tesis políticas, las recomendaciones morales y las explicaciones sobre el funcionamiento del mundo natural. Sus intereses, aproximaciones, y conclusiones fueron profundamente diferentes, pero todos tenían en común un desacostumbrado interés por el rigor intelectual. Confucio, Buda, Tales y Pitágoras fueron coetáneos y establecieron, simultáneamente, las bases de las filosofías china, india, y occidental.191 Curiosamente, fue aproximadamente en el mismo tiempo cuando se escribió el conjunto de textos que terminaron formando parte del antiguo testamento. Además, a la diversidad en los temas tratados y a las diferencias culturales, hay que añadir una amplia variedad de clases sociales; mientras que la filosofía india surgió entre sacerdotes y ascetas, la china fue cultivada, principalmente, por funcionarios y la griega por pensadores independientes. El filósofo Karl Jaspers describió esta época como la era axial, el tiempo en el que la cultura humana cambió para siempre. Al asociar a Buda con el inicio de la tradición filosófica india no quiero insinuar que el budismo sea una filosofía y no una religión. Este es un debate muy complicado. Sólo lo hago porque se le suele nombrar como ejemplo de reflexión crítica sobre la religión de su tiempo. Además, si sus discípulos siguieron o no su ejemplo es otra cuestión. En China a la época comprendida entre 551 a. C. y 233 a. C. se le denomina el periodo de las cien escuelas, fue entonces cuando se establecieron las bases de las principales escuelas de pensamiento chino. Mozi (470 a. C. - 391 a. C.), el maestro Mo, el maestro excepcional, fue el fundador del moísmo, una escuela muy atípica dentro del resto de la filosofía china. Por ejemplo, a diferencia de las demás, estaba formada por artesanos, soldados y mercaderes, en vez de por funcionarios.192 Fue un movimiento de pensadores críticos con las numerosas guerras que plagaban la China del momento y que llevaron su activismo más allá de las palabras, formando grupos paramilitares que se interponían entre las partes en conflicto para evitar guerras. Los moístas consideraban que pensar con rigor era importante y algunos se dedicaron a investigar cuestiones lógicas, creando una aproximación al conocimiento similar a la lógica deductiva.193 A pesar de este interés, no hemos de pensar que los moístas no fuesen religiosos, pues rendían culto a un dios llamado Tian, una palabra que significa cielo y naturaleza.194 Por desgracia, estos avances no interesaron especialmente a los pensadores posteriores, fueron abandonados y pocos de los escritos moístas sobrevivieron. Las escuelas filosóficas chinas más influyentes, el confucianismo y el taoísmo, fueron desarrolladas principalmente por burócratas interesados en la organización social y política.195 Confucio, el maestro Kong, (551 a. C. - 479 a. C.), fue el funcionario que fundó el confucianismo. Esta escuela tenía una filosofía política bastante conservadora: para que la sociedad funcionase adecuadamente cada individuo debía aceptar su papel, el emperador debía comportarse como un emperador, el padre como un padre y el hijo como un hijo.196 Además, consideraban que como mantener la comunidad era de vital importancia, porque es en ella donde el individuo podía desarrollarse, los deseos del individuo debían supeditarse al bien social. El confucionismo estableció las bases de la moral china tradicional y fue desarrollado en distintas direcciones por numerosos pensadores. Mencio (371 a. C. - 289 a. C.), uno de los confucianistas más eminentes, por ejemplo, sugirió que los seres humanos eran esencialmente buenos por naturaleza y que los gobernantes debían buscar el apoyo tácito del pueblo, dado que esta era la base de su legitimidad. Sin embargo, el legalismo, otro desarrollo mucho más exitoso que el de Mencio, sostenía que los seres humanos eran fundamentalmente egoístas y que sólo un gobierno fuerte era capaz de mantener el orden social. Oficialmente el legalismo, después de un período de terror político, desapareció, aunque, en realidad, muchos aspectos de esta filosofía política se fusionaron, durante la dinastía Han, con el confucianismo antiguo para dar lugar al confucianismo tradicional. El confucianismo no estaba interesado en la especulación metafísica,197 algo en lo que contrasta con la otra gran escuela filosófica china, el taoísmo. Lao-Tse, el viejo maestro, fue su supuesto fundador, aunque, en realidad, no se conoce nada de él con certeza, ni cuándo vivió, ni tan siquiera si fue un personaje histórico real. El objeto del taoísmo, a diferencia del confucianismo, que trataba sobre la relación del ser humano con la sociedad, versaba sobre la conexión entre la persona y la naturaleza. Según los taoístas, el individuo, para vivir en armonía, debía adaptarse al ritmo de lo natural y lo sobrenatural siguiendo el Tao. Por desgracia, el taoísmo no explicaba en qué consistía el tao198 ya que el tao no podía aprenderse a no ser que ya lo conocieses, los que lo conocían no hablaban sobre él y los que hablaban sobre él, en realidad, no lo conocían. El taoísmo acabó asociado a un conjunto de prácticas que lo convirtieron en algo muy similar a una religión que los funcionarios solían compatibilizar con el confucianismo.199 En cualquier caso, ninguna de estas dos escuelas filosóficas se interesó especialmente por la filosofía natural o por la epistemología, algo que sí caracterizó a la filosofía clásica griega. Mucho se ha escrito sobre las causas del origen independiente, pero coetáneo, de las escuelas filosóficas chinas, indias y griegas y, aunque se pueden apuntar algunas circunstancias, que parecen relevantes, es imposible determinar con precisión los motivos de unos desarrollos sociales tan complejos. En historia es mucho más sencillo establecer los hechos que las causas. A pesar de esta dificultad, discutir algunas de los motivos que se han planteado, tal vez pueda enseñarnos algo. En todas las regiones en las que apareció la filosofía había ciudades, por lo que este parece ser un requisito necesario, aunque no suficiente. En muchas otras regiones urbanizadas, por ejemplo, en Mesopotamia y Egipto no surgió la filosofía. La escritura también pudo ser un factor relevante, ya que permite fijar las creencias, mitos e historias de las culturas orales, algo que facilita el análisis crítico de las mismas.200 En una cultura oral las ideas cambian rápidamente al saltar de una mente a otra y esta fluidez dificulta su análisis. Tanto en China como en Grecia el florecimiento de la filosofía coincidió con el desarrollo de una escritura plena, por lo que, aunque la escritura tampoco es una causa suficiente sí puede que sea un requisito necesario. Otra característica de las sociedades china y griega de la época es el crecimiento económico. A pesar de la gran inestabilidad política, debida a continuas guerras entre pequeños reinos o ciudades estado, entre el 800 a. C. y el 400 a. C. tanto la economía china como la griega crecieron notablemente. En ambas regiones se dominaba ya la siderurgia y hacía relativamente poco tiempo que el hierro se había abaratado lo suficiente como para poder fabricar abundantes herramientas y armas con él. Además, alrededor del 600 a. C. en el reino de Lidia, en la región occidental de la actual Turquía, se acuñaron las primeras monedas, una innovación que también se desarrolló independientemente en China y que estimuló el comercio en ambas áreas. Los sumerios fueron los inventores de la deuda y los bancos, algo que, hoy en día, asociamos al dinero. Pero los préstamos en Mesopotamia se hacían en especie, por ejemplo, en trigo. El valor de la moneda, sin embargo, no depende del valor real del material que la constituye sino de la confianza de la comunidad, a esto se le denomina valor fiduciario, del latín fides, fe. 3.2 En un lugar llamado Mileto Enormes son el legado y los monumentos de nuestro imperio. Las edades futuras se maravillarán por nuestros logros, como ahora lo hace la nuestra. Pericles. Independientemente de que estemos de acuerdo o no con la política de Pericles, es difícil negar que los logros de la Grecia clásica son uno de los mayores avances de la humanidad. Hace dos milenios y medio, en el siglo VI a. C., un pequeño grupo de pensadores de Jonia, una región griega situada en la actual costa turca, comenzó a dar respuestas naturalistas a las causas de los fenómenos naturales, inaugurando así la tradición intelectual que terminaría por conducir a Darwin, Noether o Einstein. Mileto, la cuna de estos filósofos, era una rica ciudad comercial jónica en contacto con Babilonia, Egipto y el Mediterráneo. Los pioneros de esta tradición: Tales, Anaximandro y Anaxímenes, eran burgueses milesios, viajeros y comerciantes,201 que compartían una gran curiosidad por el mundo natural. Aristóteles consideraba a Tales como el primer filósofo.202 Por desgracia, poco es lo que sabemos con certeza sobre él. Se dice que era matemático, astrónomo e ingeniero y se le atribuyen varios avances, algunos creíbles y otros no tanto. Cuentan que midió la altura de las pirámides egipcias comparando la longitud de sus sombras con la proyectada por una vara203 y que era capaz de calcular la distancia de un barco a la costa utilizando construcciones geométricas similares. Además, se le atribuye el desarrollo de un método para mantener el rumbo en alta mar tomando como referencia a la Osa Menor, algo de una gran utilidad para una ciudad comercial.204 Heródoto, el historiador griego clásico, y Jenófanes, otro de los primeros filósofos, cuentan que Tales fue capaz de predecir un eclipse solar, probablemente el del 28 de mayo del 585 a. C..205 De ser cierto, esta sería la primera predicción exitosa conocida, un logro extraordinario. Si lo hizo realmente se habría basado en la periodicidad de la aparición de los eclipses, algo que podría haber inferido a partir de los catálogos de las observaciones astronómicas babilónicas.206 Sin embargo, este método no le habría permitido más que una predicción aproximada, con un error de muchos meses,207 algo muy alejado de nuestras predicciones actuales basadas en modelos astronómicos precisos. Hemos de tener en cuenta que en la época de Tales se desconocía incluso la causa de los eclipses. No sería hasta un siglo después cuando Empédocles y Anaxágoras propusieron que la sombra de la Luna era la responsable.208 En cualquier caso, el mayor logro de Tales y sus discípulos no radica en que midiesen la altura de tal o cual pirámide, sino en la aproximación que tomaron ante el mundo natural. Aristóteles los destacó como los primeros physikos de la historia.209 En griego physikos significa relativo a la naturaleza, por lo que tal vez deberíamos decir que fueron los primeros filósofos naturales, ya que para Aristóteles la física no tenía las limitaciones disciplinares actuales. Al llamarlos físicos, o filósofos naturales, los contrapuso con los theologi, aquellos que achacaban los fenómenos naturales, como los rayos, los terremotos o los eclipses, al capricho de los dioses. Es decir, que Aristóteles reconoció a estos pensadores milesios como a los primeros interesados en proponer explicaciones naturales para los fenómenos naturales. Como ejemplo puede servir la explicación que Tales propuso para las crecidas del Nilo. Lo habitual es que los ríos lleven menos aguas en verano, pero en el caso del Nilo, sus vitales crecidas ocurrían precisamente en la época de menos lluvias. Tales planteó una explicación natural, que los vientos del norte empujaban el agua hacia el sur impidiendo que el Nilo desaguase, provocando así las crecidas.210 Según los poetas Homero y Hesíodo, que eran theologi y no filósofos naturales, los terremotos eran debidos a la fuerza de Poseidón, pero Anaxímenes postuló que la causa era la excesiva sequedad o humedad de la Tierra.211 Esta es una explicación similar a la que los sismólogos actuales están dando para algunos de los recientes terremotos ocurridos en California, en la que la extracción del agua de los acuíferos está causando movimientos de tierras. Estas explicaciones eran en la mayoría de los casos erróneas y se basaban en meras especulaciones sin ninguna base observacional, algo que sí aportaría posteriormente Aristóteles212 y, mucho menos, experimental,213 una innovación que habría de esperar a la revolución científica. Siempre que alguien dice que los niños son científicos natos, recuerdo que desarrollar la aproximación científica requirió siglos a los más grandes pensadores y me apena que se confunda la curiosidad con la disciplina metodológica. La aproximación milesia fue muy relevante porque, además de que buscaban causas naturales para los fenómenos naturales, asumían que sus propuestas debían estar justificadas y estas justificaciones, a su vez, debían someterse a la crítica. Este cambio, que sitúa la justificación como aproximación principal, ha sido descrito por algunos autores como la transición del mito al logos. 3.3 Cosmos y logos Si el cosmos está ordenado uno puede plantearse indagar sobre sus leyes, sobre su orden, y esto es más sencillo que cuestionarse las motivaciones de las mentes divinas; especialmente cuando esos seres no se dignan a hacer declaraciones públicas. Los dioses de las distintas mitologías suelen comportarse de un modo arbitrario e impredecible. Muchos cristianos, por ejemplo, dicen que los caminos del Señor son inescrutables, y, por lo tanto, impredecibles e incomprensibles. Sin embargo, los milesios asumieron que el cosmos estaba regido por leyes. Tal vez llegaron a esta conclusión al extrapolar la observación de que en la vida cotidiana hay regularidades. Si uno lanza una piedra, ésta siempre acaba por caer unos metros más allá y el movimiento de los astros está relacionado con las estaciones, una observación a partir de la cual los mesopotámicos y los chinos habían creado elaborados sistemas de predicción astrológica (de nula eficacia). Esta asunción fue aventurada, podría haber ocurrido que los terremotos, realmente, hubiesen estado causados por el capricho Poseidón, es sólo a posteriori, después de miles de años, que podemos comprobar cuán fructífera resultó esa premisa. Hasta el momento, tal y como le dijo Laplace a Napoleón cuando le presentó su Tratado de mecánica celeste, nunca hemos necesitado de la hipótesis teísta. Siempre que hemos iluminado una nueva región del cosmos, lo que hemos encontrado son leyes naturales, si hay algún dios responsable se ha tomado la molestia de esconderse bastante bien. Podría decirse que el cosmos nació en Mileto. Cosmos originalmente, en griego antiguo, significaba orden214 y fue en este lugar y en este momento cuando por primera vez alguien asumió que la naturaleza estaba ordenada, que era un cosmos y no un caos sujeto a arbitrariedades divinas. Partir de que existe un orden comprensible fue un avance clave porque esta tesis estimula la investigación. Si la naturaleza obedece a razones, si es regular, puede estudiarse y, tal vez, podamos conocerla.215 Sin regularidades la ciencia sería imposible. Incluso podría estudiarse un universo habitado por mentes divinas, pero lo que es imprescindible para el éxito de la ciencia es que haya orden. Si hubiese dioses para poder comprenderlos al menos una parte importante de sus designios debería seguir un patrón. Este orden del cosmos es el logos. Logos es un término complejo y difícil de traducir.216 En principio, el sentido original del término logos significaba palabra.217 De ahí deriva, por ejemplo, nuestro término logopedia, la educación de la palabra. Pero en las manos de los filósofos logos adquirió otros significados.218 Pasó a significar lenguaje o capacidad humana de representar el mundo simbólicamente.219 Además, adquirió el sentido del estudio o la comprensión de un área de conocimiento. A este sentido hace referencia nuestro sufijo logía: la biología es el estudio de la vida, la teología de lo divino y la antropología de lo humano. El logos terminó refiriéndose también al propio orden del cosmos.220 Para los filósofos clásicos, como veremos, no había una separación muy nítida entre el orden del cosmos y nuestra comprensión de ese orden. Esta idea quedó fosilizada en el inicio del evangelio de Juan: En el principio era la palabra y la palabra estaba con Dios y Dios era la palabra. Esta frase, entendida literalmente en castellano resulta, cuanto menos, extraña, pero si recordamos que este texto se escribió originalmente en griego, y que el término que se ha traducido como palabra es logos, podríamos hacer una traducción algo más clara: En el principio fue el orden del cosmos y el orden estaba con dios y dios era el orden. Una traducción, claro está, que tendría profundas consecuencias teológicas que no estoy ni capacitado ni interesado en analizar. Dos mil seiscientos años después de esta osada propuesta jónica estamos tan acostumbrados a la idea de que el cosmos es cognoscible que la damos por sentada. Aunque creo que conviene reflexionar sobre lo profundamente asombroso y admirable que resulta que hayamos podido aprender tanto sobre el mundo que nos rodea.221 Hemos observado el destello del Big Bang, hemos aprendido que el secreto de la vida radica en el apareamiento de las bases nitrogenadas, hemos ordenado la química en una pequeña tabla y estamos empezando a comprender los propios sistemas cognitivos que hacen posible que entendamos tanto. Es asombroso que el universo tenga un orden capaz de ser comprendido, al menos parcialmente, por nuestras limitadas mentes. Einstein, reflexionando sobre esta cuestión, dijo:222 El misterio eterno del mundo es su comprensibilidad. Conviene recordar que es todavía mucho lo que no entendemos. Por ejemplo, no somos capaces de predecir la evolución de los sistemas complejos como la bolsa. Ni siquiera somos capaces de inferir la estructura tridimensional de una proteína a partir de su secuencia de aminoácidos, algo que en la célula, para muchas proteínas, suele resolver en cuestión de microsegundos.223 En realidad, no es fácil entender completamente ni siquiera el movimiento de los gatos. Un gato es capaz de girar mientras cae para llegar al suelo apoyando las cuatro patas. Esto es algo que no parece muy complicado para el gato, pero es un rompecabezas físico. En física hay un principio, denominado principio de conservación del momento angular, que, aparentemente, debería impedir que un objeto rígido varíe su velocidad de giro sin aplicar una fuerza externa. Este principio es análogo al de la conservación del momento lineal, que impide que los astronautas comiencen a moverse o se detengan sin apoyarse en algún lugar o sin un propulsor. A pesar de esto, los gatos son capaces de iniciar el giro mientras caen y detenerlo cuando sus cuatro patas apuntan al suelo sin apoyarse en nada. Cuando les pregunto a mis amigos físicos por esta cuestión me dicen que el secreto radica en que el gato no es un objeto rígido, sino que es capaz de girar partes distintas de su cuerpo en distintos sentidos al mismo tiempo y que, por lo tanto, la aplicación del principio de conservación del momento angular a este caso no es trivial. Cuando sigo insistiendo y les pido los detalles o bien confiesan no conocerlos o bien empiezan a hablar de complicadas matemáticas. Por fortuna, hay partes del cosmos más sencillas de entender que la caída de un gato, por ejemplo, el movimiento de los planetas, las estrellas y las galaxias, que podemos analizar con mayor facilidad. Dado el tremendo éxito de la ciencia hemos asumido que el mundo es comprensible, pero haríamos bien en no darlo por sentado, es mucho lo que no sabemos y puede que haya bastantes problemas que nunca lleguemos a solventar con detalle. 3.4 Logófagos Otra característica novedosa de los filósofos clásicos es que buscaban el conocimiento por sí mismo. Cuando investigaban el mundo natural o la geometría, no sólo no esperaban obtener un beneficio inmediato, sino que la mera idea de buscar una compensación más allá del gozo intelectual les parecía indigna. Los pitagóricos, por ejemplo, sostenían que el mundo natural debía estudiarse por sí mismo, no esperando un resultado práctico224 y Aristóteles defendía que el conocimiento era el más digno de los placeres, un puro gozo intelectual.225 Cuando Glauco responde a Sócrates, en un diálogo platónico, que los reyes deben estudiar astronomía por su utilidad en la elaboración del calendario y la navegación, Sócrates le reprende por ese vulgar utilitarismo;226 el conocimiento debe buscarse por su belleza intrínseca.227 El interés por el mundo natural de los milesios, de Platón o de Aristóteles puede parecernos, desde nuestra perspectiva actual, esperable, pero es en realidad muy sorprendente. En ninguna otra civilización anterior tuvo éxito una comunidad de pensadores con estas inclinaciones. Hoy en día asociamos la ciencia a la tecnología y, por lo tanto, nos parece útil que se investigue el mundo natural. Este es uno de los motivos por los que los gobiernos y las empresas financian el esfuerzo científico. Pero ya comentamos que en el mundo antiguo las explicaciones sobre el mundo natural y el conocimiento práctico estaban completamente separadas y que eran cultivadas por distintos grupos de personas: mientras sacerdotes, literatos y filósofos trataban de explicar el mundo, los encargados de modificarlo eran los artesanos. Hasta la Edad Media se insistiría en la distinción entre conocimiento teórico y práctico. Una distinción que los griegos clásicos marcaban con dos términos diferenciados: episteme (conocimiento o ciencia) y techné (técnica u oficio). Actualmente distinguimos entre ciencia pura y aplicada. El estudio de la clasificación de las especies de tomate endémicas de las islas Galápagos o de la estructura interna del protón es ciencia pura, mientras que la investigación de las moléculas que disgregan las placas amiloides es ciencia aplicada. Esta es una distinción, hasta cierto punto útil, aunque no del todo nítida y corremos el riesgo de ser confundidos por ella. El conocimiento forma una red y no es fácil saber por dónde vamos a acabar saliendo una vez empezamos a tirar del hilo. Es difícil predecir qué terminará teniendo utilidad y qué no. Pasteur dijo que no debíamos hablar de ciencia aplicada, sino de aplicaciones de la ciencia. Cuando Faraday experimentó con la rotación y el electromagnetismo no estaba tratando de crear el motor eléctrico y cuando Maxwell creó una teoría integrada de la electricidad y el magnetismo no estaba tratando de inventar la radio. Paul Dirac fue un teórico brillante, que uniendo la relatividad especial y la mecánica cuántica, construyó una teoría capaz de describir la antimateria. Sin embargo, cometió un gran error al afirmar que su trabajo no tenía ninguna aplicación práctica. Actualmente la antimateria se utiliza, por ejemplo, en la tomografía por emisión de positrones para diagnosticar el cáncer. Incluso las cuestiones más abstrusas pueden acabar teniendo aplicaciones inesperadas. Turing estaba trabajando en lógica matemática cuando utilizó la descripción de una máquina ideal en la demostración de un teorema. Esta máquina de Turing acabó convirtiéndose en un hito importante en el desarrollo que condujo a los ordenadores actuales, algo muy difícil de anticipar a priori. John Herschel, un científico decimonónico, llegó a afirmar que no sólo es posible que algunas especulaciones teóricas sin aparente utilidad puedan terminar produciendo aplicaciones prácticas, sino que son precisamente éstas las que producen los avances mayores y más disruptivos.228 En el siglo XVIII un inversor interesado en desarrollar fuentes de luz más eficientes no habría financiado estudios relacionados con la electricidad y el magnetismo, sino con la cera y las mechas.229 Es casi imposible predecir qué inversión en ciencia terminará por hacer que bajen los precios del pan de un modo radical veinte o cincuenta años después. Sin embargo, a pesar de todas estas puntualizaciones, hay algo que debemos conceder a los filósofos clásicos, hay campos de investigación con una aplicación más inmediata y otros más alejados y ellos, claramente, apostaron por estos últimos, que consideraban más puros y merecedores de la atención del verdadero filósofo. Muchos científicos actuales siguen sintiéndose identificados por esta búsqueda del conocimiento por sí mismo. En la Grecia clásica la mayoría de los filósofos trataba con condescendencia a aquellos interesados por el beneficio inmediato. Los sofistas, por ejemplo, que enseñaban por dinero230 fueron comparados con prostitutas intelectuales.231 Es cierto que muchos filósofos eran ricos, por ejemplo, Platón y Aristóteles, pero incluso Sócrates, que era hijo de un albañil y una partera y pobre, nunca cobró por sus enseñanzas.232 Yo que cobro por dar clase soy plenamente consciente de la tensión que existe entre enseñar a un alumno y complacer a un cliente. En la enseñanza es importante buscar oportunidades para que el alumno se equivoque, confrontando así sus creencias previas erróneas, pero a los clientes no suele agradarles que se les diga que están equivocados, especialmente cuando están pagando por obtener un título que puede servirles como trampolín para obtener una buena posición social. Para los filósofos clásicos el conocimiento es algo que uno perseguía por placer cuando disponía de tiempo libre. La palabra escuela deriva del griego scholé, ocio. Supongo que a Sócrates y a Platón les habría parecido irónico que las instituciones escolares acabasen convirtiéndose en una obligación. El interés por cualquier detalle, incluso por los más abstrusos, llegó a ser bastante apasionado, tanto, que en alguna ocasión se acabó barajando como móvil de asesinatos. La longitud de la diagonal de un cuadrado de lado unitario no puede ser expresada como un número racional. Un número racional es aquel que puede obtenerse como el cociente, la razón, de dos números enteros. Por ejemplo, 1/2 o 2/3 son racionales. Pero parece que Hípaso de Metaponto, uno de los primeros discípulos de Pitágoras, demostró que esa diagonal no era racional. Algo que realmente es cierto, ya que la raíz cuadrada de dos es, efectivamente, irracional, es un número que no puede ser expresado como el cociente de dos enteros. Que a estos números los denominemos irracionales es un recuerdo del poco agrado con el que los griegos clásicos trataban estas cantidades. De hecho, nunca llegaron a saber muy bien qué hacer con ellos, lo cual limitó sus matemáticas. En cualquier caso, puede que Hípaso demostrase esta irracionalidad de la diagonal del cuadrado o algún otro teorema relacionado con estos números. La secta religioso-filosófica de los pitagóricos era muy hermética y los detalles de lo que sucedía dentro no nos han llegado. Lo que sí sabemos es lo que la gente acabó pensando al respecto. Jámblico, un filósofo pitagórico y neoplatónico de la época romana, es decir de algunos siglos posteriores al incidente, dijo que la ofensa cometida por Hípaso fue tan grande que los dioses lo castigaron ahogándolo en el mar. Otros afirmaron que no fueron los dioses sino sus propios compañeros los que lo asesinaron lanzándolo por la borda de un barco como castigo por haber revelado un hecho tan desagradable. Probablemente nunca sabremos lo qué sucedió y espero por el bien de Hípaso, de sus compañeros y de las matemáticas, que este asesinato no sea más que una leyenda. Aunque lo que sí queda claro es que a los comentaristas de estos hechos no les extrañó demasiado que un pitagórico hubiese matado a otro por una discusión relativa a la teoría de números. No sé qué clase de películas de policías veis vosotros, pero en las que yo veo el móvil suele ser el dinero o el odio, no los números irracionales. Este interés por el conocimiento puro, alejado de cualquier posible aplicación, especialmente el relativo al mundo natural, es una peculiaridad de la Grecia clásica y es lícito preguntarse por las causas que llevaron a las comunidades filosóficas presocráticas a emprender un camino tan alejado de los filósofos chinos, más interesados por lo social y político o del de los indios, más comprometidos con el desarrollo humano, por la metafísica y la religión. Hay autores que nos recuerdan que en la sociedad griega se valoraba la excelencia, una virtud que denominaban areté. Este respeto por la excelencia se manifestaba, por ejemplo, en las numerosas competiciones que buscaban homenajear a los campeones de cada campo. Los griegos tenían concursos para todo: las Olimpiadas de los deportes, el festival anual de Dionisio de teatro, además de competiciones musicales, de danza y debate.233 Los filósofos serían, simplemente, los olimpistas del conocimiento. Pero que valorasen la excelencia no implica que debiese apasionarles buscarla en lugares tan extraños como la raíz cuadrada de dos y esto es, precisamente, lo que pensaban muchos de sus conciudadanos. Aristófanes, uno de los más afamados comediógrafos griegos, se burló de Sócrates situándolo en Las nubes. En esta obra de teatro Sócrates vuela entre las nubes mientras trata de medir cuánto saltan las pulgas.234 Los sofistas, las prostitutas que enseñaban por dinero, pensaban que la especulación estéril había hecho que Platón y compañía perdiesen cualquier conexión con el sentido común.235 Incluso la mayoría de los filósofos clásicos y helenísticos terminaron alejándose del interés de los presocráticos por el mundo natural. Epicuro creía que la búsqueda del conocimiento sólo tenía sentido si contribuía al desarrollo del ser humano236 y a Sócrates, a pesar de las chanzas de Aristófanes, lo que le interesaba era responder a la pregunta de cómo hemos de vivir.237 Estudiar las entrañas de las sepias, algo a lo que Aristóteles, como comentaremos, se dedicó con fruición era la excepción. Los intereses socráticos, mucho más cercanos a los de los filósofos chinos, fueron compartidos por la mayor parte de las escuelas helenísticas. El estoicismo romano de Séneca, Epitecto y Marco Aurelio, llegó incluso a abandonar el interés por la lógica y la metafísica y se centró en la cuestión de cómo debemos afrontar la vida.238 En una librería actual sus libros se encontrarían más cómodos en la sección de psicología que en las de matemáticas, física o biología. De modo que la cuestión no es por qué la sociedad griega se interesó por el conocimiento del mundo natural o la lógica, sino por qué lo hicieron unos cuantos individuos y, sobre todo, cómo es que estos pocos filósofos acabaron formando unas comunidades tan exitosas. Creo, como en otras ocasiones que he planteado preguntas similares, que la respuesta es compleja y que no podemos más que apuntar algunos aspectos posiblemente relevantes. La sociedad griega era profundamente comercial y estaba acostumbrada a surcar el Mediterráneo, lo que facilitaba que entrase en contacto con ideas muy diversas. Pitágoras era natural de Samos, una isla cercana a Mileto, pero se dice que aconsejado por Tales visitó Egipto, Babilonia e, incluso, la India antes de establecer su comunidad en Crotona, en la actual Italia. Y estos viajes de Pitágoras no fueron la excepción sino la norma entre los filósofos clásicos y helénicos. Por otro lado, resulta llamativo que estas extrañas ideas acabasen teniendo una influencia tan duradera en el mundo occidental. Las ideas de estas peculiares gentes bien podrían haber sufrido el mismo olvido que la lógica moísta de la China antigua y puede que su popularidad posterior sea debida a una serie de contingencias históricas. Alejandro Magno conquistó la práctica totalidad del mundo occidental civilizado e hizo un esfuerzo consciente por fusionar las culturas de oriente y occidente, lo que, como veremos, terminó causando el enorme florecimiento de la ciencia helénica en Alejandría, un avance que resonaría fuertemente en la revolución científica del XVII y el XVIII. Además, el cristianismo terminó, como también comentaremos, por absorber una gran parte de la metafísica clásica y la lógica aristotélica y esta, y no otra de las religiones que se practicaban en Roma, fue la que acabó asociada al Imperio, un poder que catapultó estas ideas hasta la Edad Media donde florecieron bajo el patrocinio de la Iglesia. Lo que tal vez sí sea común a muchas sociedades es la existencia de individuos interesados en el estudio de cuestiones que al resto les pueden parecer extrañas. Puede que esto forme parte de la variación natural humana. Puede que en todas las sociedades haya personas con una constitución psicológica que les haga sentirse atraídos por ciertos patrones y tipos de conocimiento. En la Austria de los años 30 hubo un investigador que describió a una comunidad de estudiantes como centrada por completo en sus intereses, con problemas de socialización, incapaz de aceptar ninguna conclusión sin cuestionarla239 e inmune, en muchas ocasiones, a la opinión de sus compañeros240 y de la autoridad académica. Según este investigador los intereses de estas personas solían ser bastante peculiares: astronomía, química, calendarios, mapas u horarios de transportes públicos241 y, además, tenían una fuerte inclinación por cuantificar y organizar cualquier información que pudiesen conseguir sobre esas pasiones.242 Esta es una caracterización que Aristófanes podría haber utilizado para burlarse de Tales y Aristóteles, pero Asperger, el psiquiatra austriaco del que estoy hablando, ni estaba describiendo el estereotipo del científico despistado ni haciendo burla alguna, sino que estaba refiriéndose a un conjunto de niños de su escuela vienesa que actualmente estarían diagnosticados dentro del espectro autista. Esa capacidad por obsesionarse por los detalles más nimios y esa necesidad por cuestionar y entender cualquier justificación parecen formar parte de la variación humana y son unos rasgos que podrían ayudar a ciertos investigadores a llegar más allá de la frontera, dedicando un tiempo que la mayoría de sus conciudadanos consideraría absurdo dado lo abstruso de sus intereses. Llegados a este punto debo confesar que mi carrera profesional se ha centrado en el estudio de la domesticación del tomate en la América precolombina, que he llegado a pelearme por la justificación de la estima del diámetro de los tomates mesoamericanos de hace dos mil años, que llevo 7 años dedicando mi tiempo libre a leer sobre filosofía e historia de la ciencia y que he caminado 1500 kilómetros buscando los pokemons perfectos. Antes de continuar quiero hacer unas aclaraciones porque no me gustaría que mis palabras fuesen malinterpretadas. No creo en absoluto que tener rasgos autistas sea necesario para hacer ciencia. De hecho, creo, a pesar de ser esta una cuestión empírica de la que, por desgracia, carezco de información, que la comunidad científica puede beneficiarse de aproximaciones e intereses diversos. Además, hay que recordar que el espectro autista es un trastorno muy serio que llega a ser devastador para mucha gente. Tampoco estoy afirmando que los filósofos clásicos fuesen autistas leves, no tengo la capacitación requerida como para diagnosticar a nadie y aunque la tuviese, no es posible hacer un diagnóstico fiable de gente que ya no puede ser estudiada con detalle. Lo único que trato de sugerir es que algunas de estas características parecen describir, en mayor o menor medida, a algunos científicos, por ejemplo, a Paul Dirac o a Henry Cavendish, y que sesgan algunas de las tensiones típicas de los humanos hacia terrenos muy sugerentes. La atención exagerada por el detalle irrelevante y la necesidad de clasificar y ordenar el conocimiento es algo que a muchas personas les puede parecer extraño, pero que, tal vez, a Aristóteles, que se dedicó a observar y clasificar invertebrados durante años, no le fuese completamente ajena. El compromiso con la honestidad intelectual por encima de la búsqueda de la aprobación social y de la autoridad, podría parecerle exagerado a muchos, pero claramente no se lo pareció a Galileo. De nuevo repito, no estoy sugiriendo que ni Aristóteles ni Galileo estuviesen dentro del espectro autista, simplemente afirmo que estos rasgos parecen formar parte de la variación natural humana y que puede que sean especialmente prevalentes en las comunidades dedicadas a cultivar unos intereses que, a la mayoría, podrían parecerles muy extraños. 3.5 Asombro reverencial Pero incluso aunque asumamos que algunos investigadores tenían una disposición natural a buscar el conocimiento y que este es uno de los motivos por los que recomendaban dedicar su tiempo libre a cultivar esta búsqueda, no debemos creer que para los filósofos clásicos este empeño era una simple afición, como hacer macramé o encaje de bolillos. Recordemos que para ellos este era el camino que dignificaba al ser humano. Demócrito dijo que prefería encontrar una sola explicación a ser el rey de Persia243 y tanto para Sócrates, como para Platón244 o Aristóteles245 el ideal de una vida plena era dedicarse a la búsqueda del conocimiento. Aristóteles pensaba que la investigación del cosmos nos acercaba a lo que hay de divino y elevado en los seres humanos246 y que era precisamente este impulso lo que nos distinguía del resto de animales.247 En griego ser humano es ánthropos, de ahí nuestra antropología, el estudio de los humanos, y resulta muy significativa la etimología que Platón propuso para este término: anathreî (reflexionar) + ópōpe (ver). Es decir, según Platón ánthropos, humano, significaría: que reflexiona sobre lo que ve. En realidad, actualmente no hay un acuerdo sobre la etimología de esta palabra y las propuestas más razonables son mucho menos interesantes que la platónica. Por ejemplo: aner (hombre) + opos (ojo o cara), por lo tanto ánthropos significaría, simplemente, aquel que tiene cara de humano. Sin embargo, en este caso, lo relevante no es tanto la etimología real, sobre la que no hay acuerdo, sino la idea que Platón tenía sobre ella. Somos muchos los que compartimos esta noción de que la búsqueda del conocimiento por el conocimiento, el desarrollo de la curiosidad, es un aspecto de lo humano que nos dignifica especialmente. Linneo, el fundador de la taxonomía moderna, nos denominó Homo sapiens, barro que conoce. Nuestro origen, como hemos visto, está asociado a la tierra sobre la que cultivamos nuestro sustento, pero es al levantar los ojos hacia el cielo estrellado preguntándonos por el orden del cosmos cuando estamos ejerciendo un rasgo puramente humano. Como dijo Porco Rosso, un personaje del maestro Hayao Miyazaki, un cerdo que no vuela, no es más que un cerdo, algo con lo que Platón o Aristóteles habrían estado completamente de acuerdo, ya que ellos también eran logófagos irredentos, devoradores de conocimiento. Un logófago es aquel que responde “sí” cuando le preguntan si quiere aprender, independientemente de que la materia sea o no sea útil. En cierto modo los términos logófago y filósofo compartirían una misma ambición etimológica, el reflejo del amor por el conocimiento, pero la palabra filósofo ha adquirido con el tiempo un sentido algo diferenciado que lo ha alejado de su sentido puro original, el amor o el hambre de conocimiento. Saber cuál es la edad del universo o escuchar la colisión de dos agujeros negros no tiene utilidad práctica alguna, pero algunos griegos clásicos decidieron explorar una conexión que podría calificarse como reverencial, o incluso sagrada o pura, entre lo humano y lo cósmico. Recordemos, además, que logos, no sólo hacía referencia al orden del cosmos sino a la comprensión de ese orden, por lo que, al contemplar este orden profundo, de algún modo, participamos en él. Este es el motivo por el que los pitagóricos decidieron estudiar los números y la geometría, para revelar la armonía profunda del cosmos.248 Esta es la misma motivación que llevó a Aristóteles a investigar el mundo biológico. Para ellos, como para muchos otros investigadores, este estudio era bello en sí mismo; tan era así que la palabra cosmos terminó por adquirir un nuevo significado, belleza, de ahí que hablemos de cosmética. La contemplación del logos, el orden del cosmos, no sólo era estéticamente placentera, sino que te hacía partícipe de ese orden. Los pitagóricos creían que este era el modo de trascender más allá de nuestro cuerpo mortal. Esta es una idea, que, una vez eliminados los aspectos más místicos del pitagorismo, ha sido compartida por numerosos investigadores. Ptolomeo, el gran astrónomo de la antigüedad, decía que al contemplar el orden de los astros nuestras almas participan en ese orden.249 Bertrand Russell recomendó el estudio de la filosofía porque es de este modo como nuestra mente puede participar en la grandeza del universo, lo cual constituye el mayor de los bienes,250 una idea que no resultará ajena a ninguno de los hijos intelectuales de Sagan. Este reconocimiento del orden del cosmos también es compartido por los creyentes religiosos, aunque, tal vez, estos creyentes hablen de divinidad para referirse a este orden en vez de logos. Hay aspectos compartidos por el camino religioso y el científico. El dios de Aristóteles es el logos contemplándose a sí mismo y el demiurgo platónico construye nuestro universo material utilizando como molde unas formas que podrían entenderse como la estructura del orden del cosmos, del logos. Muchas veces cuando se comenta la transición del mito al logos se menciona la crítica que hizo Jenófanes de los dioses homéricos, y es cierto que dijo que si las vacas tuviesen dioses tendrían forma de vaca, igual que los dioses de Homero no son más que copias de los seres humanos. Pero lo que no se recuerda con tanta frecuencia es que Jenófanes no era ateo, que lo que estaba criticando era la falta de respeto que suponía atribuir a los dioses envidias, adulterios o asesinatos.251 3.6 Filosofía y religión El desarrollo de la filosofía clásica, a pesar de las críticas de Jenófanes, no conllevó por parte de la población general un abandono de los dioses de Homero y Hesíodo, que continuaron constituyendo el núcleo de la educación y de la cultura griega.252 Además, aunque las propuestas de los filósofos si se distanciaron de estos dioses humanizados, no hemos de pensar que el naturalismo milesio hizo que los filósofos clásicos se hiciesen ateos. Lo divino continuó presente en la mayoría de sus cosmologías.253 Incluso los epicúreos,254 que eran atomistas, y los estoicos, que eran materialistas, creían en los dioses o, al menos, equiparaban el cosmos con dios.255 Lo que sí es cierto es que los dioses de los filósofos solían ser mucho más abstractos, más cercanos al logos que a los instintos primarios humanos. Aunque es verdad que algunas de las actitudes religiosas de algunos filósofos llegaron a ser mucho más pintorescas que esta noble búsqueda del logos. Pitágoras, por ejemplo, era considerado como una especie de profeta y fundó una secta religiosa que terminó por convertirse en escuela filosófica.256 Se dice que Pitágoras tenía un muslo de oro, que podía ver el futuro y hablar con los animales e, incluso, con los ríos.257 Además, creía en la reencarnación y decía ser el soldado que mató en la guerra de Troya a Patroclo, el amigo de Aquiles, y sus discípulos debían respetar algunos preceptos de lo más curiosos: estaba prohibido comer carne y habichuelas, tocar pollos blancos y enterrar cadáveres vestidos con lana. Sin embargo, a pesar de estas historias extravagantes consideramos a los pitagóricos filósofos relevantes porque hicieron avances fundamentales en matemáticas que justificaron debidamente y que, por tanto, podemos comprobar incluso aunque no confiemos en su palabra. Empédocles, que es el filósofo presocrático famoso por haber afirmado que el mundo está compuesto por cuatro elementos: tierra, aire, agua y fuego, también creía en la reencarnación y decía haber sido antes un niño, una niña, un pájaro, un pez y un matorral. Además, afirmaba ser un dios y se cuenta que resucitó a una mujer y que curó la peste en una ciudad completa.258 Pero, incluso aunque nos olvidemos de Empédocles y de los aspectos sectarios y místicos de los pitagóricos, cabe preguntarse si los filósofos clásicos fueron religiosos o no. Para contestar a esta pregunta deberíamos definir antes qué entendemos por religión, algo sobre lo que no hay un consenso. Espero que vaya observándose un patrón con los problemas de definición, casi ningún término interesante relativo a un fenómeno complejo suele ser fácil de definir. Es común asumir que se da un fenómeno religioso cuando alguien cree en un ser sobrenatural, pero las distintas religiones tienen metafísicas muy diferentes y, además, son fenómenos culturales que no se limitan a unas creencias metafísicas concretas. Hay religiones teístas, como el cristianismo, que no sólo creen que el universo fue creado por un ser sobrenatural, sino que este ser sigue interviniendo en él. Otros creyentes religiosos aceptan que el cosmos fue creado por un dios, pero asumen que una vez fijadas las leyes que lo rigen éste ya no vuelve a intervenir. Algunas religiones son monoteístas, otras dualistas o politeístas, e, incluso, hay quien, como los estoicos, los moístas o Spinoza, ha planteado la identificación de dios con la naturaleza. Además, una religión es mucho más que un conjunto de creencias metafísicas e incluye, al menos, un grupo de prácticas asociadas. Estas recomendaciones u obligaciones sobre qué ceremonias deben celebrarse o qué reglas morales deben seguirse son tan importantes o más que la creencia en seres sobrenaturales. Hay incluso ejemplos de religiones ateas centradas alrededor de la práctica y la comunidad, como, por ejemplo, el satanismo laveyano, algunos tipos de budismo, el jainismo o algunos tipos de humanismo (aunque esto último es algo que muchos humanistas discutirían). Lo que sí es cierto es que las religiones tienen sistemas de creencias que pueden ser analizados filosóficamente o que constituyen en sí mismos sistemas filosóficos con ideas metafísicas y epistemológicas, directrices morales e hipótesis sobre el funcionamiento del mundo natural. Si nos limitamos a estos aspectos sería complicado distinguir algunas propuestas filosóficas de las creencias de algunas religiones. Tal vez uno de los casos más claros de esta cercanía lo constituya el neoplatonismo, que llegó a ser integrado por los teólogos cristianos formando dos metafísicas paralelas, la cristiana y la neoplatónica, con las que se podría jugar al juego de las 7 diferencias. Muchas de las cuestiones que tratan de responder los sistemas de creencias religiosos fueron compartidas por los filósofos clásicos ya que son, en realidad, universales: cuál es el papel del humano ante el universo y ante sus congéneres, cuál es la realidad subyacente a nuestra experiencia cotidiana y si esta realidad permite algún tipo de trascendencia. Es decir, son las preguntas sobre la vida, el universo y todo lo demás cuya respuesta es, indudablemente, 42. Las explicaciones míticas antiguas, como las filosóficas o las religiosas, simplemente ansían explicar el mundo.259 Lo que diferencia a las creencias religiosas y filosóficas no son necesariamente las conclusiones a las que se llegan sino, sobre todo, el modo en el que se justifican esas creencias. Los filósofos presocráticos asumieron que sus conclusiones debían justificarse260 y este es, precisamente, el motivo por el que se les considera filósofos, independientemente de que ellos se creyesen profetas, dioses, héroes o simples mortales. Esta obligación de justificar los argumentos y de defender estas justificaciones mediante la razón es lo que diferencia a la filosofía griega de otras de las producciones culturales de esa misma sociedad.261 Hesíodo y Homero, a diferencia de Pitágoras o Empédocles, no argumentaban, simplemente narraban unas historias de las que debía extraerse entretenimiento y conclusiones morales.262 Tal vez uno de los mejores ejemplos para distinguir entre ambas aproximaciones sea el de la teología natural de Tomás de Aquino, un extraordinario filósofo y teólogo medieval que acabó siendo nombrado santo y doctor de la Iglesia. La teología natural es un ejercicio filosófico, no teológico, ya que trata de justificar la existencia de dios sin recurrir a la revelación de los profetas. Tomás presentó 5 justificaciones independientes de la existencia de dios,263 algunas tomadas directamente del pensamiento aristotélico. Por ejemplo, si todo tiene una causa previa debe haber una causa inicial que inicie esta cadena y, según Tomás, esta causa debe de ser dios. Otro de los argumentos más convincentes es el del diseño. El diseño y el propósito son aparentes en la naturaleza, mi gata, que ahora duerme junto a mí, disfruta de unas enormes orejas que le otorgan un oído exquisito y tiene unos bigotes sensibles que le permiten cazar incluso en la más completa oscuridad. ¿Quién sino dios puede haber generado este diseño pensaron Tomás y otros muchos filósofos? Antes de que el darwinismo nos mostrase como puede generarse diseño sin diseñador había que ser un gigante intelectual de la talla de Hume para encontrar el fallo en este razonamiento. De todos modos, lo relevante no es que estas conclusiones fuesen aceptadas o no. Ya en la Edad Media Guillermo de Ockham criticó razonadamente estas pretendidas pruebas264 y, en la actualidad, la mayoría de filósofos no sólo son ateos, sino que también rechazan las metafísicas de los presocráticos o de Platón. Lo importante es que al asumir que una conclusión debe ser justificada mediante un análisis racional, y que este análisis debe ser defendido en el ágora, se está haciendo filosofía. En lo que sí estaban de acuerdo Tomás y Ockham265 era en que la diferencia entre la filosofía y la teología radicaba en la aceptación de las revelaciones de los profetas.266 Mientras que la teología acepta esas revelaciones, al menos las de algunos profetas, la filosofía se basa exclusivamente en evidencias públicas y en la razón. Este es un tema que trataremos con más detalle cuando discutamos sobre si las religiones pueden constituir sistemas epistémicos alternativos. Otra de las diferencias entre la religión y la filosofía es que esta última suele ser mucho más cuidadosa con el análisis conceptual. Antes de preguntarle a un filósofo qué es el conocimiento harás bien en comprar unos cuantos refrescos y unas papas, porque te va a estar dando la brasa con propuestas, matizaciones y contramatizaciones durante horas. Sin embargo, cuando le preguntas a un creyente religioso qué es dios lo más normal es que te devuelva una respuesta vaga y si se lo preguntas a unos cuantos de la misma religión no te extrañes si cada uno te conteste algo diferente. Esto es algo que la teología, a diferencia de la religión más cotidiana, intenta mejorar, aunque, en mi opinión, lo hace de un modo un tanto deshonesto ya que suele mantener un doble discurso dependiendo de si el interlocutor es otro teólogo o de si están en la misa de los domingos. Por ejemplo, deberían explicar con más claridad a todo el mundo que la Biblia, el suspuesto texto revelado está plagado de contradicciones. ¿Eva fue creada a la vez que Adán o a partir de su costilla? ¿Nos pide dios que no matemos o nos pide que realicemos genocidios contra los que no creen en él? Alguien que aspira a ser riguroso no debe esconder estos problemas bajo la alfombra diciendo que algunos textos son meramente alegóricos. Si interpretamos la revelación según nuestras ideas, ¿qué sentido tiene que digamos que creemos en la revelación? Algo que es importante recordar es que la comparación que tiene sentido es la de los sistemas de creencias religiosos y los sistemas de creencias filosóficos. Comparar la religión con la ciencia, algo que yo solía hacer, es muy limitado, ya que la ciencia sólo trata sobre las cuestiones factuales relativas al mundo natural. Es cierto que se puede discutir si la Tierra gira o no gira alrededor del Sol, pero las propuestas religiosas van mucho más allá, ya que incluyen recomendaciones morales, algo que compete a la filosofía moral y la axiología, la rama de la filosofía que trata sobre los valores, y no a la ciencia. La ciencia es la aproximación adecuada si queremos contestar a una pregunta relativa a cómo es el mundo, pero no puede indicarnos cómo debería ser. Podemos establecer científicamente que hay homosexualidad en el mundo animal, pero para derivar conclusiones morales, necesariamente tendremos que hacer uso de valores, algo que compete a la filosofía moral. Esto es algo que suele confundirse cuando algunos científicos hablan sobre los magisterios separados de la ciencia y la religión. En primer lugar, no es cierto que las religiones no hagan afirmaciones factuales, que se lo cuenten a Bruno o a Galileo, y, en segundo lugar, cuando dicen que la religión trata sobre la moral y la ciencia no, están afirmando algo cierto, pero irrelevante ya que es la filosofía moral la que trata sobre la moral y no la ciencia. Por lo tanto, la comparación adecuada es entre filosofía y sistemas de creencias religiosos. 3.7 Libertad Un aspecto esencial de la filosofía es la crítica racional, por lo tanto, sin libertad intelectual no puede haber una verdadera filosofía. John Stuart Mill, el filósofo y economista decimonónico, sostenía que debíamos ser especialmente cautos y que no teníamos que reprimir las opiniones que no compartimos, dado que si las restringiésemos podríamos estar suprimiendo una idea de la que, eventualmente, podríamos aprender algo.267 Esto, por supuesto, no implica que tengamos que dar la razón a estas posiciones, que no debamos criticarlas o que hayamos de atender a cualquier crítico irracional, sino, tan sólo, que no debemos tratar de prohibirlas. Tampoco creo que implique que debamos permitir cualquier opinión, aunque hay casos muy extremos que sí deben ser reprimidos, especialmente aquellos en los que se pide que se atente contra la vida o la integridad física de las personas. Las religiones, especialmente cuando están cerca del poder político, no suelen defender de un modo tan entusiasta la crítica y la investigación. Algunas mitologías incluso llegan a condenar el acceso al conocimiento: Entonces la serpiente dijo a la mujer: — Ciertamente no morirán. Es que Dios sabe que el día que coman de él, los ojos les serán abiertos, y serán como Dios, conociendo el bien y el mal. (…) - Entonces el SEÑOR Dios dijo (…) Porque obedeciste la voz de tu mujer y comiste del árbol del que te mandé diciendo: “No comas de él”, sea maldita la tierra por tu causa. Con dolor comerás de ella todos los días de tu vida; 18 espinos y cardos te producirá, y comerás plantas del campo. Con el sudor de tu frente comerás el pan hasta que vuelvas a la tierra, pues de ella fuiste tomado. Porque polvo eres y al polvo volverás (Génesis 2-3). La curiosidad debería ser premiada, no castigada y resulta extraño que cualquier religión que se crea realmente en posesión de la verdad reprima la investigación racional ya que, como defendía Tomás de Aquino, que estaba realmente seguro de su creencia en el dios cristiano, si asumimos que la revelación es verdadera no es posible que el camino de la razón contradiga el de la revelación puesto que ambos deben conducirnos a la verdad. Por supuesto, podría ser que nuestros razonamientos fuesen erróneos, pero para eso está la filosofía, para criticarlos y matizarlos hasta corregirlos. En mi opinión estas restricciones a la libertad de pensamiento tienen bastante que ver con el control social, además de con una posible inseguridad ante el imparable éxito del conocimiento del mundo natural por parte de la ciencia, que no suele confirmar las revelaciones, y del avance en los sistemas éticos de la filosofía. Dicho esto, debo reconocer que una parte importante de las acusaciones ilustradas, que yo creía ciertas, a la Iglesia medieval tienen mucho de leyenda negra. La Iglesia medieval fue una decidida promotora del conocimiento y de la filosofía.268 Es verdad que, durante la primera mitad de la Edad Media, hasta Carlomagno,269 se perdió mucho del conocimiento clásico y helenístico, pero esto se debió más al caos social, a la pobreza y a la consiguiente falta de intelectuales que a cualquier otro motivo. Durante la segunda mitad de la Edad Media, que podría denominarse Plena, hubo una mayor estabilidad social acompañada de un gran desarrollo económico y cultural.270 Hubo una revolución tecnológica: mejoras agrícolas relacionadas con la popularización del molino de agua,271 el arado por caballo y el barbecho que aumentaron el rendimiento agrícola que permitieron el aumento de la población. Entre 1000 y 1300 la población europea se duplicó, triplicó o cuadruplicó.272 En el siglo XIII la Europa cristina se había urbanizado y los mercaderes y artesanos se habían hecho prominentes. Estas ricas ciudades levantaron numerosas catedrales, entre 1180 y 1270 se construyeron 80 catedrales y 500 abadías en Europa.273 Esta urbanización acompañada por la prosperidad económica y social fomentó el nacimiento de escuelas y universidades y el desarrollo intelectual. Fue entonces cuando la Iglesia promovió el estudio de la filosofía y la teología.274 El renacimiento cultural del siglo XIV y la posterior revolución científica habrían sido impensables sin esta urbanización previa.275 El término Edad Media podría abarcar desde la caída del Imperio Romano, alrededor del 500 a. C., al renacimiento de 1450.276 Un periodo muy amplio que abarcó épocas con unas características muy heterogéneas y que, a pesar de incluirse bajo un mismo término, no hemos de confundir. Tal vez sería conveniente recordar la nomenclatura anglosajona de Edades Medias para marcar la distinción entre la pobreza de la primera mitad y la clara recuperación económica, social e intelectual de la segunda. Esta recuperación económica y social se vio truncada por la hambruna de 1315, la Guerra de los Cien Años, iniciada en 1337 y la llegada de la peste bubónica a mediados del siglo XIV.277 En cualquier caso, la Iglesia medieval tenía un claro interés en hacer una defensa crítica de sus posiciones278 y era consciente del gran valor de la filosofía clásica. Suele criticarse la filosofía escolástica por resultar muy técnica y compleja,279 pero esto se debe, precisamente, a que gracias al patronazgo eclesiástico se pudieron profesionalizar los pensadores. La sociedad griega no financió a los filósofos clásicos, pero la Iglesia medieval sí pagó a Tomás de Aquino, a Guillermo de Ockham y a muchos otros. Aunque a pesar de este claro apoyo, es cierto que la Iglesia medieval siempre mantuvo una actitud ambivalente frente a la indagación filosófica y teológica, algo completamente ajeno a la actitud de los filósofos clásicos y modernos que practicaban una libertad intelectual completa. Si algún pensador llegaba a una conclusión inconveniente para la Iglesia, se exponía a la excomunión o a algo peor. Había conclusiones, especialmente las relacionadas con el mantenimiento de su poder social y político, que trataba de reprimir.280 Aunque, todo sea dicho, el éxito de esta represión fue relativo. En 1210 prohibió que los profesores de la recién fundada Universidad de París enseñasen los textos científicos de Aristóteles, pero unas pocas décadas más tarde pasaron a ser enseñanzas obligatorias. Esta relativa tolerancia se redujo durante la contrarreforma, probablemente porque la Iglesia había sufrido una clara merma de poder debida a los movimientos teológicos asociados al protestantismo. Pero este es un fenómeno más característico de la época Moderna que de la Medieval. Las condenas a Bruno y a Galileo, que han quedado marcadas en la mente de los ilustrados, son posteriores a la aparición de la imprenta, una tecnología que posibilitó una diálogo intelectual más amplio y, por lo tanto, menos fácil de controlar por parte de la Iglesia, que durante el medioevo había sido la única capaz de sufragar el elevado coste de los copistas. 3.8 Ágora, la comunidad racional Si deseamos progresar no basta con permitir la crítica racional, sino que conviene fomentarla. Debemos buscar activamente que la comunidad analice y critique nuestras justificaciones. Como humanos es fácil ser víctimas de nuestros sesgos cognitivos, de nuestro desconocimiento y del peso de la tradición. Nuestros sistemas cognitivos evolucionaron, principalmente, para extraer conclusiones rápida y eficientemente partiendo de una información parcial, no para hacer análisis pausados y rigurosos. Para conseguir hacer estas inferencias rápidas utilizamos heurísticas. Las heurísticas son atajos cognitivos que, en la mayor parte de las ocasiones, dan una respuesta muy cercana a la óptima, pero que exigen pocos recursos computacionales por lo que nos permiten salir de un apuro con celeridad.281 El problema es que nuestras heurísticas son muy vulnerables cuando nos encontramos en situaciones que violan las asunciones sobre las que están construidas. Es entonces cuando cometemos errores sistemáticos que denominamos sesgos cognitivos.282 Además, somos especialmente malos en asuntos relacionados con la inferencia lógica y estadística. Ninguna persona, por inteligente que sea, podrá manejar el conocimiento y las destrezas intelectuales disponibles en el conjunto de la comunidad. Podríamos pensar que la gente más inteligente es menos vulnerable a todas estas debilidades cognitivas, pero esto no sólo no parece ser cierto, sino que, en algunos casos, puede que estén incluso más expuestos. La inteligencia, en muchas ocasiones, es más un lastre que una solución. Hay estudios en los que se ha visto que a las personas con un mayor cociente intelectual les es más fácil encontrar justificaciones para sus ideas previas, pero tienen menos predisposición a considerar posiciones distintas a las suyas.283 Tampoco tiene por qué salvarnos tener un alto nivel educativo. Hay estudios que han encontrado que los alumnos universitarios comparten las mismas creencias paranormales, y en el mismo nivel, que la población general.284 En otros estudios se ha hallado que los profesores universitarios sí son menos crédulos que sus estudiantes,285 aunque, dentro de estos, había diferencias importantes entre los profesores de ciencias y los de humanidades. En algunos estudios se ha encontrado que la creencia en distintos fenómenos paranormales estaba correlacionada con un menor conocimiento de las herramientas que conforman el pensamiento crítico.286 Aunque también conviene ser cautos con esto, estudiar estas herramientas no sólo no garantiza nada, sino que puede llegar a ser contraproducente. Estudiar los sesgos cognitivos y las falacias lógicas puede hacer que los reconozcamos más fácilmente en los razonamientos de los demás, especialmente si eres inteligente, y eso te puede llevar a un exceso de crítica a las ideas que no compartes. Reconocer los problemas de nuestros argumentos es mucho más difícil que encontrar los problemas en las justificaciones de los demás. Feynman recomendó que fuésemos muy cautos dado que debíamos intentar no engañarnos a nosotros mismos a pesar de que somos nosotros, precisamente, los más fáciles de engañar.287 Para aprender más sobre nuestros sesgos y sobre cómo aliviarlos merece la pena estudiar algunos de los excelentes libros dedicados a estos asuntos como: Convencidos, pero equivocados del psicólogo Thomas Gilovich, Por qué creemos en cosas raras del escéptico Michael Shermer o el excelente The Skeptics’ Guide to the Universe del neurólogo y escéptico Steven Novella. Al enfrentamos a lo desconocido, a la frontera, lo hacemos con unas herramientas claramente deficientes, por lo que la actitud correcta es la humildad intelectual.288 Cuando se me ocurre una nueva idea en el laboratorio, lo primero que hago es intentar criticarla con todas mis fuerzas, buscando sus debilidades y sus limitaciones y si no consigo tumbarla o refinarla, lo siguiente que hago es ir al laboratorio de mi compañero para que él, que no comparte todos mis sesgos, me regale una crítica razonada. Sólo después de superar este esfuerzo crítico nos molestaremos por pedirle su opinión a la naturaleza mediante un experimento o un nuevo análisis. Estar equivocado no es un problema, la tragedia consiste en no corregir el error aprovechando las críticas racionales de los demás o las evidencias empíricas que podamos obtener del mundo natural. El crítico racional nos ayuda a replantear nuestras justificaciones y nuestras asunciones y este es un regalo que debemos agradecerle, aunque nuestro primer impulso al ver como destruye nuestra querida idea no sea, precisamente, darle las gracias. Este es el regalo que Sócrates hacía a sus conciudadanos al buscar analizar críticamente sus razonamientos. Los atenienses no supieron agradecer el regalo. Las comunidades habituales no tienen como único objetivo la exploración racional de cada idea. Este es uno de los motivos por los que debemos fomentar activamente el diálogo racional. Las ágoras no nacen ni se mantienen espontáneamente, deben ser cultivadas recordando continuamente que el objetivo de esas comunidades es la investigación racional y no otro. La crítica, por muy racional que pretenda ser, siempre atentará, al menos en parte, contra la cohesión comunitaria, los seres humanos tienen una aversión natural a la reprobación. Es mucho más fácil generar comunidades fuertes alrededor de dogmas indiscutibles; de hecho, esta es, precisamente, una de las funciones de los mitos sagrados. Las comunidades suelen identificarse por el respeto a unas ideas concretas. Tal vez algo que puede ayudar a las comunidades racionales sea recordar que la idea que las une es el respeto a la razón por encima de cualquier conclusión concreta, el proceso por encima de la respuesta. Dado que cualquier comunidad humana siempre estará formada por seres muy alejados del ideal vulcaniano, la búsqueda de la racionalidad siempre se encontrará en tensión con otras dinámicas sociales, como la búsqueda del apoyo de nuestros colegas y amigos o del poder. Distintas comunidades resolverán esta tensión aceptando la crítica en mayor o menor grado y esto tendrá una repercusión profunda sobre la eficiencia con la que cada comunidad consiga acercarse a la razón. Platón hacía tanta autocrítica en sus diálogos que actualmente no hay un acuerdo sobre hasta qué punto asumía su propia teoría de las formas, sobre hasta qué punto era platónico. Esta debe ser la máxima en el ágora, nuestros amigos no sólo deben tolerar, sino fomentar nuestros esfuerzos por ayudarles a eliminar el error más allá de lo que ellos mismos han sido capaces. Uno de los grandes logros de los filósofos clásicos fue conseguir mantener comunidades críticas y dinámicas. La secta pitagórica, a pesar de su respeto al maestro, terminó por convertirse en una extensa comunidad filosófica que, como veremos, alumbró uno de los avances intelectuales más extraordinarios logrados por la humanidad: la demostración matemática. Platón después de una visita a los pitagóricos,289 en 397 a. C., fundó la Academia, una institución dedicada al conocimiento en la que los estudiantes no pagaban. Aristóteles, tal vez molesto por no haber sido nombrado director de la Academia a la muerte del maestro, creó el Liceo en 335 a. C.. Epicuro reunía a su comunidad en el jardín de su casa y los estoicos se llaman así porque su comunidad se congregaba en la Stoa, una galería pública porticada. Tal vez la creación de estas comunidades críticas sea una de las aportaciones más importantes de la filosofía clásica. Una comunidad en la que se fomente la discusión racional avanzará en el camino al conocimiento, mientras que una en la que se respete al maestro o la tradición en exceso corre el riesgo de perderse en un complaciente sueño dogmático. 3.9 Recomendaciones racionales Aunque no existe un algoritmo, una receta que podamos seguir paso por paso, para acercarnos al ideal racional, sí puede ser útil considerar algunas recomendaciones generales. Bertrand Russell elaboró una lista de diez mandamientos, Sagan en El mundo y sus demonios compuso un “kit escéptico” y Daniel Dennett en el muy recomendable Intuition Pumps And Other Tools for Thinking propuso algunas aproximaciones que pueden facilitarnos la comprensión de temas complejos. En primer lugar, yo destacaría una recomendación de Sagan, no te enamores de tu hipótesis. La conclusión debe estar siempre supeditada al proceso de evaluación. Ya sabemos que es imposible no partir de un cierto conocimiento previo, pero hemos de intentar que nos sesgue lo mínimo posible. Si al comenzar un diálogo partimos de una conclusión a la que no estamos dispuestos a renunciar, incluso aunque las evidencias sean abundantes y claras, no estaremos razonando sino racionalizando. Son las evidencias y la lógica las que deben guiar el proceso y determinar la conclusión, no la conclusión la que sesgue las evidencias para defenderse de cualquier crítica. Sería ideal que todos los miembros de la comunidad respetasen este principio, aunque, por desgracia, sabemos que esto es difícil de conseguir. Sospecho que cuantos más miembros de la comunidad aspiren a dialogar racionalmente, más eficiente será el proceso de generación de conocimiento, pero no conozco ninguna receta, más allá de la educación, para conseguir mejorar esta proporción. Además, creo que si deseamos participar en una comunidad racional tenemos la obligación de respetar a los demás haciéndoles perder la mínima cantidad de tiempo posible. De modo que antes de pedirles que nos regalen su atención hemos de esforzarnos por hacer los deberes. Tenemos que buscar problemas y limitaciones en nuestras asunciones de partida y en nuestros razonamientos antes de mostrárselos a los demás. Por otro lado, si no eres un experto en el área, confía en el consenso de los expertos. Si todavía hay discusión entre ellos, si no han alcanzado el consenso, reserva el juicio, no apuestes por ninguna conclusión. Para ir en contra del juicio de los expertos debes tener excelentes razones e, incluso aunque las tengas. Para que tu criterio sea tan respetable como el de los expertos antes debes convertirte en uno de ellos, puesto que sería absurdo confiar en quien sabe menos. Es evidente que los expertos tendrán sus propios sesgos, pero también los tienes tú. Antes de empezar a dialogar asegúrate de que entiendes cuáles son las cuestiones que se están tratando. Discutir sin establecer las premisas equivale a gritarse y posturear.290 Una vez que comprendas el problema, cuestiona si las premisas y las evidencias de las que partes están bien soportadas. En muchos casos nuestra frágil memoria puede confundirnos haciéndonos confiar en datos equivocados. En el caso de que las hipótesis discutidas se refieran al mundo externo, pregúntate qué observarías en el caso de que tu hipótesis fuese correcta o en el contrario, si no hay diferencia recuerda que los positivistas se reirían de ti. Otra recomendación general es que tus conclusiones deben respetar lo obvio y si no lo hacen, has de tener excelentes razones para rechazarlo. A pesar de que el movimiento terrestre es difícil de detectar, Galileo defendió con fiereza que la Tierra se movía, pero no defendió el absurdo de que sí podía observarse el movimiento sin dificultad. Si tu reflexión te lleva a concluir que la ciencia es igual de eficiente en generar conocimiento que el vudú, puede que no hayas entendido nada sobre el juego racional o puede que estés troleando, pero en cualquier caso no estás siendo racional. A la hora de lidiar con las opiniones de los demás Russell, como John Stuart Mill, recomendó no intentar reprimir las opiniones contrarias puesto que te arriesgas a no aprender algo y, además, te expones a que cuando no detentes tú el poder sean las tuyas las reprimidas. Russell, además, añadió que no debes imponer tus argumentos simplemente por autoridad ya que esta es una victoria pírrica que te aleja de la racionalidad. Sin embargo, en un ágora racional hay que llegar mucho más allá, no sólo hay que tolerar, sino que debemos abrazar las posiciones racionales de los demás. Tanto Aristóteles como Sagan recomendaban estudiar todas las posiciones que pudiésemos encontrar sobre la cuestión estudiada. Este análisis es una herramienta fabulosa para evaluar, del modo más justo y racional posible, cualquier tema.291 Además, Mill nos instó a que invitásemos a nuestros rivales a buscar los fallos en nuestras tesis.292 Tenémos que recordar que el objetivo de una discusión racional no es ganarla sino aprender, ganar en conocimiento.293 Para aprovechar al máximo posible la oportunidad de aprendizaje que implica disponer de críticos intelectuales con opiniones dispares, no sólo debemos evaluar sus justificaciones con justicia, sino que tenemos que esforzarnos en juzgar sus posiciones del modo más caritativo posible. Para maximizar nuestras oportunidades de mejorar hemos de intentar aprender de los mejores argumentos de nuestro rival intelectual y no sólo de una versión pobre de los mismos. A esta aproximación en inglés se la denomina steel manning. Una vez nos hemos esforzado por llegar a una conclusión que creemos defendible, podemos pasar a pedir la ayuda de nuestros compañeros cercanos. Lo que buscamos de ellos no es que nos den la razón para aumentar nuestra autoestima, sino que hagan una crítica racional de nuestra posición para ayudarnos a encontrar los fallos que nosotros no hemos podido detectar. Esto es algo que hacemos habitualmente en mi laboratorio, aunque, con el tiempo, me he dado cuenta de que fuera de este entorno esta actitud crítica no es bien recibida por muchas personas. El entorno ideal estaría compuesto por críticos racionales opuestos a nuestra opinión, capaces de hacer las críticas más perspicaces partiendo de una posición distinta a la nuestra. Una práctica muy encomiable es tratar de escribir un artículo junto a tus mayores críticos para poder trabajar en un consenso. Esto es algo que en algunas ocasiones me ha funcionado muy bien, como el caso de la definición de Solanum lycopersicum var. cerasiforme.294 El grupo de Mathilde Causse sostenía que cerasiforme era un híbrido entre el tomate cultivado y el silvestre, mientras que nosotros habíamos encontrado evidencias de que era una forma semidomesticada antigua. Al analizar conjuntamente sus evidencias junto a las nuestras, llegamos al consenso de que el problema había sido que estábamos refiriéndonos a materiales que, en realidad, eran genéticamente diferentes, aunque morfológicamente fuesen muy similares. Sin embargo, en otros casos, este tipo de diálogos ha acabado como el rosario de la aurora. En mi experiencia, el éxito ha dependido de la disposición de los participantes a aceptar el proceso racional por encima de sus conclusiones previas. Una vez que hayamos alcanzado una conclusión, lo más justificada posible, podemos publicarla para que la comunidad completa tenga la oportunidad de evaluarla. A veces es posible que llegues a conclusiones impopulares, como que la Tierra se mueve o que la agricultura “ecológica” sólo tiene de ecológica la etiqueta. En estos casos Russell recomendaba, y Galileo habría estado de acuerdo, que si estas conclusiones están debidamente justificadas, la honestidad intelectual nos obliga a publicarlas, aunque nos expongamos a tener problemas. El pensador tiene la obligación, una vez ha hecho el esfuerzo de criticarse a sí mismo, de criticar a los demás. Si Galileo se hubiese callado, habría fallado en sus obligaciones morales. Otra actitud impropia de la honestidad intelectual es publicar tus conclusiones evitando exponer las objeciones que has encontrado. Esto es algo, por desgracia, muy común en la comunidad científica actual, pero que debería indignarnos. Recordemos el ejemplo de la crítica de Platón a su propia teoría de las formas.295 Si lo que uno persigue es el conocimiento y no sólo la defensa de su propia posición reconocer tus debilidades es, por supuesto, la actitud adecuada. Hemos de tratar de recordar esto cuando leemos a los expertos. Si el defensor de la propuesta no incluye autocrítica alguna es posible que sea un pseudointelectual que esté intentando vendernos humo. Casi siempre hay objeciones y si el proponente no las ha encontrado es probable que sea un verdadero experto o un simple pseudointelectual. Acabo de defender las comunidades racionales como método de progreso intelectual, pero debo hacer una puntualización importante; aunque toda crítica debe ser tolerada, sólo las racionales han de ser atendidas. 3.10 La filosofía es pensamiento sistemático Definir qué es la filosofía es en sí misma una cuestión filosófica296 y, como en el caso de otros fenómenos complejos, no se ha llegado a un consenso absoluto. Hemos de tener en cuenta que la filosofía abarca resultados tan dispares como las novelas de Albert Camus, los tratados lógico-matemáticos de Russell y Whitehead o la metafísica de Heidegger, un filósofo que sostenía que el análisis de las cuestiones más fundamentales no debe estar sometido por completo a las reglas de la lógica297 y que, por lo tanto, bordeaba el discurso ininteligible. Una vía de ataque al problema de la definición consiste en delimitar los temas que se enseñan actualmente en las facultades de filosofía: epistemología, metafísica, lógica, ética e, incluso, estética. Aunque esta aproximación, basada principalmente en ejemplos, tiene serias limitaciones. Este listado incluye áreas bastante inconexas como la lógica o la estética. Además, estoy seguro de que no todos los filósofos estarían de acuerdo con la lista de temas. Por ejemplo, muchos consideran que la lógica no es una parte de la filosofía, sino una herramienta imprescindible para cultivarla. Y lo que es peor, debemos recordar las críticas de Sócrates a las definiciones por enumeración: una lista no aclara cuáles son las características esenciales, las necesarias y suficientes. Además, a lo largo de la historia, la filosofía ha ido alumbrando a disciplinas hijas que, al menos parcialmente, han ido separándose de ella. La física se independizó entre Galileo y Newton, la biología entre Linneo y Darwin, la psicología con William James, la economía con John Stuart Mill y más tarde lo hizo la sociología. Actualmente la ciencia cognitiva está en proceso de separación e, incluso, la metafísica parece estar siendo parcialmente naturalizada. A pesar de esto, es importante recordar que estos procesos de segregación nunca han sido completos y clara muestra de ello son las áreas cuyo nombre comienza por “filosofía de…”: filosofía de la física, filosofía de la biología, etc. La filosofía no parece circunscribirse a un área concreta, no es un cuerpo doctrinal. Es una aproximación a la investigación y el conocimiento. Se caracteriza por su aspiración de hacer análisis sistemáticos y por incluir en estas investigaciones una reflexión sobre su propia actuación.298 Dicen que William James la describió como “un esfuerzo especialmente tozudo de pensar con claridad” y Bertrand Russell como una aproximación “inusualmente obstinada”. Este obstinado cuestionamiento puede llegar en ocasiones a parecer casi perverso; Russell cuestionó la justificación de que 1 + 1 fuesen 2. Otro aspecto importante de la filosofía es el del análisis conceptual, el estudio de los términos y sus definiciones.299 Esto puede parecer paradójico, dado que los filósofos rara vez llegan a estar completamente satisfechos con una definición concreta. Tratan, más bien, de analizar hasta qué punto los conceptos son coherentes, de descubrir la complejidad subyacente en ellos300 o de analizar las consecuencias de definirlos de un modo u otro. El Sócrates platónico podría ser el ejemplo paradigmático de esta actitud, un filósofo interesado por clarificar el discurso mediante el análisis de los conceptos,301 pero que nunca quedó completamente satisfecho con ninguna definición. En muchas ocasiones el mero hecho de aclarar una cuestión puede ahorrarnos muchas respuestas confusas. Por último, otro aspecto fundamental es el de la evaluación de cada una de las posiciones, de las fortalezas y limitaciones de cada uno de las tesis relativas a un problema concreto.302 Esta aproximación sistemática iniciada por los griegos clásicos contrasta con los mitos tradicionales que no tienen como objetivo crear conocimiento consistente.303 Los Mursi, una cultura actual, pero neolítica, viven a orillas del río Omo en Etiopía y poseen una agricultura rudimentaria. Los Mursi tienen un calendario basado en meses lunares. En cualquier año el primer mes lunar se corresponde con las lluvias, en el segundo se prepara la tierra de cultivo, en el tercero se siembra el sorgo del que dependen, en el quinto florece y en el sexto se cosecha. El año de los Mursi tiene 12 meses lunares, lo cual es extraño puesto que un año de 12 meses lunares sólo debería tener 336 días, de modo que las estaciones deberían ir variando año tras año, apareciendo en meses diferentes, tal y como sucede en el calendario musulmán. Sin embargo, esto no les sucede a los Mursi, que afirman que a pesar de que su calendario tiene 12 meses lunares la época de lluvias siempre coincide con el primer mes. Los antropólogos, evidentemente, no entendían cómo podía ser esto y tras preguntar a los Mursi sobre el asunto acabaron averiguando que, a veces, entre el doceavo mes y el primero del nuevo año se intercala un periodo especial. El calendario de los Mursi, en realidad, es inexacto. Los Mursi discuten sobre si las migraciones de los animales se han retrasado este año o no, o incluso sobre si lo ha hecho el solsticio. Los Mursi no creen que el Sol siga un calendario anual fijo, piensan que se adelanta o se atrasa como puede hacerlo la floración del sorgo. Esta imprecisión les permite sincronizar su calendario lunar con los eventos que realmente les interesan, que son los ciclos biológicos que les rodean. Esta solución no habría satisfecho a un filósofo natural, que habría exigido consistencia o a un científico que, además, habría demandado medidas cuantitativas para ajustar el calendario, pero es una solución típica de las aproximaciones tradicionales.304 A los egipcios antiguos no les molestaba tener narraciones inconsistentes sobre un episodio mítico concreto,305 algo que tampoco parece preocupar excesivamente a las religiones abrahámicas, que en el Génesis relatan dos veces la creación de los seres humanos de forma distinta: en una, Adán y Eva son creados a la vez, tras la creación de las plantas y los animales (Génesis 1:11-27); y en otra dios crea primero a Adán, después crea a las plantas y a los animales y, finalmente, a Eva (Génesis 2:5-25). En las culturas arcaicas, fuera de la filosofía, la norma es aceptar el consenso comunitario sin preocuparse excesivamente por la consistencia.306 Las religiones y los mitos suelen contar historias atractivas. Para los seres humanos resulta natural transmitir información sobre el funcionamiento del mundo natural y de las reglas morales que deben regirnos contando cuentos y, además, estos relatos suelen proveer el fundamento de la identidad cultural. Por ejemplo, los griegos clásicos se identificaban como tales gracias a su lengua y a su respeto por las historias homéricas. Lo que no se les exige a estas historias es una coherencia absoluta y en esto difieren claramente de la filosofía. En muchos casos, las historias funcionan más sugiriendo que analizando cada detalle. Esta tolerancia por el pensamiento poco riguroso, sin embargo, no debe ser aceptada ni en la filosofía ni en la ciencia. Aclarado, o no, el concepto de qué se entiende por filosofía queda por discutir sobre la relación entre filosofía y ciencia. En principio, filosofía y ciencia pertenecen a especializaciones muy diferenciadas, los filósofos estudian en sus facultades y los científicos en las suyas, por lo que podría parecer que ambas disciplinas tienen poca relación. Sin embargo, históricamente, las ciencias han estado muy relacionadas con la filosofía, de hecho, se han ido desgajando de la filosofía a medida que han ido adquiriendo una aproximación eminentemente empírica.307 Esta separación, claro está, es un fenómeno reciente que habría resultado completamente ajena a Aristóteles o, incluso, a Newton, que se reconocía como filósofo natural.308 El término “científico” es el más utilizado hoy en día para referirse a los investigadores del mundo natural, pero es un término reciente, fue acuñado por William Whewell en el siglo XIX, y todavía en el mundo anglosajón a los científicos se les otorga el título de doctores en filosofía, Philosophiæ Doctor (Ph. D.). Hemos defendido que la filosofía debe caracterizarse más por su aproximación sistemática que por la materia tratada. Por eso tienen cabida dentro de la filosofía áreas tan diferenciadas como la epistemología o la ética. Pero si aceptamos esto, tal vez, deberíamos considerar también las distintas disciplinas científicas como áreas filosóficas. Al fin y al cabo, la ciencia no es más que el análisis sistemático y empírico del mundo natural. Como acabamos de comentar, en el último par de siglos a medida que una disciplina se ha hecho más empírica se ha desgajado de la filosofía como una especialización merecedora de su propio espacio. Creo que esta emancipación es necesaria por motivos prácticos. El conjunto de conocimientos científicos y filosóficos es demasiado amplio y no podemos aspirar a formar comunidades que dominen todos los temas. Pero esta necesidad práctica no ha de hacerlos olvidar que las distintas ciencias, las matemáticas, la lógica y las diferentes áreas de la filosofía forman parte de una aproximación común: la generación de conocimiento riguroso. Cualquier filósofo o científico que olvida que estamos embarcados en una empresa común no sólo traiciona sus raíces, recordemos que Tales estudiaba el mundo natural, sino que se hace un flaco favor ya que estas disciplinas están todavía unidas por fuertes lazos que las fortalecen mutuamente. Además, independientemente de dónde decidamos situar estas divisiones, no se puede hacer ciencia sin estar adoptando una posición filosófica concreta de la que debemos ser conscientes (algo que muchos científicos actuales parecen haber olvidado). Ni se debe hacer filosofía sin tener en cuenta las conclusiones científicas, algo que también es, por desgracia, bastante común. Un científico debe ser consciente de las fortalezas y de las limitaciones de la postura filosófica que está adoptando y, además, tiene que saber algo de filosofía, aunque sólo sea para defenderse de la mala filosofía porque, no nos equivoquemos, igual que el mundo está lleno de mala ciencia, la mala filosofía también crece como la mala hierba. Si tuviese que contar las veces que un pseudofilósofo relativista ha querido desmontar mis sólidas convicciones científicas diciéndome que no puedo estar seguro de que mi gata existe o de que las evidencias científicas están teñidas de teoría acabaríamos aburriéndonos todos mucho. Por otro lado, un intelectual serio, cosa que los científicos deberían aspirar a ser, tendría que abstenerse de hacer propuestas en áreas que desconoce sin informarse antes. Muchas veces, me he encontrado con científicos que se hacen preguntas que la filosofía lleva sopesando milenios y que se atreven a contestarlas, con total seguridad, sin detenerse antes a leer antes ni un sólo libro que refleje las conclusiones de los expertos del área, es decir, de los filósofos. Es muy común que algún científico haga propuestas epistemológicas sin tener la más remota idea de que hace más de un siglo su tesis ya fue desechada por los expertos. Sorprendentemente, esos mismos científicos suelen molestarse cuando alguien se atreve a decir algo referente al mundo natural y demuestra tener sólo un conocimiento decimonónico sobre evolución o sobre la estructura de la materia. Por último, existe una diferencia de matiz en las aproximaciones de los filósofos y de los científicos. Mientras que el científico puede que duerma satisfecho tras llegar a un modelo útil, independientemente de que sea completamente fiel a la realidad, el buen filósofo no descansará hasta dar con todos los problemas que pueda encontrar a la solución propuesta ya que su misión es encontrar las debilidades en el pensamiento. En una reunión con unos colegas en Barcelona discutíamos sobre la definición de las distintas variedades de tomate, un asunto con implicaciones comerciales, y nos dimos por satisfechos tras alcanzar una definición, que, aunque reconocíamos como deficiente, al menos era útil para el problema que nos había congregado. Sócrates, tal vez, nos habría insultado. Cuando él pedía definiciones su objetivo no era conformarse con una convención que sirviese para salir del paso, sino que pretendía explorar cómo se pensaba sobre el asunto para llegar a una mayor comprensión del mismo.309 3.11 Resumen A lo largo del primer milenio antes de nuestra era, en las grandes civilizaciones de la antigüedad, apareció la filosofía. Esta nueva disciplina abordaba las mismas cuestiones que habían tratado de responder el pensamiento tradicional y las religiones: cómo funciona el mundo, cuál es nuestro papel en él y cómo debemos organizar nuestras vidas y sociedades. Lo que diferencia a las religiones de la filosofía no son las preguntas, sino la aproximación a las mismas. Los filósofos están obligados a tratar de ser lo más sistemáticos, lo más rigurosos posible. Los pensadores racionales deben justificar sus creencias y estas justificaciones han de ser sometidas al juicio y la crítica del ágora, de la comunidad racional. Además, el investigador racional se sabe limitado, sujeto a sesgos y falto de conocimientos, y, por lo tanto, busca activamente la crítica de la comunidad. Y, a su vez, esta crítica debe estar justificada, de modo que sirva para construir entre todos mejores respuestas y preguntas más precisas. La racionalidad debe ser defendida tanto individual como comunitariamente, ya que el compromiso con la razón no es nuestra única inclinación. Somos mamíferos sociales y para nosotros suele ser más importante la lealtad que la razón. Esto nos obliga a que, en todo momento, debamos de resistir la tentación de limitar la crítica racional para mantener la armonía. Los primeros filósofos occidentales estaban interesados, sobre todo, por entender el mundo natural. Asumieron que la naturaleza está ordenada, que se rige por leyes y trataron de analizar este orden mediante la reflexión racional. Hoy en día puede que Tales se sintiese más cómodo en una facultad de ciencias que en la de filosofía, pero esto no ha de extrañarnos. La relación entre ciencia y filosofía es estrecha. La ciencia nació como especialización de la aproximación filosófica, al fin y al cabo, no es más que el estudio sistemático del mundo externo. Además, no es posible hacer ciencia sin asumir unos postulados epistemológicos y metafísicos y el investigador haría bien en comprender su labor. "],["conocimiento_y_organon.html", "4 Conocimiento y organon 4.1 Conocimiento 4.2 Lógica 4.3 Matemáticas: los sublimes arquitectos 4.4 Resumen", " 4 Conocimiento y organon 4.1 Conocimiento Tanto la filosofía como la ciencia tienen por objeto la generación de conocimiento, pero, ¿qué es el conocimiento, cómo se obtiene, qué puede ser conocido y cómo debe justificarse? Estas preguntas constituyen el objeto de la epistemología, una de las principales áreas de la filosofía.310 Platón dedicó varios de sus diálogos a tratar estas cuestiones y planteó una definición de conocimiento que se acabó aceptando como clásica: el conocimiento está constituido por creencias verdaderas justificadas. Platón no fue el primer filósofo, pero se podría decir que con él la filosofía alcanzó la mayoría de edad.311 El filósofo y lógico-matemático Alfred North Whitehead dijo que el resto de la filosofía no eran más que una serie de notas a la filosofía platónica. Fue Platón quien planteó muchas de las cuestiones fundamentales que han definido el análisis filosófico posterior. Platón, además, fue el maestro de Aristóteles, tal vez una de sus máximas creaciones. Cada vez que pienso que durante dos décadas ambos compartieron el mismo espacio, la Academia, me asalta un respeto reverencial. ¿Cómo es posible que tres de los más grandes filósofos de la historia, Sócrates, Platón y Aristóteles, constituyesen una línea de maestros y discípulos? Después de esto dudo si la pedagogía actual podrá alguna vez alcanzar la excelencia de la clásica. Por cierto, Platón era sólo un mote, algo que tenemos que agradecer, ya que habría sido muy confuso que los tres filósofos más importantes de la antigüedad fuesen Sócrates, Aristocles y Aristóteles.312 Platón escribió un diálogo fundacional en el cual sus principales personajes, Teeteto, un matemático amigo de Platón, y Sócrates discuten sobre el conocimiento. Sócrates, como es su costumbre, pide una definición y Teeteto como primer intento ofrece una lista de ejemplos. Son conocimientos: la geometría, la astronomía, el arte de hacer zapatos y la carpintería.313 Pero, como ya hemos comentado previamente, a Sócrates no le satisfacían los ejemplos; demandaba definiciones que especificasen características necesarias y suficientes. Teeteto responde entonces que tal vez el conocimiento sea equivalente a la percepción.314 Yo sé que mi gata está sobre la mesa cuando la veo sobre la mesa. Sin embargo, Sócrates encuentra varios problemas a esta propuesta. En primer lugar, la percepción es subjetiva, depende, en parte, del sujeto que la experimenta. El viento que a mi amigo le parece frío a mí puede parecerme cálido. Y, además, la percepción es falible, puede estar equivocada. Puede que yo crea estar viendo a mi amigo en la lejanía cuando, en realidad, es mi miopía la que me ha confundido. En el diálogo Sócrates concluye que, debido a estos problemas, si aceptásemos esta definición de conocimiento, como simple percepción, estaríamos abocados al relativismo ya que deberíamos aceptar, como proponía el sofista Protágoras, que el hombre es la medida de todas las cosas, que cualquier opinión es verdadera para él y que la objetividad es inalcanzable.315 Como veremos, rebatir esta crítica de Sócrates no será trivial y terminaremos llegando a la conclusión de que el conocimiento dependerá en parte del mundo externo y en parte del conocedor y que su fiabilidad habrá de evaluarse conclusión por conclusión. En cualquier caso, aunque la percepción es uno de los fundamentos del conocimiento, éste debe de ser algo más que simple percepción. Decimos que la fuerza de la gravedad atrae a los cuerpos hacia la Tierra, pero nadie ha visto esta fuerza, tan sólo hemos observado como caen los cuerpos. De modo que Sócrates propone a Teeteto que pasen a discutir sobre qué proposiciones son conocimiento y cuáles no lo son. Una proposición es una afirmación que puede ser verdadera o falsa. Por ejemplo, “la gata está sobre la mesa” es una proposición puesto que puede ser verdad o mentira. Sócrates, al añadir esta restricción, reconoce que el conocimiento es heterogéneo y que van a limitar la discusión sólo a algunos de ellos, los explícitos. Hay muchos conocimientos no proposicionales que Teeteto y Sócrates ignoraron en su discusión. Por ejemplo, puede que sepamos montar en bicicleta, pero este es un conocimiento implícito, no podemos expresarlo en proposiciones.316 Por otro lado, para que podamos afirmar que sabemos algo, al menos, debemos creerlo. Sería muy extraño que dijésemos que sabemos que existen los leones si no lo creyésemos, por lo que Teeteto propone que el conocimiento debe ser doxa, un término griego que se traduce habitualmente como creencia u opinión.317 El problema es que no todas nuestras creencias son conocimiento. Está claro que una simple opinión no será conocimiento a no ser que tenga alguna otra característica. Un requisito muy razonable es que sólo serán conocimientos aquellas creencias que son verdaderas. Si yo creo que el campo está lleno de piruletas o que la homeopatía cura, no pienso que tenga conocimiento, el conocimiento parece requerir verdad. De modo que Teeteto propone que puede que el conocimiento sea una creencia verdadera. Pero Platón dejó muy claro que esto no es suficiente, que hay diferencias importantes entre creencia verdadera y conocimiento.318 Por ejemplo, yo podría creer que voy a acertar los números de la primitiva y puede que realmente terminase acertándolos, pero ¿debería considerar esa creencia verdadera y, por lo tanto, conocimiento, a pesar de haber acertado por casualidad? Platón rechazó equiparar conocimiento con creencia verdadera y propuso que para que pudiésemos aceptarla como conocimiento la creencia, además de ser verdadera, debería estar justificada. El conocedor debe ser capaz de explicar cuáles son los motivos por los que debemos aceptar su tesis, el conocimiento requiere justificación, debe ser racional.319 En el Teeteto se habla de verdad más logos. De modo que para que aceptemos algo como conocimiento: debemos creerlo, debe ser verdadero y debemos poder justificarlo. Esta es la definición clásica de conocimiento: el conocimiento es una creencia verdadera justificada. La ciencia y la filosofía aspiran a ser conocimiento, por lo tanto, a diferencia de los mitos, deben justificar sus afirmaciones, deben ser racionales, esta es una conclusión fundamental. Esta definición fue aceptada durante milenios y sólo en el siglo XX empezó a ser cuestionada seriamente, aunque ya Sócrates, como era su costumbre, le encontró problemas. Uno podría creer algo verdadero, incluso podría tener motivos para creerlo, y aún así sería discutible aceptar que lo sabe. Sócrates propuso el siguiente ejemplo. Imaginemos a un jurado en un juicio que tras escuchar los argumentos de la defensa cree, correctamente, que el acusado es inocente. Si le preguntamos, podría justificar su creencia utilizando los argumentos del abogado defensor, pero si esos argumentos han sido falaces, ¿podríamos decir que el jurado sabe realmente que el acusado es inocente, aunque esa sea una creencia verdadera y, desde el punto de vista del jurado, justificada?320 Uno puede estar justificado para creer algo y, sin embargo, esa justificación puede ser errónea. Podemos creer algo verdadero por los motivos equivocados. Este mismo tipo de problemas, en el que alguien cree algo verdadero, pero por las razones equivocadas, fue discutido por Dharmottara, un filósofo indio alrededor del 770 d. C..321 Dharmottara nos pidió que imaginásemos a un cazador que ha empezado a cocinar su caza, el fuego acaba de comenzar y, por lo tanto, todavía no hay humo, pero una nube de moscas ha sido atraída por el olor de la carne. Un viajero que observase la nube de insectos desde la lejanía podría confundirla con humo y podría creer, correctamente, aunque por motivos equivocados, que alguien ha decidido hacer un fuego. Russell planteó que alguien podría mirar a su reloj estropeado a las dos en punto, ver las manecillas en las dos en punto y creer justificadamente que esa era la hora.322 Este tipo de problemas se han convertido en un entretenimiento de los epistemólogos y son especialmente conocidos los planteados por el filósofo estadounidense Edmund Gettier.323 Una forma de tratar de solventar estos problemas es exigir que las premisas sobre las que se fundamenta nuestro conocimiento sean también verdaderas, pero ¿cómo podemos estar seguros de que lo son? Por otro lado, el concepto de verdad también es problemático. Imagina que vives en el siglo III a. C. y, después de estudiar en la Academia, llegas a la conclusión de que la Tierra es esférica, que ocupa el centro del universo y que no se mueve. Estas serían, dadas las evidencias disponibles, creencias racionales, es decir justificadas, pero no se corresponderían con la realidad, la Tierra se mueve. Aunque de esto último no podríamos estar absolutamente seguros hasta los siglos XVII o XVIII d. C.. Este es un problema que, como veremos, complicará severamente la definición del concepto de verdad. En cualquier caso, tu creencia estaría justificada, pero sería falsa. Según la definición clásica tú no sabrías que la Tierra no se mueve, aunque no podrías saber que no lo sabes, ya que estarías justificado para creerlo, porque, hasta el siglo XVIII, no tendrías forma de saber con seguridad que esa creencia no era verdadera. Los lectores aficionados a la astronomía helénica puede que se hayan dado cuenta de que mi elección de la fecha de este experimento hipotético no ha sido casual. Fue en el siglo III a. C. cuando vivió Aristarcos. De modo que, si como buenos logófagos hubiésemos decidido viajar en el tiempo y visitar Alejandría, allí podríamos haber escuchado a Aristarcos explicarnos su justificación de la creencia de que la Tierra realmente se mueve a una velocidad fantástica alrededor del Sol. Esta habría sido, como ahora sabemos, una creencia verdadera, ¿pero habría estado justificada? Aristarco planteó su modelo por motivos geométricos, dado que situar al Sol en el centro simplificaba el movimiento de los planetas en su modelo. Pero, Aristarco no podía justificar por qué, a pesar de que fuimos perfectamente capaces de percibir el vaivén del barco que nos trajo a Alejandría, no somos capaces de percibir el supuesto movimiento de la Tierra. Esto es algo que no podría explicarse hasta que Galileo propuso su principio de inercia. De modo que, si rechazásemos la justificación de Aristarco, podríamos considerar que su creencia era verdadera, es decir, se correspondía con el mundo real, pero no justificada. Es decir, Aristarco creería algo verdadero, pero estaría siendo irracional. ¿Podemos decir entonces que Aristarco sabía que la Tierra se movía? ¿Habría algún modo de comprobar esta correspondencia entre el modelo de Aristarco y la realidad? Hay filósofos que han propuesto redefiniciones radicales del concepto de conocimiento para evitar estas limitaciones de la definición clásica. Por ejemplo, los hay que sugieren que debemos aceptar como conocimiento sólo las creencias que han sido generadas por un método fiable. Esta sería una definición que podrían aceptar quienes afirman que la ciencia produce conocimiento porque sus metodologías son fiables o la que yo mismo estaría dispuesto a aceptar al afirmar que podemos confiar, hasta cierto punto, en nuestros sistemas perceptuales y cognitivos porque han sido seleccionados para que podamos sobrevivir. El problema es que tanto la ciencia como nuestros sentidos, en ocasiones, pueden estar equivocados. Newton pensó que los objetos caían porque eran atraídos por la fuerza de la gravedad, pero la relatividad general de Einstein explica esta caída en función de la curvatura del espaciotiempo causada por la Tierra. ¿Cómo podemos saber en qué circunstancias nos proporciona un método un conocimiento fiable? Robert Nozick, un filósofo norteamericano, propuso otra teoría epistemológica que hace una aproximación completamente distinta. Sería conocimiento aquello que funciona.324 Si le hacemos una pregunta a alguien y da la respuesta correcta, esa persona tiene conocimiento. Esta teoría tiene la ventaja de poder aplicarse al conocimiento implícito. Sabemos ir en bici si somos capaces de ir en bici. Incluso podría ser aplicable al caso de los profetas. Si un profeta bíblico hubiese sido capaz de predecir con exactitud el valor de pi y el movimiento de la Tierra deberíamos tomarlo muy en serio. La limitación de esta aproximación es, de nuevo, que no aclara hasta qué punto una nueva creencia es fiable hasta que no se comprueba. En la actualidad los epistemólogos siguen discutiendo sobre estas cuestiones325 y, aunque hay propuestas que se han descartado claramente, como las primeras de Teeteto, no se ha llegado a ninguna que esté completamente libre de problemas, algo que, a estas alturas no debería ni molestarnos ni preocuparnos, ya que lo relevante es lo que hemos aprendido por el camino y no sólo la conclusión. Una enseñanza fundamental es que debemos aspirar a ser racionales, aunque esto no siempre implique que vayamos a alcanzar la verdad. La verdad es, como veremos enseguida, un concepto bastante problemático. Si a alguien le apetece leer más sobre epistemología le recomiendo: Knowledge: A Very Short Introduction de Jennifer Nagel. Al menos la exigencia de justificación de la teoría clásica tiene varias ventajas. Por un lado, las justificaciones pueden ser defendidas, discutidas y mejoradas.326 Creemos en el teorema de Pitágoras porque los pitagóricos ofrecieron una demostración del mismo, una justificación, no porque Pitágoras afirmase ser un profeta. Además, el conocimiento justificado sobre el mundo natural o sobre las matemáticas puede ser progresivo. Por ejemplo, si alguien encuentra un fallo en alguna inferencia, la enmienda puede acabar integrándose. Otra cuestión, relacionada con la anterior, que ha sido objeto de dilatadas polémicas, es si se puede alcanzar el conocimiento o si hemos de resignarnos a la mera opinión. Platón, Aristóteles y los estoicos pensaban que sí era posible alcanzar el conocimiento, aunque, según ellos, hacerlo no era nada sencillo.327 Sin embargo, los escépticos clásicos creían que esto no estaba tan claro. Estas discusiones fueron muy productivas y las comentaremos en profundidad. Las conclusiones de estas discusiones dependerán de qué criterio se elige para aceptar que una creencia es conocimiento y de cómo se define el concepto de verdad. Es evidente que si afirmamos que el conocimiento es creencia verdadera justificada debe ser relevante precisar qué entendemos por verdad. Es intuitivo pensar que una creencia será o no verdadera dependiendo de la relación que tenga con el mundo. La teoría de la correspondencia, propuesta por Aristóteles,328 una de más aceptadas, es una excelente primera aproximación a la definición de la verdad: son verdaderas las creencias que se corresponden con como es realmente el mundo.329 Los mapas son verdaderos en tanto y en cuanto se corresponden con el territorio.330 En una encuesta, dirigida a los filósofos profesionales, publicada por David Chalmers y David Bourget, la mitad de ellos contestó que estaba de acuerdo con esta definición, mientras que el resto se repartió entre otras teorías.331 Durante el siglo XX la teoría de la correspondencia ha sido sometida a un severo escrutinio y se han discutido extensamente otras propuestas.332 Uno de los problemas del concepto de verdad es que es heterogéneo. Podemos defender que es verdad que mi gata está sobre la mesa si realmente, en el mundo exterior, mi gata está sobre la mesa, pero este no será el modo en el que un lógico matemático justificará que 1 + 1 son efectivamente 2. Independientemente de que los matemáticos sean platónicos o no lo sean, de que crean que las abstracciones matemáticas tienen una realidad metafísica o no la tengan, lo que está claro es que las afirmaciones relativas a los objetos físicos y a los matemáticos son muy diferentes. Además, también suele hablarse de verdad en los ámbitos morales e incluso estéticos. Solemos considerar que es verdad que está mal matar a otros seres humanos y también suele aceptarse que es verdad que El Quijote es una excelente novela. Pero estas afirmaciones no se corresponden con objetos que podamos encontrar en el mundo externo, de modo que ¿en qué sentido podemos decir que son verdad? Para una introducción muy clara a estas cuestiones os recomiendo On truth de Simon Blackburn. Como en ciencia lo que nos interesa es el mundo natural podríamos ignorar los problemas relacionados con la heterogeneidad del concepto de verdad. Pero, incluso en las ciencias naturales el concepto de correspondencia puede resultar problemático. Podríamos aceptar sin problemas que existe el mundo exterior y que, por lo tanto, la correspondencia entre el mundo exterior y nuestras ideas debe ser relevante. Pero hay un problema, el mundo exterior es exterior, está fuera de nuestras cabezas, por lo que para comprobar si hay correspondencia estamos limitados a comparar distintas creencias y esto es un hecho que nos empuja a aceptar definiciones de verdad muy distintas de las basadas en la correspondencia. Tenemos acceso a los mapas sobre el mundo, pero sólo a una información limitada proveniente del mundo externo y esto limita, evidentemente, nuestra capacidad para comparar el mapa con el territorio. Esta es una crítica muy dura contra la teoría de la correspondencia. Podría parecer que estas discusiones sólo tienen sentido dentro de esas perversas mentes filosóficas obsesionadas con ser más papistas que el Papa, pero veremos que estos detalles pueden acabar teniendo implicaciones profundas. En algunos casos no parece muy arriesgado aceptar la teoría de la correspondencia, la información que recibo del mundo externo es suficiente como que sea fácil comprobar si hay un gato sobre la mesa o no lo hay. Sin embargo, si hablamos sobre electrones o sobre campos gravitatorios nos adentramos en terrenos metafísicamente más pantanosos. Recordemos que en la relatividad general la fuerza de la gravedad no existe, por lo tanto ¿de qué hablaba Newton cuando calculaba la caída de las manzanas? ¿En qué sentido podemos afirmar que la teoría newtoniana o la de Einstein se corresponden con la realidad si no tenemos un acceso directo a ella? Uno de los principales debates abiertos en filosofía de la ciencia, el relativo al realismo, trata precisamente sobre estas cuestiones, pero antes de llegar a él comentaremos otros aspectos. De hecho, incluso en los casos más evidentes la exigencia de verdad puede ser problemática. Los babilonios consideraban evidente que la Tierra era plana y, por lo tanto, podrían haber afirmado que sabían que la Tierra era plana. Pero los griegos clásicos descubrieron que esa asunción era falsa, la Tierra no era plana. Los griegos creían que la Tierra no se movía, pero ahora sabemos que se mueve. Pero ni los babilonios ni los griegos ni nosotros tenemos acceso más que a nuestras percepciones y a nuestras propias ideas, de modo que en ¿qué sentido podemos hacer uso de la teoría de la correspondencia para comprobar si algo es verdad o no lo es? ¿Era verdad para los babilonios que la Tierra era plana? Por un lado, parece que como esa conclusión era para ellos tan evidente deberíamos considerar que era verdadera, pero esto nos llevaría a una definición de verdad relativa al conocimiento interno, alejada de la correspondencia con el mundo externo que nos acerca, incluso, al relativismo. Aunque parece imprescindible conceder un gran protagonismo al mundo externo a la hora de decidir qué es verdad y qué no lo es sobre ese mundo detallar el papel que debe jugar el mundo externo en el concepto de verdad no es trivial. Los babilonios podrían decirnos que era verdad que la Tierra era plana ya que todas sus percepciones e ideas eran coherentes con esa conclusión. De nuevo vemos que la racionalidad es más defendible que la verdad, aunque más modesta. Además, si no podemos tener confianza ni tan siquiera en estas conclusiones tan evidentes, ¿cómo podemos llegar a estar seguros de que hemos alcanzado conocimiento alguno? Podría ser que mañana los físicos descubran que el movimiento, tal y como decía Parménides, no es real en un sentido fundamental. ¿Serían entonces todo lo que creemos hoy en día falso? Una forma de obviar estos problemas es eliminar el requisito de verdad de la definición de conocimiento y pasar a admitir como conocimiento aquellas creencias que están debidamente justificadas, es decir, aquellas que sean racionales. Algunos filósofos han aceptado esta tesis dado que la certeza absoluta y la verdad son inalcanzables, lo mejor que podemos hacer es aspirar a ser racionales, sin embargo, otros la han rechazado porque al final es el mundo externo quien debe tener la última palabra.333 Otra opción es aceptar como verdadero aquello que esté más allá de toda duda razonable, como que mi gata está ahora frente a mí, aunque debamos admitir que siempre quedarán las no razonables. Lo que es indudable es que, al menos, debemos aspirar a ser racionales, incluso aunque no tengamos una garantía de haber alcanzado la verdad absoluta. Nuestras ideas sobre el mundo cumplen varias funciones, pero una de las fundamentales es que nos permiten actuar sobre él. Las creencias que nos permiten hacer predicciones que se después se cumplen, son creencias útiles. En nuestras sociedades actuales son muchos los que creen que las vacunas no previenen algunas enfermedades. En base a esa creencia muchos padres puede que dejen de vacunar a sus hijos y, aunque podríamos entrar en discusiones bizantinas con ellos, será difícil convencerlos de que las vacunas son eficaces. Sin embargo, lo que es prácticamente seguro, es que si observan que esas enfermedades aumentan su prevalencia y comienzan a afectar a muchos de los hijos de sus amigos, cambiarán de opinión y volverán a vacunar a sus hijos. Es fácil mantener creencias arbitrarias cuando no tienen implicaciones, pero cuando las tienen solemos descartarlas. Este es uno de los pilares fundamentales de nuestra maquinaria cognitiva y es también una de las bases fundamentales de la ciencia. Uno puede tener dudas sobre si ha visto o no ha visto pasar un gato por el rabillo del ojo, pero cuando la realidad le araña suele convencerse rápidamente. Podemos discutir sobre hasta qué punto los ciclos, epiciclos y deferentes del modelo ptolemaico se corresponden con la realidad, pero lo que está claro es que si el modelo se mantuvo hasta la Edad Moderna fue porque hacía predicciones lo suficientemente buenas como para corresponderse con las observaciones de la época. Hay muchos filósofos que creen que la exigencia de verdad, entendida como correspondencia con el mundo externo, es un criterio inalcanzable, pero, casi todos coinciden en que, al menos, deberíamos exigir adecuación empírica, es decir, debemos esforzarnos por que esas creencias se correspondan con las evidencias disponibles. A estas cuestiones les dedicaremos varios capítulos posteriores. 4.2 Lógica Además de discutir sobre qué es el conocimiento, los filósofos clásicos se interesaron por crear herramientas para alcanzarlo y a eso le debemos dos avances fundamentales: la lógica y la demostración matemática. La lógica trata sobre los principios que rigen el razonamiento correcto334 y para ello establece las reglas de la inferencia racional.335 Es decir, establece el modo en el que debemos inferir, derivar conclusiones a partir de las premisas, ayudándonos así a diferenciar las inferencias válidas de las inválidas. La etimología de la palabra “lógica” hace referencia, por supuesto, a que trata sobre la teoría del logos, del discurso.336 La lógica nació a partir de dos padres: el debate público y las matemáticas demostrativas que, como veremos, habían desarrollado los pitagóricos. Aristóteles, que fue el fundador de la lógica,337 estaba muy interesado en encontrar reglas que regulasen el debate racional más allá de las recomendaciones que hacían los profesores de retórica. La retórica trata sobre el arte de convencer en el debate, pero Aristóteles no estaba interesado en convencer, sino en establecer debates racionales en los que las inferencias pudiesen ser tan fiables como las demostraciones matemáticas y como no existía una herramienta que le permitiese realizar este análisis decidió crearla. No puedo llegar a imaginar cómo debió de sentirse este pionero al sentarse un buen día en la Academia y resolver que iba a buscar las reglas de la racionalidad, un desarrollo humano ante el cual es difícil encontrar palabras que reflejen la admiración suficiente. Y, además, Aristóteles, tal y como explicó en las Refutaciones sofísticas, era perfectamente consciente de estar creando una nueva disciplina desde cero.338 Los tratados que dedicó a la lógica y a la epistemología fueron recogidos por otros autores posteriores en el Organon, la herramienta. Sólo por esta creación, Aristóteles debería ser considerado junto a su maestro, Platón, uno de los filósofos más importantes de la historia. En la encuesta de Chalmers que he mencionado antes, Aristóteles fue elegido, junto con David Hume, como uno de los filósofos que más han influido a los filósofos actuales;339 y Aristóteles y Hume, como se irá viendo, son mis dos filósofos favoritos. Aristóteles nació en Estagira, una ciudad costera cercana a Tesalónica, en el 384 a. C.. Era hijo del médico de la corte macedonia y esto hizo posible que fuese a estudiar a la Academia con Platón. Aristóteles resultó ser, probablemente, la creación platónica más relevante, alguien tan increíblemente impresionante que si no hubiese existido sería absurdo imaginarlo.340 En su obra se cubren un gran número de áreas: metafísica, ética, teoría política, historia constitucional, retórica, poética, teología, zoología, anatomía, fisiología, meteorología, astronomía, cosmología, física, química, epistemología, lógica formal, razonamientos falaces, fundamentos de las matemáticas, análisis del lenguaje y método científico.341 Y no sólo escribió sobre estos temas, sino que fue el creador de varias de estas disciplinas: lógica, zoología y filosofía de la mente.342 Además, Aristóteles elaboró un currículum que sirvió como base a la educación posterior. Los filósofos anteriores no habían dedicado, normalmente, tratados independientes a cada tema.343 Sin embargo, muchos de los títulos de los tratados aristotélicos se corresponden con nuestras divisiones modernas del conocimiento: física, psicología, zoología, literatura, política.344 Por si esto fuese poco, incluso podría defenderse que Aristóteles fue el inventor de la lectura, o al menos así lo pensaban sus compañeros en la Academia que le llamaron: anagnostes, el lector. Es evidente que la lectura se originó junto a la escritura, pero hasta el tiempo de Aristóteles leer no había sido tan común. Los alumnos de filosofía aprendían escuchando los textos que eran leídos en voz alta por un maestro o por un esclavo especializado, el anagnostes.345 Sin embargo, la voracidad intelectual de Aristóteles no podía satisfacerse con esas lecturas, por lo que aprovechó el dinero de su padre para proveerse de una gran biblioteca y se dedicó a leer por sí mismo todo lo que cayó en sus manos. Durante más de mil años estudiar filosofía fue sinónimo de estudiar a Aristóteles.346 Cuando en la Edad Media alguien se refería a el Filósofo no se necesitaba precisar más.347 Pero volvamos a la lógica. Una proposición es una aserción que puede ser considerada verdadera o falsa.348 Por ejemplo, “el gato está sobre la mesa” es una proposición puesto que puede ser verdadera o falsa. Una premisa es una proposición que se asume para iniciar una inferencia, por ejemplo, todos los hombres son mortales y Sócrates es un hombre podrían ser premisas. Una deducción es una inferencia en la que, si se asume que las premisas son verdaderas, las conclusiones también deben ser necesariamente verdaderas.349 Si todos los hombres son mortales y Sócrates es un hombre, podemos hacer una deducción válida y concluir que necesariamente Sócrates será mortal. La lógica deductiva es la más común de las lógicas y muchas veces cuando alguien se refiere a la lógica, se está refiriendo, en realidad, sólo a la lógica deductiva. Lo estupendo de la lógica deductiva es que trasmite la verdad con certeza absoluta,350 si partimos de premisas verdaderas y sólo utilizamos deducciones válidas tendremos la certeza de obtener una conclusión verdadera. Sin embargo, en esta fortaleza radica también su limitación. El precio que hay que pagar para disfrutar de esta garantía de certeza es que no podemos llegar más allá de lo que ya se encontraba implícito en las premisas.351 En cierto modo podría decirse que, al utilizar la deducción, a cambio de la garantía de certeza, estamos renunciando a aumentar nuestro conocimiento. Por ejemplo, a partir de un razonamiento deductivo si en nuestras premisas iniciales no se encuentra ya implícita la conclusión, nunca podremos saber si todos los hombres son mortales. A pesar de esta limitación, la lógica deductiva es de una gran utilidad puesto que puede servir para hacer explícito conocimiento que las premisas contenían sólo implícitamente.352 Por ejemplo, todas las matemáticas se construyen mediante la lógica deductiva. Se asumen unas premisas y mediante la deducción se alcanzan unas conclusiones que pueden ser enormemente informativas y útiles. El problema sólo aparece cuando queremos ir más allá de las matemáticas y deseamos conocer el mundo real, para eso necesitamos otros tipos de inferencias. Las otras clases de inferencias lógicas son las no deductivas, y dentro de estas la más popular es la inducción simple. En una deducción partimos de unas premisas que contienen una cierta información y llegamos a unas conclusiones que implican una información más limitada: razonamos de lo más general a lo más específico. Por ejemplo, a partir de las premisas: 1) todos los hombres son mortales y 2) Sócrates es un hombre, podemos llegar a la conclusión, deductivamente válida, de que Sócrates es mortal. En la inducción se parte de unos ejemplos concretos y se llega a una conclusión más general. Por ejemplo, a partir de las premisas: 1) Sócrates es mortal, 2) Platón es mortal y 3) Aristóteles es mortal podemos plantear la conclusión de que todos y cada uno de los hombres son mortales. Las conclusiones inductivas son lógicamente inválidas: la conclusión podría ser falsa incluso aunque las premisas fuesen verdaderas. Por ejemplo, podríamos encontrar un cuarto hombre que fuese inmortal. Para poder alcanzar una proposición más general hemos realizado un salto lógico más allá de lo que permite la lógica deductiva y esto nos expone a estar equivocados. Al inducir hemos de renunciar a la certeza. De modo que las inferencias pueden dividirse entre deductivas, si son lógicamente válidas y no deductivas. A las inferencias no deductivas se las denomina habitualmente inductivas, lo cual resulta algo confuso porque la inducción simple, que acabamos de mencionar, es sólo un tipo particular de inferencia no deductiva. El razonamiento por analogía o la inferencia a la mejor explicación son otros tipos de inferencias no deductivas, o de inferencias inductivas, que analizaremos posteriormente. Por ejemplo, es común decir que hemos hecho una inducción cuando después de ver plumas en la terraza y una gotita de sangre en el pecho del gato, inferimos que el gato ha cazado un pájaro. Esta, por cierto, sería una inferencia a la mejor explicación. En los capítulos siguientes hablaremos mucho sobre la inducción porque, como veremos, no se puede hacer ciencia sin inducir, lo cual implica que el conocimiento racional del mundo natural será siempre falible, podrá ser erróneo o, en todo caso, estará expuesto a ser refinado. La ley de la gravedad de Newton, a pesar de haber servido para enviar personas a la Luna, ya no es nuestra mejor descripción del mundo natural. Sin embargo, el teorema de Pitágoras seguirá siendo válido para siempre en cualquier tipo de matemáticas en las que se asuman las premisas que aceptaron los pitagóricos. En los Primeros analíticos Aristóteles habló sobre las inferencias de un modo muy peculiar, separó su contenido de su estructura.353 Es decir, en vez de proponer: 1) todos los hombres son mortales, 2) Sócrates es un hombre y, por lo tanto, Sócrates es mortal, lo que dijo es 1) todos los A son B, 2) C es A y, por lo tanto, C es B. Fue Aristóteles quien inventó el uso de las variables en lógica, algo que actualmente nos resulta muy familiar, pero que a nadie antes se le había ocurrido. Esto le permitió considerar la forma de las inferencias de un modo abstracto, definiendo la lógica como una disciplina formal que lidia con la estructura de las inferencias y no con su contenido.354 Sabemos que la inferencia: 1) todos los gamusinos son fantabulosos, 2) Fimulín es un gamusino, por lo tanto 3) Fimulín es fantabuloso es válida, incluso aunque no sepamos qué es un gamusino o en qué consiste ser fantabuloso. En la lógica formal la validez de las inferencias no depende de que las conclusiones sean o no sean verdaderas sino, tan solo, de que se deriven correctamente de las premisas.355 La validez de un razonamiento no depende de que las premisas sean verdaderas o falsas. La inferencia será válida independientemente de que en el mundo real los gamusinos sean fantabulosos o no lo sean. Lo único que concierne a la lógica deductiva es la corrección de estructura de la inferencia. La validez es una propiedad formal de las inferencias,356 esta es otra de las aportaciones aristotélicas.357 Las inferencias no son verdaderas o falsas, lo son sus premisas y sus conclusiones. Una inferencia será válida o inválida dependiendo de si es formalmente correcta o no lo es y una inferencia es válida cuando es imposible que todas sus premisas sean ciertas y su conclusión sea falsa y es inválida cuando sucede lo contrario, es decir, que su conclusión puede ser falsa a pesar de tener premisas verdaderas.358 Cuando razonamos utilizando inferencias inválidas cometemos una falacia lógica y esto es algo que debemos evitar. Sin embargo, esta recomendación hay que tomarla con mesura, hemos de ser cautos porque es común extralimitarse cuando se habla de falacias lógicas. En primer lugar, hemos de recordar que no es cierto que una conclusión sea falsa, simplemente, por ser el resultado de unas premisas falsas o de una inferencia inválida. 1) Los cerdos no son serpientes, 2) los cerdos no pueden volar, por lo tanto 3) las serpientes no pueden volar.359 Este razonamiento es inválido, y sus premisas falsas, pero la conclusión sigue siendo verdadera. Lo único que debemos afirmar en este caso, es que la conclusión no se deriva de esas premisas. En general una inferencia inválida no debe ser considerada una justificación válida de una conclusión, pero esto no nos permite inferir si la conclusión es verdadera o falsa. En segundo lugar, hemos de distinguir las falacias lógicas formales, las que dependen sólo de la estructura del razonamiento, de las informales. Estas últimas dependen del significado y, en muchas ocasiones, del contexto y son mucho menos claras que las formales.360 El público general, como los moístas chinos o los lógicos indios, que luego mencionaremos, suele tener una idea de la lógica que va más allá de la estructura formal e incluye la teoría del conocimiento, la semántica, la gramática y la retórica.361 Pero las cuestiones que tienen que ver con los significados y el contexto, como ya hemos comentado, son mucho más confusas.362 Hay autores que llegan incluso a sostener que tal vez la idea de las falacias lógicas informales haga más mal que bien al a comunidad escéptica.363 Puede que no sea así, pero, al menos, debemos ser cautos al utilizarlas, ya que son mucho menos claras que las formales.364 Además, nuestro conocimiento del mundo real debe sustentarse, necesariamente, sobre inferencias inductivas ampliativas, es decir, sobre razonamientos inválidos y esto, estrictamente hablando, es una gran falacia lógica. Para terminar con esta brevísima introducción a la lógica deductiva me gustaría comentar algo sobre la historia de la disciplina. Las tres civilizaciones que desarrollaron la filosofía independientemente: la griega clásica, la india y la china, se interesaron, en mayor o menor medida, por la epistemología y la lógica y llegaron a conclusiones similares, aunque, como veremos, fue la tradición occidental la que terminó haciendo un desarrollo más amplio. Aristóteles, en realidad, limitó su análisis a un sólo tipo de inferencias deductivas, los silogismos.365 Un silogismo es una inferencia con dos premisas, que incluyen un término común, y una conclusión. El ejemplo de silogismo más famoso es el relativo a la mortalidad de Sócrates. En Primeros analíticos Aristóteles determinó todas las posibles formas que podían adoptar los silogismos, 192, y cuales de ellas eran válidas, 14.366 Este análisis sistemático fue uno de los grandes avances aristotélicos y muchos pensadores a lo largo de la historia, impresionados por este gran logro, llegaron a pensar que esta era toda la lógica posible. Sin embargo, la lógica aristotélica, aunque magnífica, está restringida a un área concreta, los silogismos. No cubre, por ejemplo, la lógica proposicional,367 aquella en las que las proposiciones son más simples y están unidas por conectores lógicos que representan operaciones sobre esas proposiciones. En la Wikipedia dan el siguiente ejemplo de inferencia proposicional válida: 1) mañana es miércoles o mañana es jueves, 2) mañana no es jueves, por lo tanto, 3) mañana es miércoles. Los silogismos tampoco sirven para analizar inferencias en las que se utilizan términos relativos, del tipo: 1) Ana es mayor que Berto, 2) Berto es mayor que Cecilia, por lo tanto, 3) Ana es mayor que Cecilia. Algunas de estas limitaciones fueron tratadas por los primeros estoicos, especialmente por Crisipo de Solos, un filósofo griego del siglo III a. C., que es considerado uno de los lógicos más relevantes de la historia, no superado, tal vez, hasta el siglo XIX. Los estoicos estudiaron la lógica proposicional y la lógica modal. Esta última trata con cuestiones relativas a la necesidad, la posibilidad y la imposibilidad.368 Otro de los avances estoicos fue la distinción entre sentido y referencia, un desarrollo que, como el resto de la lógica estoica, se perdió y no fue recuperado hasta el siglo XIX.369 Por desgracia, fue mucho lo que se perdió tras la caída del Imperio Romano. El siguiente movimiento intelectual interesado en la lógica, en la tradición occidental, fue el de los escolásticos medievales. Algunos de los más destacados fueron Pedro Abelardo, Guillermo de Sherwood, Pedro Hispano, Guillermo de Ockham, Gualterio Burley y Alberto de Sajonia.370 Estos pensadores no limitaron su análisis a la lógica formal, sino que se interesaron también por otras cuestiones relativas al lenguaje, por ejemplo, por el problema de los universales que trataremos cuando hablemos sobre clasificaciones y sobre metafísica.371 Pedro Abelardo fue el primer gran lógico medieval y tuvo junto a su amada Eloísa un final trágico que dio lugar a una maravillosa leyenda de amor imposible. Otro de los grandes fue Guillermo de Ockham, el de la navaja. Este principio ya había sido propuesto por Roberto Grosseteste y Juan Duns Scoto,372 pero fue popularizado por su trabajo. Aunque en la época de Ockham no se formuló así, la navaja suele enunciarse diciendo que las hipótesis deben ser lo más simples posible. Es un principio que puede resultar útil, pero que filosóficamente es delicado. En primer lugar, deberíamos definir qué entendemos exactamente por “simple”, dado que, si no lo hacemos, quedaremos expuestos a todo tipo de problemas. Por ejemplo, una hipótesis simple que puede explicar cualquier cosa es: “lo hizo la bruja”. Como nos recuerda Yudkowsky en * Rationality: From AI to Zombies* puede parecer mucho más simple decir que algo lo hizo una bruja que cualquier otra explicación. Hay definiciones técnicas de simplicidad, que relacionan la complejidad de una hipótesis con su compresibilidad informática, que solucionan este problema. Sin embargo, esta preferencia por la simplicidad adolece de otro problema más serio. Que una hipótesis sea simple no garantiza que se corresponda con la realidad, puede que la conclusión correcta no sea la más simple. Los defensores actuales de este principio lo circunscriben a la asignación de las probabilidades a priori de las hipótesis, pero la explicación detallada de este asunto la dejaremos para más adelante. Jean Buridan, otro escolástico del siglo XIV, mostró que la teoría silogística aristotélica era en realidad un subtipo de una teoría más general llamada de consecuencias.373 Por desgracia, muchos de estos avances cayeron en el olvido a partir del siglo XV. Puede que el interés de los autores de la época Moderna por la observación y la experimentación limitase el desarrollo del análisis lógico, que estaba muy asociado al análisis sutil de los textos. No volvió a haber lógicos de este nivel hasta el siglo XIX. En la India, la lógica y la epistemología siguieron un desarrollo independiente, aunque paralelo al occidental. Los primeros textos budistas ya se interesaron, como en el caso griego, por las reglas que debían regir los debates y las críticas públicas374 y esto condujo a la creación de unas herramientas muy similares a las occidentales.375 Por ejemplo, hay textos indios en los que se desarrollaron formas de argumentación equivalentes a las del modus tollens, el modus ponens, la reducción al absurdo, el principio de no contradicción y el principio aristotélico del tercero excluso.376 El desarrollo lógico en las escuelas indias se inspiró más en el análisis gramatical que en las matemáticas y cubrió un área más amplia que la lógica deductiva formal, ya que incluyó análisis epistemológicos sobre los modos correctos de obtener conocimiento. Uno de los principales debates que mantuvieron estas escuelas fue el relativo a qué fuentes de conocimiento debían ser aceptadas como válidas, siendo las alternativas en disputa: la percepción del mundo exterior y de nuestra propia mente, la inferencia, la comparación y la analogía, la implicación circunstancial, la imposibilidad lógica y el testimonio de un tercero. A partir del siglo XIX la lógica experimentó el gran florecimiento del que todavía disfrutamos hoy en día. Uno de los principales intereses de los autores contemporáneos ha sido la transformación de la lógica en una especie de cálculo matemático, así como el análisis de la relación entre la lógica y las matemáticas. Dos de los autores fundacionales fueron el matemático y lógico alemán Gottlob Frege y el filósofo estadounidense Charles Sanders Peirce.377 Otros lógicos notables fueron el italiano Giuseppe Peano, los alemanes Ernst Zermelo y David Hilbert y los ingleses Alfred North Whitehead y Betrand Russell. Por último, cabe destacar el trabajo de George Boole, que estableció las bases del cálculo lógico378 que constituye el fundamento del posterior desarrollo de los ordenadores, que en el fondo no son más que calculadoras lógico-matemáticas. El desarrollo de la lógica fue un gran avance para la filosofía y para la ciencia. Una ventaja de este análisis, comparado con el que hacen nuestros sistemas cognitivos automáticos, es que la lógica descansa en un número de premisas muy pequeño que, además, son explícitas. En realidad, la lógica surge de la sistematización de un pequeño conjunto de intuiciones elementales como: que toda entidad es idéntica a sí misma, que una proposición y su negación no pueden ser verdaderas al mismo tiempo, “o dos más dos son cuatro o no lo son”, y que si una proposición afirma algo y otra lo contradice, una de las dos debe ser verdadera y, además, no hay otra posibilidad, “es verdad que uno más uno son dos o que no lo son”. A estos principios se le añaden unas reglas de inferencia elementales como modus ponens, “Cuando llueve llevo paraguas y está lloviendo, por lo tanto, llevo paraguas” y modus tollens, “Si cuando llueve llevo paraguas y no llevo paraguas, seguro que no está lloviendo”. Estos principios elementales son fáciles de aceptar, pero lo que no hacemos habitualmente es aplicarlos sistemáticamente y eso es lo que diferencia las inferencias lógicas válidas de nuestros razonamientos cotidianos. No es que partan de principios incompatibles o muy diferentes, sino que la lógica formal es sistemática. Este hecho se refleja en el propio nacimiento de la lógica; lo que hizo Aristóteles, precisamente, fue analizar sistemáticamente los razonamientos presentes en la oratoria sofística para destilar aquellos que eran estrictamente válidos. Y por eso no ha de sorprendernos que en la India y en Grecia se llegasen a conclusiones tan similares. Sin embargo, esto no ha de hacernos pensar que existe una sola lógica ya que puede elegirse añadir principios adicionales o, incluso, modificar alguno. Este es un tema avanzado que aquí no podemos explicar con detalle, pero que está muy bien explicado en diversos textos sobre lógica. Seguir las reglas de la lógica nunca garantizará que hayamos alcanzado la verdad, pero al menos, podremos asegurarnos de que nuestras inferencias son válidas y que las conclusiones se siguen de las premisas. Además, la lógica nos permite analizar la coherencia de nuestras creencias, incluso aunque no asumamos que son verdaderas. Debemos aspirar a defender sólo creencias coherentes, el conocimiento debe ser consistente.379 Nadie en su sano juicio habría de aceptar que algo es y no es a la vez y exigir coherencia lógica es un modo de protegernos contra nuestros propios sesgos. Sin embargo, el conocimiento intuitivo cotidiano, como el mítico, no suele exigir coherencia. Muestra de ellos son los numerosos refranes incoherentes que pueblan nuestro refranero como: a quien madruga dios le ayuda, aunque no por mucho madrugar amanece más temprano o a la tercera va la vencida, pero no hay dos sin tres. La exigencia de coherencia puede incluso obligarnos a abandonar creencias muy queridas. Los escolásticos medievales tuvieron muchos problemas con algunas ideas relacionadas con el dios cristiano. Uno de ellos es la paradoja de la omnipotencia: si un dios es omnipotente, lo puede todo, ¿podría crear una piedra tan pesada que él mismo no pudiese levantar? Otro problema es el de la compatibilidad de la omnisapiencia divina y el libre albedrío. Si proponemos un dios creador que ya lo sabía todo cuando creó el universo, también sabría cómo vamos a comportarnos en todo momento, por lo tanto, no tenemos libre albedrío, por lo que se nos pueda condenar en base a este comportamiento resulta un tanto perverso. Si por el contrario realmente podemos decidir por nosotros mismos y dios no podría conocer nuestras decisiones de antemano y no sería omnisapiente. Ni si quiera pensadores de la talla de Tomás de Aquino fueron capaces de resolver estos problemas, algo que sería injusto recriminarles, ya que el problema del libre albedrío, libre ya de las implicaciones teológicas, continúa siendo debatido por los filósofos morales actuales. Al lector interesado en la lógica le recomiendo Philosophical Devices: Proofs, Probabilities, Possibilities, and Sets de David Papineau, una introducción, escrita por un veterano profesor de filosofía del King’s College londinense, a ésta y a otras cuestiones que trataremos sólo tangencialmente en este libro. 4.3 Matemáticas: los sublimes arquitectos Otra de las grandes creaciones del mundo clásico fueron las matemáticas. Al hablar de las grandes civilizaciones antiguas ya dijimos que todas desarrollaron matemáticas elementales y, efectivamente, las matemáticas clásicas y helenísticas son herederas de esos resultados.380 Sin embargo, las matemáticas clásicas representan un avance monumental, son el verdadero inicio de las matemáticas actuales.381 Tal vez el ejemplo más notable de estos logros sea Euclides. A parte de que fue un gran matemático helenístico y de que vivió en Alejandría alrededor del 300 a. C., no sabemos prácticamente nada de la biografía de Euclides.382 Sin embargo, lo que es seguro es que Los elementos es el libro matemático más influyente jamás escrito. Desde que se introdujo la imprenta en el siglo XV, se han publicado más de mil ediciones. Los elementos es en realidad una compilación de trabajos previos que, partiendo de una pequeña lista explícita de definiciones y postulados, construye un gran edificio matemático mediante la deducción.383 Esta aproximación resulta tan moderna que Los elementos todavía sirvieron como libro de texto e inspiración a Russell y Einstein.384 El magistral uso de la deducción lo convirtió en el modelo a seguir para toda la matemática posterior.385 Además, Euclides no fue un fenómeno aislado en el mundo helenístico. Como otros ejemplos de la impresionante producción matemática de esta cultura pueden servir Apolonio, que fue otro gran geómetra cuyo trabajo sobre las secciones cónicas llegó a tener una gran influencia en el periodo moderno,386 y Diofanto, uno de los creadores del álgebra, cuyo innovador trabajo, por desgracia, se perdió casi por completo. Sin duda, el desarrollo fundamental de la matemática griega fue la demostración. La única otra tradición filosófica que llegó a aproximarse, aunque no con tanto rigor, al uso de la deducción fue la india.387 De hecho, fue en las matemáticas en donde la deducción se utilizó por primera vez, y fue esta, como hemos comentado, una de las inspiraciones de Aristóteles, que quiso trasladar el rigor y el éxito matemático al resto de áreas del conocimiento. Aunque el origen histórico de la lógica esté ligado a la deducción matemática no hemos de pensar que la lógica deriva de las matemáticas. De hecho, la relación precisa entre lógica y matemáticas sigue siendo un debate abierto actualmente. Hay autores que sostienen que la lógica podría ser la base de las matemáticas y otros que piensan que la lógica es en realidad una rama de las matemáticas.388 En cualquier caso, ambas disciplinas tienen una relación muy estrecha. Lo relevante de las matemáticas es que de una conclusión matemática bien demostrada podemos tener, en principio, certeza absoluta. Los teoremas suficientemente contrastados quedan para siempre. Antes de continuar conviene hacer una aclaración terminológica. Muchas veces en nuestra vida diaria, e incluso en la ciencia, utilizamos el término “prueba” como sinónimo de evidencia, pero en filosofía de la ciencia el “prueba” se reserva para la demostración matemática. La sangre en la escena del crimen o las observaciones de la posición de Marte no son pruebas, son evidencias. Es una prueba la demostración del teorema de Pitágoras. La lógica deductiva conduce al conocimiento cierto.389 Este hecho debió fascinar a los griegos clásicos, y es esto lo que hizo que se adoptase como el estándar al que aspirar por encima de la percepción, que en algunos casos puede engañarnos, y de la inducción que, precisamente por ser deductivamente inválida, siempre implica una renuncia a la certeza. Por primera vez en la historia de la humanidad fue posible obtener conocimiento con una certeza absoluta y, además, se hizo mediante la razón pura. Las conclusiones deductivas son infalibles y esto hizo que la tradición occidental las tomase como ejemplo hasta la revolución científica. Las matemáticas de las civilizaciones antiguas se asentaban sobre la observación y la inducción, como las ciencias actuales390 y fueron los pitagóricos quienes dieron un giro copernicano a la situación. El resultado que hoy conocemos como teorema de Pitágoras era conocido ya en China y Mesopotamia,391 pero no tenían una demostración deductiva que lo garantizase. Ni tan siquiera tenían la idea de que tal cosa pudiese hacerse. Algunos atribuyen la creación de la demostración matemática a Tales,392 pero esto parece poco probable.393 Tampoco parece razonable que Pitágoras fuese capaz de conseguir levantar el edificio deductivo en una sola generación. El problema es que cuando se trata de pitagóricos es imposible distinguir los avances de los discípulos de los del maestro, ya que cualquier desarrollo de la secta-escuela era atribuido a Pitágoras.394 Lo que sí parece más probable es que fuesen los pitagóricos los que alumbraron este gran avance.395 Sabemos, por ejemplo, que Hipócrates de Quíos, un filósofo probablemente pitagórico, ideo la prueba por reducción al absurdo y escribió un libro sobre geometría compuesto por teoremas.396 Estos desarrollos no fueron propiciados por un interés práctico, para eso eran suficientes las matemáticas de Mesopotamia y Egipto. El interés de los pitagóricos era en gran parte místico. Platón heredó la tradición pitagórica y esto hizo que la Academia se convirtiese en un centro de estudio y desarrollo matemático.397 Sin embargo, no hemos de confundir esta aproximación pitagórico-platónica con el uso moderno de las matemáticas en ciencia. Platón no se planteaba crear leyes que resumiesen observaciones cuantitativas. En realidad, los griegos clásicos ni siquiera consideraban que la aritmética fuese parte de las matemáticas, ya que, debido al problema de los números irracionales, carecía de una fundamentación deductiva y era considerada como una mera herramienta tecnológica, algo que Platón despreciaba. La aproximación de la Academia se limitaba al uso de la geometría, que sí tenía una fundamentación demostrativa, y su objetivo era utilizarla como herramienta para desentrañar los secretos del logos de un modo puramente racional. De modo que la aproximación pitagórico-platónica no resultó ser productiva para las ciencias naturales en la época clásica, pero, por el contrario, este interés sí que causó un extraordinario desarrollo matemático. Muchos de los matemáticos importantes previos a Euclides fueron alumnos de la academia, como Heráclides Póntico o Eudoxo de Cnido.398 Esto permitió que se sistematizasen las reglas deductivas,399 estableciendo así las bases de la matemática moderna400 con las que Euclides elaboró su gran síntesis. 4.4 Resumen La definición clásica de conocimiento es: creencia verdadera justificada. Es decir, el conocimiento debe corresponderse con la realidad y ha de poder ser defendido razonadamente. Una de las ventajas de exigir justificaciones es que éstas pueden ser defendidas ante la comunidad que puede criticarlas y enmendarlas y esto hace que el conocimiento progrese. Dado el interés de los mundos helénico y helenístico por estas justificaciones no es de extrañar que desarrollasen la lógica. Su objetivo era alcanzar la certeza matemática en sus justificaciones. Esto, con el tiempo, se comprobó imposible, pero, al menos, consiguieron asegurar coherencia entre proposiciones, por ejemplo, entre premisas y conclusiones. La lógica se basa en sistematizar intuiciones muy elementales y aunque este rigor pueda parecer baladí, en realidad, la convirtió en una herramienta muy poderosa. El conocimiento debe aspirar a ser coherente, consistente y hemos de tratar que nuestras inferencias sean válidas. Este requisito de coherencia es suficiente para construir disciplinas formales como la propia lógica o las matemáticas. Puede utilizarse incluso para desvelar verdades que, aunque se siguen de las premisas ya aceptadas, son desconocidas previamente. En esto se basa todo el edificio deductivo matemático construido siguiendo el paradigma euclídeo. Por otro lado, la exigencia de verdad, tiene mucho sentido en el estudio del mundo externo. Una creencia es verdadera cuando refleja ese mundo. Los mapas verdaderos son aquellos que reflejan el territorio. Cuando estamos tratando con el estudio del mundo externo esta exigencia es incluso más relevante que la de la coherencia lógica. Hay muchos mapas perfectamente coherentes que no se corresponderán con el territorio. Podemos construir un gran número de bellos edificios deductivos, pero sólo algunos reflejarán la realidad externa y por lo tanto servirán como mapas fiables. En las disciplinas formales lo relevante es que las conclusiones se sigan de las premisas, pero cuando estamos tratando con la realidad la justificación última del mapa es sólo una: o funciona o no funciona. Debemos aspirar a razonar con validez lógica, pero hemos de recordar que esto no garantizará verdad. La verdad depende del mundo externo, no de la validez formal del razonamiento. El conocimiento del mundo externo exige conexión empírica. Además, si aspiramos a descubrir regularidades, por ejemplo, leyes físicas generales, hemos de renunciar a la estricta validez lógica. La deducción no es ampliativa, permite deducir conclusiones concretas a partir de reglas generales, pero para construir esas reglas generales a partir de observaciones limitadas siempre estaremos obligados a dar saltos lógicos inválidos. La consecuencia de este hecho es que el conocimiento del mundo externo siempre será limitado y falible. "],["metafisicos.html", "5 Metafísicos 5.1 El estudio de lo que es 5.2 Metafísica matemática 5.3 Asaltemos los cielos 5.4 La recuperación medieval 5.5 Especulativos vs naturalistas 5.6 Resumen", " 5 Metafísicos 5.1 El estudio de lo que es Los filósofos clásicos no se limitaron a desarrollar un conjunto de herramientas con las que pensar racionalmente, sino que, como era de esperar, las utilizaron para estudiar el cosmos. Concretamente, uno de sus temas favoritos fue la metafísica. Esto puede sonar a oídos del no iniciado como algo abstruso, pero, en realidad, el objetivo de la metafísica es muy pedestre. Cuando decimos que hay un gato sobre la mesa estamos haciendo una afirmación metafísica, estamos asumiendo que existen dos entidades en el mundo externo a nuestra mente: el gato y la mesa, y de eso, precisamente, va el asunto. La metafísica no es más que el estudio de lo que es.401 Al afirmar que creemos que las mesas y los gatos tienen una existencia real estamos defendiendo una posición metafísica sobre lo que existe en el mundo externo. Si esto te parece algo muy elemental es porque realmente lo es. Aristóteles lo consideró tan básico que lo denominó primera filosofía. El nombre de metafísica se lo darían posteriormente quienes recopilaron los escritos aristotélicos y decidieron colocar los relativos a esta primera filosofía después de los que trataban sobre la física, por lo que acabaron más allá (meta) de la física. Otro término muy relacionado con el anterior es “ontología”. W. V. O. Quine dijo que el problema ontológico era muy simple y que se podía resumir con la pregunta “¿Qué hay?”. Una ontología es el conjunto de entidades que existen en el mundo. Por ejemplo, forman parte de mi ontología, mi gata, la mesa sobre la que escribo, etc. Ontología deriva del verbo einai que significa ser o existir.402 Se puede considerar que Parménides, el maestro de Zenón, el de las paradojas, fue el primer metafísico, el primero en interesarse por estudiar lo que existe realmente403 y su conclusión fue que lo que realmente existe es homogéneo, inmóvil y perfecto y que, por lo tanto, el cambio que observamos en el mundo no ocurre en un nivel fundamental. Parménides no consideraría que mi gata, a pesar de que procura no moverse más que lo imprescindible, tiene una realidad última. Los metafísicos a lo largo de la historia han tendido a hacer planteamientos bastante peculiares sobre lo que realmente existe en el mundo. La metafísica es una parte de la filosofía incluso más controvertida que la epistemología.404 Aristóteles pensaba que los gatos individuales tenían una existencia fundamental, mientras que la teoría platónica de las formas planteaba que es la gatunidad, la esencia de lo gatuno, la que realmente es fundamental. Muchos físicos actuales dirían que lo que existe a nivel fundamental realmente son campos cuánticos y, a lo largo de la historia, ha habido discusiones sobre la existencia de diversos dioses o sobre la existencia del alma como un ente separado de lo físico. Como acabamos de comentar los primeros metafísicos ya plantearon que lo que observamos no es la realidad última. Demócrito, siguiendo con la tradición, pensó que el mundo estaba compuesto por átomos, y que, por lo tanto, nuestros ojos no nos muestran la realidad. El problema que se plantearon los pensadores clásicos fue cómo obtener ese conocimiento sobre entidades que no eran observables directamente. Dado que nuestros sentidos no son capaces de mostrarnos la realidad fundamental muchos pensaron que la única herramienta adecuada era la razón. Parménides y Zenón, por ejemplo, actuaban de este modo, confiaban más en la razón que en sus sentidos405 e intentaban justificar sus conclusiones mediante especulaciones racionales. Los atomistas tampoco se preocuparon por ver ningún átomo, llegaron a ellos mediante un análisis racional.406 De hecho, no hemos podido observar átomos directamente hasta finales del siglo XX. Demócrito llegó incluso a afirmar que existían dos tipos de conocimiento: el bastardo ofrecido por nuestros sentidos y el profundo y real que sólo era alcanzable mediante la razón.407 Los pitagóricos también tenían ideas parecidas, asociaban los sentidos a la mortalidad, a lo pasajero, mientras que la razón sería capaz de acercarnos a las ideas realmente trascendentes.408 Esta es una conclusión que Platón, como buen pitagórico, también compartiría.409 Los filósofos naturales de la Edad Moderna y los científicos actuales también piensan que es fundamental utilizar la razón para estudiar el funcionamiento del cosmos, al fin y al cabo, es habitual que la ciencia contradiga nuestras percepciones: la Tierra se mueve y los objetos están compuestos por moléculas y átomos. Sin embargo, la actitud de Parménides, Demócrito y muchos otros filósofos clásicos y medievales, e incluso de los racionalistas de la Edad Moderna, iba más allá; su desconfianza de los bastardos sentidos les llevaba a basar sus conclusiones en la mera especulación intelectual. No se planteaban hacer observaciones sistemáticas ni, mucho menos, experimentos. Aunque es cierto que no todos rechazaron tan radicalmente sus sentidos. Aristóteles, por ejemplo, fue empirista. 5.2 Metafísica matemática El programa metafísico pitagórico acabó siendo especialmente relevante a lo largo de la historia de la ciencia. La fascinación pitagórica por los números parece tener su origen en un fenómeno que ellos descubrieron y que relaciona las matemáticas con la armonía. Hay notas musicales que al sonar a la vez producen un sonido armónico y otras que suenan disonantes. Los pitagóricos se dieron cuenta, probablemente estudiando la lira, de que estas armonías tenían una relación muy estrecha con la longitud de las cuerdas. Hay intervalos musicales, diferencias en frecuencia entre dos notas, que suenan especialmente armónicos, por ejemplo, los que los músicos denominan una cuarta y una quinta justas. Y los pitagóricos observaron que dos cuerdas producían notas armónicas cuando sus longitudes tenían una relación de, por ejemplo, cuatro tercios o de tres medios.410 Es decir, que dos sonidos son armónicos cuando son producidos por cuerdas cuyas longitudes tienen como relación un número racional sencillo. Esta relación entre la armonía musical y los números racionales hizo pensar a los pitagóricos que las matemáticas debían de ser la clave para entender la estructura y el orden del universo.411 Es posible que debamos a esta convicción el extraordinario desarrollo matemático de los pitagóricos y de sus herederos intelectuales. Platón visitó las comunidades pitagóricas de la Magna Grecia, localizadas en el sur de la península itálica, y quedó profundamente influido por ellas y fue Platón quien más hizo por popularizar la idea de que la realidad física sólo puede ser comprendida mediante las matemáticas. De hecho, su demiurgo, el creador de nuestro mundo material, se convirtió en un geómetra divino.412 El programa platónico consistió en trasladar la metodología deductiva de las matemáticas para tratar de conseguir conocimiento seguro. Esta idea de que las matemáticas son fundamentales para estudiar el cosmos tampoco le es ajena a ningún físico actual. Aunque, en realidad, hay diferencias importantes entre las ideas pitagóricas y las de la mayoría de los científicos contemporáneos. Mientras que para estos últimos las matemáticas son una herramienta para el estudio de la realidad física, parece que para los pitagóricos los números constituían la realidad última metafísica. El cosmos era número, no materia.413 En cualquier caso, el programa pitagórico ha seguido resonando a lo largo de la historia. Kepler intentó cuadrar las observaciones planetarias con una supuesta armonía celeste.414 Más recientemente, Heisenberg dijo que la física había dado la razón a Platón y que la realidad fundamental está constituida por formas platónicas que pueden ser expresadas solamente mediante lenguaje matemático.415 Estas afirmaciones pueden sonar exageradas, pero las matemáticas parecen tener un poder casi inaudito de desvelar las relaciones más profundas del mundo físico. A partir del estudio matemático de la electricidad y el magnetismo, Maxwell fue capaz de obtener fórmulas que describían la luz. Las matemáticas habían relacionado los imanes con los arcoíris, algo que resulta bastante inesperado. Y este no fue el único caso en el que de la aplicación de las matemáticas a la física surgieron resultados imprevistos. Emmy Noether fue una de las principales mentes matemáticas del siglo XX y, sin embargo, uno de sus muchos logros consistió en deducir que las simetrías que pudiera contener la expresión matemática de una teoría física se corresponden con cantidades conservadas en el mundo natural, como, por ejemplo, la energía o la masa. Es decir, no es necesario comprobar experimentalmente que la energía se conserva: hoy en día sabemos, gracias al teorema de Noether que cualquier teoría física que respete el principio de que la física no varía a lo largo del tiempo, de que un experimento hecho hoy dará el mismo resultado que uno que hagamos mañana, también deberá respetar necesariamente el principio de conservación de la energía. Esta es una de las ideas más profundas que haya tenido jamás un ser humano: no se puede tener simetría sin conservación ni conservación sin simetría y este resultado no es experimental, sino deductivo. Aunque este es uno de los ejemplos más sobresalientes de la aplicación de la deducción en la ciencia, no hemos de pensar que podemos prescindir de la observación y la inducción para hacer física fundamental. El teorema de Noether no nos indica qué simetrías hemos de introducir en las teorías y, por lo tanto, qué teoría física concreta se corresponde con nuestro universo. Tan sólo restringe el conjunto de posibles teorías coherentes a aquellas que cumplan estos principios de simetría y conservación. Este teorema igual puede utilizarse para hacer física newtoniana, relativista o cuántica. Lo que es indiscutible es que, ante estos descubrimientos profundos y completamente inesperados, no es extraño que algunos piensen que las matemáticas tienen una relación esencial con el logos. Sin embargo, para explicar el extraordinario éxito de las matemáticas, no es necesario adquirir el compromiso metafísico pitagórico de que el número es la esencia de la realidad; un compromiso, que, además, no tiene un significado demasiado claro. Recordemos que las matemáticas están estrechamente relacionadas con la lógica y, por lo tanto, no es de extrañar que en el estudio del universo acaben creándose modelos matemáticos que describan la realidad más profunda y sencilla con precisión. Al utilizar las matemáticas lo que estamos haciendo es simplemente razonar con corrección y precisión, estamos aprovechando la exigencia de coherencia de nuestra red de creencias para llegar más allá de lo que hemos observado. Aunque, en cualquier caso, hemos de reconocer que el programa pitagórico fue excepcionalmente productivo, pocas ideas han cosechado tantos éxitos, desde la armonía musical a las profundidades del mundo cuántico. 5.3 Asaltemos los cielos Platón planteó una de las teorías metafísicas más famosas de todos los tiempos, la conocida como teoría de las formas o de las ideas. Esta propuesta surgió a partir de una reflexión sobre el problema de los universales. ¿A qué se refieren los términos como humano o gato que engloban a multitud de individuos?416 ¿Dónde reside la gatunidad? Uno podría plantear que la gatunidad sólo existe en nuestra mente, pero esta propuesta tendría el problema de que los gatos parecen existir independientemente de que un ser humano los reconozca como tales. Según Platón cada gato sería un ejemplo imperfecto de una forma, de un tipo ideal inmutable. Esta tesis parece funcionar muy bien en algunos casos. Por ejemplo, podríamos decir que todas las notas que jamás hayan sonado o vayan a sonar como un do central son ejemplos de una nota pura ideal correspondiente a una sinusoidal perfecta con una frecuencia de 261,63 hercios. Según los platonistas esta nota ideal tendría una existencia más real que cualquier otra nota que podamos escuchar en nuestro mundo. Del mismo modo, la forma relativa a la gatunidad no sólo reuniría todas las cualidades esenciales de las que cualquier gato concreto participa, sino que sería más real que cualquier gato físico.417 Esta realidad compuesta por las formas constituiría la realidad profunda del cosmos, mientras que el mundo físico tendría una existencia secundaria.418 Las formas, que serían inmutables, eternas e imperceptibles para los sentidos. Nuestros ojos sólo son capaces de mostrarnos gatos físicos, pero a la forma, al verdadero objeto del conocimiento sólo puede llegarse mediante la razón.419 Aristóteles, que de animales entendía porque fue el fundador de la zoología, criticó duramente esta teoría. Para él, lo que tenía una existencia primaria eran las sepias individuales que estudiaba en la laguna de Lesbos. Antístenes el cínico, expresó las mismas dudas al decir que había visto caballos, pero no la caballidad.420 La teoría platónica parece funcionar mejor en el mundo de la física fundamental, en la que todos los electrones son exactamente iguales al tipo ideal definido por la teoría, que en el mundo biológico. Tal vez sea por esto que los físicos que conozco tiendan a simpatizar más con esta idea que los biólogos. Aristóteles y mis amigos biólogos, al no aceptar la existencia primaria de los tipos ideales, no acaban de ver qué comparten, qué hay de universal, en todos los individuos que pertenecen a un mismo tipo.421 De hecho, en biología, los criterios de definición de las especies son un tema de confrontación constante. ¿Somos los seres humanos la misma especie que los neandertales? ¿En base a qué criterio? La mayoría de los biólogos actuales los separan en su propia especie, Homo neanderthalensis, pero no hace tanto lo común era situarlos dentro de la nuestra, denominándolos Homo sapiens neanderthalensis. Una polémica similar afecta a los gatos domésticos, que eran clasificados por la mayoría de los zoólogos como una subespecie de gato silvestre, Felis silvestris catus, pero que, recientemente, han sido elevados a su propia especie: Felis catus. Sin embargo, Platón no se limitó a aplicar su teoría de las formas a las notas musicales, a la geometría o a la biología, fue mucho más allá y llegó a hablar de la forma de la belleza o del bien de la que participarían todos los objetos bellos o buenos. Además, estableció una jerarquía en las formas, con la forma del Bien en la cima que sería la forma de la que todas las demás participarían. Esta fue una propuesta que los cristianos pudieron compatibilizar fácilmente con su propia metafísica; el Bien sería equivalente al Dios cristiano y toda la creación surgiría de él. No es de extrañar que el Timeo, el diálogo en el que Platón propuso una cosmología, fuese uno de los pocos textos que sobrevivieron a la caída del Imperio Romano y que disfrutase de una gran popularidad durante la Edad Media.422 Estas ideas, además, fueron desarrolladas por los neoplatónicos de las épocas helenística y romana creando metafísicas con jerarquías de formas realmente barrocas. Plotino, del siglo III d. C., fue uno de los máximos representantes de esta escuela de pensamiento. Este filósofo estaba tan interesado en alcanzar los cielos metafísicos, a los que no podía acceder mediante la observación, que incluso llegó a aceptar la revelación mística como vía de conocimiento.423 Agustín de Hipona, un filósofo y teólogo de los siglos IV y V, comenzó siendo maniqueo y neoplatónico antes de convertirse al cristianismo y terminó siendo uno de los teólogos más influyentes de la historia. De hecho, la Iglesia lo considera santo, padre y doctor de la Iglesia católica. Fue Agustín quien cristianizó a Platón.424 Las formas se convirtieron en ideas eternas e inmutables en la mente del dios cristiano.425 Poco tiempo después de Agustín el Imperio Romano de Occidente cayó y Europa quedó sumida en una pobreza incapaz de sostener ningún desarrollo intelectual hasta, al menos, el reinado de Carlomagno en el siglo IX. Esta caída conllevó la pérdida de la mayor parte de la filosofía griega. De Platón, por ejemplo, la única traducción latina que perduró fue el ya comentado Timeo.426 5.4 La recuperación medieval Este programa metafísico clásico tuvo continuidad en el mundo medieval. Aristóteles, que no fue integrado en el cristianismo por los filósofos y teólogos del mundo romano, pero se recuperó en Europa a partir del siglo XII.427 Desde ese momento, una parte del trabajo de los escolásticos y los humanistas consistió en integrar el conocimiento clásico con la visión cristiana del mundo.428 Esta tarea, dada la magnitud de la obra recuperada, fue hercúlea y requirió varios siglos. Alberto el Grande primero429 y, sobre todo, Tomás de Aquino, el filósofo más relevante de la Edad Media, hicieron un gran esfuerzo por integrar la filosofía aristotélica con la platonico-cristiana. En cualquier caso, el corpus aristotélico no sólo fue integrado, sino que acabó convirtiéndose, una vez adaptado al cristianismo, en el estándar académico. Para los modernos, como Galileo, Aristóteles era, de hecho, un símbolo del antiguo régimen, de una autoridad más interesada en intrincadas especulaciones metafísicas que en observar la naturaleza. Resulta irónico que esto estuviese completamente alejado del ánimo del Aristóteles original que, como veremos, era empirista.430 La metafísica medieval llegó incluso a plantearse como una alternativa a la filosofía natural.431 Parménides al plantear sus hipótesis estaba estudiando la realidad profunda de la naturaleza, pero en la Edad Media la metafísica se convirtió en el estudio de lo trascendente, de aquello que está más allá del mundo físico. Emborrachados por el recién recuperado conocimiento antiguo y por la lógica se creyeron capaces de alcanzar la realidad última mediante el uso de la pura especulación, olvidando el ejemplo aristotélico, que pasó años en una playa en Lesbos diseccionando sepias con sus propias manos. Para muchos de los filósofos posteriores esta desmesurada confianza en la razón llegó a ser casi motivo de chanza. Para Hume, el epítome de la filosofía ilustrada, y para los positivistas, “metafísico” se convirtió, prácticamente, en un insulto con el que acusar a quien pretende alcanzar el conocimiento asentándose sobre una pila de sofismas.432 Todavía hoy cuando un metafísico, como James Ladyman, caracteriza a alguien como neoescolástico, no lo hace con cariño. 5.5 Especulativos vs naturalistas Aunque, tal vez el problema no estribe tanto en la metafísica como área de estudio, que recordemos sólo trata de comprender lo que hay en el mundo, sino en los métodos que algunos han utilizado para conseguir este objetivo. Actualmente la mayoría de los filósofos asume que la metafísica debe estar basada, en última instancia, en la ciencia, es decir, en el conocimiento sistemático del mundo natural. Además, si queremos estudiar el mundo natural habremos de partir de las observaciones que hagamos del mismo. Aunque esta es una idea obvia, no fue la aproximación defendida por los filósofos escolásticos medievales ni por otros metafísicos especulativos posteriores, incluyendo a algunos actuales. Algunos metafísicos todavía sostienen que para estudiar el mundo natural es útil partir de intuiciones básicas y que, a partir de éstas mediante la razón pura pueden alcanzarse conclusiones sólidas.433 Ejemplos de intuiciones claras son: que el mundo está poblado por objetos sólidos que ocupan una posición definida en el espacio o que en el cosmos hay, al menos, un ser consciente, yo. Este tipo de filosofía fue criticada duramente entre otros, por Hume, los positivistas y Russell. Una cuestión relevante es hasta qué punto nuestras intuiciones más queridas deben tomarse como un fundamento en la filosofía. En realidad, la metafísica especulativa y la naturalista no parten de presupuestos tan diferentes. Ambas utilizan información que hace referencia al mundo externo: intuiciones en el caso de la especulativa y evidencias empíricas en el caso de la ciencia y la metafísica naturalista. Y ambas emplean esta información para justificar sus teorías. Sin embargo, hay que recordar que la ciencia nos ha enseñado que nuestras intuiciones pueden estar profundamente equivocadas y que antes de aceptarlas hemos de contrastarlas con el resto del conocimiento científico. Por ejemplo, aunque parece evidente que existen objetos sólidos, en realidad, esta es una intuición muy discutible. Las bolas de billar están compuestas por átomos, que, a su vez, en nuestras teorías actuales, están compuestos por entidades más fundamentales, concretamente por excitaciones de campos cuánticos. Lo que existe a nivel fundamental se parece mucho más a la onda causada por el impacto de una piedra en un lago en calma, que a una bola de billar localizada en una región concreta del espacio. Ni tan siquiera podemos estar seguros de que el propio espacio tenga la estructura que nos parece. Los físicos no descartan que a un nivel más profundo el espacio sea algo mucho más extraño de lo que, por el momento, somos capaces de imaginar. Además, ¿acaso han conseguido los metafísicos especulativos algún éxito predictivo? Hemos de tener en cuenta que nuestras intuiciones, como nuestros sistemas perceptivos y cognitivos son creadas por un sistema nervioso que ha surgido para responder a unos retos concretos.434 En la sabana es útil creer que los tigres y los frutos ocupan posiciones concretas en el espacio, pero esto no implica que la misma intuición vaya a ser aplicable en el dominio de lo muy pequeño. La evolución ha adaptado nuestras intuiciones a nuestra escala, por lo que no debemos asumir que funcionarán en otras escalas.435 De hecho, gran parte del progreso científico se ha basado en destruir muchas de nuestras intuiciones. La Tierra no es plana y se mueve, no es necesario ejercer una fuerza para que se mueva un objeto sino para modificar su estado de movimiento, las especies biológicas no son inmutables, etcétera. Los filósofos denominan al conjunto de las ideas intuitivas que tenemos sobre el mundo natural imagen manifiesta del mundo y las contraponen a la imagen científica. Por lo que si basamos nuestras especulaciones metafísicas en esta imagen manifiesta lo que realmente estamos haciendo es antropología introspectiva.436 Además, este problema de las intuiciones no es el único. Los razonamientos, por muy cuidadosos que seamos con la lógica, pueden acabar llevándonos a lugares completamente equivocados. Lo primero que uno aprende tras hacer unos cuantos experimentos en el laboratorio, es que la mayoría de las ideas razonables que uno tiene acaban en el cubo de la basura tras someterse al juicio del mundo externo y las que quedan, son simplemente una aproximación que no acaba de capturar por completo la complejidad de la realidad. Como alternativa a esta metafísica neoescolástica se ha propuesto una aproximación naturalista basada en el conocimiento científico.437 Quine defendió que la metafísica debía ser científica, puesto que el empirismo es el único modo que ha funcionado de anclar nuestras creencias a la realidad.438 Mientras que la metafísica especulativa no ha tenido ningún éxito predictivo, la ciencia ha continuado progresando. Ladyman propone que la metafísica debe aspirar a mostrar una visión integrada del mundo natural basada en el conocimiento aportado por las distintas ciencias:439 la relatividad y la mecánica cuántica deben guiar la metafísica relativa al espacio y el tiempo y la sustancia, y la biología la concerniente a las clases naturales.440 Por supuesto, esta aproximación tiene la consecuencia de que nuestra metafísica será, como la ciencia en la que se basa, falible. Es decir, no habrá lugar para dogmas absolutos, nuestro mejor modelo del mundo siempre será revisable y puede que mañana debamos modificarlo. A cambio, esta metafísica será la más racional disponible en cada momento. Antes de terminar me gustaría hacer una precisión. En esta discusión he hablado sobre la metafísica relativa al mundo natural. Hay muchos filósofos que piensan esto es todo lo que hay, pero otros plantean metafísicas enriquecidas con otros aspectos. Por ejemplo, algunos proponen que los estados psicológicos o las leyes morales merecen una consideración metafísica y que no han de ser englobados dentro del mundo natural. Por ejemplo, es razonable plantear que los estados psicológicos o las reglas morales tienen poderes causales. Decimos que el niño golpeó la pelota porque quiso hacerlo. Es decir, su estado mental fue la causa de lo que ocurrió. En este caso las intuiciones constituirían un modo de estudiar filosofía de la mente o filosofía moral y algunos filósofos propondrían metafísicas asociadas a estos estudios.441 Esta es una cuestión complicada que trataremos con algo más de detalle posteriormente, baste decir por el momento que en esta sección nos estábamos refiriendo únicamente a la metafísica relativa al mundo natural. La discusión sobre las metafísicas no naturalistas, que no supernaturalistas, es una cuestión muy diferente que trataremos más adelante. 5.6 Resumen El éxito de la lógica y las matemáticas y las dudas sobre la capacidad de nuestros sentidos por mostrarnos la realidad última condujeron a la metafísica occidental a un fracaso que duró milenios. Es cierto que las matemáticas y la lógica son herramientas muy útiles, imprescindibles, que pueden ayudarnos en múltiples aspectos, tanto en la justificación como en el descubrimiento. Pero no son suficientes. Los filósofos que trataron de asaltar los cielos metafísicos terminaron perdiéndose en un laberinto deductivo que, por muy válido que fuese, no tenía ninguna relación con la realidad. Lo razonable no es suficiente. El empirismo es el único modo que ha funcionado de anclar nuestras creencias al mundo externo. La lógica y las matemáticas no son suficientes, la observación es imprescindible. Es cierto que la observación y la inducción, a diferencia de la deducción, son falibles y, por lo tanto, requieren modestia intelectual, pero una vez aceptadas sus limitaciones consiguen elevarnos a los cielos, tal vez no a los metafísicos, pero sí a los surcados por los motores a reacción. "],["escepticos.html", "6 Escépticos 6.1 Fundamentos: empirismo y racionalismo 6.2 El escéptico feroz 6.3 Contra la razón 6.4 Las matemáticas no son ciencia 6.5 Analíticos o sintéticos 6.6 ¿Ver es creer? 6.7 Relativistas 6.8 Escépticos, investigación y cautela 6.9 La duda y el problema de la acción 6.10 El grado de creencia 6.11 Escépticos modernos y actuales 6.12 La elección 6.13 Resumen", " 6 Escépticos 6.1 Fundamentos: empirismo y racionalismo En los mundos clásico y helenístico hubo una discusión profunda sobre cuáles debían ser los fundamentos del conocimiento. Como ya hemos comentado, se había llegado a la conclusión de que el conocimiento requería una justificación. Además, se pensó que la justificación debía ser deductiva, aunque Aristóteles se dio cuenta, inmediatamente, de que la deducción sólo podía garantizar la verdad si las premisas de la inferencia eran, a su vez, verdaderas.442 Esto implica que, o bien asumimos que todas las premisas deben ser, a su vez, justificadas, lo cual nos lleva a una cadena infinita de inferencias o a razonamientos circulares, o, por el contrario, defendemos que hay premisas fundamentales que no requieren justificación. Aristóteles optó por el fundacionalismo: tenía que haber unas creencias básicas sobre las que descansaría todo el edificio inferencial. Además, Aristóteles pensó que estos principios fundamentales debían ser tan claros y obvios que debíamos aceptarlos como evidentemente verdaderos, es decir, debían ser evidentes por sí mismos e inmunes al escepticismo.443 Los escépticos helenísticos criticaron duramente el fundacionalismo. Una de sus críticas fue que, si alguien propone un principio sin justificarlo otro pensador podría proponer uno alternativo también sin justificación alguna. Por ejemplo, yo podría proponer como una verdad obvia que mi gata está sobre la mesa porque la estoy viendo en este momento. Esto, podría asumir que no requiere más justificación puesto que mi visión es suficientemente buena, pero el escéptico podría replicar, como de hecho lo hicieron, que puedo estar sufriendo una alucinación y, por lo tanto, podría negarse a asumir mi observación como un fundamento válido del conocimiento. Además, los escépticos también negaron que un razonamiento circular pudiese ser una justificación válida. Veremos que este debate ha continuado hasta la actualidad y que se han propuesto alternativas al fundacionalismo, pero, por el momento, y a pesar de sus limitaciones, aceptemos que esta es una primera aproximación razonable. Una vez hemos aceptado el fundacionalismo deberíamos establecer cuáles son esas creencias que vamos a aceptar sin justificación. Una posible opción consistiría en aceptar los testimonios. ¿Es el testimonio de una persona una fundación válida para nuestro conocimiento? Esta es una propuesta problemática, en primer lugar, la persona que nos ha dado el testimonio podría estar engañándonos. Pero, incluso aunque obviemos esta posibilidad, podría ser que estuviese equivocada. Debemos tener muy buenas razones para confiar en un testimonio. Esto es algo que, en la práctica, hacemos continuamente. Cuando alguien actúa de un modo que denota un conocimiento profundo sobre un área, asumimos que es un experto y confiamos en su testimonio. Por ejemplo, confiamos en los médicos porque, bastantes veces, nos ayudan con nuestras enfermedades y en el mecánico habitual porque, en más de una ocasión, nos ha arreglado el coche. Este es el mismo tipo de razonamiento que llevó a los teólogos medievales a aceptar la revelación de los profetas. En la Edad Media se creía que esos profetas habían hecho milagros y, por lo tanto, que era razonable creer que tenían una conexión especial con el creador del universo. Hume, cuestionó este razonamiento diciendo que debíamos valorar la posibilidad de que alguien hubiese exagerado o mentido en la cadena de transmisión del testimonio sobre los milagros. Hume defendió que debíamos valorar si era más probable que hubiese habido algún engaño o exageración en el testimonio o que el milagro hubiese ocurrido realmente. Si lo más probable era el fallo en el testimonio, deberíamos desestimar el milagro. Además, los testimonios tienen otro problema. Aunque podríamos considerarlos fundaciones válidas del conocimiento de una persona concreta; por ejemplo, yo confío en que mi amigo Víctor no tiene gato porque me lo ha dicho. Sin embargo, no son justificaciones válidas del conocimiento de toda la comunidad. El conjunto de personas sabe que existe Moscú porque la comunidad ha recogido muchísimas evidencias de ese hecho y porque la tesis contraria, que la existencia de Moscú es una mentira, una conspiración, es mucho más improbable. Cuando se considera el conocimiento de toda la comunidad el testimonio no es válido. Esa es la diferencia entre un experto y un profeta de la antigüedad. A un experto siempre podemos pedirle que nos ofrezca justificaciones de su conocimiento que no se basen en su autoridad, por lo que podemos acceder a contrastar sus afirmaciones. Pitágoras afirmaba ser un profeta, pero sólo aceptamos aquellas de sus conclusiones, como el teorema que lleva su nombre, que seguimos pudiendo comprobar, e ignoramos las que sólo se basaban en su palabra o la de sus seguidores, como las recomendaciones relativas a las judías y los pollos blancos. Es decir, el criterio de autoridad puede ser válido en un momento concreto para una persona concreta, pero no lo es para el conocimiento en su conjunto. Otra propuesta, que ya hemos comentado, es la de los racionalistas. Estos sostenían que se podía alcanzar el conocimiento mediante el uso de la razón pura, utilizando como fundamentos las intuiciones más elementales. El modelo a seguir para muchos racionalistas eran Los elementos de Euclides; un ejemplo de cómo, sobre unas fundaciones muy elementales, se puede construir un edificio deductivo que parece decirnos cosas profundas sobre nuestro universo. El problema es que este es un mal ejemplo porque, como veremos en breve, las matemáticas no son ciencia, no estudian nuestro mundo, sino todos los posibles mundos coherentes concebibles. Podemos construir todas las geometrías que queramos, pero para determinar la que se corresponde con nuestro universo concreto no tenemos más remedio que observar. La percepción es, precisamente, la otra de las grandes fundaciones del conocimiento, la defendida por los empiristas. La ciencia moderna es empirista, pero antes de la modernidad ya hubo defensores de esta postura, por ejemplo, en el mundo helénico. Heráclito nos recomendó utilizar nuestros ojos y oídos para observar el mundo y aprender sus leyes.444 Y, sobre todo, uno de los mayores defensores del empirismo fue Aristóteles, por lo que resulta especialmente irónico que en la Edad Media terminase siendo asociado a una actitud racionalista. En el mundo helenístico la aproximación racionalista tampoco fue, ni mucho menos, hegemónica. Epicuro, por ejemplo, defendía la percepción como fuente de conocimiento, puesto que mediante los sentidos interaccionamos con el mundo exterior.445 Los estoicos, que también se preocuparon mucho por este asunto, eran profundamente empiristas, aunque nos recomendaron cautela. Según ellos, no debíamos atender a todas las impresiones por igual. Algunas impresiones son confusas, como las que tenemos al soñar o al intentar ver dentro de una espesa niebla, otras, sin embargo, según los estoicos, son tan claras que debían de ser verdaderas. A estas últimas las denominaban cognitivas y eran las que debían constituir la fundación de nuestro conocimiento.446 Esta es una propuesta muy similar a la de la ciencia moderna y la contemporánea que descartan que hagamos uso de una evidencia cualquiera y nos recomienda utilizar sólo evidencias suficientemente contrastadas. Por eso los científicos nos piden que ignoremos la evidencia anecdótica y que nos esforcemos por hacer observaciones sistemáticas. El conocimiento se alcanzaba, según los estoicos, cuando se utilizan estas impresiones cognitivas de un modo sistemático para construir una comprensión global del mundo que nos rodea.447 6.2 El escéptico feroz Los escépticos helenísticos fueron un variopinto conjunto de pensadores más interesados en atacar las propuestas dogmáticas de los filósofos de su época, sobre todo, las de los estoicos, que en plantear las suyas propias.448 Dogmático era un calificativo que se aplicaba a quien creía que se podía llegar a tener conocimiento sobre alguna cuestión. Recordemos que este conocimiento requería, según la definición clásica, verdad, y esto parecía implicar certeza absoluta. Por lo tanto, los estoicos eran un ejemplo de dogmáticos, ya que planteaban que era posible alcanzar un conocimiento absolutamente cierto partiendo de las impresiones cognitivas. Los escépticos, sin embargo, criticaron con dureza esta osadía. La mayor inspiración escéptica fue la inquisitiva actitud socrática.449 Sócrates preguntaba mucho más de lo que se atrevía a contestar450 y en la mayoría de los diálogos platónicos en los que interviene no se alcanza ninguna conclusión definitiva. Tras la muerte de Platón, la Academia realizó un giro escéptico y durante dos siglos albergó a algunos de los principales representantes de esta escuela como: Arcesilao, Carnéades o Filón de Larisa.451 Aunque estos escépticos académicos terminaron siendo considerados demasiado moderados por otro grupo que se autodenominó pirrónico. Estos escépticos más radicales adoptaron como ejemplo a Pirrón de Elis, un contemporáneo de Alejandro Magno. Se dice que para Pirrón el escepticismo extremo era un modo de vida, aunque, en realidad, no sabemos mucho sobre su vida ya que no dejó nada escrito. Enesidemo, el primer pirrónico, escribió un texto fundacional, Los diez modos, en el que enseñaba al escéptico a investigar críticamente cualquier presunción de conocimiento. Modo, en este contexto, podría traducirse como argumento o esquema de pensamiento452 ya que son un conjunto de herramientas, de formas de pensar, con las que hacer agujeros a las pretensiones de conocimiento de los estoicos o de cualquier otro filósofo dogmático. Como compañeros de estos diez modos, se escribieron otras muchas obras, siendo la más famosa la correspondiente a los 5 modos de Agripa. En el libro The Modes of Scepticism Annas y Barnes hacen un análisis exhaustivo de estas estrategias.453 Aquí sólo comentaré algunas de ellas. Todos estos debates contra los dogmáticos y entre los propios escépticos nos han llegado relatados por varias vías, aunque la más importante es, sin duda, la obra de Sexto Empírico, un médico helenístico que recogió el pensamiento escéptico.454 6.3 Contra la razón Razonar con corrección no es nada fácil. Podemos cometer errores lógicos formales e incluso, aunque no lo hagamos, una inferencia formalmente válida no garantiza que la conclusión sea verdadera. Se nos puede colar alguna premisa falsa o puede que haya premisas ocultas que no hemos considerado en el razonamiento. Cuanto más larga sea la cadena de inferencias, más probable es que terminemos cometiendo alguno de estos errores y que la conclusión final sea errónea. Además, en muchas ocasiones en la ciencia real, cuando nos enfrentamos a un problema complejo realizamos simplificaciones para que sea tratable, por lo que puede que las conclusiones que buscamos no son completamente precisas, es decir, estrictamente hablando son falsas. Que el razonamiento no nos ofrece una fundación sólida del conocimiento nos lo recuerdan el primer modo de Agripa y el décimo de Enesidemo. Prácticamente sobre cualquier creencia siempre habrá disputas y se podrá encontrar gente con opiniones diversas, especialmente si visitamos culturas muy diferentes.455 Los escépticos nos recordaban que incluso entre los filósofos, que han aprendido las reglas del razonamiento correcto y que han discutido sus conclusiones en sus distintas comunidades, se encontraban opiniones muy diversas, tesis incompatibles, sostenidas por argumentos aparentemente válidos. Parménides concluyó que a nivel fundamental no hay cambio, mientras que Heráclito sostenía que todo fluía y experimentaba un cambio continuo. Parménides afirmaba que no existía el vacío, pero los atomistas defendían que el mundo estaba formado por átomos que se mueven en el vacío. Protágoras, el sofista, enseñaba dialéctica defendiendo tesis contrarias456 y el escéptico Arcesilao practicaba buscando argumentos a favor y en contra de cualquier tesis.457 El gran escéptico Carnéades en 155 a. C. acudió a Roma en misión diplomática y realizó dos discursos sobre el origen de la justicia. En el primero defendió que la sociedad no es más que el reflejo del orden natural del cosmos y, por lo tanto, la justicia nace de ese orden natural. En el segundo explicó que la naturaleza está compuesta por una danza frenética y desordenada de átomos, mientras que la sociedad es un sistema ordenado, por lo que la ley no nace del orden natural, sino que resulta de un acuerdo entre los ciudadanos sobre lo que es justo. Se dice que en ambas ocasiones fue vitoreado por la audiencia. Estas dos posiciones eran las defendidas por los estóicos y los epicúreos respectivamente.458 El escándalo que se montó en Roma fue tan grande que Catón el viejo pidió al senado que expulsase a la corrosiva embajada ateniense.459 Los escépticos razonaban que si el conocimiento puede ser alcanzado realmente, ¿cómo era posible que los filósofos dogmáticos no se pusiesen de acuerdo? Este es un argumento realmente poderoso, cuando hay discrepancias entre los expertos, probablemente lo más razonable sea reservar el juicio. Por otro lado, tal vez, si los expertos han alcanzado el consenso sí podríamos pensar que se ha alcanzado un conocimiento firme. A esta tesis los escépticos podrían responder citando numerosos casos en los que el consenso de los expertos acabó demostrándose erróneo. Por ejemplo, los físicos creían que el tiempo era absoluto y el espacio plano hasta que Einstein planteó sus relatividades. 6.4 Las matemáticas no son ciencia Algo que ha confundido a los racionalistas durante milenios fue el mal ejemplo de las matemáticas. Los pensadores del mundo clásico tomaron el razonamiento matemático como el mejor de los ejemplos de obtención de conocimiento y pretendían estudiar el cosmos tal y como Euclides había elaborado su geometría. Sin embargo, esto resultó ser un profundo error; un error que no se aclararía definitivamente hasta el siglo XIX. Las matemáticas son ciertas, en el sentido de que podemos tener certeza prácticamente absoluta de que el teorema de Pitágoras es válido dentro de la geometría euclídea, pero lo que no está nada claro es que sean verdaderas. Recordemos que, por el momento, habíamos aceptado la teoría de la correspondencia de la verdad: es verdad aquello que se corresponde con el mundo externo a nuestra mente. ¿Son entonces verdad las matemáticas? ¿En qué sentido podríamos afirmar que un teorema matemático se corresponde con el mundo externo? Un triángulo no tiene una existencia equivalente a la de un gato y si queremos afirmar que las matemáticas son verdaderas antes debemos revisar nuestra definición del concepto de verdad. Las matemáticas son formalmente válidas y son una herramienta imprescindible en la ciencia, pero eso no implica que, con ellas, por sí solas, pueda estudiarse el mundo natural. Este es el motivo por el que prefiero separar, tal y como suele hacerse en filosofía de la ciencia, las matemáticas de la ciencia. Las matemáticas son una disciplina formal, pero no son una ciencia puesto que su objetivo no es comprender el mundo externo. Euclides construyó un rico edificio deductivo partiendo de un puñado de definiciones y postulados y el resultado parecía estar compuesto por conclusiones que nos informaban sobre el comportamiento del mundo físico.460 Por ejemplo, los sumerios tuvieron que medir triángulos físicos para obtener la relación entre los catetos y la hipotenusa de un triángulo rectángulo. Esto es lo que hace un científico, observar, experimentar e inducir una regla. Sin embargo, Euclides pudo deducir ese mismo resultado mediante la razón pura y, además, mientras que Euclides tenía la certeza garantizada, puesto que sólo había usado la deducción, el conocimiento científico siempre será falible puesto que parte de observaciones con errores experimentales y, además, hace uso de la inducción. Los sumerios no podían descartar que algún triángulo, en el futuro, no cumpliese la relación que habían observado en todos los triángulos previos, algo que a Euclides no podrá pasarle nunca. Además, los sumerios no podían estar seguros de que su regla no fuese más que una aproximación. No es de extrañar que este logro se tomase como el ejemplo a seguir; al abandonar la observación y abrazar la deducción Euclides parecía haber conseguido alcanzar certeza y verdad. Sin embargo, hay algo que ya preocupó a Euclides y que quedó para siempre como una mácula en su obra, el quinto postulado. Este postulado, también denominado de las paralelas, equivale a la afirmación de que dados una recta y un punto exterior, por este punto exterior pasará una y solo una recta paralela a la primera.461 En principio esta asunción parece muy razonable y, por eso, Euclides la propuso como postulado, pero es una afirmación que no parece tan trivial como el resto de sus definiciones y postulados. Durante milenios se intentó demostrar este quinto postulado a partir de los otros, pero nunca se logró. En el siglo XIX se averiguó por fin el motivo y la geometría tomó un giro radical. En los años 20 del siglo XIX Nikolái Lobachevski y János Bolyai demostraron, independientemente, que el quinto postulado nunca podría demostrarse a partir del resto y Bernhard Riemann demostró que también se podía obtener una geometría consistente si se asumía que por el punto externo no pasaba ninguna línea paralela.462 Este programa de investigación continuó desarrollándose durante el XIX y acabó demostrándose que podían construirse varias geometrías alternativas sustituyendo el quinto postulado de distintos modos. Esto abrió los ojos a los matemáticos, que, de repente, se encontraron ante mundos más ricos y llenos de posibilidades, pero, a la vez, planteó una pregunta: si hay distintas geometrías posibles, ¿cuál se corresponde realmente con nuestro universo físico? Esta no es una pregunta que preocupe a los matemáticos demasiado, su interés consiste en crear mundos matemáticos lógicamente consistentes;463 sin embargo, para el físico es una cuestión clave. Si puede haber distintos universos consistentes, ¿cómo determinamos cuál es el nuestro? Hermann von Helmholtz, un físico alemán, concluyó que la geometría del espacio físico sólo podía ser decidida empíricamente.464 De modo que, después de dos milenios y medio pensando que mediante la razón pura podíamos demostrar que el universo tiene una geometría euclídea, resultó que estábamos equivocados, que teníamos que medir. Por cierto, al principio se pensó que el universo era euclídeo, porque parecía evidente, pero la relatividad general acabó con esa noción, el espaciotiempo está muy curvado en algunas regiones. Lo único que nos dicen las matemáticas sobre el mundo físico es que si asumimos que el universo es describible mediante teorías coherentes hay ciertas restricciones que deben cumplir las estructuras de esas teorías, pero, más allá de eso, hemos de observar para estudiarlo. La ciencia, el estudio riguroso del mundo natural es ineludiblemente empírica. A pesar de todo este barullo decimonónico, lo que siguió siendo cierto es que, si uno acepta los postulados euclídeos, incluyendo el quinto, el teorema de Pitágoras continúa siendo válido. De eso teníamos certeza puesto que era una conclusión deductiva y la deducción preserva la verdad; si las premisas se aceptan como verdaderas, la conclusión también lo será. Lo que nunca podremos hacer mediante la deducción es averiguar qué premisas se cumplen en nuestro universo concreto. Para llegar a esto debemos observar e inducir465 y, recordemos, la inducción es deductivamente inválida, cualquier conclusión inductiva podría ser falsa, incluso aunque sus premisas fuesen verdaderas. Esta es una encrucijada de la que nunca podremos escapar, es una limitación fundamental del conocimiento del mundo externo, podemos deducir y tener certeza, nuestras conclusiones serán válidas, pero no sabremos hasta qué punto se corresponden con el mundo, o podemos observar e inducir para estudiar ese mundo, pero deberemos renunciar a la certeza. Realidad o certeza, pero no ambas. Einstein dijo:466 En la medida en la que las matemáticas se refieren a la realidad, no son ciertas, en la medida en la que son ciertas, no se refieren a la realidad. Con esta discusión no pretendo defender que las matemáticas no sean una herramienta útil en ciencia, todo lo contrario. Recordemos que Noether, una de las mentes matemáticas más importantes de la historia, demostró que cualquier cantidad conservada en un sistema físico tendrá una simetría equivalente y viceversa. Es decir, aunque no podemos saber qué simetrías o cantidades conservadas habrá en nuestro universo concreto, sí podemos estar seguros de que en todos los universos que puedan existir habrá un mismo número de simetrías y de cantidades conservadas. Seguimos teniendo que observar, pero Noether restringe, de entre todos los universos imaginables, aquellos que son coherentes. Por otro lado, las matemáticas también tienen sus propias limitaciones intrínsecas. En algunos casos puede que haya errores en las demostraciones que pasen desapercibidos durante décadas o, incluso, durante siglos. Además, Gödel y otros lógicos del siglo XX demostraron que no todo es demostrable, que hay proposiciones matemáticas válidas que nunca podrán ser demostradas como tales dentro de las propias matemáticas. Pero estos problemas, que atañen a las matemáticas, son menos relevantes para la ciencia que el hecho de que las matemáticas sean una disciplina formal, una herramienta para la ciencia, pero no una ciencia. 6.5 Analíticos o sintéticos En el siglo XVIII Hume, en Investigación sobre el entendimiento humano, ya había adelantado una idea relacionada con la necesidad de la observación conocida como el tenedor de Hume (Hume’s fork). Según Hume los objetos de la razón pueden dividirse en dos tipos, los analíticos y los sintéticos. (Esta es la terminología que utilizaría Kant posteriormente en su Crítica de la razón pura, Hume los denominó relaciones de ideas y cuestiones de hecho).467 Una proposición analítica es aquella cuya verdad se deriva a partir de su definición. Por ejemplo, si definimos soltero como aquella persona que no tiene cónyuge, podremos concluir que cualquier soltero siempre carecerá de cónyuge. Estas proposiciones pueden ser justificadas por definición, sin que necesitemos hacer ninguna observación sobre el mundo.468 Por otro lado, hay proposiciones cuya veracidad no puede establecerse basándose exclusivamente en las definiciones de sus términos, estas se denominan sintéticas.469 Antes de continuar convendría hacer una aclaración. Esta clasificación relativa a las proposiciones podría recordarnos a la diferencia entre inferencias válidas e inválidas, pero, en realidad, se refiere a algo completamente distinto. En primer lugar, la diferencia analítico-sintética trata sobre proposiciones, no sobre inferencias. “Ningún soltero tiene cónyuge” no es una inferencia es una proposición que, en todo caso, podría aparecer en una inferencia como premisa o conclusión. Además, mientras que las inferencias se clasifican como válidas o inválidas en función de su forma, es decir, sin tener en cuenta su significado, la distinción analítico-sintética trata, precisamente, sobre el significado, es semántica, no formal. Antes de continuar también conviene precisar que esta clasificación analítico-sintética fue cuestionada porque, en algunos casos, no es completamente nítida. El filósofo estadounidense W. V. O. Quine, en su Two Dogmas of Empiricism, publicado en 1951, planteó que hay proposiciones como, por ejemplo, “mi gato es un animal” que podrían ser clasificadas como analíticas por algunos hablantes y como sintéticas por otros. En los lenguajes naturales las definiciones no son precisas del todo470 y, por lo tanto, un hablante podría pensar que ser un animal forma parte de la definición del término “gato”, mientras que otro podría considerar que este esta es una conclusión que se establece mediante una serie de observaciones.471 En realidad, la distinción analítico-sintética, estrictamente hablando, sólo es aplicable a los lenguajes artificiales construidos siguiendo reglas muy estrictas.472 En cualquier caso, esta matización no afecta demasiado a nuestro argumento actual, pero la he comentado porque es posible que el lector lea que la distinción analítico-sintética fue cuestionada por Quine . Como acabamos de comentar la veracidad de las proposiciones analíticas, dado que depende exclusivamente de su definición, puede establecerse a priori, sin necesidad de hacer ninguna observación, pero ¿cómo podemos averiguar si “hay algunos doctores que son, además, solteros” o no? La veracidad de una proposición sintética no puede establecerse basándose sólo en las definiciones de sus términos. Una proposición sintética hace referencia a algo que en el mundo externo podría ser de un modo u otro, por lo tanto, la veracidad de las proposiciones sintéticas sólo puede ser establecida a posteriori, es decir, después de haber obtenido evidencias empíricas. Esto es algo esperable ya que las proposiciones sintéticas, añaden información que va más allá de la contenida en la definición de los términos, amplían nuestro conocimiento y es normal que este conocimiento no surja de la nada, sino de la información empírica recabada en el mundo externo. Hume, además, clasificó las distintas áreas de estudio según si podían funcionar sólo mediante proposiciones analíticas o, si, por el contrario, requerían observaciones empíricas. El estudio lógico de la semántica sería analítico a priori473 mientras que las ciencias, que establecen conocimiento sobre el mundo externo, serían factuales y, por lo tanto, sintéticas a posteriori.474 De modo que hay proposiciones analíticas a priori y proposiciones sintéticas a posteriori y la cuestión que resta sería si existen las proposiciones sintéticas a priori. Es decir, si es posible ampliar nuestro conocimiento mediante la razón pura, sin recurrir a la experiencia. Kant defendió que esto era posible, que la veracidad de algunas proposiciones sintéticas podía establecerse a priori. Por ejemplo, “la recta es la distancia más corta entre dos puntos” sería un candidato a juicio sintético, puesto que en la definición de recta o punto no parece estar contenida la noción de que la distancia más corta entre dos puntos deba ser necesariamente una recta, y, además, tampoco parece que se necesite ninguna evidencia empírica para alcanzar dicha conclusión. Podría considerarse que, al menos en algunos casos, se puede aprender sobre el mundo externo mediante la razón pura, sin necesidad de hacer observaciones o experimentos. Kant tenía fresco el gran éxito de la mecánica clásica y era consciente de que algunas afirmaciones newtonianas no parecían provenir de la experiencia y que, por lo tanto, parecía que Newton las había incorporado a su teoría a priori.475 Por ejemplo, se admitía que el espacio era euclídeo, pero esto no era el resultado de un experimento que hubiese determinado la cuestión, sino que era una asunción newtoniana a priori que cualquier mente humana era capaz de aceptar por simple reflexión. Sin embargo, la mayoría de los filósofos, incluidos Hume y los positivistas lógicos, se oponen a esta tesis. La veracidad de las proposiciones sintéticas sólo puede ser establecida a posteriori, es decir, tras haber obtenido información empírica,476 no podemos aprender sobre el mundo externo sin observarlo. Kant fue un gran filósofo, los juicios sintéticos a priori fueron una idea fallida. Además, recordemos que uno es libre de plantear las hipótesis que desee a priori, pero lo que las valida, en última instancia, es que las evidencias empíricas las justifiquen. Yo puedo dibujar cuantos mapas desee sin pisar el mundo externo, pero esos mapas sólo serán verdaderos si reflejan el territorio externo y eso no puedo comprobarlo sin evidencias empíricas, sin obtener información sobre el territorio que representan. Euclides pudo construir un gran edificio deductivo sobre unas cuantas proposiciones. Pero pudo hacerlo porque lo único que importa en matemáticas es la compatibilidad lógica de los axiomas.477 Las matemáticas son deductivas y gracias a la deducción podemos construir edificios lógicamente coherentes, pero sin evidencias empíricas no podemos establecer en qué medida estas construcciones se corresponden con la realidad. Kant, como todos los investigadores hasta el siglo XIX, creía que el cosmos debía tener necesariamente una geometría euclídea, por lo qué es irónico que esta idea resultase ser errónea. El problema radica en asumir que nuestras ideas intuitivas deben ser necesariamente verdaderas.478 El consenso filosófico establece que la veracidad de los juicios sintéticos sólo puede ser establecida a posteriori. Sin embargo, de las ideas kantianas sí pueden extraerse algunas enseñanzas interesantes. Kant partía de la premisa de que el diseño de nuestras mentes nos obliga a considerar el espacio como tridimensional y euclídeo y el tiempo como independiente del espacio. A pesar de que la relatividad general nos ha enseñado que ambas ideas, aunque son útiles en nuestra vida cotidiana, están equivocadas a un nivel profundo, el tiempo está ineludiblemente ligado al espacio y el espaciotiempo no es necesariamente euclídeo, nuestras mentes no están capacitadas para captar estas ideas de un modo intuitivo. Nuestro sistema cognitivo es capaz de reconocer, gracias a la razón, que el espaciotiempo parece ser curvo, pero esta aceptación no implica que podamos verlo de este modo. Es un caso análogo al de la percepción de las ilusiones ópticas, podemos reconocerlas mediante la razón, pero no podemos dejar de verlas. Estas son limitaciones humanas con las que estamos obligados a convivir. Además, podría discutirse hasta qué punto nuestras ideas intuitivas son a priori puesto que han sido modeladas por millones de años de relación entre el material genético y el mundo externo. Pero volvamos a la discusión entre Hume y Kant. Uno podría pensar que lo de los juicios sintéticos a priori no tendría mucha más transcendencia que la de martirizar a los estudiantes de filosofía, pero había mucho más en juego. Lo que Hume tenía en su punto de mira era a la teología y la metafísica especulativa o escolástica.479 Hume se planteó si estas disciplinas estarían tratando con proposiciones analíticas a priori, como las matemáticas, o si requerirían de afirmaciones sintéticas a posteriori, como la física. Según Hume si eran analíticas podrían desarrollarse mediante la razón pura, pero carecerían de contenido factual y, por lo tanto, no nos informarían sobre el mundo real, mientras que si pretendían hacer afirmaciones sobre el mundo externo deberían basarse en evidencias empíricas. El gran escocés consideró que la teología y la metafísica especulativa no son ni carne ni pescado. Si la teología fuese analítica debería abstenerse de emitir juicios sobre si un dios particular existe o no existe en el mundo real y, si es sintética, como la física, debería estar sujeta a las limitaciones empíricas de cualquier otra ciencia, tendría que basar sus afirmaciones en observaciones claras y asumir que sus conclusiones deben ser revisables o, de lo contrario, no sería más que mera sofistería. Hume criticó con dureza que la teología y la metafísica especulativa pretendiesen llegar a conclusiones sobre la existencia de un dios concreto en el mundo real basándose simplemente en largas cadenas de razonamientos, sin acompañarse de evidencias empíricas que respaldasen sus conclusiones.480 Kant al proponer sus juicios sintéticos a priori lo que estaba haciendo es intentar salvar a la metafísica especulativa de la dura crítica de Hume. Según Kant la metafísica estaría legitimada para hacer afirmaciones sobre el mundo real basándose en la razón pura, sin necesidad de hacer observación alguna. Pero no pensemos que Hume fue el único que siguió esta línea de trabajo. A principios del siglo XX, en el manifiesto del círculo de Viena, los fundadores del positivismo lógico, por ejemplo, también rechazaron de plano los juicios sintéticos a priori y se manifestaron contra la metafísica.481 Volveremos a tratar esta crítica en los capítulos dedicados a la relación entre la metafísica y la ciencia. Por otro lado, podemos pensar en estas cuestiones desde otra perspectiva. Algo que sí podemos exigir a nuestros modelos sobre el mundo es que sean coherentes. En este caso habrá modelos, mapas, que podremos descartar a priori, simplemente, por ser incoherentes. Esto es, por ejemplo, lo que hizo Noether, cualquier teoría física futura tendrá que obedecer su teorema, habrá de tener una relación entre las simetrías planteadas y las magnitudes físicas conservadas. Esto elimina muchísimas teorías imaginables, aunque para saber en qué grado las restantes se corresponden con el mundo físico habrá que observar y experimentar. 6.6 ¿Ver es creer? De modo que si queremos estudiar el mundo natural estamos obligados a abrir los ojos y percibirlo. Esta fue la actitud de los empiristas de la antigüedad, como Epicuro, Aristóteles y los estoicos, y fue la conclusión que terminaría triunfando definitivamente durante la Edad Moderna. Cualquiera de nosotros suele otorgar un gran valor epistémico a lo que nos muestran nuestros sentidos; creemos ver un gato cuando vemos un gato. Sin embargo, los estoicos nos recuerdan que debemos ser cautos, no todas las impresiones son cognitivas. Hay percepciones dudosas. Por ejemplo, cuando vemos una vara recta introducida parcialmente en un estaque, la vara parece torcida. Según los estoicos el verdadero sabio sólo debe aceptar como fundamento del conocimiento las impresiones cognitivas, aquellas que realmente aportan conocimiento.482 Pero los escépticos no se conformaron con esto. Lo que acabo de escribir no es más que un razonamiento circular: son cognitivas las impresiones que aportan conocimiento, pero esto no nos indica cómo distinguir aquellas impresiones cognitivas de las no cognitivas. Muchos de los modos de Enesidemo y Agripa hacían notar los problemas asociados a la percepción. En primer lugar, las impresiones no nos muestran el mundo tal cual es. Cuando miras al gato no ves átomos, y mucho menos, campos cuánticos, esa realidad profunda no es sólo invisible a nuestros sentidos, sino que, como veremos, parece que estará por siempre más allá de lo detectable. La función de onda cuántica, en principio, no puede ser medida directamente. Lo que vemos, además, depende de nuestra constitución, la evolución ha moldeado nuestros sistemas perceptivos para que nos sean útiles, no para que generen representaciones completamente fieles del mundo externo.483 La percepción depende, en parte, del ser que la experimenta. En el primer modo Enesidemo nos pide que pensemos en cómo perciben el mundo los animales. Un murciélago no percibe el mundo como un humano, incluso una misma persona, en distintas circunstancias, puede percibir el mismo estímulo de un modo diferente. Los escépticos nos recordaban que la miel que nos es dulce cuando estamos sanos, puede resultarnos amarga cuando estamos enfermos.484 Los griegos utilizaban el término phainomenon que se suele traducir como impresión o apariencia y que literalmente significa lo que aparece o lo que es aparente485 para remarcar esta dependencia de la impresión del individuo que la experimenta. Yo puedo considerar qué mí me ha parecido ver, qué impresión he tenido, pero esto no sólo depende del objeto percibido, sino también, en parte, de mí.486 Podemos saber cómo nos parecen las cosas, pero no cómo son realmente. La percepción siempre estará contaminada por nuestro punto de vista, es imposible tener un acceso al mundo externo independiente de nosostros mismos. Por otro lado, Enesidemo en su tercer modo nos recuerda que distintos sentidos se contradicen. Cuando vemos una pintura realista en la que se ha cuidado la perspectiva nos parece apreciar profundidad, sin embargo, nuestro tacto inmediatamente nos indica que esto no es más que una ilusión. En el quinto modo se nos conmina a ser cautos ya que lo que percibimos depende de nuestro punto de vista. Por ejemplo, la iridiscencia del cuello de la paloma bravía cambia cuando la paloma se mueve en relación a nuestros ojos. Una misma realidad percibida desde distintos puntos de vista parece ser distinta. Además, la información que nos llega desde el objeto percibido ha de atravesar un medio y esto puede afectarla de distintas formas (sexto modo). Por ejemplo, el color del Sol parece variar a lo largo del día, a pesar de que sabemos que el Sol, en sí mismo, no varía en la misma medida. El color que observamos no se debe sólo al Sol, sino también, en gran medida, a la atmósfera que debe atravesar su luz. Algo similar sucede con la vara sumergida, cuya percepción se ve afectada por el tránsito de la luz a través del agua y del aire. Los escépticos hicieron otra crítica durísima que afecta tanto a la percepción como a la ciencia en general. Las percepciones están subdeterminadas por el estímulo. Es decir, que un mismo estímulo puede corresponderse con diferentes hipótesis sobre el mundo. Dicen que al estoico Esfero, como broma, le dieron una granada de cera tan realista que trató de comerla.487 Sexto Empírico se refirió al ejemplo del cuadro pintado en perspectiva para ilustrar el mismo problema.488 Es decir, que un estímulo, por ejemplo, la observación que hizo el sistema visual de Esfero, no es suficiente para determinar con absoluta precisión cuál es la realidad externa. Ambas hipótesis, la de que tenía ante sí una granada real y la de que la granada era de cera, producen en el observador la misma percepción. A esto se le denomina subdeterminación. Esta es una limitación que es, hasta cierto punto, fundamental ya que es debida a que la cantidad de información que obtenemos sobre el mundo externo es limitada, por lo que no podemos estar seguros de haber obtenido toda la información relevante. Siempre será posible que la hipótesis que elaboremos a partir de esa información limitada no coincida del todo con la realidad. Uno puede pensar que este problema no es tan serio, al fin y al cabo, Esfero acabó mordiendo la granada y se dio cuenta de su error. Pero las consecuencias pueden ser relevantes. Durante más de un siglo los físicos estuvieron convencidos de que existía algo que denominaban fuerza de la gravedad que era responsable del movimiento de los planetas y las manzanas, pero, a principios de siglo XX, Einstein planteó la relatividad general, una teoría que cuadraba con casi todas las predicciones y observaciones de los físicos newtonianos, pero que era radicalmente distinta en sus propuestas metafísicas. A pesar, de que en nuestra vida cotidiana es casi imposible realizar observaciones que nos permitan distinguir entre ambas físicas las realidades planteadas por la relatividad general y la newtoniana son muy diferentes. ¿Quien nos dice que mañana no habrá otro avance que proponga que el espaciotiempo de la relatividad no se corresponde con la realidad profunda? Incluso no es una imposibilidad lógica que vivamos en Matrix. Esto es algo que hemos de conceder al escéptico radical,489 lo cual no implica que sea relevante o que sea racional creer que efectivamente vivimos en Matrix. Pero los problemas de la percepción no se acaban con este duro varapalo. Aunque solemos decir que ver es creer, en muchos casos, lo cierto es que creer es ver. Locke y Hobbes, dos empiristas modernos, creían que la percepción es un acto pasivo, que uno recibe el estímulo y esto genera una representación.490 Esto es, de hecho, lo que solemos creer todos intuitivamente, que nuestros sistemas visuales son una especie de cámara de vídeo que registra pasivamente la realidad que ocurre frente a nosotros. Pero la realidad es mucho más sutil. Cada acto de percepción es, en cierto grado, un acto de creación, y cada acto de memoria es, en cierto grado, un acto de imaginación. Oliver Sacks, Musicofilia. La información que llega a nuestros sentidos es muy incompleta y, además, la señal está parcialmente comprometida por algo de ruido. Para crear las representaciones que caracterizan nuestra percepción nuestros sistemas perceptivos toman un papel activo haciendo un procesamiento muy intenso de la señal recibida. A pesar de lo que pensaban Locke y Hobbes, es un error creer que la realidad se imprime pasivamente en nuestra mente.491 Para limpiar y completar las carencias de la señal recibida, nuestros sistemas perceptivos aprovechan la información previa, una información que puede manifestarse en forma de expectativa o de la propia estructura de esos sistemas. Esto es algo que los escépticos helenísticos desconocían, pero que ha sido estudiado en profundidad por los psicólogos y los filósofos en el siglo XX. Por ejemplo, el físico y filósofo de la ciencia Ernst Mach (1838 - 1916) estudió las ilusiones ópticas y llegó a la conclusión de que la ciencia debería abstenerse de hacer afirmaciones sobre la naturaleza última de la realidad y conformarse con crear modelos útiles que permitan hacer predicciones.492 Por otro lado, el filósofo Norwood Russell Hanson, en su Patterns of Discovery de 1958, hizo otro análisis de las ilusiones ópticas y concluyó que están contaminadas por nuestras expectativas previas, una idea fundamental que acabaría formando parte de la conclusión de que las observaciones están cargadas de teoría (Theory-ladenness). Abrir los ojos implica una teoría implícita sobre la constitución y el funcionamiento del mundo externo. Nuestro sistema visual hace asunciones que le permiten fijar su atención en la información más relevante, eliminar el ruido de la señal recibida y rellenar la información faltante. No percibimos todo lo que ocurre a nuestro alrededor, nuestra atención selecciona y destaca algunos estímulos por encima de otros. Esto nos permite, por ejemplo, seleccionar una conversación cuando hay varias personas dialogando al mismo tiempo. Podemos hacerlo porque nuestro sistema auditivo se prepara para procesar de un modo determinado la confusa señal que recibe. Esta es una capacidad que causa fenómenos muy curiosos, como, por ejemplo, los soramimis o las pomporrutas en los que una cadena de sonidos fonéticos es interpretada de un modo erróneo. Es lo que sucede, por ejemplo, cuando nos parece escuchar palabras castellanas en una canción en inglés o cuando escuchamos “Juan Tanamera” en la canción Guantanamera. En estos casos, una vez que alguien nos dice que es lo que vamos a escuchar, nuestra mente se prepara para hacerlo y es casi imposible no oírlo. Además, no somos conscientes de todo el procesamiento mental implicado en la percepción.493 Se pensaba que sería muy fácil hacer un robot que viese o escuchase porque no nos dábamos cuenta del esfuerzo subconsciente que implica la percepción, sin embargo, ha sido mucho más fácil enseñar a las máquinas electrónicas a jugar al ajedrez. Nuestro sistema visual realiza un procesamiento muy complejo para mostrarnos una representación de la realidad continua y en alta definición, a pesar de que parte de una información visual muy deficiente. En cada ojo tenemos un punto ciego debido a la intersección del nervio óptico con la retina, nuestra visión sólo es óptima en la fóvea, que ocupa un 1% de la retina, pero cuya señal requiere, para ser procesada, de la mitad del córtex visual y, además, cada vez que parpadeamos o movemos los ojos nuestro sistema visual debe rellenar la información faltante. A pesar de estas limitaciones, no vemos ninguna región oscura, incluso aunque miremos con un solo ojo, ni nos parece que veamos con buena definición y en color sólo un 1% del campo visual, ni creemos estar ciegos entre dos y tres horas al día, el tiempo que pasamos parpadeando. Según el escéptico, todo este procesamiento es problemático ya que lo percibido no depende exclusivamente del mundo externo, sino que depende, en buena medida, del sistema de procesamiento de la información visual. De hecho, lo que vemos puede estar muy contaminado por el contenido de nuestra mente. El cuarto modo nos recuerda que cuando soñamos o enloquecemos creemos ver objetos que no tienen ninguna correspondencia con el mundo exterior. Es natural pensar que en el sistema visual la información viaja desde el mundo externo hacia nuestro cerebro. Por ejemplo, la luz reflejada por el gato es recibida por la retina, y ,a partir de ese momento, la información va siendo tratada por distintas áreas del sistema nervioso hasta llegar a las regiones que se ocupan del pensamiento más abstracto, por ejemplo, aquellas en las que se activa la etiqueta “gato” para la representación que se ha creado. Es decir, lo intuitivo, es pensar que la información fluye desde el mundo exterior al interior. Sin embargo, la realidad, de nuevo, es más sutil. En el sistema visual hay numerosas neuronas que envían información desde las áreas cerebrales encargadas del procesamiento más abstracto hacia las regiones más cercanas al mundo exterior. Una parte significativa de la actividad neuronal del sistema visual no es debida al estímulo exterior sino a nuestro mundo interior. Nuestra mente va procesando la señal disponible, en las áreas más abstractas, y va informando a las áreas cerebrales más cercanas al mundo exterior del resultado de este procesamiento inicial para que puedan modificar el procesamiento de la señal. Por ejemplo, cuando vemos por primera vez la famosa imagen del dálmata, no somos capaces de distinguir más que un confuso barullo de manchas negras, sin embargo, una vez que hemos visto el dálmata por primera vez, nuestras áreas cerebrales superiores pueden avisar a las externas de qué es lo que se espera ver, para que puedan prepararse. A partir de ese momento veremos el dálmata sin problemas. Esto tiene como consecuencia que cuando no hay estímulo externo, el sistema visual no tiene por qué dejar de crear representaciones y, de hecho, en algunos casos, puede crear alucinaciones, es decir, representaciones que no se corresponden con la realidad, mapas que no se corresponden con el territorio. Dado que en todo momento las áreas superiores están influyendo en el procesamiento de la información, no podemos decir que las representaciones que crea habitualmente sean debidas sólo a la señal visual externa. Tal vez la forma más adecuada de pensar en lo que está sucediendo sea plantearse que hay un equilibrio entre la expectativa de nuestra mente y la señal externa y que la representación final es el resultado de este equilibrio. Aparece una alucinación cuando la expectativa interna domina sobre la señal externa. Una alucinación es también una representación, el único problema es que nuestro mundo interior ha tomado un protagonismo excesivo. Durante la visión normal la mente también crea una representación basándose en nuestras expectativas, pero la va actualizando para ajustarse a la información externa que recibe. Una información que, recordemos, es insuficiente. No sería descabellado describir una percepción normal como una alucinación modificada a cada instante para corresponderse, en mayor o menor medida, con el mundo externo. Esta imagen de nuestros sistemas perceptuales está bastante alejada de las expectativas de Locke y Hobbes y, desde luego, nos debe hacer tomar bastante en serio las reservas de los escépticos helenísticos. Además, el problema no se limita a que nuestras expectativas dominen el proceso perceptivo. Incluso aunque no lo hagan, la propia estructura de los mecanismos perceptivos tiene implícitas unas asunciones sobre el mundo externo. Cuando estas expectativas son violadas aparecen ilusiones perceptuales.494 Por ejemplo, Escher dibujaba mundos que violaban estas asunciones para que nuestros sistemas visuales creasen representaciones de objetos imposibles. En estos casos puede que seamos capaces de darnos cuenta de que algo está yendo mal, pero esta seguridad consciente no hará que podamos desver el objeto imposible495 ya que no podemos modificar nuestro sistema de procesamiento visual. Alguien podría plantear solucionar el problema prescindiendo de toda información previa. Si lo hiciésemos formaríamos las representaciones únicamente en base a la información externa recibida, sin embargo, esto ni es posible ni es deseable. Sin la información previa sobre la estructura del mundo acumulada por la evolución en el diseño de nuestros sistemas perceptivos, no tendríamos mecanismos para percibir nada. El mero hecho de percibir algo implica un mecanismo en el sujeto capaz de crear representaciones del mundo externo. Además, son estas expectativas sobre el funcionamiento del mundo externo las que, a pesar de la pobreza de la señal recibida por nuestros órganos sensoriales, nos permiten percibir eficientemente. Es ineludible, la percepción dependerá siempre del objeto percibido y, en parte, del sujeto que lo percibe. A lo que debe aspirar un sistema perceptivo o cognitivo es a actualizar las representaciones que va generando en base a la información que va recibiendo continuamente, de modo que esas representaciones se correspondan cada vez con mayor precisión con el objeto representado. Algo muy similar ocurre con las observaciones teñidas de teoría en ciencia. Cuando salgo al campo con un amigo botánico, mi amigo y yo no vemos lo mismo; mientras que yo simplemente percibo plantas, él distingue cada una de las especies. Como veremos, todos estos problemas descritos para la percepción tendrán su equivalencia en el proceso científico, a fin y al cabo, en ciencia también tratamos de generar modelos del mundo externo partiendo de información limitada. El precio que debemos pagar por utilizar la información previa es la posibilidad de error. Nuestras percepciones y nuestras observaciones científicas no dependen, ni pueden depender, exclusivamente del mundo externo y esto hace que, además de ser aproximadas, sean falibles. Cuando veo al gato he de ser consciente de que una parte de esa representación es debida a mi sistema visual y no al estímulo externo. Los escépticos decían que no percibimos la realidad en sí, sino que creamos una impresión que depende de nuestra constitución y estado y tenían razón. Aunque, claro está, en la mayor parte de las ocasiones, esa representación se corresponderá, al menos aproximadamente, con el mundo externo. Rara será la ocasión en la que mi cerebro me engañe completamente y me muestre una alucinación completa, al menos cuando la señal externa sea lo suficientemente clara como para ser dominante y mi cerebro esté funcionando adecuadamente. La razón puede ayudarnos a detectar y corregir estos fallos, por ejemplo, comparando los resultados de distintas percepciones. Pero esto será un flaco consuelo para el escéptico helenístico que nos recordará que la razón también resultó ser falible. A todas estas limitaciones hemos de añadir, no nos olvidemos, las relativas a la memoria. Si hemos de dudar, en cierta medida, de lo que vemos, con mucha más cautela hemos de tratar lo que recordamos. Todos estos problemas cuestionan severamente la aspiración estoica de aceptar sólo las impresiones cognitivas. Si la impresión depende, hasta cierto punto, del sujeto, ¿qué criterio podemos seguir para distinguir las impresiones cognitivas de las no cognitivas? Siempre cabe la posibilidad de que alguien nos haga caer en la cuenta de ese querido amigo que hace años nos visita no es más que una creación de nuestra mente enferma. Los escépticos académicos dejaron claro que no hay percepciones infalibles496 y Carnéades insistió en que la claridad de una impresión no era tampoco garantía suficiente. Sin embargo, los escépticos no pretendían convencernos de que nuestros sentidos no representasen la realidad. Sexto Empírico aceptó que nuestros sentidos tenían una naturaleza tal que las impresiones solían corresponderse con la realidad.497 Lo que criticaban era la pretensión estoica de que fuésemos capaces de distinguir con absoluta certeza qué percepciones eran erróneas y cuáles no lo eran. Nadie ha podido rebatirlos: la idea de una impresión cognitiva infalible es insostenible.498 6.7 Relativistas Los sofistas compartieron muchas de las preocupaciones escépticas. Gorgias499 y Protágoras500 insistieron en que no podemos aspirar más que a tener impresiones, es imposible percibir por completo el mundo exterior. De esto concluyeron que la verdad objetiva era inalcanzable y propusieron optar por el relativismo. Si no podemos más que tener impresiones dependientes del sujeto, deberíamos aceptar que cada persona juzgue lo que es verdadero para ella.501 Protágoras afirmó que “el hombre es la medida de todas las cosas”. Es decir, que si a mí me parece que el aire es fresco, el aire es fresco, puesto que lo es para mí.502 Las cosas son lo que nos parecen, no hay otra posibilidad. Todavía hoy en día hay relativistas que parten de posiciones muy similares. El problema de esta propuesta es que por mucho que nos empeñemos en eliminar el mundo externo de la ecuación, este mundo sigue existiendo y el tigre se nos puede comer y el pozo engullirnos, independientemente de que insistamos en que a otra persona podría parecerle que no hay tigre. El mundo externo es eso que insiste en darte palos independientemente de tu opinión. Sócrates criticó a los relativistas diciendo que para ellos no hay percepciones erróneas, cualquier cosa que le parezca es la verdad, incluso los sueños y la locura.503 La conclusión del escéptico es muy distinta. El escéptico acepta que hay un mundo exterior que dicta cuáles de sus creencias son verdaderas y cuáles no lo son e incluso, como veremos, acepta que algunas de estas creencias son más plausibles que otras, simplemente asume que es imposible alcanzar la certeza absoluta, por lo que hemos de ser cautos.504 Sólo podemos aspirar a tener mapas, modelos del mundo externo, pero esto no ha de hacer que nos rindamos y que aceptemos los mapas como la realidad. La lección es que hemos de esforzarnos por hacer que estos mapas se correspondan, en la medida de lo posible, con la información empírica disponible y que seamos muy conscientes de que puede haber regiones del territorio, de la realidad externa, peor cartografiadas. 6.8 Escépticos, investigación y cautela En griego skeptikoi significaba examinar, indagar, estudiar con detenimiento, por lo que los escépticos se identificaban como investigadores.505 A diferencia de los escépticos modernos no partían de la duda radical506 y en principio, estaban inmersos en una investigación filosófica en busca del conocimiento. Puede que sus pesquisas les llevasen a suspender el juicio, pero incluso aunque así fuese, siempre se mantenían abiertos a encontrar un conocimiento cierto. En la práctica, la mayor ocupación escéptica consistía en evaluar las conclusiones de los demás filósofos,507 especialmente las de los epicúreos, cínicos y estoicos, que pretendían haber alcanzado conclusiones firmes. A diferencia de sus rivales intelectuales, los escépticos siempre encontraron puntos débiles en cualquier propuesta filosófica, por lo que, ante la posibilidad de estar equivocados, recomendaban suspender el juicio. A esta suspensión la denominaban epojé. Esta es una idea clave en la filosofía helenística que compartían incluso los estoicos. Ante la posibilidad de error era preferible ser cauteloso y suspender el juicio. Si sobre una cuestión no podemos obtener una respuesta suficientemente segura, es razonable suspender el juicio y no actuar bajo la asunción de que conocemos la respuesta. Ante la duda es recomendable la prudencia. La diferencia de los escépticos y los estoicos helenísticos con nuestras posiciones actuales es que su criterio para aceptar una creencia como conocimiento era la certeza absoluta. El consenso de la época es que sólo podía denominarse conocimiento aquella creencia de la que se tuviese una certeza completa. En lo que diferían Aristóteles y los estoicos de los escépticos es que mientras los primeros planteaban que alcanzar este grado de seguridad era muy difícil, los segundos pensaban que, dadas las limitaciones del razonamiento y de la percepción, conseguir certeza no sólo era difícil sino imposible. De modo, que ninguna conclusión debía considerarse conocimiento. Esta conclusión puede parecer radical, pero eran los propios filósofos dogmáticos, aquellos que consideraban que el conocimiento sí era posible, los que se habían metido en el lío al exigir certeza absoluta. Actualmente, sin embargo, asumimos que el conocimiento es falible y revisable. Uno puede estar tentado de pensar que hay cosas que conoce con completa certeza, por ejemplo, que ahora mismo está leyendo, pero hemos de recordar que, tal y como nos recuerdan los escépticos, podríamos estar soñando o alucinando. Los escépticos no buscaban esta conclusión, ni se abstenían de investigar el mundo, simplemente se veían obligados a rechazar las pretensiones dogmáticas de conocimiento debido a la exigencia de certeza absoluta. La escuela pirrónica, la más radical, recomendaba aceptar la duda para, de ese modo, alcanzar la ataraxia, es decir, la tranquilidad y la paz que nos conduce a la felicidad. Esta búsqueda de la ataraxia también era una característica general de las escuelas helenísticas. Los epicúreos y los estoicos tenían como objetivo alcanzar este estado, aunque, sus recomendaciones para conseguirlo eran muy distintas de las de los pirrónicos. Este consejo escéptico puede resultar muy llamativo, lo común no es que la duda no produzca paz, sino, más bien, desasosiego. Aunque puede que tenga bastante sentido. Por ejemplo, solemos angustiarnos por la marcha de la actualidad política y de los indicadores sociales. A lo largo de mi vida he escuchado avisos provenientes de personas muy serias que pronosticaban el caos que se avecinaba debido a: la guerra nuclear, la crisis económica, el crimen incontrolado o las catástrofes naturales. La recomendación del pirrónico habría sido que mantuviésemos la calma dado que, estas predicciones catastrofistas, como el paso del tiempo ha demostrado, no estaban suficientemente justificadas. Es difícil hacer predicciones correctas, especialmente sobre el futuro, así que, tal vez, hagamos bien en no rendirnos a nuestro pesimismo. El eslogan del escéptico, podría ser: acepta tus limitaciones epistémicas y mantén la calma. Además, hemos de asumir la duda como una parte ineludible de la vida y no debe angustiarnos la posibilidad de que debamos actualizar nuestras creencias cuando obtengamos nueva información. De hecho, no sólo no tendría que preocuparnos que un nuevo dato nos haga cambiar de idea, sino que deberíamos buscar activamente evidencias que cuestionen nuestras creencias actuales. Debemos aspirar a corregir el error, no a vivir sin dudas. Otra de las diferencias entre las diversas escuelas escépticas helenísticas estribaba en su grado de confianza respecto a su propia creencia de que el conocimiento era inalcanzable. Los pirrónicos acusaban a los académicos de ser dogmáticos negativos ya que se atrevían a afirmar con rotundidad que el conocimiento era imposible. Esta posición es peligrosamente inconsistente dado que el hecho de creer firmemente que el conocimiento es inalcanzable es una forma de dogmatismo. Sexto y los pirrónicos preferían ser más modestos, o más radicales, según queramos verlo, y afirmaban que el escéptico verdadero debe abstenerse incluso de pronunciarse sobre si es posible o no tener conocimiento.508 Es decir, no podríamos saber, ni siquiera, si es posible llegar a conocer. 6.9 La duda y el problema de la acción Estas discusiones pueden parecernos un tanto académicas, pero los escépticos helenísticos eran más pragmáticos de lo que el párrafo anterior nos puede inducir a pensar. El problema del escepticismo radical es que la duda absoluta lo acaba devorando todo.509 Ya en aquel tiempo se criticó el escepticismo radical por ser incompatible con la supervivencia.510 Hume pensaba lo mismo, señaló que si los pirrónicos no hubiesen actuado en base a ninguna creencia habrían muerto de hambre.511 Russell recibió una vez una carta de una admiradora solipsista, es decir, que afirmaba dudar de la existencia de los demás seres humanos. La contestación de Russell fue que nunca había encontrado a una solipsista sincera.512 Los escépticos helenísticos se plantearon este problema y concluyeron que, dado que era evidente que cuando tenían sed buscaban agua, su filosofía debía explicar qué creencias les permitían actuar en el mundo. Nuestra supervivencia requiere que tengamos creencias que se correspondan, al menos en cierta medida, con el mundo exterior. Este problema es extensible a nuestra convivencia comunitaria, la duda excesiva actúa como un ácido social. Cuando los médicos empezaron a darse cuenta de que el tabaco causaba cáncer, las empresas tabacaleras contrataron a la compañía de relaciones públicas Hill y Knowlton513 para que les aconsejase sobre cómo defender su negocio. Su recomendación fue que sembrasen la duda. En un informe de 1953 se podía leer que el objetivo de las campañas de relaciones públicas debía ser que el público general creyese que había dudas sobre la implicación del tabaco en el cáncer. Llegaron a escribir: “La duda es nuestro producto”. La intención no era convencer al público de que el tabaco no era peligroso, sino crear una aparente controversia, con esto bastaba. Esta es exactamente la misma estrategia que se ha utilizado para retrasar la acción contra el cambio climático, exagerar la duda para dificultar la toma de decisiones. La duda exagerada puede crearse fijando la atención del público sobre los aspectos que todavía se desconocen, haciendo críticas exageradas sobre aquellos que ya han sido consensuados o, simplemente, lanzando desinformación contradictoria para causar confusión.514 Esto tiene como resultado que los ciudadanos, que no son expertos, se vean obligados a reservar el juicio. El objetivo de las páginas de noticias falsas no tiene porqué ser tratar de convencernos, sino crear un aparente debate que, en realidad, no existe. La estrategia no consiste en convencernos de una mentira concreta, sino de hacer que la ciudadanía ya no sea capaz de discernir la verdad enterrada bajo un alud de gilipolleces.515 Naomi Oreskes y Erik M. Conway en Merchants of doubt detallan la historia de estas estrategias de relaciones públicas aplicadas al tabaco, la lluvia ácida y el agujero en la capa de ozono. Asimismo, merece la pena mencionar la tesis defendida, en el ya clásico On bullshit (Sobre la gilipollez), por el filósofo Harry G. Frankfurt. Según este pensador debemos distinguir la actitud de los mentirosos de la de los embaucadores (bullshiters). Mientras un mentiroso, ante una crítica, intentará defender su mentira creando una historia, más o menos, verosímil, un embaucador sepultará la crítica en una avalancha de nuevas gilipolleces, que ni siquiera tienen por qué ser coherentes.516 El principal objetivo del embaucador no es alejarnos de la verdad, sino sepultarnos en gilipolleces para impresionarnos o manipularnos.517 Esta actitud ya fue criticada por Platón al acusar, en el Eutidemo, a los sofistas de estar interesados sólo en ganar las discusiones y ser indiferentes a la verdad,518 pero fue Frankfurt quien revitalizó el debate sobre las gilipolleces. Por cierto, que Sobre la gilipollez se publicó en 1986, antes de que se acuñase el desafortunado término postverdad o de que Donald Trump llegase a ser presidente de Estados Unidos. Lo que es incuestionable es que el ensayo de Frankfurt es un serio candidato al premio de tratado filosófico con el mejor título de la historia de la filosofía. Volveremos a tratar este asunto cuando hablemos sobre pseudociencias. Pero regresemos a los honestos debates del escepticismo helénico. Ante el problema de la acción planteado por nuestra vida cotidiana una posible respuesta es asumir que, aunque no podemos alcanzar el conocimiento infalible, sí es posible llegar a tener una confianza suficiente en algunas creencias. Por ejemplo, podemos confiar en que si tenemos sed el agua saciará nuestra sed. Tal vez no podamos decir mucho sobre la metafísica concerniente a la estructura última de la realidad de las moléculas de agua, pero es evidente que podemos desenvolvernos en nuestra vida cotidiana.519 Aunque no hayamos alcanzado un acuerdo completo sobre qué caracteriza a la gatunidad, al menos, somos capaces de llegar a ponernos de acuerdo, más allá de toda duda razonable, sobre si hay o no hay un gato sobre la mesa. Hubo distintos grados de escepticismo y algunos admitieron que para desenvolvernos en nuestros quehaceres cotidianos podíamos prescindir de la inalcanzable certeza, que bastaba con considerar cómo nos parece que es el mundo. Es decir, para interaccionar con el mundo, nos bastaría con actuar en base a nuestras creencias. Timón de Fliunte decía: no postulo que la miel sea dulce, aunque admito que parece dulce.520 Las apariencias, claro está, puede que estén equivocadas, pero siempre podremos utilizar aquellas que merezcan una mayor confianza como guía. Según este planteamiento escéptico, no hemos de concluir que el mundo externo es de un modo determinado, yo no estoy justificado para afirmar con certeza absoluta que el gato está sobre la mesa, no puedo alcanzar ese conocimiento, simplemente, Sexto, habría admitido que podía tratar de acariciar al gato porque le había parecido que estaba sobre la mesa.521 Esta actitud puede recordarnos al relativismo, pero mientras que el relativista renuncia a la posibilidad de alcanzar algún acuerdo sobre la constitución y el comportamiento del mundo externo y se conforma con su propio punto de vista, el escéptico asume que el acuerdo razonable es una buena guía para la acción y sólo renuncia a la pretensión de haber alcanzado la certeza. Arcesilao llegó a proponer que las creencias razonables son suficientes para actuar en el mundo.522 Filón de Larisa moderó todavía más el discurso escéptico al escribir que, aunque sea imposible alcanzar la verdad absoluta, debemos aceptar aquellas conclusiones más plausibles y actuar en consecuencia.523 Ser racionales no nos garantiza la verdad, pero sí nos capacita para actuar del mejor modo posible dadas unas evidencias concretas. Esta es una propuesta que todavía resuena en las críticas a la metafísica científica por parte de los filósofos antirrealistas actuales. Según esta corriente, la ciencia no puede establecer cómo son realmente las cosas y debe conformarse con crear teorías y modelos que resuman, al menos aproximadamente, las observaciones que hemos obtenido. A algunos escépticos, como, por ejemplo, Enesidemo les pareció que esta corriente del escepticismo moderado se estaba acercando demasiado a las posturas dogmáticas originales.524 Un problema de esta propuesta es que si aceptamos nuestra impresión de que nuestro gato existe, deberíamos establecer bajo qué criterio admitimos esta conclusión y no las de los filósofos dogmáticos. Al fin y al cabo, si aceptamos las falibles percepciones como guía, ¿qué criterio nos impide aceptar las conclusiones metafísicas de los filósofos dogmáticos? 6.10 El grado de creencia Carnéades llegó incluso a plantear una propuesta extraordinariamente moderna. Como escéptico estaba de acuerdo en que la ambición estoica de alcanzar el conocimiento infalible mediante las impresiones cognitivas no era realizable, sin embargo, sugirió que debíamos reconocer que algunas impresiones eran más pithanon que otras. Este término, pithanon, podría traducirse como plausibilidad,525 aunque también podría traducirse como probabilidad o verosimilitud. En cualquier caso, Carnéades nos instó a investigar cuál es el grado de confianza que debe otorgarse a una impresión o a una conclusión. Esta es una idea muy cercana a los grados de confianza que los bayesianos contemporáneos asignan a las creencias. Debemos evaluar en qué medida una creencia concreta es fiable, cuál es el grado de duda racional. En cualquier caso, los escépticos helenísticos hicieron varias aportaciones fundamentales. Si sus críticas a las afirmaciones metafísicas más alejadas de la evidencia empírica se hubiesen escuchado, tal vez nos habríamos ahorrado una gran cantidad de especulación vacía. Además, su insistencia en que debemos asumir la falibilidad de cualquier propuesta debe ser un pilar fundamental de nuestra aproximación al conocimiento. Cualquier evidencia y cualquier conclusión ha de tener asociada un cierto grado de duda y siempre debemos recordar que el conocimiento sobre el mundo externo es revisable. Carnéades y Filón de Larisa, y casi todos los demás escépticos, también habrían estado de acuerdo en que es lícito llegar a tener una confianza elevada en algunas creencias, aunque la certeza absoluta sea inalcanzable.526 Recordemos que incluso aquellas leyes que nos parecieron establecidas más allá de toda duda razonable, como la de la gravedad newtoniana puede que en algún momento deban ser revisadas. Tal vez la crítica escéptica no habría sido tan vitriólica si los estoicos no hubiesen aceptado un criterio de verdad tan elevado. Si asumimos que sin certeza hemos de suspender el juicio y que la falibilidad es inevitable nos quedamos, estrictamente hablando, sin posibilidad de conocimiento, por lo que, tal vez, lo más razonable sea plantear alguna definición alternativa de conocimiento. Puede que el problema, al fin y al cabo, esté en el criterio, en el inalcanzable nivel de exigencia. Las reservas escépticas se perdieron en el caos que engulló a la civilización occidental tras la caída de Roma, y cuando en el mundo medieval los metafísicos se dispusieron a analizar sus creencias, lo hicieron con un gran exceso de confianza. Las cautelas escépticas se habían olvidado y el escolasticismo no sólo aceptó como verdaderas algunas intuiciones cotidianas, sino que se atrevió incluso, partiendo de estas intuiciones, a plantear un asalto a los propios cielos metafísicos. 6.11 Escépticos modernos y actuales El escepticismo helenístico murió con Sexto Empírico y no fue recuperado hasta la Edad Moderna.527 Sexto fue publicado en 1562,528 en una época que asombrada por los continuos descubrimientos geográficos y enfrascada en terribles guerras religiosas estaba dispuesta a apreciar su mensaje. Durante los siglos XVI, XVII y XVIII los escépticos antiguos tuvieron una profunda influencia en pensadores como Michel de Montaigne, Descartes o Hume.529 Podría decirse que la filosofía moderna, por un lado, abrazó este cuestionamiento radical y, por otro, trató de responder a él. Descartes, por ejemplo, intentó proteger a la filosofía de la amenaza del escepticismo, pero al mismo tiempo, utilizó la duda radical como una herramienta filosófica. Descartes era matemático y racionalista, es decir, confiaba en la razón pura como fuente de conocimiento. En su trabajo más famoso, partió de la duda más absoluta para construir, mediante la razón, su filosofía. Se planteó que uno podía dudar sobre todo, pero que, aun así, había verdades irrefutables que podían ser tomadas como premisas: pienso luego existo, todo fenómeno debe tener una causa, un efecto no puede ser mayor que su causa y la mente tiene ideas innatas correctas relativas a la perfección, el tiempo, el espacio y el movimiento. Sin embargo, y a pesar de la confianza cartesiana, casi todas estas ideas fueron matizadas o descartadas posteriormente. La ciencia ficción también ha hecho una profunda exploración de la duda radical: podríamos vivir en Matrix, nuestro mundo podría ser una simulación, o podríamos ser un replicante creado hace cinco minutos con memorias falsas o prestadas. Estas posibilidades son lógicamente coherentes, no pueden ser descartadas del todo. Cualquier hipótesis que plantee un mundo que no podamos distinguir del nuestro mediante la observación es, evidentemente, empíricamente indistinguible del nuestro. A este problema se le denomina, como ya hemos mencionado, subdeterminación. Sin embargo, esta posibilidad no implica que sea necesariamente racional asumir esta duda radical. Todo pensador racional debe dudar, pero no todas las dudas son racionales.530 Que una idea, como la de que vivimos en Matrix, no sea irrefutable, no implica ni que sea verdad, ni que sea racional, ni que sea relevante. Si dos hipótesis tienen idénticas consecuencias empíricas, que aceptemos una o la otra no tendrá más consecuencia práctica que nuestra propia creencia en ellas. La hipótesis más racional es asumir que el mundo externo existe y se parece, más o menos, a lo que describen nuestras ideas cotidianas y nuestras mejores teorías científicas.531 La hipótesis más sencilla que es coherente con nuestras observaciones es que los gatos existen efectivamente en el mundo externo. En cualquier caso, lo cierto es que el tratamiento del escepticismo por parte de los filósofos modernos fue bastante distinto del de los helenísticos. Mientras que el objetivo del moderno era utilizar la duda radical como herramienta, el helenístico se interesó, sobre todo, por cuestionar las conclusiones de las distintas escuelas filosóficas. Actualmente el término escepticismo ha adquirido un nuevo significado relacionado con la aproximación racional al mundo. Tal vez un término más adecuado para describirlo habría sido racionalismo; es una pena que este término tenga ya otro significado tan distinto. Estos nuevos escépticos, con los que me identifico, buscan ir refinando sus herramientas cognitivas con el objetivo de obtener conocimiento sobre el mundo, son empiristas y, por supuesto, falibilistas. El escéptico actual intenta establecer de un modo racional el grado de confianza en las distintas creencias que se plantea. 6.12 La elección La posición del escéptico radical es lógicamente intachable. Uno puede asumir que sus recuerdos han sido implantados por un dios juguetón hace cinco minutos y que todo lo que cree saber es falso. Esta posición es lógicamente coherente y tal y como puntualizaron los escépticos helenísticos, cualquier intento de creación de conocimiento estará siempre sujeto a limitaciones; la certeza absoluta es inalcanzable. En realidad, no podría esperarse otra cosa de un sistema que está intentando aprender sobre otro a partir de una información incompleta. Pero que una posición sea lógicamente coherente no implica que esté libre de problemas prácticos. Si uno opta por el escepticismo radical está condenado al solipsismo y no poder decidir si lo que cree tener delante de sus narices es una puerta por la que salir o un engaño. Creo que cualquier pensador debe responder a dos preguntas. En primer lugar: ¿Cree que es razonable asumir que existe un mundo externo con una cierta estructura, es decir, un cosmos y que tus sentidos te hacen llegar información aproximadamente correcta sobre el mismo? Puedes elegir responder que no a esta pregunta y convertirte en un escéptico radical, pero, en ese caso, tienes que pagar un alto precio, el conocimiento es imposible y estás condenado a vivir completamente aislado del resto del cosmos. Nunca he oído hablar de nadie que se haya comportado de un modo coherente con esta extraña elección. La segunda cuestión es esta ¿piensas que tenemos que esforzarnos por intentar ser lógicamente coherentes? Responder que sí implica un compromiso con la racionalidad, pero, a la vez, una renuncia a algunos aspectos de nuestra naturaleza. La mayoría de los seres humanos no tienen la razón en suficiente estima como para, por ejemplo, enfrentarse a creencias fundamentales de su entorno social ni como para entablar diálogos racionales en los que el objetivo no es vencer, sino construir conocimiento. Esto, como iremos viendo es muy costoso e implica sacrificios importantes. Lo habitual es que los seres humanos se comporten siguiendo su naturaleza y que su esfuerzo por construir posturas coherentes sea limitado. Además, como veremos, el compromiso no es garantía de éxito. Las posibilidades de conseguir conocimiento dependen tanto de ti como del problema. Hay cuestiones demasiado difíciles. 6.13 Resumen Los escépticos helenísticos descubrieron limitaciones muy reales del conocimiento y enfriaron el optimismo del resto de escuelas filosóficas. Sin embargo, esto no implica que debamos abrazar la duda radical, esta duda, aunque es lógicamente coherente carece de interés práctico, el conocimiento es necesario para la acción. La duda absoluta, ilimitada, es incompatible con la supervivencia. No, la lección ha de ser: cautela, modestia y compromiso con el rigor intelectual. Los escépticos encontraron problemas en varios frentes. Por ejemplo, nuestros sentidos pueden engañarnos. Además, las evidencias, hasta cierto punto, están teñidas de teoría, las conclusiones dependen, al menos en parte, del investigador y no sólo del mundo externo. Y, por último, aunque la lógica es una herramienta irrenunciable, en realidad, para poder estudiar el mundo externo estamos obligados a hacer inferencias ampliativas y, por lo tanto, lógicamente inválidas. El investigador está sujeto a estas limitaciones y sólo mediante una aproximación sistemática podrá alcanzar el ideal racional, que no consiste en conseguir certeza, sino en ir actualizando nuestros modelos del mundo a medida que vamos obteniendo información, de modo que nuestros mapas, paulatinamente, pero con la máxima eficiencia, vayan pareciéndose al territorio. Lo que consigue el investigador racional es que las estructuras de sus modelos vayan aproximándose a los patrones presentes en el mundo externo. Para conseguirlo dispone de varias herramientas, todas consistentes en sistematizar lo que ya hace en su vida cotidiana. La adquisición de información debe realizarse, en la medida de lo posible, con protocolos claramente definidos. Esta es la diferencia entre la percepción o la información anecdótica y la observación científica. Pero incluso estas observaciones rigurosas serán falibles y deberán ser evaluadas en conjunto exigiendo coherencia lógica entre toda la información adquirida. Evidentemente, este camino no será sencillo y, como veremos, los retos no serán sólo intelectuales, pero, como mínimo, exigirá que el investigador se convierta en un experto prudente. Este es el mejor modo de aprender sobre el territorio, aunque, siempre deberemos recordar que habrá regiones más difíciles de explorar y, cuando ni los expertos lleguen a consensuar una respuesta tendremos que seguir las recomendaciones escépticas: reservemos el juicio o evaluemos la verosimilitud de las conclusiones. "],["primera_ciencia.html", "7 Primera ciencia 7.1 Aristóteles el naturalista 7.2 Aristóteles, el filósofo de la ciencia 7.3 Método aristotélico 7.4 Filosofía natural medieval 7.5 El esplendor de Alejandría 7.6 Astronomía, observación y teoría 7.7 Arquímedes, el gigante helenístico 7.8 Experimentación en el mundo helenístico 7.9 Tecnología helenística 7.10 Filosofía y ciencia 7.11 La caída 7.12 Resumen", " 7 Primera ciencia En paralelo al optimismo racionalista de los metafísicos neoplatónicos y a las radicales críticas escépticas, el mundo helenístico experimentó un desarrollo que no suele tratarse en los libros sobre historia de la filosofía, sino en los de historia de la ciencia. Dados sus intereses, la sofisticación de sus aproximaciones metodológicas y el éxito de sus resultados, podría argumentarse que fue en el periodo helenístico cuando nació la filosofía natural moderna, o si nos sentimos con ganas de discutir, podríamos incluso hablar del primer alumbramiento de la ciencia. A diferencia de los escépticos, Aristóteles, Arquímedes, Galileo y Newton creían que el conocimiento era alcanzable, y planteaban que, para llegar a él, debían utilizar una aproximación empírica y deductiva; el conocimiento del mundo natural había de partir de premisas empíricas y, a partir de ellas, mediante inferencias deductivas debía llegar a conclusiones ciertas. 7.1 Aristóteles el naturalista Aristóteles fue el primer gran naturalista y no hubo otro más relevante hasta el siglo XVIII. Sus contribuciones a otras ramas de la filosofía, como ya hemos comentado, fueron extraordinarias, pero no hemos de olvidar que una gran parte de su trabajo estuvo relacionado con la zoología. Un cuarto de los escritos que conservamos de él trata sobre este tema532 y se le considera el fundador de esta área de conocimiento.533 Aristóteles dedicó, junto a su discípulo Teofrasto, varios años a estudiar la fauna y la flora de Lesbos, una isla cercana a la actual Turquía. Describió la anatomía interna de 110 tipos de animales,534 estudió la dieta, el hábitat y los sistemas de reproducción de mamíferos, peces, reptiles, aves e insectos.535 Aristóteles fue el padre de la clasificación taxonómica y creó un sistema organizado en géneros y especies cuya siguiente mayor actualización hubo de esperar hasta Linneo en el siglo XVIII. Por ejemplo, fue él quien determinó que los cetáceos, a pesar de su apariencia externa, no son peces sino mamíferos.536 Además, partiendo de la disección de huevos de gallina en distintos estadios de desarrollo fue el primero en proponer que los animales adultos se desarrollan a partir de un embrión. Sin embargo, la botánica no aparece tan preeminentemente en sus escritos, muy probablemente porque de esta tarea se encargó su discípulo Teofrasto.537 La influencia aristotélica en los naturalistas modernos fue enorme: Andrés Vesalio, Leeuwenhoek, Linneo y Georges Cuvier absorbieron la estructura de su pensamiento.538 El propio Darwin, que consideraba a Linneo y Cuvier como los grandes de la biología, dijo que no eran más que aprendices del gran Aristóteles.539 Resulta curioso que cuando se recuerdan las aportaciones científicas aristotélicas no sea la biología, sino la física la ciencia más comentada. A esta ciencia no le dedicó tanta atención y, además, sus propuestas no sólo no sirvieron como fundación de la física moderna, sino que fueron rechazadas de plano por los filósofos naturales modernos. 7.2 Aristóteles, el filósofo de la ciencia Aristóteles no se conformó con ser el filósofo natural más importante del mundo clásico, sino que, además, reflexionó sobre cómo debía llevarse a cabo la investigación y cuál era la forma adecuada de justificar los resultados. Es habitual situar el inicio de la filosofía de la ciencia en la Viena de principios de siglo XX. Es en este momento cuando un grupo de filósofos se especializó, por primera vez, en el análisis del fenómeno científico como un problema específico, es decir, separado de la epistemología, del estudio del conocimiento en general. (Algunos autores utilizan el término gnoseología cuando se refieren al conocimiento en general y reservan el término epistemología sólo para el conocimiento científico). Aunque, tal vez, si le planteases a un filósofo de la ciencia que Aristóteles fue su homólogo más importante durante la antigüedad, probablemente te respondiese con una sonrisa cómplice seguida, inmediatamente, por una larga explicación sobre los motivos que hacen que no podamos considerar que existiese ciencia en la época clásica. En aquella época ni tan siquiera existía la palabra ciencia. Este término deriva de scientia, el vocablo que se utilizaba en latín para traducir el griego episteme. Además, ni Aristóteles, ni sus homólogos de la Edad Media, distinguían de un modo especial el conocimiento del mundo natural del resto, y se referían a todos ellos simplemente como conocimiento.540 Aunque lo que Aristóteles denominaba conocimiento tiene un cierto parecido con lo que hoy denominamos ciencia,541 por lo que es en este sentido general que algunos filósofos caracterizan sus Analíticos posteriores como un tratado sobre filosofía de la ciencia.542 El conocimiento que se discute en Analíticos posteriores está más cerca de las propuestas de Galileo o Newton que de las cuestiones más cotidianas que suelen tratar los epistemólogos. Mientras que en epistemología es típico discutir sobre cuáles son los motivos que llevan a un individuo a afirmar justificadamente que existe Nueva York, Aristóteles estudiaba el modo en el que debíamos investigar para obtener leyes generales sobre el comportamiento del mundo natural. Aristóteles fue decididamente empirista, su método de estudio de la naturaleza parte de la observación, es decir, de la exploración sistemática del mundo natural. Su recomendación era que nos manchásemos las manos, en muchos casos literalmente, como cuando recomendaba que diseccionásemos animales.543 En general, el método aristotélico reconocía la observación como el fundamento del conocimiento544 y en el caso en el que hubiese un conflicto entre ésta y la razón recomendaba otorgar la primacía a la observación.545 En esto se asemeja más a los empiristas ilustrados546 y a los científicos contemporáneos que a Zenón y al resto de metafísicos especulativos, más interesados en razonar cuidadosamente que en seguir de cerca lo que sus ojos les mostraban. Incluso podría defenderse que esta preeminencia de la observación fue la que le llevó a cometer algunos errores. Por ejemplo, la física aristotélica, que tanto suele criticarse, concordaba mejor con las observaciones y el sentido común que la cinética de Galileo y la dinámica newtoniana.547 Mientras que el principio de inercia de Galileo dicta que un objeto mantendrá su estado de movimiento a no ser que una fuerza actúe sobre él, la dinámica aristotélica coincide con nuestras impresiones cotidianas: los objetos no se moverán a no ser que una fuerza actúe sobre ellos. Todavía más llamativo fue el error de la generación espontánea: propuso que algunos animales se generaban espontáneamente a partir de la materia inerte. Este fallo suele aprovecharse para burlarse de la biología aristotélica. Sin embargo, esta conclusión estaba apoyada por dos observaciones. Por un lado, cuando la carne se pudre aparecen larvas sin que se pueda observar, a simple vista, ningún huevo del que puedan surgir y, además, en sus disecciones fue incapaz de encontrar los órganos reproductivos de algunos animales.548 Además, es muy notable que defendiese la conclusión de la generación espontánea, ya que planteaba un problema a su sistema filosófico. Según este sistema, la clave del funcionamiento del cosmos no reside en la composición de su materia, sino en la estructura que adopta la misma. Mientras los filósofos naturales presocráticos habían propuesto que el comportamiento de la materia dependía de su composición, Aristóteles defendió que era la forma que adopta la materia la que dicta su función. Esta es una conclusión que cualquier biólogo actual, moleculares incluidos, defenderá. Todos los seres vivos tienen una composición muy similar: proteínas, azúcares, lípidos, ácidos nucleicos y agua y lo que los distingue es, principalmente, la forma en la que estos compuestos están organizados. Según el sistema aristotélico esta forma la heredarían los seres vivos de sus padres, por lo que plantear que las larvas podían aparecer en la carne putrefacta sin que un padre les transmitiese su forma representaba un desafío a este sistema.549 Sin embargo, respetando sus observaciones propuso, erróneamente, que algunos animales aparecían espontáneamente. También es común que algunos autores se mofen de sus pobres dotes observacionales. Aducen que cometió errores que podría haber evitado fácilmente si hubiese observado con una mínima atención. Propuso, por ejemplo, que las mujeres tienen menos dientes que los hombres.550 Es cierto que las mujeres tienen el mismo número de dientes que los hombres, pero es posible que esta crítica sea injustificada ya que establecer este hecho no es tan sencillo como podría pensarse. Tal vez el problema estribe en que no nacemos con las muelas del juicio y el error de Aristóteles pudo deberse a que contase el número de dientes de mujeres y hombres de distinta edad. Además, en un mundo sin higiene dental ni dentistas el número de piezas dentales podía variar bastante entre individuos. En cualquier caso, es evidente que Aristóteles otorgó preeminencia a la observación en su método. A pesar de ello no fue esto lo que pensaron muchos modernos, sino más bien lo contrario. Francis Bacon (1561 - 1626), el filósofo moderno más interesado por la ciencia y el defensor por antonomasia del empirismo, criticó dura, e injustamente, a Aristóteles por poner sus hipótesis y especulaciones por delante de la observación.551 Puede que Bacon no conociese todas las obras aristotélicas y le resultase natural pensar que el maestro clásico fundador de la lógica defendiese la deducción por encima de la observación. Además, también puede que estuviese influido por la visión moderna de rotura con el pensamiento clásico y medieval, un pensamiento centrado en los trabajos menos científicos de Aristóteles, un filósofo que, recordemos, era considerado por los escolásticos y humanistas, los representantes del antiguo régimen contra el que Bacon luchaba, como el Filósofo o el maestro de los que saben. Galileo, sin embargo, tal vez porque dedicó su vida a hacer investigación y no sólo a pensar sobre ella y a pesar de pertenecer a una generación anterior a la de Bacon, sí que reconoció el empirismo aristotélico y lo señaló como uno de sus maestros.552 7.3 Método aristotélico La observación es fundamental, pero no es suficiente, no se hace ciencia escribiendo una lista de evidencias, es necesario llegar a conclusiones, plantear hipótesis que resuman esta información empírica. Aristóteles planteó que el investigador debía averiguar las razones, los motivos que causaban el fenómeno observado. Un investigador aristotélico no debía conformarse sólo con describir, sino que aspiraría a explicar cuáles son las causas de los procesos estudiados.553 El conocimiento, según Aristóteles, además debía ser general, tenía que tratar sobre características esenciales de los fenómenos investigados.554 Explicar la causa de que un pez individual haya hecho tal o cual cosa no sería conocimiento, las conclusiones debían versar sobre características generales: ¿qué hace que los peces de esa especie se comporten de ese modo? Por último, estas conclusiones debían ser justificadas deductivamente. El conocimiento tenía que justificarse, tal y como se hacía en las matemáticas, mediante inferencias válidas. Concretamente debía expresarse en forma de los silogismos válidos que él mismo había descubierto.555 Aristóteles proponía una ciencia axiomática: a partir de unas premisas, que se asumirían como verdaderas, mediante silogismos alcanzaríamos un conocimiento necesariamente cierto.556 Aunque hay que precisar que Aristóteles no creía que debiésemos llegar al descubrimiento mediante la deducción. El proceso de descubrimiento, tal y como también propondría Arquímedes, podía ser más libre, la deducción tan sólo era imprescindible para la presentación y justificación de las conclusiones.557 Además, también es importante recordar que el método aristotélico era empírico ya que las premisas tenían que basarse en observaciones. Mientras que Platón buscaba el conocimiento razonando dialécticamente, planteando las fortalezas y las limitaciones de distintas propuestas, los aristotélicos planteaban partir de principios empíricos.558 Lo que la deducción aportaba es rigor lógico, por lo que esta primera propuesta de método científico pretendía alcanzar la certeza gracias a la aplicación del rigor deductivo a unas evidencias empíricas claras. Esta propuesta resonó a lo largo de la historia y se podría defender que varios de los trabajos científicos de Galileo o los propios Principios matemáticos de la filosofía natural newtonianos, una de las obras cumbre de la revolución científica, y de la historia de la Humanidad, seguían muchas de estas recomendaciones. Lo que no quedaba demasiado claro era cómo partiendo de la observación debíamos llegar a las premisas. Las observaciones siempre tratarán con individuos concretos, pero las premisas debían versar sobre características esenciales y generales de los objetos estudiados.559 De algún modo teníamos que alcanzar, a partir de observaciones concretas, premisas generales. Esto implica que las premisas debían generarse mediante la inducción, lo cual conlleva una limitación fundamental. Por un lado, las observaciones, tal y como criticaron los escépticos, podían ser erróneas y, por otro, las inferencias ampliativas no pueden ser lógicamente válidas por lo que las premisas generadas mediante inducción siempre serán falibles. Este es un problema fundamental para la ambición aristotélica de alcanzar la certeza, si las premisas están comprometidas, la deducción no puede garantizar certeza. Sin embargo, sobre estos problemas no discutió demasiado, se limitó a asumir que, de algún modo, nuestra mente debía de ser capaz de llegar a esas premisas básicas generales y evidentes. Mientras que los estoicos asumían que nuestros sistemas perceptivos eran capaces de ofrecernos algunas impresiones cognitivas, Aristóteles defendía algo aún más arriesgado, que éramos capaces de aprehender verdades fundamentales generales.560 A esta limitación hay que añadir otras que todavía alejan más el método aristotélico de los que se propondrían durante la Edad Moderna. Por ejemplo, Aristóteles nunca experimentó561 ni cuantificó. A pesar de que era conocedor de que los astrónomos hacían observaciones cuantitativas, él mismo nunca midió, incluso su propia física se basó en argumentaciones puramente cualitativas.562 Esto le habría parecido muy extraño a un filósofo natural moderno. Aristóteles pretendía estudiar el funcionamiento de la naturaleza y por eso consideraba que el investigador no debía intervenir en el devenir del fenómeno observado. Esto, claro está, impedía la realización de experimentos, ya que un experimento se basa, precisamente en controlar cuidadosamente las circunstancias en las que ocurre la observación. Según Aristóteles, los experimentos, al alterar artificialmente el fenómeno estudiado, podían modificarlo, confundiendo así al investigador.563 Estas dos características, la cuantificación y el experimento, sólo pasaron a un primer plano durante la revolución científica de los siglos XVI y XVII. Fue precisamente un experimento realizado en el siglo XVII el que permitió rechazar la hipótesis de la generación espontánea. Francesco Redi, un naturalista y poeta italiano, publicó en 1668 una serie de experimentos en los que estudió el proceso de putrefacción de la carne. Para aclarar si las larvas podían aparecer espontáneamente preparó varios botes en los que situó un trozo de carne en el fondo. Algunos botes los cubrió con una gasa, mientras que otros los dejó abiertos. Transcurridos unos días comprobó que, en los botes cubiertos por la gasa, que impedía el paso de las moscas, no había larvas mientras que en los abiertos sí las había. La carne no generaba larvas por sí sola. Este es un procedimiento que hoy en día puede parecernos obvio, pero se necesitaron siglos para asumir que la manipulación experimental debía ser una parte importante del proceder científico. A pesar de estas limitaciones, las aportaciones aristotélicas, tanto las relativas a las distintas ciencias, como la física o la zoología, como sus reflexiones sobre el proceder científico influyeron profundamente a los investigadores posteriores. 7.4 Filosofía natural medieval El ejemplo y las recomendaciones aristotélicas sirvieron de base para el desarrollo de la filosofía medieval en los mundos musulmán y europeo. Los dirigentes musulmanes, interesados por el desarrollo cultural, promovieron la traducción y los comentarios de los textos de los filósofos clásicos y reavivaron el interés por la filosofía natural. Primero fue la Bagdad de los abasíes, seguida por el Cairo de los fatimíes en el siglo XI y la Córdoba de los omeyas en los siglos XI y XII, para terminar, al final de la Edad Media en oriente, en Maraghe y Samarcanda.564 Esta filosofía natural, heredera del mundo clásico, fue desarrollada por una élite cultural educada en entornos cosmopolitas, diversos y multiculturales. El objetivo de este esfuerzo no sólo consistió en recuperar el conocimiento clásico, sino en ampliarlo. Por ejemplo, la astronomía y astrología continuaron con la tradición ptolemaica, pero, al mismo tiempo, se mejoró el instrumental de medida y se crearon observatorios en los que se elaboraron nuevas tablas astronómicas.565 Las matemáticas árabes también partieron de las helenísticas de Euclides, Arquímedes y Herón, además de las hindúes,566 y a partir de éstas iniciaron un programa de investigación que obtuvo resultados notables. Al-Juarismi, por ejemplo, escribió un tratado fundacional sobre el álgebra. Sin embargo, a pesar de estos avances y de su conocimiento de las demostraciones griegas, ni los hindúes ni los árabes se molestaron por desarrollar pruebas deductivas.567 Su interés era más bien práctico, como el babilonio y el egipcio. Por otro lado, hay quien considera a Juan Filópono, un teólogo y filósofo bizantino del siglo VI, el primero de los medievales europeos y quien lo sitúa como el último de los clásicos, aunque, en realidad, fue una figura aislada. Filópono criticó la física aristotélica y propuso que los objetos en movimiento tienen un ímpetu que los va impulsando hasta agotarse. Según Aristóteles un objeto era movido cuando se ejercía una fuerza sobre él, pero esta hipótesis, que funcionaba bien para carros y carretas, no explicaba qué hacía que una piedra lanzada siguiese moviéndose una vez abandonaba la mano del lanzador, algo que Filópono trató de explicar con su ímpetu, un concepto que podríamos considerar como antecesor de los de la inercia y el momento lineal. Esta propuesta sería reintroducida en el mundo medieval por Jean Buridán (1300-1358), un discípulo de Ockham que llegó a ser rector de la Universidad de París y que fue maestro de Nicolás Oresme, un obispo, teólogo, filósofo, economista, matemático, físico, astrónomo, psicólogo y musicólogo que exploró, sin aceptarla, la hipótesis de que la Tierra realiza un giro completo sobre su eje una vez al día.568 Roberto Grosseteste (1175-1253), otro gran filósofo escolástico del siglo XIII, fue, sin duda, uno de los pensadores más importantes en la revitalización de la filosofía natural medieval europea y, además, fue el maestro de Roger Bacon (1214-1294). Este Bacon medieval, que no hay que confundir con Francis Bacon, el moderno, fue un fraile franciscano inglés dedicado al estudio, que, además de interesarse por la lógica, trabajó en óptica y en la naturaleza de la luz.569 Mientras tanto, en Alemania, Alberto Magno, un filósofo, obispo y doctor de la Iglesia del siglo XIII, trabajó en física, astronomía, astrología, alquimia, mineralogía, fisiología, medicina, lógica y matemáticas y fue, como Aristóteles, un gran observador del mundo animal y vegetal.570 Otro avance físico medieval fue la demostración, por parte del conjunto de filósofos conocido como los Calculadores de Oxford, de que el espacio recorrido por un cuerpo que se mueve con aceleración constante es igual a su velocidad media por el tiempo transcurrido.571 Este teorema cinemático representa un avance sobre la metodología aristotélica que, recordemos, era demostrativa, pero no cuantitativa. Como veremos en breve, esta aproximación cuantitativa a la física fue un desarrollo helenístico que se perdió con la caída de Roma y que sólo volvió a abrazarse por completo tras las propuestas galileanas. 7.5 El esplendor de Alejandría Estos avances medievales, que terminaron floreciendo durante la revolución científica, tan solo representan uno de los dos caminos que heredaron el programa aristotélico y palidecen frente al esplendor del otro: la revolución de la filosofía natural helenística. Alejandro Magno murió con 32 años, pero tuvo tiempo suficiente para conquistar todo el mundo civilizado conocido, desde su Macedonia natal a la India, pasando por las grandes potencias de su tiempo: Grecia, Egipto y Mesopotamia. Alejandro fue alumno de Aristóteles, lo cual demuestra, según el profesor de filosofía Peter Adamson, la importancia de estudiar filosofía con un buen maestro. Además, la ambición de Alejandro no se limitaba a la conquista, sino que aspiraba también a crear las bases de un imperio universal fundado sobre la unión cultural de los grandes imperios de la antigüedad, Mesopotamia y Egipto, con la tradición clásica griega. Este proyecto continuó tras la muerte de Alejandro, por lo que suele considerarse que la época helenística comenzó con su muerte en 323 a. C. y terminó con la de Cleopatra en 30 a. C.. El mundo helenístico de Alejandría no fue una mera continuación del griego, sino que resultó de una verdadera síntesis de las tradiciones egipcia y clásica.572 Cleopatra, la última gobernante ptolemaica, la postrera dinastía del antiguo Egipto, era, culturalmente, tan griega como egipcia. No es casual que los textos egipcios y griegos escritos en la piedra de Rosetta se correspondan con un decreto de un faraón ptolemaico. En el terreno cultural la fusión de las matemáticas demostrativas, la lógica y la filosofía clásica con las preocupaciones prácticas del gobierno egipcio dio lugar a un fenómeno inusitado, el nacimiento de una filosofía natural rigurosa sufragada con fondos públicos que llegó a medir la Tierra, crear Los elementos de Euclides, desarrollar el mecanismo de Anticitera e, incluso, a fabricar incipientes máquinas de vapor. Alejandro fundó la magnífica ciudad de Alejandría. Desde ella pretendía gobernar la rama egipcia de su imperio, a caballo entre el Nilo y el Mediterráneo. Esta fue sólo una de las, al menos veinte, ciudades que fundó a lo largo de sus conquistas y, además, como hombre modesto que era, a la costumbre de fundar ciudades añadió la de llamarlas, a casi todas, Alejandría. La Alejandría que nos ocupa, la más famosa, entre 280 a. C. y su conquista por parte del imperio romano, disfrutó de una relativa paz, de crecimiento económico y de un gran desarrollo cultural.573 La ciudad llegó a alojar a 300 000 habitantes en un entorno urbano que seguía, por primera vez, una planificación racional creada desde cero. Alejandro encargó su diseño a Dinócrates, el primer urbanista de la historia. La primera propuesta de éste fue modelar una montaña de 2000 metros de altura con la figura de Alejandro y construir la ciudad a sus pies. Este proyecto no pudo llevarse a cabo por razones prácticas, aunque debió complacer al modesto Alejandro ya que, finalmente, fue Dinócrates el encargado de diseñar la urbanización de Alejandría. Los gobernantes ptolemaicos sufragaron la construcción del Museo, el primer centro público de investigación de la historia de la Humanidad. Un centro dedicado a las musas en el que, gracias a la financiación pública, se alojaban poetas, filósofos, filólogos, astrónomos, geógrafos, historiadores, médicos, artistas y los más importantes matemáticos.574 El Museo estaba acompañado por la Biblioteca, un observatorio astronómico, un parque zoológico, un jardín botánico y por instalaciones adecuadas para la disección de cadáveres. Se albergaban en el Museo, como huéspedes del faraón, cien profesores becados que podían dedicarse por completo al desarrollo de sus investigaciones.575 Recordemos que, sin embargo, ninguno de los filósofos helénicos disfrutó nunca de una beca estatal. Además, esta financiación no estaba limitada a la obtención de conocimiento práctico, sino que se extendía a la filosofía natural general, a lo que actualmente denominaríamos ciencia fundamental.576 Este patrocinio del conocimiento puro no había ocurrido nunca antes ni habría de volver a darse hasta la época de la revolución industrial. Mientras en Atenas los escépticos discutían si el conocimiento era o no posible, en Alejandría la filosofía natural estalló. La ciencia que Aristóteles había soñado alcanzó en el mundo helenístico un nivel comparable al de los siglos XVII y XVIII europeos. La Biblioteca habría hecho feliz a Aristóteles, el lector, ya que se estima que llegó a albergar unas decenas de millares de obras en medio millón de rollos. Una biblioteca que fue organizada por Demetrio de Falero, un discípulo de Teofrasto y, por lo tanto, un nieto intelectual del gran maestro.577 7.6 Astronomía, observación y teoría Los mesopotámicos, que estaban interesados en el calendario y en la astrología, disponían de registros astronómicos desde el segundo milenio a. C. y de observaciones sistemáticas desde el 747 a. C..578 Gracias a este esfuerzo eran conocedores de los solsticios, los equinoccios, los ciclos lunares y los solares. Sin embargo, pese a este interés, las civilizaciones antiguas nunca dieron el siguiente paso en el camino científico, desarrollar modelos teóricos, en este caso modelos geométricos sobre el funcionamiento de los astros.579 El conocimiento científico no se limita a recopilar observaciones, sino que, a partir de ellas, elabora modelos e hipótesis. Podría decirse que quienes convirtieron la astronomía en una ciencia, o al menos en una disciplina organizada alrededor de la elaboración de modelos cuantitativos, fueron los griegos. Lo hicieron, como ya hemos comentado, partiendo de las observaciones mesopotámicas, pero su interés no se limitó a la predicción de fenómenos, sino que pretendían entender el cosmos. Eudoxo de Cnido, uno de los pupilos de Platón, fue el primero en proponer un modelo astronómico capaz de explicar, al menos cualitativamente, el errático movimiento de los planetas. Por cierto, la palabra planeta deriva del griego planétes, vagabundo. Los planetas son los astros errantes, puesto que mientras que las estrellas giran noche tras noche manteniendo las mismas posiciones relativas, los planetas danzan entre ellas ejecutando complicados movimientos. El modelo de Eudoxo explicaba el movimiento irregular de los planetas descomponiéndolo mediante el uso de un conjunto de esferas concéntricas. Para el Sol y la Luna se requerían tres esferas y para cada planeta 4.580 Por primera, vez un fenómeno natural podía describirse utilizando un modelo matemático. Supongo que el día que Eudoxo compartió su modelo con Platón, éste creería estar observando las eternas formas en sí mismas. Estos avances académicos palidecen, sin embargo, ante los del gran astrónomo helenístico Hiparco de Nicea. Fue él quien complementó la geometría con la observación cuantitativa. A partir de este momento, un modelo astronómico sólo sería considerado correcto si hacía predicciones cuantitativas precisas. La astronomía fue la primera ciencia en hacerse cuantitativa. Por desgracia, a parte de que vivió entre 190 y 120 a. C., no sabemos casi nada de él, ni con quién estudió y trabajó, ni cuál fue su relación con Alejandría o con otros centros de conocimiento, ni cuáles fueron sus aportaciones exactas. Casi todo lo que sabemos de Hiparco se lo debemos a Claudio Ptolomeo (c. 100 d. C.- c. 170 d. C.), el otro gran astrónomo, que nació un par de siglos después, y en la mayoría de los casos es difícil diferenciar las aportaciones de cada uno de ellos. Lo que sí parece indudable es que Hiparco decidió acometer un programa observacional que mejorase los antiguos catálogos mesopotámicos. Para conseguirlo construyó nuevos instrumentos. Se le atribuye la invención de la dioptra, un instrumento que utilizó para medir los diámetros de la Luna y el Sol.581 Además, puede que fuese el inventor de la proyección estereográfica, un elemento esencial del astrolabio e incluso es posible que inventase el propio astrolabio, un instrumento crucial en la astronomía medieval y renacentista. Sin embargo, Hiparco, no se limitó a observar, sino que también realizó cálculos muy precisos. Determinó, por ejemplo, el ángulo de la eclíptica, midió la longitud del año solar con sólo medio minuto de diferencia sobre nuestra medida actual582 y estableció la longitud del mes lunar con una diferencia sobre nuestra estimación actual de un sólo segundo;583 algo muy notable, sobre todo si tenemos en cuenta que la longitud de los meses lunares puede variar hasta en 12 horas de unos a otros. Aunque tal vez su mayor hazaña fuese la de calcular la duración del ciclo de la precesión de los equinoccios: 25 800 años584 Este conocimiento avanzado helenístico fue utilizado para construir el mecanismo de Anticitera, una computadora analógica, datada entre el 200 y el 100 a. C., capaz de predecir las posiciones astronómicas de la Luna, incluyendo su fase, el Sol y los planetas, los eclipses solares, así como la fecha de los Juegos Olímpicos y de otras competiciones,585 aunque con poca precisión.586 Por muy impresionantes que sean estos desarrollos, la cumbre de la astronomía helenística no llegaría hasta el Almagesto, es decir, el Gran Tratado,587 la gran obra de Claudio Ptolomeo, uno de los últimos astrónomos del Museo. Ptolomeo mejoró el modelo de Hiparco utilizando un complejo sistema geométrico de ciclos, epiciclos, deferentes y ecuantes capaz de ajustar las observaciones del movimiento de los astros con una precisión superior incluso a la del modelo copernicano. Además, fue este tratado el que transmitió el conocimiento astronómico al mundo musulmán y a la Europa medieval y el que acabaría siendo discutido por Copérnico, Kepler y Galileo más de mil años después. 7.7 Arquímedes, el gigante helenístico Arquímedes (c. 287 a. C.- c. 212 a. C.) es, sin duda, el filósofo natural helenístico por antonomasia, un matemático extraordinario y un físico e ingeniero magnífico. Nació y vivió en Siracusa, fue hijo de un astrónomo y, siendo un niño, construyó un planetario que simulaba el movimiento del Sol, la Luna, los planetas y los eclipses. Aunque donde se formó realmente fue en Alejandría, pues fue allí donde estudió con los discípulos de Euclides.588 Esto le permitió desarrollar una gran carrera en las matemáticas puras y aplicadas. Entre sus avances destaca el método de exhausción, un antecedente geométrico del análisis matemático que Newton y Leibniz desarrollaron en el siglo XVII, y que permitía calcular áreas y volúmenes de superficies y volúmenes curvos. Por ejemplo, mediante este método consiguió acotar, utilizando un polígono de 96 lados, el valor de pi entre 3 + 10/71 y 3 + 10/70.589 Además, hizo grandes aportaciones físico-matemáticas determinando, por ejemplo, los centros de gravedad de cuerpos de distintas formas y fundó el estudio sistemático de la hidrostática. Estos trabajos requirieron el desarrollo de una nueva metodología que Arquímedes recogió en El Método. Este ensayo se creía perdido, Leonardo da Vinci, Galileo, Newton lo buscaron, pero sus esfuerzos fueron vanos.590 A pesar de esto, cuando ya habíamos añadido esta obra a la trágica lista de las perdidas con la caída del mundo helenístico, alguien que estaba echando un vistazo a un texto litúrgico del siglo XIII vio unos símbolos semiborrados. Al parecer, un religioso, falto de pergamino, había decidido reutilizar uno borrando antes el texto griego original. Este palimpsesto, transcrito en el siglo XX, es la única copia conocida de El método, un extraordinario documento en el que Arquímedes detalla a su amigo Eratóstenes, el director de la biblioteca de Alejandría, su proceder científico. Arquímedes recomendó dividir la investigación en dos fases. En la primera fase podían utilizarse intuiciones mecánicas, heurísticas y cálculos aproximados para hacerse una idea del problema y para plantear una posible solución. Mientras que, en la segunda, siguiendo el ejemplo aristotélico y euclídeo, debía exigirse una deducción rigurosa que garantizase certeza.591 Veremos que los positivistas también plantearon, en el siglo XX, una distinción entre contexto de descubrimiento y de justificación que recuerda a la metodología de Arquímedes. Durante el descubrimiento el investigador podía explorar el problema sin restricción alguna; pero al proceder a justificar sus conclusiones Arquímedes requería rigor deductivo. Este método, aunque similar al aristotélico, representa un gran avance, ya que mientras Aristóteles planteaba silogismos, inútiles para una investigación cuantitativa, Arquímedes utilizaba demostraciones geométricas que sí le permitían tratar los problemas físicos cuantitativamente. Esta es la aproximación que utilizó, por ejemplo, para demostrar su ley de la palanca. Por desgracia, estas demostraciones también se perdieron y no fueron recuperadas hasta el renacimiento, momento en el que resonaron con fuerza inspirando a los filósofos naturales modernos.592 Arquímedes, de hecho, llegó a considerarse en el siglo XVI en oposición al Aristóteles medieval.593 Galileo, sin embargo, aunque también se veía a sí mismo como un discípulo de Arquímedes,594 no se olvidó de recordar que él también era un buen aristotélico ya que sentía un profundo respeto por la lógica y la aproximación empírica del maestro.595 Esta afirmación, en el contexto moderno, podría ser considerada como una provocación más de Galileo pues, como hemos mencionado, gran parte de los modernos consideraban que la modernidad consistía, precisamente, en rebelarse contra el anticuado legado aristotélico medieval. En cualquier caso, el objetivo de Galileo fue reinstaurar el método deductivo helenístico. Solemos recordar a Galileo como una figura eminentemente empírica, centrada en crear telescopios y observar, pero esto constituyó sólo una parte de su actividad. En la física galileana los experimentos tenían un papel secundario. En De Motu Antiquiora (Sobre el movimiento) aunque reconoció que la observación y el experimento debían obligarnos a reconsiderar nuestras conclusiones filosóficas, la justificación final, tal y como recomendaba Arquímedes, debía ser deductiva.596 En este sentido Galileo, uno de los padres de la revolución científica, puede considerarse como uno de los últimos antiguos. Aunque, en realidad, esta forma de exponer los resultados científicos no terminó con Galileo, incluso en los Principia Mathematica Newton presentó su mecánica exactamente como Arquímedes había recomendado hacerlo en su El Método. 7.8 Experimentación en el mundo helenístico En la filosofía natural helenística, a diferencia de en la clásica, sí se hicieron algunos experimentos. En neumática, por ejemplo, se construyeron aparatos para hacer demostraciones de diversos principios.597 Otro experimento famoso es el relativo a la función del cerebro. Aristóteles creía que el control del cuerpo corría a cargo del corazón y no del cerebro, mientras que otros filósofos defendían el papel del cerebro. Galeno, el médico helenístico más influyente, decidió hacer un experimento para dirimir la cuestión. El experimento consistió en cortar los nervios del cuello de un animal vivo, si era el corazón el que controlaba el movimiento, en principio, esta intervención no debería afectar a ese movimiento. Sin embargo, como podemos imaginar, el animal quedó paralizado. Además, en otro experimento, hurgó en distintas partes del cerebro de un animal para observar cómo cada una de estas intervenciones afectaba al comportamiento de distinto modo.598 En otro experimento, que requirió de medidas muy precisas, Erasístrato estudió cómo un pájaro sin alimento, con el tiempo, iba perdiendo masa. Para eso tuvo que pesar con mucho cuidado tanto al pájaro como sus excrementos. La conclusión fue que algo de masa debía de perderse mediante algún tipo de emanación invisible. Ptolomeo, el del modelo astronómico, también se interesó por la óptica y realizó una serie de experimentos para estudiar la refracción de la luz. Para llevarlos a cabo midió los ángulos de incidencia y salida de la luz al pasar de un medio a otro: aire y agua, aire y vidrio y agua y vidrio. Estas observaciones no le permitieron inducir la relación correcta entre los ángulos de incidencia y de refracción, aunque sí llegó a plantear una relación matemática aproximada. Por cierto, la que se conoce como ley de Snell fue propuesta por primera vez en 984 por el matemático persa Ibn Sahl, redescubierta por el aventurero y pensador inglés Thomas Harriot en 1602, vuelta a redescubrir por el matemático y astrónomo Snellius en 1621 y deducida, independientemente, por Descartes y por Pierre de Fermat, que la infirió como una consecuencia del principio que lleva su nombre. Esto es algo que deberían explicar los relativistas: ¿cómo es posible que investigadores de épocas y culturas tan alejadas acaben llegando, una y otra vez, a las mismas descripciones matemáticas? Pero volvamos a Alejandría. Este experimento de Ptolomeo fue absolutamente inusual. En una época centrada en la deducción de las leyes naturales a partir de primeros principios o premisas muy elementales, Ptolomeo utilizó un método puramente experimental. Sin plantear una hipótesis a priori, decidió realizar un conjunto de experimentos, medir e inducir para obtener una relación puramente empírica. Este es exactamente el método que utilizaría Newton en su Opticks, otra de las obras cubres de la revolución científica y ejemplo paradigmático del método experimental. En este conocidísimo estudio óptico, Newton utilizó prismas para descomponer la luz blanca en un espectro de colores y para comprobar que esos colores eran fundamentales, es decir, que no podían descomponerse a su vez. ¿Podemos concluir, dados estos ejemplos, que la filosofía natural helenística fue, como la moderna, experimental? No, en absoluto. La aproximación ptolemaica fue extraordinaria, es decir, fuera de lo común. Aunque es cierto que en la época helenística se realizaron experimentos, estos no llegaron a tener, ni mucho menos, la relevancia que adquirirían en la Época Moderna. Puede que, si el mundo helenístico no hubiese caído, se hubiese desarrollado una aproximación experimental completa, pero, por desgracia, los experimentos realizados hasta la época moderna, incluidos los de la Edad Media, fueron la excepción, no la regla. 7.9 Tecnología helenística Un aspecto muy sugerente del mundo helenístico y sobre el que desconocemos bastante es el tecnológico. Sabemos que se desarrollaron nuevas tecnologías, pero no conocemos con detalle cuáles fueron, la relación de su origen con el conocimiento del mundo natural y, sobre todo, cuáles fueron sus implicaciones sociales. Las evidencias arqueológicas, por desgracia, son fragmentarias y difíciles de interpretar.599 Sin embargo, sí tenemos algunas evidencias muy llamativas. En un papiro del siglo II a. C. un tal Laterculi Alexandrini hace un listado de personajes eminentes y cita: legisladores, pintores, escultores, arquitectos e ingenieros mecánicos (mechanikoi).600 Esta última categoría no se le habría pasado por la cabeza a ningún ateniense helénico. También sabemos que en el mundo helenístico aparecieron algunas invenciones tecnológicas completamente novedosas como los tornillos (sí, alguien tuvo que inventarlos), las ruedas dentadas (los engranajes) y las máquinas compuestas.601 Estos engranajes hicieron posible, por ejemplo, que se construyese la máquina de Anticitera, una precursora de la maquinaria de precisión que mucho más tarde haría posible la aparición de los relojes mecánicos. Además, los engranajes fueron utilizados para crear odómetros capaces de medir distancias con precisión. Ctesibio inventó una bomba hidráulica de la que se han encontrado decenas de restos arqueológicos romanos. También fueron un invento helenístico los molinos de agua que durante la Edad Media contribuyeron a la mejora de la agricultura y a la recuperación europea. Aunque ya durante el Imperio Romano se construyó en Arlés el molino de Barbegal, capaz, gracias a sus 16 ruedas y 32 piedras, de moler 4,5 toneladas de harina diarias. Lo que me recuerda que mi amigo Víctor Guisado suele decirme que la gente tiende a ignorar que el conocimiento acaba por hacer que baje el precio del pan. Por cierto, este complejo industrial romano puede visitarse todavía hoy en el sur de Francia. Otra invención, esta vez militar, fue la catapulta de torsión, un aparato tan eficiente que hubo de compensarse con una mejora en la fortificación de las ciudades. Finalmente, dada la relevancia del invento en la revolución industrial, merece la pena destacar que Herón de Alejandría describió dos tipos de máquinas de vapor rudimentarias: una denominada Eolípila, que simplemente hacía rotar una esfera metálica, y otra que se utilizaba para abrir automáticamente las puertas de un templo.602 Nunca antes en la historia se había concentrado un número tan grande de invenciones en un tiempo tan corto. Parece difícil pensar que el esfuerzo por subvencionar la filosofía natural, que también apareció por primera vez en ese momento y en ese lugar, no tuviese ninguna relación con este desarrollo ingenieril. Ctesibio, el inventor de la bomba hidráulica, fue, probablemente, director del museo y es considerado como el fundador de la neumática, la rama de la física que estudia los flujos gaseosos y el aire comprimido. El propio Arquímedes trabajó en el tornillo que lleva su nombre, una máquina que se utilizaba para sacar agua de las acequias y regar los campos y que fue utilizada posteriormente para extraer agua de las minas y para achicar agua en los barcos.603 La geografía fue otra clara aplicación del conocimiento teórico astronómico. Es bien conocido que Eratóstenes midió el radio de la Tierra, pero suele mencionarse este hecho como el logro aislado de una mente despierta. Sin embargo, Eratóstenes estudió en Atenas y Alejandría, fue amigo de Arquímedes y director de la Biblioteca. Resulta evidente que para un imperio disponer de mapas precisos es muy ventajoso, y este fue uno de los cometidos que se le encomendó a uno de los investigadores más destacados de la época, que recordemos, estaba pagado por el estado. Sin embargo, la obra cumbre de la geografía helenística se la debemos a otro astrónomo, Ptolomeo. En su Geografía, que se compone de 8 libros, se listan la longitud y latitud de 8000 lugares,604 desde la isla de El Hierro hasta China. Por último, dada mi profesión, me gustaría mencionar que Varrón, un militar e intelectual romano, citó 49 tratados sobre agronomía y parece que en el Museo se encargaban de aclimatar e hibridar plantas con interés agrícola. Además, se introdujeron cambios en las técnicas agrícolas, algo que tal vez tuviese que ver con el gran aumento de la población egipcia, que, se estima, pasó de tres a ocho millones, y con que el Egipto helenístico y Romano se convirtiese en el mayor exportador de grano del Mediterráneo.605 Conviene poner este logro en perspectiva para apreciar su magnitud; en 1882, muchos siglos después y tras medio siglo de crecimiento, la población egipcia alcanzó los 6,8 millones. De nuevo el precio del pan. 7.10 Filosofía y ciencia Suele decirse que fue en Alejandría cuando la filosofía se separó por primera vez de la ciencia606 y lo cierto es que si se comparan los intereses de la Academia de Platón con los del Museo la diferencia es notable. Mientras que durante la época helenística Atenas continuó siendo la capital filosófica, sede de los epicúreos, estoicos, peripatéticos y escépticos, Alejandría lo fue de los matemáticos, astrónomos e ingenieros.607 Incluso hay quien defiende, basándose en este hecho, que la ciencia nació en Alejandría y no en la Europa de los siglos XVII y XVIII. Prefiero no entrar en esta discusión puesto que se corre el riesgo de contribuir a un debate un tanto estéril, ya que la conclusión depende, en parte, de la definición que hagamos de ciencia. Lo que está claro es que en el periodo helenístico el conocimiento del mundo natural disfrutó de un gran progreso tanto metodológico como de resultados. A pesar de estas características, esta notable actividad helenística metodológicamente no fue como la de la revolución científica. La ciencia europea del XVII fue mucho más experimental y, como veremos, estaba más centrada en la observación y la inducción. La aproximación helenística sería perfectamente comparable a la copernicana del siglo XVI, no en vano Galileo dijo ser discípulo de Aristóteles y Arquímedes. La metodología científica evoluciona y este es un proceso que todavía hoy no ha acabado. Entre Tales y el LIGO no existe un punto claramente delimitado en el que podamos decir que lo que hizo la generación anterior no es ciencia y la posterior sí lo es. Lo cual no implica que entre lo que planteó Tales y lo que ha logrado LIGO no haya una diferencia clara. Sucede lo mismo con las especies biológicas. Ninguna madre en los últimos 5 millones de años ha tenido un hijo que no fuese de su especie, pero cuando un cambio continuo se acumula durante un largo tiempo un mono arbóreo puede acabar perdiendo el pelo y ganando ínfulas y sueños. La filosofía natural helenística también tenía otro aspecto en el que se la podía comparar con la contemporánea: la financiación. Los gobernantes decidieron que era importante financiar tanto la generación de conocimiento aplicado como la del teórico. Esto es algo que no había sucedido en la Grecia clásica y que tampoco sucedería durante la revolución científica. Francis Bacon planteó que era muy importante para el progreso que los estados financiasen la ciencia, pero esto sólo empezó a ocurrir, lentamente, a partir del siglo XVIII. Además, resulta evidente que Atenas y Alejandría sufrieron una especialización similar a la que se da actualmente entre las facultades de ciencias y letras. Llega un momento en el que un intelectual no puede abarcar todo el conocimiento y no tiene más remedio que especializarse. La separación entre filosofía y ciencia no se debe a que los intereses de ambas disciplinas sean incompatibles o a que los que practican una deban ignorar las otras, sino a que cuando se acumula suficiente conocimiento es imposible aprender en una sola vida lo necesario como para ser un especialista en todas las áreas.608 Además, en la época helenística, como ya hemos comentado, la filosofía, con la excepción de los neoplatónicos, pasó a interesarse más por cuestiones relacionadas con la moral y la forma de afrontar los avatares vitales. Esta especialización no se debió a que el mundo de la filosofía o de las letras constituyese un mundo intelectualmente irreconciliable con el de la ciencia, sino, principalmente, a una simple cuestión práctica. Un ciudadano educado haría bien en tener una idea general tanto de las ciencias como de las letras. No podemos especializarnos en todo, pero sí tenemos el privilegio, y la necesidad, de poder obtener una visión global gracias al esfuerzo de los especialistas de las diferentes disciplinas 7.11 La caída El mundo helenístico unió el interés práctico por la tecnología de las civilizaciones antiguas con el estudio teórico del mundo natural y gracias a esta fusión y a la financiación estatal estuvo muy cerca de alcanzar un desarrollo científico moderno. Este esplendor intelectual me provoca dos emociones: por un lado, alegría por lo conseguido, y, al mismo tiempo, una profunda sensación de pérdida. Se acabaron olvidando muchísimas cosas que nunca debieron olvidarse. El Museo y la Biblioteca no fueron borrados por un incendio, sino por una terrible indiferencia. Puede que la Biblioteca, tal y como suele comentarse, fuese destruida parcialmente en el 48 a. C., pero esto no supuso su fin. Durante los últimos siglos antes de nuestra era surgió un nuevo poder en el Mediterráneo, Roma, un imperio que resultó imparable y que llegó a controlar por completo su Mare Nostrum. Arquímedes fue asesinado en 212 a. C. durante la conquista de Siracusa y en 146 a. C. el dominio romano sobre el mundo griego llegó a ser completo. Fue en esa fecha cuando Roma destruyó Cartago y la antigua Corinto, una ciudad estado a mitad de camino entre Atenas y Esparta. A partir de ese momento los centros culturales helenísticos desaparecieron casi por completo.609 Cleopatra, la última de los Ptolomeos, cedió el control de Alejandría en 30 a. C. y aunque la Biblioteca sobrevivió, la vibrante filosofía natural y las matemáticas helenísticas fueron decayendo lentamente. Un declive que se agudizó aún más con la llegada del dominio cristiano.610 El último gran matemático, Diofanto, vivió en el siglo III d. C.,611 el Serapeo, un santuario pagano que albergaba parte de la Biblioteca, fue destruido por Teófilo de Alejandría, un patriarca considerado santo por la iglesia copta, y en 391 una turba de fanáticos cristianos linchó a Hipatia, la última maestra alejandrina, cerrando de este modo sanguinario una época extraordinaria y retrasando el reloj de la historia durante siglos. El mundo romano siguió estando interesado por algunas ramas de la filosofía. No todas las civilizaciones pueden hacer gala de haber tenido filósofos como dirigentes, pero en Roma Marco Aurelio, un filósofo estoico, fue emperador. Durante el periodo romano el estoicismo y el epicureísmo se preocuparon, principalmente, por la cuestión de cómo debe un ser humano afrontar la vida, mientras que el platonismo se fue perdiendo progresivamente en sus laberínticas especulaciones metafísicas. Sin embargo, y por desgracia, la historia de la ciencia romana puede resumirse rápidamente: no hubo.612 El mundo romano no se interesó por el estudio del mundo natural, los logros de Alejandría no fueron borrados por un incendio, sino por simple desinterés. Es cierto que hubo divulgadores de la ciencia en Roma, pero su trabajo se centró en lo anecdótico y fue meramente superficial. Las clases acomodadas estaban educadas y tenían a su disposición el conocimiento griego, del cual absorbieron la literatura, la política, las artes y parte de la filosofía.613 Tal fue la influencia de la cultura griega en el mundo romano que hoy los conocemos a ambos como clásicos, un error que debemos a los autores renacentistas. Pero esto no debe confundirnos, desde el punto de vista del interés por la filosofía natural ambas culturas fueron completamente diferentes. Sirva como muestra de esta actitud el hecho de que no se molestasen en traducir Los Elementos de Euclides, la obra cumbre de las matemáticas. A pesar de la proximidad de la cultura romana con la griega no hubo matemáticas romanas,614 simplemente no les interesaron. No fue hasta el siglo VI d. C., en un intento desesperado por salvar algo del mundo antiguo, que alguien trató de traducir Los elementos al latín,615 pero no se dispuso de una traducción completa hasta que, en la Edad Media, Adelardo de Bath completó la suya en 1120 a partir de una versión árabe. Los romanos hicieron grandes obras de ingeniería, ya sabemos que hemos de agradecerles los acueductos y las carreteras, y avanzaron de un modo definitivo el sistema legal, pero el estudio sistemático del mundo natural no les interesaba. La romana era una civilización práctica que no llegó a entender que el desarrollo de la ciencia pura puede acabar influyendo en el precio del pan y que, por lo tanto, la despreció. Si que es cierto, que como buena civilización práctica que era, se interesó por el calendario y lo mejoró notablemente. Aunque para hacerlo Julio César tuvo que llamar a Sosígenes. Fue este matemático alejandrino quien recomendó que los años tuviesen 365 días y que hubiese un año bisiesto cada cuatro. Sin embargo, no debemos ser demasiado duros con ellos, al fin y al acabo esta fue la actitud de todas las civilizaciones de la antigüedad. Los filósofos naturales helénicos y helenísticos fueron la excepción, no la norma. Recordemos la opinión que Aristófanes tenía sobre las especulaciones de Sócrates, el filósofo al que situó en Las nubes. Tampoco ayudó que el cristianismo se convirtiese en la religión oficial del Imperio Romano. Si bien es cierto que los pensadores cristianos, como hemos visto, incorporaron una gran parte del neoplatonismo, no lo es menos que los primeros cristianos rechazaron el mundo pagano con fiereza. Los cristianos, a diferencia de los paganos no eran tolerantes con las otras religiones.616 Por ejemplo, en 391 a. C. el emperador cristiano Teodosio ordenó la destrucción de los templos paganos, lo que condujo a la destrucción del Serapeo primero y al asesinato de Hipatia más tarde. Finalmente, Justiniano, en 529, ordenó el cierre de la Academia platónica, una institución que había sido fundada un milenio antes por Platón. Aunque este cierre, desgraciadamente, no fue demasiado importante, pues llegado este momento, no quedaban muchos estudiosos interesados en la filosofía. El general romano encargado de la conquista de Siracusa, Marco Claudio Marcelo, ordenó que buscasen y protegiesen a Arquímedes, el gran ingeniero, pero cuando un soldado encontró en la playa a un señor mayor dibujando círculos en la arena, el soldado hizo lo que suelen hacer los soldados, atravesarlo con la espada. Uno de los más grandes pensadores de la historia murió por la incapacidad de un soldado romano de reconocer la grandeza del matemático. En 137 a. C. Cicerón buscó la tumba del gran matemático, pero para entonces nadie en Siracusa recordaba ni la tumba ni al propio Arquímedes. Por fortuna, logró encontrar la tumba, que consistía en un cilindro y una esfera, y mandó que la limpiasen. Este suceso me trae a la memoria al otro supuesto asesinato ocurrido, cerca del Mediterráneo, cientos de años antes a manos de unos pitagóricos ofendidos por la fealdad de los números irracionales. Los pitagóricos habrían honrado a Arquímedes como se merecía. Podría pensarse que estas dos muertes, la primera debida al interés por las matemáticas y la segunda al desinterés, marcan el principio y el final de una etapa, un momento histórico que pasó, pero que, por fortuna, renacería en la modernidad. Por fortuna, las semillas griegas y helenísticas quedaron latentes en polvorientos manuscritos a la espera de que, durante la Edad Media y el renacimiento, alguien volviese a interesarse por ellas devolviéndolas a la vida y preparando el camino al mundo moderno. 7.12 Resumen Mientras los escépticos trataban de lidiar con los problemas generados por su exceso de prudencia y en Roma y Atenas se desentendían de una filosofía natural que les parecía demasiado alejada de las necesidades humanas. Por el contrario, en Alejandría y el mundo helenístico la fusión del rigor helénico con los intereses prácticos del antiguo imperio egipcio dio lugar a un extraordinario florecimiento de las matemáticas y la filosofía natural. Arquímedes, Eratóstenes y el resto de filósofos naturales helenísticos asumieron que el estudio del mundo natural debía basarse en la observación, la cuantificación, la lógica y las matemáticas demostrativas. Además, plantearon una división entre una fase de descubrimiento metodológicamente más libre y una justificación deductiva de sus conclusiones En cualquier caso, el avance metodológico, si se compara con las especulaciones racionalistas de los filósofos naturales anteriores, fue enorme y, aunque en algunos aspectos esta ciencia caracterizada por el uso limitado de la experimentación y la falta de álgebra, puede parecernos ajena, sentó las bases del posterior desarrollo de la ciencia moderna. "],["hechos_modernos_y_reaccionarios_part.html", "Hechos, ciencia y reaccionarios", " Hechos, ciencia y reaccionarios "],["la_modernidad.html", "8 La modernidad 8.1 La era de los descubrimientos 8.2 Coleccionistas y magia natural 8.3 Artesanos y marineros 8.4 Ratas de biblioteca 8.5 Escépticos y protestantes 8.6 La imprenta 8.7 Revolución artística 8.8 Revolución científica", " 8 La modernidad En la Época Moderna el estudio del mundo natural comenzó a abordarse con una nueva actitud que terminó por alumbrar a la ciencia moderna. Esta fue la época de los grandes descubrimientos geográficos, de la imprenta y de las guerras religiosas. Fue, además, el tiempo en el que el zeitgeist, el clima intelectual de la época, pasó de estar centrado en la reflexión sobre el pasado clásico a la confianza en que podía generarse nuevo conocimiento y en que esta mejora intelectual nos haría progresar socialmente. El nacimiento de la ciencia y la modernidad están íntimamente entrelazados. En este capítulo trataré de dar unas pinceladas sobre el contexto histórico, los eventos, los avances tecnológicos y las actitudes que impulsaron el nacimiento de la ciencia moderna. Además, como veremos posteriormente, los incipientes éxitos de esta actitud científica influyeron, a su vez, en la sociedad, ya que fueron parte de la inspiración del movimiento ilustrado. Gentes de muy distintas épocas se han definido a sí mismas como “modernas” por lo que este término ha acabado siendo un tanto ambiguo. En su origen, la palabra, simplemente, significaba contemporáneo y se derivó del adverbio latino modo, que significa: hace un momento, recientemente. Sin embargo, desde que este calificativo se acuñó en la Edad Moderna, somos muchos los que nos hemos sentido inspirados por similares ideas progresistas y lo hemos hecho nuestro. Dado que las épocas no se inician con una ceremonia oficial como los Juegos Olímpicos, el inicio y el final de cualquier época histórica siempre será un tanto convencional. Sin embargo, no es descabellado asociar la Época Moderna con el periodo comprendido entre la caída de Constantinopla en 1453 o el descubrimiento de América en 1492 y el inicio de las revoluciones americana (1775) y francesa (1789). Son figuras de esta época Leonardo da Vinci (1452-1519), Cervantes (1547-1616), J. S. Bach (1685-1750) y Mozart (1756-1791). El comienzo de la modernidad es especialmente difícil de situar dado que está asociado al Renacimiento, un movimiento cultural que se dio a caballo entre el final de la Edad Media y el comienzo de la Moderna. 8.1 La era de los descubrimientos A finales de la Edad Media, pasada la crisis del siglo XIV asociada a la peste negra, la población europea se encontraba en plena recuperación, el comercio estaba aumentando, especialmente en el Mediterráneo, y la burguesía, impulsada por un capitalismo emergente, se hacía cada vez más relevante. Muchos renacentistas creían que la forma de aumentar el conocimiento era rescatar el legado perdido de la antigüedad y, dado todo lo que se había perdido tras la caída del Imperio Romano de Occidente, el esfuerzo tenía sentido.617 El inicio de la modernidad le debe tanto a estos humanistas como a los navegantes de la época que, espoleados por el comercio y las ansias coloniales, no se conformaron con el mundo antiguo y acometieron un enorme programa de exploración y descubrimiento geográfico. Los portugueses, por ejemplo, fueron estableciendo a lo largo del siglo XV asentamientos en Madeira, las Azores y Cabo Verde y terminaron por alcanzar el Cabo de Buena Esperanza, el sur de África, en 1487 y por navegar el océano Índico entre 1497 y 1499. Colón descubrió América en 1492 y la expedición de Magallanes completó la primera vuelta al mundo en 1522. A los modernos no les quedó ninguna duda de que había nuevos mundos por descubrir. La propia palabra, descubrimiento, se acuñó en esta época. Los griegos habían utilizado palabras relacionadas con eureka, que significa descubrimiento o invención, pero en latín nadie había hecho uso de un concepto análogo.618 El término portugués descobrir, utilizado ya en 1484 con el sentido de explorar, comenzó a popularizarse en Europa con la publicación, a partir de 1500, de las cartas en las que Américo Vespucio relataba el descubrimiento del Nuevo Mundo. Y este no fue el único nuevo término: veremos que esta época también se acuñaron los términos hecho, evidencia, hipótesis y teoría.619 Estas palabras reflejan una nueva forma de pensar sobre nuestra relación con el mundo, una forma que es la nuestra actual. Si a algún lector le quedan dudas al respecto, le reto a volver a vivir en un mundo sin evidencias ni teorías. 8.2 Coleccionistas y magia natural Otra corriente relacionada con la incipiente ciencia moderna fue la de los virtuosi y la magia natural. En una comunidad acostumbrada a ser deslumbrada continuamente por los nuevos descubrimientos de ultramar no es de extrañar que apareciesen coleccionistas compulsivos, denominados en el mundo anglosajón virtuosi, que crearon enormes colecciones privadas en las que trataban de acaparar el torrente de maravillas que llegaba continuamente a los puertos. A estos coleccionistas, como a otros intelectuales de la época, les habría extrañado separar la ciencia de la magia natural, ya que parecía esperable que entre tanto nuevo descubrimiento se escondiesen numerosos secretos mágicos.620 Ni Francis Bacon (1561-1626), el filósofo moderno apóstol de la ciencia, ni el gran Isaac Newton (1643-1727) tenían dudas sobre la existencia de lo oculto, y no eran los únicos: muchos de los miembros de las nuevas sociedades científicas tampoco distinguían entre las enseñanzas sobre los planos inclinados de Galileo y la alquimia de Paracelso (1493-1541). Al lector interesado en estos aspectos le recomiendo el libro del químico y periodista científico Philip Ball: Curiosity: How Science Became Interested in Everything. 8.3 Artesanos y marineros La burguesía de la época demandaba de los artesanos conocimiento funcional,621 avances técnicos, como, por ejemplo, brújulas, catalejos o mejores barcos, y estaba dispuesta a pagar por él. Esto incentivó tanto la mejora de los métodos empleados en los talleres como los resultados obtenidos. Por ejemplo, fueron los artesanos los que, sin un conocimiento extenso de las leyes de la óptica, inventaron el catalejo y el microscopio.622 A esto hay que añadir la importación de varias tecnologías desarrolladas en China: la brújula, la pólvora, el papel y la imprenta, avances que contribuyeron a cambiar Europa para siempre. Además, este mundo tecnológico empezó a relacionarse con el de la filosofía natural. Muestra de ello es que Galileo, el filósofo natural por excelencia, no sólo creó el telescopio mejorando el catalejo, sino que desarrolló otras tecnologías, como la pantómetra, una especie de regla de cálculo con forma de compás, y escribió libros de ingeniería militar en los que se trataba la cuestión de las fortificaciones militares en la era de la pólvora. Recordemos que esto ya había sucedido antes. En Alejandría una interacción similar entre los artesanos y los filósofos naturales, en aquel caso sufragada por el estado, también fue un factor clave en el florecimiento del estudio del mundo natural. Hoy en día puede parecernos normal que el mundo de la ciencia y la tecnología interaccionen, pero en aquel tiempo esto no era tan habitual. Hay que tener en cuenta que los universitarios y los teólogos pertenecían a un mundo intelectual completamente alejado del de los artesanos. Ambos colectivos estaban interesados por resolver problemas completamente diferentes y mientras los primeros escribían en latín, los segundos no tenían por qué tener educación formal alguna y sólo entendían el idioma vernáculo de su región. Una muestra de la modernidad de Galileo y de su distancia del mundo universitario es su decisión de escribir en italiano. 8.4 Ratas de biblioteca Durante el renacimiento se hizo un gran esfuerzo de búsqueda y traducción de los textos clásicos. Los humanistas, los estudiosos de las humanidades, ansiaban recuperar la excelencia clásica y para ello se enfrascaron en una inmensa labor de recuperación de los antiguos textos paganos.623 Los estudiosos medievales solían considerar el texto como la principal fuente de conocimiento. No es casual que el judaísmo, el cristianismo y el islam, las religiones del libro, otorgasen la autoridad suprema a un libro sagrado.624 Para el investigador medieval la forma principal de estudiar un fenómeno consistía en recopilar y comentar textos respetados como: la Biblia, los escritos de los teólogos padres y doctores de la Iglesia, así como los recuperados de los autores griegos y romanos.625 Se asumía que los autores antiguos ya habían averiguado todo lo que podía conocerse y, por lo tanto, para aprender sobre cualquier tema, bastaba con estudiar sus textos. La observación y el experimento eran, por lo tanto, innecesarios. Además, recordemos que Aristóteles había recomendado sostener el conocimiento sobre sólidas bases deductivas y esto contribuyó a que sus admiradores escolásticos otorgasen la primacía en el estudio de la naturaleza a la lógica frente a la observación;626 lo que acabó teniendo el efecto paradójico de convertir a Aristóteles, un claro defensor del empirismo, en el paradigma de la discusión de sillón. Anthony Ashley Cooper, el 3er conde de Shaftesbury, un político y filósofo inglés del XVII afirmó que el Aristóteles medieval no era más que un fantasma del Aristóteles de la antigüedad.627 Y este fue el fantasma al que Galileo y el resto de filósofos naturales modernos convirtieron en la figura a batir. Federico Cesi, uno de los fundadores de la Academia de los Linces, el hogar intelectual de Galileo, escribió que la labor de la modernidad era destruir las principales doctrinas dominantes, es decir, las doctrinas aristotélicas. La aproximación de Galileo y sus colegas al estudio de la naturaleza contrastaba fuertemente con la de los escolásticos medievales. Para los modernos, el conocimiento debía buscarse mediante la observación del mundo, no en textos polvorientos. Lo cual no era contradictorio con que, a la vez, Galileo se reconociese como discípulo de Aristóteles y Arquímedes. Los descubrimientos geográficos tuvieron una cierta influencia en el establecimiento de esta nueva actitud decididamente empírica. El 18 de marzo de 1523 el humanista italiano Pietro Pomponazzi explicó en la universidad de Padua que Aristóteles y su comentarista medieval Averróes negaban la posibilidad que pudiese haber vida en las antípodas. Según estos autores al viajar hacia el sur de Europa las temperaturas aumentan y de esto inferían que se habría una latitud en la que las temperaturas serían incompatibles con la vida. Pero Pomponazzi añadió que esta antigua disputa académica había quedado resuelta por una carta que le había enviado un amigo que había navegado los mares de sur y que había observado no sólo islas habitables, sino habitadas.628 El método utilizado por Pomponazzi para zanjar la disputa es típicamente moderno. La propia existencia de América cuestionó severamente la autoridad de unos textos antiguos que no habían anticipado la existencia de un continente entero. Galileo resumió esta nueva aproximación al afirmar que mil Demóstenes y mil Aristóteles podían ser desplazados por un sólo observador de la naturaleza.629 Este rechazo moderno a los sistemas filosóficos medievales también tuvo algunas consecuencias negativas. El estudio de la lógica pasó a un segundo plano y no volvió a haber lógicos relevantes hasta Leibniz, un contemporáneo de Newton.630 Otra de las instituciones atacadas por los investigadores modernos fueron las universidades. Recordemos que el calificativo “escolástico”, que terminó por convertirse en un insulto que hacía referencia a los tortuosos razonamientos medievales,631 surgió originalmente como referencia a las escuelas, a las universidades medievales. Mientras la revolución científica se desarrollaba en los recién creados laboratorios y en las academias se reunían los nuevos filósofos naturales, las universidades siguieron ancladas en el pasado. El núcleo del currículum universitario lo constituía el Aristóteles medieval y la filosofía seguía enseñándose comentando sus textos. Muchos de los grandes matemáticos y filósofos modernos, como, por ejemplo, Pascal, Fermat, Descartes, Huygens y Leibniz, nunca dieron clases en la universidad y, aunque Kepler y Galileo sí lo hicieron, su trabajo innovador lo hicieron fuera de ella.632 Mientras el sistema metafísico escolástico fue destruido en el siglo XVII, en las universidades sobrevivió hasta bien entrado el siglo XVIII.633 Thomas Hobbes (1588-1679), un filósofo moderno fundamental, se refirió a las universidades como “el reino de la oscuridad”. 8.5 Escépticos y protestantes El esfuerzo humanista no sólo rescató textos aristotélicos, sino muchos otros libros clásicos, entre los que se encontraban los de los escépticos helenísticos y las recién recuperadas palabras de Sexto Empírico y Diógenes Laercio resonaron con fuerza en un mundo moderno dispuesto a cuestionar las certezas teológicas medievales. No es casual que para Descartes, el filósofo moderno por antonomasia, la duda radical se convirtiese en una herramienta filosófica. Sexto se publicó en latín a mediados del siglo XVI634 y sus dudas sobre la fiabilidad de la percepción y el conocimiento inspiraron a autores como Michel de Montaigne que se enfrentaban a un mundo sorprendido continuamente por descubrimientos de lugares ignotos y nuevas culturas. Estas novedades cuestionaban las convicciones de la sociedad europea. Por ejemplo, Montaigne se preguntó en un ensayo qué costumbres eran más bárbaras, las de los caníbales de ultramar, que él había observado en una exhibición en 1561, o las de los civilizados europeos que quemaban vivos a los herejes y que permitían enormes desigualdades sociales.635 Esta actitud escéptica fue abrazada por los investigadores modernos que la utilizaron tanto para atacar las viejas ideas aristotélicas como para cuestionar sus propias hipótesis. Montaigne comentó que puesto que las enseñanzas del gran Ptolomeo, a pesar de haber funcionado durante más de mil años, habían resultado ser erróneas, ahora deberíamos dudar de las propuestas de los astrónomos modernos.636 Francisco Sánchez (1551-1623), un médico y escéptico de padre español, madre portuguesa y afincado en Francia, recomendó en su tratado Que nada se sabe ser cauto, observar y admitir que nuestras conclusiones nunca podrán ser definitivas. Una aproximación que Sánchez resumió acuñando un nuevo término: método científico.637 Incluso los fundamentalistas religiosos contribuyeron al resurgimiento del escepticismo. En 1517 Lutero inició la Reforma protestante con sus noventa y cinco tesis. Lutero era la antítesis de Galileo, no era un empirista, sino un fundamentalista,638 pero al cuestionar la autoridad del Papa y la corrupción de la Iglesia católica, se convirtió en el ejemplo ideal tanto de los nuevos escépticos como de multitud de fanáticos religiosos. Además, las atroces guerras religiosas, causadas por el cisma entre protestantes y católicos, que asolaron Europa al inicio de la Época Moderna, terminaron por convencer a los modernos de que la teología, la autoridad académica y el poder político debían separarse. Durante la guerra de los treinta años, en la que intervinieron la mayor parte de las grandes potencias europeas, y que, al menos en parte, tuvo motivaciones religiosas, murió un tercio de la población centroeuropea.639 Suele pensarse en la Edad Media como en una época caracterizada por el fanatismo religioso, pero los debates teológicos medievales acostumbraban a ser mucho más equilibrados y racionales que los propiciados por Lutero y compañía.640 8.6 La imprenta Otro factor sin el cual sería difícil entender la modernidad es el de la invención y popularización de la imprenta de tipos móviles. A los que hemos vivido la irrupción de internet, no ha de extrañarnos que la popularización de una tecnología que revolucionó las comunicaciones tuviese una profunda influencia social y cultural. Gutenberg inició, en 1454, lo que podríamos llamar la Edad de la Imprenta publicando una Biblia. A partir de ese momento la producción de los libros comenzó a abaratarse. Copiar un volumen manualmente era tan caro que durante la Edad Media los libros llegaban a encadenarse a las estanterías. Esto cambió paulatinamente durante los siglos XVI y XVII. En el XV se copiaron unos 5 millones de manuscritos,641 mientras que en 1500 ya había entre 200 y 300 imprentas en Europa que produjeron unos 10 millones de ejemplares,642 que pronto quedaron eclipsados por los 200 millones del XVI, los 500 del XVII y los 1000 del XVIII.643 Sin imprenta la acumulación de conocimientos que caracterizó el progreso de la revolución científica habría sido difícil de conseguir. Para que cada generación construya sobre el legado de la que le precede se requiere un modo fidedigno y económico de transmitir la información,644 por lo que la nueva capacidad de difundir el conocimiento constituyó un factor clave de la revolución científica.645 Gilbert, uno de los más importantes experimentalistas de la revolución científica, comenzó su libro más influyente haciendo una revisión del océano de libros que, según él, tenía a su disposición.646 Del mismo modo, sería difícil imaginar la Reforma fundamentalista protestante sin la impresión de las biblias baratas. Hasta ese momento pocos habían tenido acceso a leer el libro, por lo que su interpretación había sido fácil de controlar por parte de la Iglesia, la única institución capaz de producir las pocas copias disponibles durante la Edad Media. 8.7 Revolución artística Asociados a estos cambios sociales y culturales también llegaron profundos cambios artísticos caracterizados por una representación del mundo externo mucho más fiel que la presente en el arte medieval, que se había centrado más en la transmisión de las ideas que en el realismo. Una de las claves de estos cambios fue el desarrollo de la pintura en perspectiva. Aunque todavía se conservan algunos mosaicos y frescos helenísticos y romanos que hacían uso de la perspectiva, los trabajos sobre escenografía que describían la técnica se habían perdido647 y el mundo moderno hubo de redescubrir la técnica. Esta tarea fue llevada a cabo, en paralelo, por los artistas y artesanos flamencos de la ars nova y por los artistas y matemáticos de la península itálica. Filippo Brunelleschi, el arquitecto de la cúpula de la catedral de Florencia, mostró a principios del siglo XV como utilizar la geometría para dibujar algunos edificios. Aprovechando estos avances el renacentista Masaccio pintó figuras, edificios y paisajes tridimensionales, como el fresco de la Trinidad de la iglesia de Santa María Novella de Florencia, y en 1436 el arquitecto, matemático y poeta Leon Battista Alberti publicó la primera obra teórica sobre la cuestión: De Pictura. Ésta fue seguida, décadas después, por varios libros matemáticos escritos por el gran pintor del Quattrocento Piero della Francesca y por las obras del matemático y pintor alemán Alberto Durero. Fue Durero quien en 1515 publicó junto al cartógrafo Johannes Stabius la primera imagen de un globo terrestre dibujado en perspectiva. Por cierto, haríamos bien en esforzarnos por aprender algo sobre el hecho de que estos grandes personajes fuesen a la vez artistas y matemáticos. La unión de estos avances en la perspectiva y la fidelidad otorgada por la imprenta hizo posible la creación de nuevas obras anatómicas capaces de transmitir el conocimiento del cuerpo humano como nadie antes había podido imaginar. La más celebrada de estas obras fue el De humani corporis fabrica (De la estructura del cuerpo humano) de Andrés Vesalio. Las ilustraciones se habían utilizado anteriormente en los libros, pero en la cultura de los manuscritos resultaban poco útiles puesto que para los copistas era imposible reproducirlas con fidelidad.648 Sin embargo, los grabados producidos por los artistas de los talleres de Tiziano para Vesalio revolucionaron el conocimiento anatómico. Posiblemente sea esta obra, más que ninguna otra, la que haga más patente la supremacía de la observación frente al texto. Vesalio corrigió numerosos errores del texto de referencia medieval, el escrito en el siglo segundo por el griego Galeno, y lo hizo mostrando imágenes.649 8.8 Revolución científica La revolución científica fue, por supuesto, otra de las claves de la modernidad. Entre mediados del XVI y del XVII la filosofía natural, el modo de estudiar el mundo, cambió radicalmente.650 Estas fechas son, hasta cierto punto, también fruto de la convención, pero como hito inicial se puede citar la publicación en 1543 de las obras de Copérnico y de Vesalio, mientras que la culminación suele situarse en el trabajo de Newton. En la historiografía actual se ha discutido mucho la conveniencia de denominar revolución a un fenómeno que abarcó más de un siglo y que se dio lejos del caos de los campos de batalla y las sublevaciones populares, pero si comparamos la forma de investigar de los filósofos naturales medievales con la de los científicos posteriores a Newton es necesario reconocer que el cambio fue radical. Un cambio del que, además, los propios modernos eran perfectamente conscientes651 y al que le debemos nuestra ciencia actual, que se asienta por completo en las fundaciones establecidas por la ciencia moderna. "],["el_triunfo_del_empirismo.html", "9 El triunfo del empirismo 9.1 Prolegómenos medievales 9.2 La caída del sistema aristotélico 9.3 El experimento crucial 9.4 La subdeterminación tycónica 9.5 Experimentos y laboratorios 9.6 Objetividad instrumental 9.7 Razonamiento matemático 9.8 La vaca esférica 9.9 Una modernidad desigual 9.10 Ciencia y filosofía 9.11 La república del conocimiento 9.12 Hechos 9.13 La evidencia tiene la última palabra 9.14 El triunfo del empirismo 9.15 Falibilismo 9.16 Resumen", " 9 El triunfo del empirismo Una vez descrito el contexto social e intelectual que acompañó a los filósofos naturales modernos que llevaron a cabo la revolución científica, es el momento de explicar, ayudándonos de algunos ejemplos de sus propias investigaciones, cuáles son las características de la nueva aproximación al estudio del mundo natural que propusieron. 9.1 Prolegómenos medievales La ciencia moderna relegó a un segundo plano la especulación intelectual típica del medievo en favor del empirismo. Sin embargo, esto no implica que el mundo moderno se materializase en 1500 a partir de la nada, lo que hubo fue una evolución desde el mundo medieval. Es cierto que en la Edad Media la actividad filosófica consistía, principalmente, en el estudio de un conjunto de textos, pero, sería profundamente injusto olvidar que también hubo filósofos medievales que exigieron más observación, más experimentos y más libertad de pensamiento. Esto es algo que no debería extrañarnos de unos intelectuales que se consideraban discípulos de Aristóteles. Es cierto que esta no fue la actitud predominante, pero ninguna época, ninguna comunidad ni ningún movimiento social son uniformes. En el siglo XIII Alberto Magno, obispo, doctor de la Iglesia, maestro de Tomás de Aquino y experto en el recién recuperado corpus aristotélico, se distinguió por ser un defensor del empirismo en sus tratados sobre botánica, zoología, alquimia, geología, geografía y astronomía. Y no fue el único, los escolásticos ingleses Robert Grosseteste y Roger Bacon, por ejemplo, le acompañaron en su defensa del empirismo. Roger Bacon (1214-1292) escribió que el razonamiento puede conducirnos a una conclusión correcta, pero sólo la observación puede llevarnos a la certeza652 e incluso se atrevió a afirmar que, en algunos casos, como en el estudio de los efectos medicinales de ciertas plantas, la experiencia puede brindarnos conocimiento que sería inalcanzable mediante el razonamiento puro. Esta es una actitud moderna que anticipó algunas de las propuestas de Galileo por más de tres siglos. Sin embargo, no es menos cierto que este puñado de escolásticos no representaba la ortodoxia y que, en muchos casos, fueron represaliados. A Alberto Magno se le acusó de practicar la magia,653 a Nicolás de Autrecourt, otro filósofo natural empirista y crítico con la metafísica, se le expulsó de la Universidad de París en 1346 y tuvo que asistir a la quema de sus libros654 y Roger Bacon acabó en la cárcel y tuvo una influencia limitada en su tiempo. Además, sus ideas, como era de esperar, tampoco eran completamente modernas. Grosseteste defendía la observación sólo cuando el razonamiento y la deducción no fuesen suficientes655 y Roger Bacon admitía las visiones y las experiencias místicas como evidencias válidas.656 Lo que es indiscutible es que, a pesar del rechazo de los modernos, como Francis Bacon o Voltaire, al, según ellos, oscuro mundo medieval, la continuidad entre la Edad Media, el renacimiento, los humanistas y la ciencia moderna es clara. Tal vez, el éxito del modo moderno de afrontar el estudio de la naturaleza no se debiese sólo a que algunos intelectuales propusieron nuevas aproximaciones, sino a que las circunstancias sociales, que hemos discutido en el capítulo anterior, favorecieron la aparición de una comunidad dispuesta a asumirlas. Aunque tampoco creo que debamos admitir que esta continuidad, adelantada por un puñado de filósofos naturales medievales heterodoxos, esté reñida con aceptar que hubo un cambio radical a partir del siglo XVI. 9.2 La caída del sistema aristotélico Durante siglos, ni en el mundo helenístico ni durante la Edad Media, se había cuestionado la división aristotélica entre una esfera supralunar inmutable y un mundo sublunar sujeto al cambio. Sin embargo, las observaciones astronómicas modernas destruyeron esta división al comienzo de la Edad Moderna. Al anochecer del 11 de noviembre de 1572 un joven astrónomo danés llamado Tycho Brahe observó en el cielo un nuevo astro, una nova, que durante un tiempo llegó a ser incluso más brillante que Venus, el lucero del alba. Esta observación parecía estar en conflicto con la inmutabilidad de la esfera supralunar. Aunque, probablemente, no fue esta la primera vez que un astrónomo había detectado una nova, por ejemplo, es posible que Hiparco también hubiese visto alguna en el mundo clásico, siempre habían quedado dudas sobre si el fenómeno era atmosférico o astronómico, es decir, sub o supralunar. En este caso, Brahe, gracias a la trigonometría y a las observaciones de otros astrónomos, entre ellos dos españoles: el humanista Bartolomé Barrientos y el valenciano Jerónimo Muñoz, pudo determinar con claridad que el fenómeno era supralunar y que los cielos, a pesar de lo que pensase Aristóteles, eran mutables.657 Actualmente los restos de la explosión observada por estos astrónomos forman una nebulosa a unos 7500 años luz de la Tierra, denominada SN 1572, y disponemos de imágenes detalladas de estos rescoldos gracias al observatorio de rayos X Chandra.658 Brahe fue un astrónomo brillante, pero si yo tuviese que elegir una figura como el paradigma del científico moderno mi voto sería para otro gran observador de los cielos nacido en 1564, el año de la muerte de Miguel Ángel y del nacimiento de Shakespeare: Galileo Galilei. Este pisano fue un científico extraordinario; interesado tanto por el resultado de sus investigaciones como por el método adecuado para llevarlas a cabo. Por ejemplo, fue Galileo quien, tras tener noticia de la invención del catalejo por parte de los artesanos holandeses, decidió fabricar un instrumento mucho más capaz que le permitiese observar los cielos, fue Galileo quien creó el primer telescopio. Cuando en 1609 apuntó por primera vez su telescopio al cielo, nuestro mundo intelectual cambió para siempre. Inmediatamente descubrió que la Vía Láctea está compuesta por innumerables estrellas invisibles para el ojo desnudo, que la Luna tiene montañas, el Sol manchas y Júpiter lunas. Copérnico es una de las primeras figuras que suelen citarse cuando se habla de la revolución científica. Sin embargo, yo, a pesar de que fue anterior a Brahe y Galileo y de que su libro tenía la palabra revolución en el título, no lo he mencionado todavía. Y no lo he hecho porque metodológicamente Copérnico no fue demasiado revolucionario. Es cierto que planteó un sistema heliocéntrico alternativo al antiguo de Ptolomeo, pero lo hizo movido por la simplicidad teórica y no por la observación. De hecho, su modelo era más inexacto que el ptolemaico.659 Copérnico era un platónico convencido motivado por su creencia en la racionalidad del cosmos y esto lo convierte, en cierto modo, en el último de los antiguos, más cercano a Ptolomeo que a Galileo. Además, el modelo copernicano fue planteado a la comunidad astronómica como un mero instrumento de cálculo que no debía ser tomado en serio como propuesta física. Es decir, que, aunque el modelo era útil porque simplificaba los cálculos, no debía pensarse que la Tierra giraba realmente alrededor del Sol. Puede que Copérnico sí hubiese defendido el heliocentrismo, pero su obra se publicó póstumamente y su editor, tal vez preocupado por la inquisición, quiso quitar hierro al asunto añadiendo un prefacio en el que se recomendaba al lector tratar el modelo como una mera herramienta matemática. Los astrónomos y matemáticos aceptaron el nuevo modelo porque facilitaba los cálculos astronómicos, pero el libro no convenció a casi ningún filósofo natural de que la Tierra se moviese realmente.660 Cincuenta años después de la muerte de Copérnico tan sólo cuatro personas se habían pronunciado a favor de una Tierra móvil: el matemático y astrónomo inglés Thomas Digges, el filósofo y teólogo italiano Giordano Bruno, el matemático italiano Giambattista Benedetti y el filósofo escolástico español Diego de Zúñiga.661 El verdadero revolucionario que defendió a ultranza el movimiento de la Tierra fue Galileo. Esto, no le sentó nada bien a la Iglesia. Es cierto que el Papa, a pesar de los problemas previos con la inquisición, le permitió redactar un libro en el que explicase, de un modo equilibrado, los argumentos a favor del heliocentrismo y el geocentrismo, pero Galileo, que no parecía estar muy interesado por el arte de la diplomacia, escribió diálogo en el que la propuesta del modelo antiguo no sólo quedaba en desventaja, sino que era defendida por alguien llamado Simplicio. Podría decirse que la curia pontificia no se tomó Diálogos sobre los dos máximos sistemas del mundo con humor. David Wootton, un excelente historiador de la ciencia muy interesado en la figura de Galileo, y Alice Dreger, una historiadora y activista social, sostienen que el interés de Galileo por el modelo copernicano se debía, en parte, a razones psicológicas662 y es posible que así fuese. Sin embargo, es indiscutible que su defensa del movimiento terrestre también estaba motivada por razones teóricas y que, además, aportó evidencias empíricas bastante claras. Galileo había desarrollado una nueva física que incluía el principio de inercia y que predecía que, si la Tierra se moviese, su movimiento sería casi indetectable. Esta idea la ilustró mediante un experimento mental. Imaginó a un viajero situado en el camarote de un barco que se mueve suavemente por aguas tranquilas y concluyó que este observador sólo podría darse cuenta del movimiento si mirase por el portillo del camarote. Esto es muy similar a lo que nos ocurre cuando estamos en la estación y nuestro tren comienza a moverse con suavidad, muchas veces nos es difícil saber si es nuestro tren el que se mueve o el que está junto al él. Sin embargo, las evidencias más fuertes no fueron teóricas, sino observacionales. Alrededor de Júpiter descubrió un sistema de lunas, que actualmente denominamos galileanas, que giraban alrededor del planeta. Por primera vez se observaba un conjunto de astros que, claramente, no orbitaban alrededor del Sol663 y si las lunas jovianas giraban alrededor de Júpiter, por qué no habría la Tierra de girar alrededor del Sol. 9.3 El experimento crucial La observación crucial fue la de las fases de Venus. Galileo pensó que si los planetas no emitían su propia luz deberían tener fases, como nuestra Luna. Además, si orbitaban alrededor del Sol, estas fases habrían de ser completas, desde creciente a llena, mientras que según el modelo ptolemaico las fases sólo oscilarían entre llena y media.664 El pisano eligió Venus como objeto de sus observaciones y tras hacer esta predicción comenzó a observarlo a partir de junio de 1610. En los meses siguientes comprobó que, efectivamente, las fases de Venus eran equivalentes a las de la Luna. La predicción derivada de la hipótesis copernicana era correcta y la ptolemaica errónea. Francis Bacon propuso para describir este tipo de observaciones la idea del experimento crucial. Cuando un científico dispone de dos hipótesis alternativas, puede proponer qué diferencias empíricas espera observar si el mundo externo funcionase de acuerdo a la primera o a la segunda. Por ejemplo, ante la disyuntiva de si los planetas orbitan alrededor de la Tierra o del Sol, Galileo ideó una observación capaz de distinguir ambas alternativas. Esta es una característica esencial del proceder científico tradicional. Entre los filósofos de la ciencia se ha discutido mucho hasta qué punto una observación puede hacer cambiar de opinión a la comunidad científica. El consenso de los historiadores y los filósofos es que la ciencia no progresa mediante una sucesión ininterrumpida de experimentos cruciales, el devenir científico es mucho más sutil que esta caricatura. Sin embargo, algunos filósofos han ido mucho más allá y han planteado, como veremos más adelante y a pesar de que este y otros ejemplos lo desmienten, que la propia existencia de las observaciones cruciales es imposible.665 Una crítica común a las observaciones telescópicas galileanas es que sus rudimentarios telescopios podían estar creando artefactos. Además, se suele recordar que cuando Galileo trató de mostrar sus descubrimientos en una observación pública en Bolonia casi nadie consiguió ver las maravillas que el astrónomo decía observar a través del tubo. Esto no es de extrañar ya que observar usando estos telescopios requería una cierta práctica, y es normal que sólo alguien acostumbrado a manejarlos pudiese ver algo relevante con ellos. A pesar de estos problemas, los astrónomos profesionales sí pudieron reproducir inmediatamente la observación de las fases de Venus. Galileo envió una carta con la información a Kepler y a Cristóbal Clavio, el astrónomo alemán que se encargó de la reforma del calendario gregoriano, y ambos vieron las fases. No sólo eso, Roberto Belarmino, el inquisidor de Bruno y Galileo, también fue capaz de repetir las observaciones. La evidencia fue tan clara que los astrónomos jesuitas llegaron a organizar una fiesta en honor a Galileo para celebrar el descubrimiento de que Venus orbitaba alrededor del Sol.666 El sistema ptolemaico, que había monopolizado el mundo intelectual durante 1400 años, fue abandonado inmediatamente. David Wootton muestra en su The Invention of Science cómo la publicación original de la hipótesis copernicana no afectó al número de impresiones de los libros de texto ptolemaicos utilizados en las universidades a finales del siglo XVI; sin embargo, las fases de Venus acabaron con ellos inmediatamente.667 Nadie volvió a discutir que Venus giraba alrededor del Sol ni que la Luna tenía montañas, Júpiter lunas y el Sol manchas.668 9.4 La subdeterminación tycónica Lo que sí continuó cuestionándose es si la Tierra se movía o no. Esto puede parecer sorprendente, pero es que no había dos modelos astronómicos en liza, sino tres. Brahe había planteado una hipótesis alternativa en la que los planetas giraban alrededor del Sol, pero el Sol orbitaba alrededor de la Tierra. Este modelo era geométricamente equivalente al copernicano y, por lo tanto, indistinguible mediante las observaciones astronómicas disponibles en aquel momento. Este es un caso de subdeterminación de las hipótesis. Los filósofos de la ciencia hablan de subdeterminación cuando las evidencias no nos permiten distinguir entre hipótesis alternativas. Brahe tenía varias razones válidas para dudar del movimiento de la Tierra. En primer lugar, si uno no aceptaba la nueva física galileana la intuición le dictaba que un movimiento de rotación en el ecuador de 1600 km/h y de traslación alrededor del Sol de 104.400 Km/h debería notarse. Sin embargo, cuando uno sale a la calle no parece observar ninguna consecuencia de estos movimientos. Además, había incluso observaciones astronómicas que parecían apoyar la inmovilidad terrestre. Si la Tierra se moviese realmente alrededor del Sol, la posición de las estrellas en el cielo nocturno debería variar estacionalmente debido al paralaje. Pero el paralaje era indetectable y para poder explicar esta anomalía los partidarios del movimiento terrestre tuvieron que proponer una hipótesis ad hoc: las estrellas están a una distancia tan lejana que el paralaje es indetectable. Una hipótesis ad hoc es aquella que se plantea específicamente para salvar una hipótesis ante una evidencia anómala. Era posible que las estrellas estuviesen realmente muy lejos, al fin y al cabo, nadie conocía la distancia a la que se encontraban, pero la falta de paralaje era un motivo legítimo para dudar de la propuesta copernicana ya que, aunque no había ninguna forma de medir las distancias estelares, la enormidad del universo resultante parecía absurda. Veremos que estos problemas de la subdeterminación y de las hipótesis ad hoc son, hasta cierto punto, inevitables y forman parte del devenir habitual de la ciencia. Las observaciones son fundamentales en la ciencia, pero la relación entre las observaciones y las hipótesis no es trivial. En cualquier caso, lo que está claro es que, aunque se continuaron evaluando tanto la elegante hipótesis copernicana, como el físicamente intuitivo modelo tycónico, el modelo ptolemaico sucumbió inmediatamente a las evidencias. 9.5 Experimentos y laboratorios El experimento, tan común hoy en la ciencia, fue otra de las innovaciones modernas. Un experimento es una observación de un fenómeno en unas condiciones controladas. Ya hemos mencionado anteriormente que en la época helenística y en el medioevo se habían hecho algunos experimentos aislados, pero fue en la Época Moderna cuando se convirtieron en uno de los pilares de la ciencia. Los experimentos permitían crear y reproducir fenómenos de un modo controlado, estandarizar las condiciones de las observaciones y, además, controlar la modificación de distintas variables para estudiar su influencia en el fenómeno estudiado. El experimento permite incluso crear fenómenos que no se dan de forma natural. Por ejemplo, durante los siglos XVII y XVIII se realizaron numerosos experimentos con bombas de vacío creando condiciones que no existen naturalmente en la Tierra. Tradicionalmente se había temido que la intervención del investigador en el fenómeno estudiado pudiese alterarlo; recordemos que los escépticos helenísticos habían dudado incluso de la percepción, por lo que más razonable aún era dudar de una intervención susceptible de causar un artefacto. Francis Bacon fue el primer filósofo que propuso que la distinción entre fenómenos naturales y artificiales era irrelevante669 y que no debemos pensar que un mismo fenómeno varía en función de si se genera de forma natural o artificial. El trabajo que popularizó el método experimental fue el De magnete, publicado en 1600 por el inglés William Gilbert. Los imanes tenían una gran importancia práctica en la navegación y fue Gilbert quien propuso que la Tierra se comportaba como un imán y lo hizo por analogía con los resultados que obtuvo haciendo experimentos con brújulas e imanes.670 Gilbert fue el primero en acometer un amplio programa experimental y la influencia de su trabajo fue enorme. Los estudiosos del mundo natural lo tomaron como un ejemplo a seguir. Galileo reconoció a Gilbert como un gran filósofo natural y, probablemente, no sea casual que el pisano describiese, por primera vez, tras leer a Gilbert en 1602, un experimento: el clásico de la isocronía del péndulo.671 Galileo ideó experimentos tanto mentales como reales y se convirtió en el gran popularizador del nuevo método experimental. En mi opinión, uno de los experimentos más hermosos de la ciencia es el de la trayectoria del proyectil. Esta es una cuestión que Aristóteles no había conseguido resolver satisfactoriamente. Según la física aristotélica los objetos se mueven cuando son empujados por algo o por alguien, pero esto planteaba el problema de cómo explicar entonces que las piedras continuasen moviéndose una vez se habían separado de la mano del lanzador. Además, no quedaba claro cuál era la forma de la trayectoria del objeto lanzado. Galileo tenía mucho interés en estas trayectorias por distintos motivos, entre ellos porque parte de su trabajo consistía en diseñar fortificaciones militares capaces de resistir el embate de los cañones. Actualmente estamos acostumbrados a observar películas de este y otros movimientos, pero Galileo no disponía de cámaras cinematográficas con las que capturar el movimiento, por lo que para obtener una traza de la trayectoria hubo de recurrir a su enorme ingenio. Lo que hizo fue preparar una superficie prácticamente perpendicular al suelo, una especie de pared ligeramente inclinada, de modo que un objeto esférico que fuese lanzado en paralelo a la misma circulase apoyándose sobre ella, pero sólo ligeramente. Así se conseguía que el objeto estuviese en contacto con la superficie, pero que, al mismo tiempo, el movimiento no se alterase demasiado por la fricción de modo que su trayectoria debería ser, probablemente, similar a la de un proyectil que no tuviese contacto alguno con la superficie. A continuación, embadurnó una bola para que manchase la superficie y la lanzó sobre la misma. La trayectoria dibujada fue una curva muy similar, aunque no exactamente igual, a una parábola.672 Galileo interpretó este movimiento como la combinación de dos, un movimiento uniformemente acelerado hacia la Tierra en la vertical y un movimiento de velocidad uniforme en la horizontal. Esta interpretación le llevó a proponer el principio de inercia; lo que debe explicarse no es el movimiento, sino el cambio del estado del movimiento. Esto es algo que todavía hoy sigue siendo contraintuitivo para los estudiantes de física, pero que es un aspecto fundamental de las físicas galileana, newtoniana y relativista y es la clave profunda que llevó a Galileo a aceptar el movimiento de la Tierra, ya que el principio de inercia y la relatividad del movimiento están profundamente relacionados. Sin embargo, a pesar de su clara defensa y promoción del método experimental, Galileo no fue un científico eminentemente experimental. Su física fue más cercana a la teórica de Einstein que la experimental de Gilbert. El pisano utilizó los experimentos, principalmente, para contrastar alguna conclusión previa y no para encontrar nuevos fenómenos y, además, muchos de los experimentos que propuso fueron mentales y nunca llegó a realizarlos.673 Un ejemplo clásico de sus experimentos mentales es el de la velocidad de caída de un cuerpo. Según la física aristotélica, que no es más que una formalización de nuestra intuición, un cuerpo más pesado debería caer con mayor velocidad que un cuerpo más ligero; una piedra grande debería caer más rápidamente que una piedra pequeña. Sin embargo, si esto fuese así, planteó Galileo, si uniésemos ambas piedras con un hilo: ¿la velocidad de caída sería mayor o menor? Según Aristóteles la piedra pequeña debería caer más lentamente y tendría que frenar, tirando del hilo, de la piedra grande, lo que haría que disminuyese su velocidad. Sin embargo, esto contradice el hecho de que la unión de ambas piedras tiene una masa mayor, por lo que parecería que deberían caer con mayor velocidad. Para ver una demostración espectacular de que efectivamente, cuando el rozamiento es despreciable, dos cuerpos de distinto peso caen con la misma velocidad, recomiendo al lector que busque el vídeo del experimento que Dave Scott, comandante del Apollo XV, realizó en la Luna con una pluma y un martillo. A pesar de esto, habría que recordar que la física aristotélica funciona bastante bien cuando el rozamiento no es despreciable. Basta con sustituir la piedra pequeña por un paracaídas ligero para darse cuenta de que Galileo estaba obviando la resistencia del aire. Este es un detalle al que volveremos más tarde cuando comentemos la cuestión de la aproximación en las teorías. En cualquier caso, los experimentos se convirtieron en la piedra angular de la ciencia moderna. Por ejemplo, la Royal Society inglesa acordó en su primera reunión, en noviembre de 1660, que su objetivo sería promover el estudio fisico-matemático y experimental.674 Y tal vez el ejemplo más ilustre y paradigmático de esta nueva forma de estudiar la naturaleza sea la investigación de Newton sobre la naturaleza de la luz recogida en su Opticks (1704). En este trabajo mostró, utilizando 35 experimentos realizados mediante prismas, que la luz blanca estaba compuesta por un espectro de distintos colores. El propio término, experimento, es una construcción moderna. Antes del siglo XVI no existía una palabra específica para designar una observación hecha en condiciones controladas. Las palabras latinas que solían utilizarse experientia y experimentum significaban, indistintamente, observación o experiencia y no asumían ninguna planificación. Para Hobbes (1588 - 1679), por ejemplo, experimento era aplicable tanto a las observaciones controladas como a las observaciones casuales675 y Galileo nunca utilizó las palabras italianas para experimento (esperimento y cimento), sino el término más general esperienza.676 La distinción entre los términos que utilizamos en la actualidad para hablar de la experiencia proporcionada por una visita al museo y el experimento de la bomba de vacío fue estableciéndose lentamente a lo largo de los siglos XVII y XVIII.677 Esta preeminencia del experimento en la ciencia moderna no implica que las observaciones se abandonasen. Las evidencias observacionales y experimentales son complementarias. Incluso hay ciencias, como la astrofísica o la epidemiología en las que la manipulación controlada de la realidad estudiada es prácticamente imposible. Otra gran invención moderna es el laboratorio. Aunque hoy en día nos pueda resultar extraño, hubo un tiempo en el que los laboratorios no existían. Para el filósofo natural medieval, que no se planteaba realizar observaciones controladas, el laboratorio era irrelevante y su principal lugar de trabajo era la biblioteca. Sin embargo, el científico moderno, tal y como explicó Francis Bacon, transformó el taller del artesano en el laboratorio de la nueva ciencia.678 Galileo, por ejemplo, pulió sus propias lentes para fabricar los primeros telescopios. Su padre, Vincenzo Galilei, era músico y disponía de un taller en el que comprobar el efecto de los distintos materiales y tensiones en el sonido de sus cuerdas. Vincenzo, además, no tenía en muy buena consideración a los teóricos, que él denominaba pitagóricos, y exigía comprobar las hipótesis en su taller/laboratorio musical. Su hijo adquirió una gran destreza manual que, más tarde, le permitiría crear distintos instrumentos. Consiguió, por ejemplo, pulir más de 200 lentes que utilizó para fabricar sus telescopios. Inicialmente obtuvo 8 aumentos, pero en 1610 llegó a 30.679 Los catalejos holandeses del artesano Hans Lippershey (1570-1619), sin embargo, tenían una ampliación de solo tres aumentos. Esta conversión del taller en laboratorio rompió, tal y como demandaba Francis Bacon, la antigua división entre conocimiento teórico y práctico.680 Por primera vez desde la caída de Alejandría la destreza del artesano volvía a tener lugar en el estudio de la naturaleza. Un estudio que, recordemos, hasta el momento había sido desarrollado por filósofos naturales completamente alejados del trabajo manual. Esta unión entre teorización y práctica sólo se había dado previamente en los compañeros helenísticos de Arquímedes.681 Los nuevos laboratorios dotaron a los investigadores de herramientas, como los microscopios o los telescopios, capaces de producir evidencias correspondientes a regiones del mundo natural que previamente habían sido inimaginables. Los grabados del libro Micrographia de Robert Hooke (1665) se convirtieron en un éxito inmediato. Por primera vez los humanos descubrían los mundos microscópicos de las pulgas y los cristales. Los telescopios y microscopios no cambiaron el mundo externo, pero sí cambiaron nuestra percepción del mismo, llegando con el tiempo a transformar los átomos en montañas.682 Tras esta revolución de la escala los seres humanos ya no volverían a pensar en su lugar en el mundo del mismo modo. 9.6 Objetividad instrumental Los nuevos laboratorios también se utilizaron para crear instrumentos de medida, como el termómetro y el barómetro. Estos artilugios permitieron cuantificar muchas sensaciones subjetivas, convirtiéndolas así en medidas objetivas que, en gran parte, pasaron a ser independientes del observador.683 Desde la antigüedad se había constatado que la sensación térmica es subjetiva, que lo que a uno podía parecerle una brisa fresca a otro le traía a la memoria una ventisca helada. Sin embargo, es mucho más fácil que distintos observadores se pongan de acuerdo en si un termómetro marca o no 15 ºC. Esta posibilidad de hacer mediciones instrumentales objetivas de distintas magnitudes físicas fue otra de las claves del éxito de la nueva ciencia. La capacidad de avance científico de un área de conocimiento depende, en buena medida, de la posibilidad de establecer mediciones objetivas. Este es uno de los motivos por los que la astronomía antigua había conseguido alcanzar un alto grado de sofisticación en la antigüedad.684 Sin embargo, este éxito temprano no ha de restar mérito a Tycho Brahe, que creó nuevos instrumentos mediante los cuales pudo medir ángulos con una precisión de dos minutos de arco, algo impensable en la antigüedad. Si extendemos nuestro brazo y observamos nuestro dedo meñique, éste medirá unos treinta minutos de arco, por lo que Brahe pudo medir la posición de los astros con una precisión capaz de distinguir 15 líneas en el dedo meñique. También hay que añadir que esto no fue barato, los primeros observatorios de Brahe, Uraniborg y Stjerneborg, llegaron a consumir una parte apreciable de la riqueza danesa. Antes de Galileo los filósofos naturales pensaban en un mundo poblado por cualidades como olores, colores y sabores, pero el mundo científico moderno decidió limitarse a aquello cuantificable.685 Este cambio fue duramente criticado por algunos pensadores de la época, pero terminó siendo una de las claves del rápido avance de la ciencia moderna. Aristóteles discutió las leyes del movimiento, pero no hizo medida alguna.686 Galileo, sin embargo, se esforzó en diseñar experimentos que le permitiesen fundar su física en observaciones cuantitativas. En ciencia conviene hablar sobre observaciones y no sobre simples percepciones. Las observaciones son planificadas, sistemáticas y documentadas y pueden hacer uso de sofisticados instrumentos que complementan nuestros sistemas perceptuales. 9.7 Razonamiento matemático La nueva física además de estar basada en medidas cuantitativas, optó por el razonamiento matemático. En este sentido, tal vez, el trabajo de Kepler sea uno de los ejemplos más relevantes de este nuevo proceder. Brahe quería convertir sus excelentes observaciones en un modelo matemático y contrató a un matemático, a Kepler, para llevar a cabo la tarea. A Kepler, por su parte, le interesó el cometido porque esperaba validar así sus creencias pitagóricas sobre la armonía matemática de los cielos.687 Su primera idea fue comprobar si las órbitas de los seis planetas conocidos podían ajustarse a las esferas definidas por los cinco sólidos platónicos regulares.688 Sin embargo, Kepler era un empirista decidido y no estaba dispuesto a aceptar ningún modelo que no coincidiese con las precisas medidas de Brahe. Este compromiso exigió un esfuerzo titánico al matemático. Intentó ajustar las observaciones de Marte a varios epiciclos y a varias órbitas ovoides, hasta que, tras cuatro años de cálculos, concluyó que la órbita marciana era en realidad elíptica. Este resultado lo publicó en su La armonía de los mundos junto a la siguiente nota: “querido lector, puede que te canse este procedimiento, pero compadécete de mí que tuve que hacerlo al menos 70 veces”689. Este esfuerzo puede homenajearse utilizando las palabras de William James, el decimonónico fundador de la psicología, o las de Thomas Henry Huxley, uno de los más famosos defensores de Darwin. James escribió que la ciencia se construye sobre la paciencia y la sumisión a las evidencias frente a las preferencias personales y Huxley dijo que la gran tragedia de la ciencia es que la más hermosa de las hipótesis puede morir a manos de una simple observación desagradable.690 Esta matematización moderna es heredera de varias corrientes antiguas. Por un lado, tenemos la influencia de los pitagóricos. Recordemos que estos filósofos asociaban la estructura metafísica última del cosmos a las matemáticas. Incluso hoy en día no es extraño que alguien concluya que, dada la extraordinaria efectividad de las matemáticas, la estructura última del mundo esté escrita, tal y como expresó Galileo, en lenguaje matemático. Pero hay otra posibilidad representada por la influencia helenística. Arquímedes, por ejemplo, había utilizado las matemáticas como una herramienta con la que razonar sobre problemas físicos. Si el mundo tiene un orden, es esperable que pueda describirse y razonarse sobre él mediante herramientas especializadas en manejar estructuras lógicas. En este sentido las matemáticas no serían más que un modo de razonar con rigor,691 algo que no exige ningún compromiso metafísico fundamental. En cualquier caso, la combinación del empirismo y la aproximación matemática demostraron ser extraordinariamente efectivos692 y tal vez la culminación de esta aproximación sean los Principios matemáticos de la filosofía natural publicados por Newton en el verano de 1687. Esta obra, que integra los resultados de Brahe, Kepler y Galileo en un sistema matemático coherente, sentó las bases de toda la física posterior y, además, sirvió como ejemplo, como paradigma, metodológico. Lo que no debemos concluir a partir de este énfasis en la cuantificación y el razonamiento matemático es que todas las ciencias deban ser necesariamente matemáticas. El único requisito imprescindible es que la observación y el razonamiento sean lo más rigurosos posible. En El origen de las especies, otro de los paradigmas científicos más relevantes publicados jamás, no hay ni una sola fórmula.693 Se puede hacer gran ciencia sin matemáticas. Aunque también es cierto que la cuantificación facilita la obtención de observaciones más objetivas y que el razonamiento matemático, por ejemplo, el estadístico, limita el tipo de errores de razonamiento que podemos cometer. De hecho, es común que durante el proceso de maduración de una ciencia ésta se vaya haciendo más cuantitativa. Por ejemplo, durante el siglo XX se desarrollaron modelos teóricos que cuantificaban las ideas darwinianas y, en la actualidad, los que estudiamos la evolución lo hacemos utilizando sofisticadas herramientas matemáticas. Hace unos años que estudio la evolución del tomate y en este campo abundan los análisis de componentes principales, los filtros estadísticos, las distribuciones y los espectros de frecuencias alélicas. También es muy importante recordar que a pesar de que reconozcamos las ventajas ofrecidas por la cuantificación, no debemos caer en el enorme error de creer que por el simple hecho de cuantificar algo ya estamos haciendo ciencia rigurosa. Uno puede pasarse décadas midiendo el PIB o la frecuencia alélica de distintas poblaciones de tomate sin pensar con rigor ni un solo día. 9.8 La vaca esférica Un aspecto del proceder científico que suele pasar desapercibido es que una buena hipótesis científica no tiene por qué aspirar a ser absolutamente precisa. Muchos asumen que la ciencia trata, en todos los casos, de llegar a la verdad absoluta, pero esto no es cierto, abundan los ejemplos en los que se conforma con disponer de modelos aproximados útiles, incluso aunque estos se establezcan sobre algunas premisas que se saben falsas o aunque sus conclusiones sean tan solo aproximadas. Puede sorprender que muchos de los modelos que se utilizan comúnmente acepten asunciones que sabemos falsas, pero así es.694 Por ejemplo, ahora mismo me encuentro tratando de establecer un modelo que describa los flujos migratorios neolíticos del tomate entre la región andina del norte de Perú y el sur de Ecuador y Mesoamérica. Mi objetivo no es crear una hipótesis evolutiva que se corresponda exactamente con lo que ocurrió hace miles de años, sino elaborar un modelo aproximado que resuma las evidencias actuales y que permita hacer predicciones correctas sobre la estructura genética de las poblaciones actuales. Para que este modelo funcione no es necesario que sea absolutamente preciso, sólo necesito que la estructura del modelo se corresponda, aproximadamente, con la estructura de lo que pasó en realidad hace miles de años. Algunos de los ejemplos más comentados de las teorías científicas, como el de la relatividad general o el modelo electrodébil pertenecen a la física fundamental y se caracterizan por haber hecho predicciones muy precisas sobre un gran número de fenómenos. Sin embargo, esta no es una característica de todas las hipótesis planteadas por los investigadores. De hecho, es crítico reconocer que las hipótesis científicas no tienen por qué ser exactas. En muchos casos, incluso puede que en la mayoría, se desprecian muchos de los detalles observados porque los modelos se limitan a reflejar aproximadamente el fenómeno estudiado. Galileo, por ejemplo, insistió en que cuando se propone una hipótesis, y esto es especialmente cierto fuera de la física fundamental, lo que estamos haciendo es tratar de capturar ciertos aspectos del mundo, pero que, a la vez, podemos estar desechando otros. Por ejemplo, al describir sus experimentos con los planos inclinados Galileo comentaba que las superficies debían ser muy rectilíneas y pulidas y que los objetos que caían tenían que ser completamente esféricos.695 ¿Por qué esta recomendación? Porque Galileo era perfectamente consciente de que sus hipótesis sólo eran precisas en un mundo ideal sin rozamiento ni resistencia. Sus fórmulas matemáticas hacían predicciones que, en condiciones reales, sólo eran aproximadas, era consciente de estar descontando, entre otros aspectos, el rozamiento con la superficie y la resistencia del aire. Su física llegó más allá que la aristotélica, pero a cambio, hubo de ignorar la caída de los objetos reales. Cuando el rozamiento y la resistencia no son despreciables, los modelos galileanos funcionan peor que los aristotélicos. Además, diga lo que diga el principio de inercia, en nuestro mundo cotidiano, cuando un objeto no es empujado acaba por detenerse. Sus críticos indicaron, con razón, que los objetos al caer no aceleran indefinidamente, a lo que él respondió que estos aspectos, aunque se observasen, debían ser descartados.696 Galileo optó por despreciar los detalles y plantear una simplificación, una vaca esférica. El pisano estaba asumiendo que, bajo el complejo fenómeno que estaba observando, subyacía una ley sencilla que recogía sus aspectos más destacables. Es cierto que las trayectorias de los objetos reales eran algo más complejas debido a factores difíciles de controlar, pero, según él, estos detalles eran despreciables. Esta es una idea que habría hecho feliz a un platónico. Nunca hemos observado un cuerpo que caiga siguiendo exactamente los dictados de nuestras teorías, del mismo modo que nunca hemos escuchado una nota musical perfecta. Sin embargo, de algún modo, nuestras teorías parecen referirse a la estructura de un cosmos ideal. Resulta llamativo el contraste de esta actitud con la defensa galileana del empirismo. ¿Cómo es posible que Galileo defendiese que la ciencia debe rendirse al dictado de la observación y, al mismo tiempo, asumiese que las predicciones teóricas sólo tienen que coincidir con las observaciones aproximadamente? Como mínimo, esta aproximación exige cautela puesto que esta división entre lo esencial y lo prescindible exige un equilibrio entre observación y teorización que es susceptible a ser influido por nuestras ideas previas. Algunos criticaron esta actitud, pero Galileo respondió que él era capaz de juzgar qué aspectos del fenómeno estudiado eran descartables y cuáles no. Lo que no pudo hacer fue precisar qué criterios le permitían elegir los aspectos del fenómeno que debían ser ignorados sin recurrir, al menos en parte, a su juicio y experiencia. Al hacer ciencia uno se ve obligado a elegir qué es relevante y qué no, qué es señal y qué ruido.697 Esto, claro está, nos expone a que estemos desechando aspectos importantes del fenómeno estudiado. El problema es que, si no aceptásemos estas simplificaciones, ninguna propuesta que no explicase todas las observaciones de un modo absolutamente preciso sería aceptable, algo que impediría el progreso científico. Este es un aspecto clave: nuestras hipótesis tratan de capturar parte de la estructura del fenómeno observado, pero, habitualmente, serán sólo aproximadas porque descartarán algunos aspectos. Para rescatar lo esencial nos conformamos con capturar la esfericidad vacuna. Este es un aspecto sutil que suele omitirse al hablar sobre ciencia y que puede causar problemas de percepción social. Si se asume que la ciencia sólo acepta asunciones y teorías completamente verdaderas, se abona el terreno para que cualquier violación de esta premisa errónea se utilice para desacreditar el esfuerzo científico.698 Lo relevante no es si los economistas aceptan o no la premisa del consumidor ideal con información absoluta, sino si sus modelos funcionan o no cuando se utilizan para hacer predicciones sobre el mundo real. De hecho, lo más relevante en un modelo no es que sus asunciones teóricas sean verdaderas, sino que el modelo sea lo suficientemente robusto a las violaciones de esas asunciones como para que sus predicciones sí lo sean.699 9.9 Una modernidad desigual Los métodos y las actitudes del filósofo natural moderno no llegaron al mismo tiempo a todas las ciencias. La astronomía y la física fueron las primeras, mientras que la química, la geología o la biología hubieron de esperar algo más. Kepler y Galileo ya estaban haciendo ciencia moderna a principios del XVII, sin embargo, en ese momento, los términos química y alquimia todavía no se habían diferenciado y los químicos académicos no aparecieron hasta finales del XVIII.700 La nueva ciencia exigía observaciones reproducibles, por lo que demandaba cuidado en la elaboración y descripción de los experimentos y precisión en las medidas instrumentales. En química estas innovaciones sólo se impusieron después del trabajo de Antoine Lavoisier (1743-1794), uno de los grandes padres de la química moderna. Lavoisier no sólo generó una revolución conceptual, sino que aportó un gran rigor intelectual y experimental.701 La geología y la biología también fueron ciencias tardías. No fue hasta 1795 cuando el geólogo William Smith entendió los estratos geológicos como una secuencia histórica.702 En biología los investigadores más relevantes abarcan tanto el XVIII como el XIX: Linneo (1707-1778), Georges Cuvier (1769-1832), Charles Darwin (1809-1882). Y, por último, las ciencias psicológicas y sociales aparecieron, aún más tarde, a lo largo del XIX.703 9.10 Ciencia y filosofía Fue también durante el XVIII cuando la ciencia completó el proceso de especialización que la llevaría a desgajarse de la filosofía. Esta evolución se refleja en una serie de términos que fueron aplicándose durante la revolución científica. Mientras que a finales del XVI era común referirse a los filósofos naturales como naturalistas, durante la revolución se pasó a hablar de fisiologistas o físicos.704 Sin embargo, no fue hasta 1834 cuando William Whewell propuso el término científico como analogía con el de artista. Sobre esta cuestión es importante recordar que lo que inventó Whewell fue el término “científico” no el de “ciencia”, que había sido utilizado como equivalente a conocimiento desde la Edad Media. “Ciencia” acabó asociado a la rama correspondiente a la filosofía natural, y no a las de la epistemología o la metafísica, simplemente porque, durante el XIX, se terminó por abreviar el término común ciencia natural, es decir, conocimiento del mundo natural, hasta dejarlo en ciencia.705 Es importante recordar que ciencia significa, desde sus inicios, simplemente conocimiento y eso es lo que es en esencia. La popularización del término “científico” coincidió con la profesionalización de los filósofos naturales en el siglo XIX.706 Fue entonces, además, cuando aparecieron numerosos estudios oficiales y revistas especializadas, y cuando la especialización se hizo muy relevante.707 A pesar de esto la denominación del estudio de la naturaleza como filosofía natural sobrevivió hasta finales del XIX y recordemos que, aún hoy, los doctores en ciencia se denominan Doctor of Philosophy (Ph. D.) en el mundo anglosajón. 9.11 La república del conocimiento La ciencia la hacen las comunidades. Tendemos a imaginar que la ciencia avanza de revolución en revolución gracias a grandes genios aislados y heterodoxos, como Einstein, Darwin o Galileo. Sin embargo, estas ideas son equivocadas, la ciencia suele avanzar suavemente, no a trompicones, y es, eminentemente, una empresa comunitaria puesto que sus practicantes no están aislados, sino conectados en extensas comunidades que suelen mantener un equilibrio sutil entre la ortodoxia y la contestación. Tal vez el caso más cercano al del mito del genio aislado e inconformista sea el de Einstein. Este investigador hizo gran parte de su trabajo fuera del mundo académico y se describía a sí mismo como solitario y pocas veces tuvo estudiantes.708 Sin embargo, durante el desarrollo de la relatividad general colaboró con otros investigadores como Marcel Grossmann, David Hilbert o Emmy Noether.709 Y, por supuesto, su destacado papel en el desarrollo de la mecánica cuántica se enmarca en el esfuerzo colectivo de cientos de investigadores. Michael Polanyi, el científico, economista y filósofo húngaro, dijo que la ciencia la pensaba un cerebro comunitario710 y ese cerebro, aunque es heredero de las comunidades filosóficas clásicas, se estructuró e institucionalizó en su forma moderna durante la revolución científica. William Gilbert, por ejemplo, en su De magnete (1600) ya agradecía a la comunidad de expertos que le había ayudado a desarrollar sus experimentos711 y Galileo pertenecía a la Academia de los linces, una comunidad de investigadores que le acompañó y apoyó, y se carteaba con media Europa. Durante la Edad Moderna la comunicación dentro de estas comunidades se incrementó enormemente. La imprenta, como ya hemos comentado, fue una de las herramientas fundamentales, pero no la única. El servicio postal, aunque aparentemente más modesto, también tuvo una influencia enorme. En el siglo XVII se publicaban bastantes libros, pero todavía eran caros y no era fácil encontrar buenos impresores por lo que los investigadores utilizaban principalmente las cartas. Fueron estos intercambios epistolares los que tejieron la República de las letras, una comunidad internacional que trascendía fronteras, lenguas y religiones.712 Una república que, como Thomas Jefferson recordó, se encontraba en paz incluso cuando las naciones a las que pertenecían los científicos estuviesen en guerra. La denominación inglesa de esta república (republic of letters) hacía honor a la contribución del servicio postal, algo que se pierde con la traducción al castellano. Estas redes epistolares terminaron por formalizarse en forma de revistas que, desde entonces, han constituido la principal fuente de comunicación formal en las comunidades científicas. La primera fue la Philosophical Transactions (1665) de la Royal Society, una revista que sigue publicándose en la actualidad y que, como muchas otras, fue editada por una de las recién creadas sociedades científicas.713 Además, se crearon academias a lo largo de toda Europa. En Alemania se fundó la Academia Naturae Curiosorum (1652), en Italia algunos de los discípulos galileanos fundaron la Accademia del Cimento (1657), en París el primer ministro apoyó la fundación de la Academia de Ciencias de Francia (1666) y en Londres se creó, bajo el marchamo real, la insigne Royal Society (1662). Si los investigadores estuviesen aislados su avance sería minúsculo. El científico, como filósofo natural que es, tiene el deber de pensar con rigor y de criticar sus propias ideas, pero esto no siempre es sencillo. A uno no le es fácil escapar de sus propios sesgos y de su desconocimiento, por lo que necesita una comunidad que examine sus propuestas con severidad. Además, incluso nuestras ideas más fructíferas suelen ser incompletas porque, en muchos casos, carecemos de alguna habilidad necesaria. Yo no habría sido capaz de desarrollar por mí mismo ninguno de los trabajos de investigación que he firmado como primer autor. En todos y cada uno de los casos ha sido imprescindible tanto la crítica como la colaboración constructiva de expertos en distintas áreas. Puede que a quien no esté familiarizado con el funcionamiento interno de la ciencia le resulte extraño que los propios autores de los trabajos no sean expertos en todos los aspectos de sus investigaciones, pero esa es la realidad. El conocimiento actual es mucho más amplio de lo que ninguna mente puede abarcar. Convertirse en experto en una pequeña área requiere décadas de esfuerzo y experiencia, pero la naturaleza no tiene por costumbre restringir sus problemas a áreas concretas. En la época en que Einstein desarrolló sus teorías, un estudiante de doctorado podía abarcar la mayor parte de la Física de su tiempo. El propio Einstein es un ejemplo de ello, pero también de que le fue imposible abarcar al mismo tiempo las Matemáticas y la Química. Hoy en día, esto no es posible ni siquiera dentro de un área tan restringida como la genética del tomate. La cantidad de conocimiento actual es inabarcable para cualquier individuo. A Hipócrates (460 a. C. - 370 a. C.), el médico clásico del juramento, le debemos el profundo aforismo: el conocimiento es amplio, la vida breve, la oportunidad fugaz, la evidencia traicionera y el juicio difícil (Ars longa, vita brevis, occasio praeceps, experimentum periculosum, iudicium difficile). Además, el trabajo interdisciplinar sólo puede ser desarrollado por redes de colaboración y confianza en la que distintos investigadores comprueban distintas partes del modelo propuesto. Si un investigador individual hubiese de comprobarlo todo no podría avanzar demasiado.714 Es la comunidad la que avanza y la que realmente conoce los problemas.715 Además, también es la comunidad la que replica o construye sobre los resultados obtenidos. Un descubrimiento que no es utilizado es sólo papel muerto. Y no olvidemos que también es la comunidad la última jueza, la que decide otorgar o no el consenso a una idea, aceptándola temporalmente, desechándola o manteniéndola en el purgatorio de la crítica, la réplica y la contrarréplica. 9.12 Hechos Uno de los términos relacionados con el empirismo que se adoptó durante la revolución científica fue evidencia. El término procedía originalmente del latín y significaba evidente. Se aplicaba a aquello tan claro, tan patente, que no merece ser discutido. Etimológicamente, proviene de evideri, un verbo que significaba aparecer completamente, verse por completo. En castellano el vocablo evidencia conserva este sentido, que la RAE recoge de este modo: “Certeza clara y manifiesta de la que no se puede dudar”. Este es el sentido del término en la frase: La evidencia de la existencia del gato es abrumadora. Algo es evidente cuando estamos muy seguros de su corrección. Este, sin embargo, no es el sentido utilizado en filosofía de la ciencia. El término llegó a la ciencia desde el derecho, área en la que se usaba para referirse al conjunto de testimonios y documentos relevantes para un caso.716 Evidencia vino a significar aquello que justifica nuestra creencia. Este concepto fue popularizándose entre los filósofos naturales a partir del siglo XVII. Sin embargo, es posible que el término más relevante de la revolución científica fuese hecho. En ciencia podría definirse hecho como una evidencia muy probable, como algo en lo que podemos depositar nuestra confianza porque ha sido establecido hasta tal punto que sería irracional negarlo.717 Esta definición implica, además, una cierta objetividad; un hecho sería tan fiable que podríamos asumir que será aceptado casi por cualquier observador. En lógica también se utiliza el término hecho, aunque con un significado distinto. Un hecho en lógica es una proposición que se asume como verdadera, una proposición que puede servir, por ejemplo, como premisa en una deducción. En realidad, el uso del término hecho en la filosofía de la ciencia actual puede llegar a ser un tanto confuso. Podríamos distinguir entre dos sentidos del término: hecho epistémico, que sería aquella evidencia muy probable, y hecho ontológico, que es aquello que ha ocurrido en el mundo externo. Que un árbol caiga en el bosque, lo vea alguien o no lo vea, sería un hecho en el sentido ontológico, que alguien documente la caída mediante fotografías y observaciones detalladas sería un hecho en el sentido epistémico. El hecho ontológico tiene relación con el territorio, mientras que el epistémico forma parte de nuestros mapas, de nuestras ideas sobre lo que sucede en el mundo externo. En el mundo anglosajón es común utilizar la palabra fact para referirse a ambos sentidos, aunque hay autores que sí marcan la diferencia y prefieren emplear otros términos, como data u observation. En castellano lo más habitual es optar por esta segunda opción, reservando hecho para los hechos ontológicos y utilizar datos u observaciones para referirse a la información que obtenemos. Estas distinciones podrían parecer menores, pero es fundamental distinguir entre mapa y territorio, entre nuestras ideas sobre lo que ha ocurrido y lo que ha ocurrido realmente. Este es el motivo por el que el término hecho es confuso. ¿Qué significa que es un hecho que el asesino llegó a la escena del crimen a las 10, que alguien ha afirmado haberlo visto llegar o que realmente llegó? Durante la revolución se llegó a la conclusión de que los hechos son los ladrillos sobre los que se construye la ciencia. J. T. Desaguliers, un filósofo natural francés, escribió, en su Curso de filosofía experimental (1717), que todo el conocimiento que tenemos del mundo natural depende de los hechos.718 Hoy en día puede parecernos más o menos obvio que la ciencia se asiente sobre observaciones, sobre evidencias recogidas sistemáticamente, sin embargo, hay que tener en cuenta el cambio que supuso respecto a un mundo medieval en el que el conocimiento se buscaba más en la biblioteca que en la observación. La confusión terminológica es consecuencia de la curiosa posición que pretenden ocupar los hechos, a medio camino entre el territorio y el mapa, entre el mundo externo y nuestras ideas sobre el mismo. Los hechos aspiran a ser objetivos, independientes del observador, y, por lo tanto, parecen depender exclusivamente del mundo externo. Recordemos que los pensadores helenísticos habían criticado la idea estoica de la impresión cognitiva y que preferían poner el énfasis en que una impresión siempre era, al menos en parte, subjetiva, atañía a un sujeto concreto y, por lo tanto, podía variar entre distintos observadores. Los escépticos antiguos nos recordaban que cualquier información que nos llegue del mundo externo siempre estará teñida, hasta cierto punto, por nuestra perspectiva. Sin embargo, las observaciones aspiran a ser objetivas, independientes del observador. Un viento puede parecerle más o menos cálido a distintos observadores, pero todos ellos podrán acordar si un termómetro está indicando o no 30 ºC. Los modernos modificaron incluso el significado de la palabra fenómeno. El término griego que actualmente traducimos como impresión o apariencia era phainomenon y originalmente, como hemos dicho, ponía el énfasis en la subjetividad de la experiencia. Un fenómeno griego no ignoraba que la impresión pertenecía a un sujeto. Sin embargo, para Newton, un fenómeno es algo que se produce en la naturaleza, en el mundo externo, y que puede ser percibido objetivamente por cualquier investigador. Una propiedad esencial de las observaciones es que son públicas. No es una evidencia, por ejemplo, que yo no creo en Zeus, esto es un estado interno de mi mente y, por lo tanto, es un estado privado; es una evidencia, sin embargo, que yo afirmo no creer en Zeus.719 Algunos filósofos dirían que las observaciones son objetivas, mientras que otros preferirían evitar el término y hablarían de intersubjetividad. El investigador no puede llegar a aprehender por completo el mundo externo, a lo que, podemos tener acceso, estrictamente hablando, es a nuestra percepción y en base a esta información nos hacemos una idea de qué ocurre en el mundo externo, pero esa idea no será el mundo externo, será un modelo, un mapa de esa realidad. Por eso los positivistas prefieren hablar de intersubjetividad y no de objetividad.720 Al limitarnos a la intersubjetividad evitamos el problema de tratar con el objeto y nos limitamos a afirmar que cualquier investigador debería poder acceder a los datos para poder comprobarlos. Para los positivistas el conocimiento debe ser intersubjetivo y testable.721 La imprenta también jugó un papel en la evaluación pública de las evidencias ya que al facilitar la difusión de la información favoreció la mejora de la calidad de las evidencias.722 La imprenta puso en manos de los investigadores modernos muchas más fuentes de las disponibles para los medievales.723 Esta abundancia de textos permitió a los académicos buscar las referencias originales, lo cual les liberaba de confiar en el testimonio de un autor posterior. Sin esta posibilidad, los estudiosos medievales estaban condenados a confiar en recopilaciones de testimonios en las que era difícil diferenciar lo fiable de lo dudoso. Sin embargo, los modernos, al disponer de copias de los textos originales, podían contrastar la información con una mayor facilidad. Una consecuencia de esta nueva capacidad fue la aparición de numerosos libros de errores, volúmenes en los que se recogían los fallos detectados en la bibliografía.724 La etimología del término hecho es muy reveladora, un hecho no sólo ha sucedido, sino que puede hacerse, es susceptible, en principio, de ser reproducido. Dado que el interés de Gilbert era que el resto de la comunidad pudiese reproducir sus experimentos magnéticos su libro está compuesto, básicamente, por una colección de recetas.725 Aún hoy en día esta cuestión continúa siendo clave en la empresa científica. Este es el motivo por el que los artículos científicos constan de una sección denominada “material y métodos” en la que los autores del estudio han de explicar con suficiente detalle sus experimentos. Se asume que a partir de esta descripción el resto de sus colegas debería ser capaz de reproducir sus resultados. Las observaciones, además, desbancaron a la autoridad. Cuando cualquiera es capaz de replicar un experimento ya no es necesario confiar en la autoridad. En El ensayador, Galileo nos previene contra los testimonios: sólo debemos considerarlos cuando no podamos reproducir la observación por nosotros mismos.726 Este fue otro cambio radical respecto a la tradición medieval. Galileo mantuvo un curioso debate con Horazio Grassi, un matemático y astrónomo que afirmaba que los huevos podían ser cocidos, tal y como afirmaban los libros antiguos, dándoles vueltas a alta velocidad con una honda. El pisano, seguramente más interesado en el método que en la respuesta, aprovechó para recordarle que lo que debíamos hacer era ignorar el texto, conseguir una honda, un huevo y girarlo a alta velocidad para ver qué sucedía.727 La Royal Society adoptó incluso el lema Nullius in verba, que podría traducirse como por la palabra de nadie, que ponía de manifiesto la voluntad de los miembros de la sociedad de depositar su confianza en las observaciones reproducibles y no en los testimonios. Esta reproducibilidad es, además, una de las bases del progreso científico. Si dejamos de lado los problemas planteados por el cambio de las entidades teóricas, que trataremos en la sección sobre la metafísica naturalista, lo que es indudable es que con el tiempo la ciencia acumula observaciones reproducibles de fenómenos.728 Si nos referimos al sentido epistémico podría decirse que los hechos bien establecidos están aquí para quedarse. Una vez Faraday realizó el primer experimento con un motor eléctrico homopolar o Hertz detectó las primeras ondas electromagnéticas no hubo vuelta atrás, cualquiera puede repetir sus experimentos volviendo a obtener resultados muy similares. Todas las teorías posteriores deben acomodar, al menos aproximadamente, los hechos epistémicos bien establecidos que se han generado hasta el momento en el que son planteadas. Cualquier teoría gravitatoria futura, independientemente de que postule fuerzas, curvaturas del espaciotiempo, gravitones o cualquier otra entidad, deberá dar cuenta de la órbita de Marte. En principio, las evidencias y las teorías son conceptos distintos y las observaciones son independientes de las teorías. Una teoría o hipótesis no sería una observación, sino un modelo sobre el funcionamiento del mundo. Por este motivo se utilizan los términos empírico y teórico como contrapuestos. Esta separación nítida entre observación y teoría es una de las bases de la filosofía clásica de la ciencia. Fue aceptada, por ejemplo, tanto por los positivistas como por Popper. La distinción entre observación e hipótesis es tan fundamental que también tiene su reflejo en la estructura de los artículos científicos, en los que se suelen separar los resultados y la discusión de los mismos. Mis observaciones relativas a la composición genética de los tomates son resultados, mientras que el modelo histórico que propongo en base a estas observaciones es una hipótesis. Si nos imaginamos un plano cartesiano en el que hemos representado unas observaciones en forma de puntos, los puntos serían los datos, las observaciones, y la recta ajustada sería la hipótesis. En capítulos posteriores comentaremos con detalle las críticas que distintos filósofos de la segunda mitad del siglo XX hicieron a esta pretendida independencia entre observaciones y teoría y concluiremos que, aunque no es descabellado asumir que, en muchos casos, esta separación es bastante nítida, en otras ocasiones habrá que matizar o incluso descartar la división. La reproducibilidad de las observaciones tiene una ventaja adicional, incentiva la honestidad científica.729 Por ejemplo, la investigadora japonesa Haruko Obokata publicó hace pocos años en una prestigiosa revista que había encontrado un nuevo método para producir células madre. Sin embargo, cuando numerosos laboratorios fallaron al intentar reproducir sus resultados se asumió que sus trabajos eran un fraude realizado para ganar notoriedad. Aunque también es importante recordar que incluso aunque dispongamos de observaciones consensuadas por la comunidad, éstas no dejan de ser evidencias muy fiables, pero falibles, y, por lo tanto, no debemos depositar en ellas una confianza ciega. La observación es falible, cabe la posibilidad de que sea errónea y deba ser descartada o desechada en el futuro. Podemos decir que dadas las evidencias disponibles hasta el momento sería irracional negar la conclusión de que existen gatos en el mundo, sin embargo, puede que en algún momento nuevas evidencias nos hagan revisar esa afirmación. Como nos recuerda el Dr. Indiana Jones: “en arqueología se buscan hechos (epistémicos), no verdades, si estás interesado en la verdad, estudia filosofía”. La potencial reproducibilidad de las observaciones científicas tampoco implica que replicar una observación o un experimento tenga que ser necesariamente trivial. Muchas veces se necesita experiencia con el fenómeno o los instrumentos utilizados y puede que reproducir un resultado requiera un esfuerzo de años. En otras ocasiones es posible que el instrumental requerido sea tan sofisticado que, en la práctica, la reproducción sea casi imposible. No será fácil, por ejemplo, replicar los resultados del Gran Colisionador de Hadrones. Incluso los experimentos más sencillos requieren de un cierto saber hacer, de un oficio, difícil de transmitir. Por ejemplo, yo he intentado, junto a mis sobrinas, rehacer el experimento galileano de la caída de los cuerpos dejando caer dos objetos de distinto peso, pero no es fácil conseguir soltar ambos objetos al mismo tiempo ni medir con precisión su caída. Los científicos suelen asumir que, si quieren aprender una técnica, lo más eficiente es visitar un laboratorio que la conozca, ya que hay un conocimiento implícito difícil de transmitir. Intentar reproducir el experimento independientemente suele ser más costoso. Cuando los investigadores trataron de reproducir los experimentos que Newton describía en su Opticks se toparon con el problema de la calidad de los prismas. ¿Cuál era el estándar que tenían que cumplir los prismas para reproducir los resultados newtonianos?.730 Además, aunque los científicos deberían explicar con suficiente detalle cómo han hecho sus observaciones, a veces ocultan pequeños detalles para conservar una ventaja competitiva frente a sus colegas. Y aunque ignoremos estas malas prácticas, puede que incluso para los propios investigadores, dado que en algunos casos hay variables desconocidas que no se controlaron, sea difícil reproducir un resultado. Mi colega Joaquín Cañizares perdió meses tratando de reproducir un experimento con cultivos celulares. Al final, tras todo este tiempo perdido, averiguó que la empresa que le suministraba el suero con el que alimentaba sus células había cambiado el lote. El suero provenía de una nueva vaca, y esto alteraba el comportamiento de sus cultivos. En estos casos deberá ser la comunidad en su conjunto la que haya de decidir si el resultado es suficientemente fiable o si, por el contrario, es mejor descartarlo. Lo que nunca debemos hacer es ignorar que, en ciertos casos, estamos trabajando con evidencias endebles. Las áreas de estudio en las que los problemas de reproducibilidad son abundantes tienen un problema serio ya que sus conclusiones tienen los pies de barro. Los que investigan esos temas deben ser conscientes de que hacer verdadera ciencia en esas circunstancias puede que sea imposible. A esta cuestión le dedicaremos un capítulo completo. 9.13 La evidencia tiene la última palabra Hemos caracterizado las observaciones como los ladrillos sobre los que se construye la ciencia: el investigador obtiene datos y, a partir de ellos, elabora hipótesis. Sin embargo, este no debe ser su único papel. Las observaciones también deben tener la última palabra en la evaluación de las hipótesis. Lo ideal es que utilicemos este modelo para generar predicciones y que realicemos nuevas observaciones para comprobar si coinciden o no con las predicciones. Esta es la base del denominado método hipotético-deductivo y aunque las investigaciones no siempre siguen esta aproximación, sí que es una buena primera caracterización de muchas investigaciones. Tenemos que ser conscientes de que la mayoría de las hipótesis que ideemos, incluso las que se basen en los datos que hemos obtenido hasta el momento, serán erróneas. De hecho, lo primero que uno aprende en el laboratorio es que casi todas las hipótesis, aunque sean razonables, serán erróneas y no resistirán la contrastación con nuevas observaciones. Casi todas acabarán en la papelera.731 Esto no suele aprenderse cuando se estudia en la universidad, es el laboratorio el que te lo enseña riéndose de tus hipótesis día tras día. Lo habitual es estar dándose cabezazos contra la realidad durante meses, descartando una hipótesis tras otra, hasta que consigues algo que parece predecir aproximadamente algunos aspectos del comportamiento del fenómeno que estás estudiando. Este es uno de los secretos fundamentales de la ciencia: las teorías científicas mejor contrastadas, merecen ser tenidas en cuenta, simplemente, porque son las hipótesis supervivientes de una severa purga. Esta fue otra de las grandes ideas galileanas. El pisano no se conformaba con aceptar las hipótesis que había derivado a partir de las observaciones, insistía en que sus conclusiones debían ser contrastadas empíricamente.732 Esto es lo que hizo, por ejemplo, con la hipótesis copernicana: se esforzó por validarla mediante observaciones. Nuestras hipótesis pueden fallar por muchos motivos. El mundo externo suele ser más complejo que nuestras ideas sobre él, es común que haya detalles que desconocemos, por lo que es probable que nuestras asunciones sobre el funcionamiento del fenómeno estudiado incluyan premisas erróneas. Además, puede que nuestras deducciones fallen por haber cometido errores formales e, incluso aunque sean formalmente válidas, en una larga cadena deductiva basta con que falle una sola premisa, un solo eslabón para que la conclusión sea errónea. Uno de los modos más comunes de separar el grano de la paja es contrastar las nuevas hipótesis con nuevas observaciones. Éste, de hecho, es uno de los secretos de la autocorrección de la que es capaz la ciencia. La ciencia tiene un éxito mayor que la teología en describir el mundo externo porque no sólo acepta el duro dictado de las evidencias provenientes de los fenómenos que estudia, sino que las busca activamente. Este principio metodológico es tan importante que muchos filósofos de la ciencia han llegado a relegar a un papel secundario el proceso de generación de hipótesis y se han centrado en el de justificación de las mismas. El químico alemán August Kekulé dijo haber soñado la estructura del benceno, una de sus aportaciones más relevantes. Sin embargo, a nadie le preocupó que adujese haber utilizado este extravagante sistema de generación de hipótesis. Lo relevante es que su modelo daba cuenta de las evidencias. A esta separación entre la generación de la hipótesis y su justificación, los filósofos de la ciencia la denominan división entre el contexto de descubrimiento, los motivos por los que las hipótesis son generadas, y el contexto de justificación, las razones por las que son aceptadas.733 En principio, el descubrimiento podría ser subjetivo, pero la justificación debería ser objetiva. Puede que hubiese razones psicológicas que hicieron que Galileo se decantase por la hipótesis copernicana, sin embargo, esto no es demasiado relevante. Mientras que la justificación de la hipótesis se base en las observaciones y la razón estamos haciendo ciencia. Compete a los historiadores y a los psicólogos discutir sobre los motivos que llevaron a Kekulé a plantear su estructura para el benceno, pero la justificación es una cuestión científica y filosófica que tendría que estar sujeta a las estrictas reglas de la lógica, las matemáticas y la observación. Esta división entre la generación de hipótesis y su justificación es uno de los pilares fundamentales de la objetividad y la universalidad científica734 y también está relacionada con la capacidad que tiene la evolución, que discutimos al hablar de la evolución biológica y la cultural, de generar conocimiento. Incluso aunque las hipótesis se generen al azar, como sucede en la evolución biológica, si disponemos de un modo eficiente de filtrar hipótesis basándonos en cuánto reflejan la estructura del mundo externo acabaremos por obtener conocimiento. Esta separación fue propuesta por el positivista lógico Hans Reichenbach (1891-1953) y fue aceptada, como veremos, entre otros, por Popper. Explicaremos que los positivistas y los falsacionistas no estaban de acuerdo en el papel exacto que debería atribuirse a las observaciones en el devenir de las investigaciones científicas; los primeros proponían que debían servir para confirmar las hipótesis, mientras que Popper sólo aceptaba su papel como destructoras de conjeturas. Sin embargo, ambas escuelas aceptaban la distinción entre los contextos de descubrimiento y justificación. Otros filósofos de la ciencia, como también comentaremos extensamente, han criticado que esta separación sea tan nítida y han sugerido que, al menos en algunos casos, la aceptación de una hipótesis puede ser debida a motivos no estrictamente epistémicos. 9.14 El triunfo del empirismo Hemos comentado que durante la antigüedad se habían hecho propuestas para el estudio del mundo natural que oscilaban desde un racionalismo casi absoluto hasta un empirismo más o menos tibio. Había quien abogaba más por la especulación teórica basada en la deducción y quien defendía más la observación. Además, en el capítulo dedicado al escepticismo helenístico enumeramos las principales críticas filosóficas a ambas aproximaciones. Sin embargo, los modernos tuvieron menos dudas, durante la revolución científica se asumió que la aproximación debía ser fundamentalmente empírica y que la especulación teórica debía ser limitada.735 Esta es una actitud radicalmente diferente a la de los filósofos naturales antiguos y medievales. El cambio de postura no se debió a que Hobbes, Locke, Descartes o ningún otro de los filósofos modernos hubiese conseguido resolver las críticas escépticas. No, siempre deberemos admitir que podríamos estar profundamente equivocados y en algunas ocasiones lo estamos realmente. El empirismo triunfó porque los científicos modernos, rindiéndose a las evidencias, avanzaron más en el conocimiento del mundo que todos los filósofos naturales racionalistas anteriores juntos. El empirismo se adoptó porque, en la práctica, demostró funcionar mejor que cualquier otra aproximación previa.736 Los Principia de Newton son uno de los ejemplos que convencieron a los científicos, y a los filósofos interesados por la ciencia, de que la aproximación metodológica adecuada era esta: el conocimiento debía construirse sobre la observación. De hecho, fue tal la confianza de algunos filósofos en la observación que adoptaron el término positivista, una palabra que se deriva de positum, lo dado, lo real, en contraposición a lo abstracto o lo quimérico. Para los positivistas, la razón y la observación deben gobernar sobre la oscuridad y la intuición.737 Las revoluciones científicas posteriores pueden haber acabado con la fuerza de la gravedad, pero no han afectado lo más mínimo a esta actitud empirista.738 La aceptación de esta conclusión fue tal que en la actualidad la ciencia podría definirse como el estudio empírico y sistemático del mundo. Si queremos averiguar cómo funciona el mundo no debemos limitarnos a construir elaborados razonamientos, hemos de observarlo, tenemos que interactuar con él. La ciencia no lo sabe todo, pero dispone de evidencias que justifican todo lo que sabe. El japonés y el chino recogen esta idea fundamental en su forma de escribir experimento: 実験 en japonés y 實驗 en chino tradicional. El primer sinograma, 実 o 實, significa realidad o verdad y el segundo, 験 o 驗, test o prueba. Por lo que podría decirse que la escritura japonesa y china de experimento recoge a la perfección la esencia empírica de la ciencia: interroga a la realidad. La necesidad de la observación puede incluso justificarse a nivel físico. Yudkowsky planteó en su Rationality: From AI to Zombies una justificación que parte de la asunción de que el conocimiento debe estar representado en un sustrato físico.739 En este caso, el conocimiento siempre implicaría una cierta correlación entre el sistema conocedor y el conocido que, tal y como demostró Leo Szilard, el físico húngaro que inventó la reacción nuclear en cadena, podría utilizarse para realizar un trabajo útil. En este sentido queda demostrado que el conocimiento, realmente, puede convertirse en poder termodinámico. Si dispusiésemos de un sistema capaz de generar conocimiento burlando estas limitaciones físicas podríamos construir máquinas que violasen la segunda ley de la termodinámica: un profeta podría conseguir que tu nevera enfriase sin que estuviese conectada a una fuente de energía.740 Para poder generar conocimiento de un sistema del que no tenemos información previa alguna sin observarlo, deberíamos ser capaces de violar la segunda ley de la termodinámica. Esta prevalencia de las observaciones, sin embargo, no ha de hacernos caer en el error de que las teorías se derivan de un modo sencillo a partir de los datos. Es un hecho que la Tierra no parece moverse, pero esto no impidió que Galileo estuviese convencido de que se movía.741 La ciencia trata con abstracciones y sus conclusiones son, en muchos casos, profundamente contraintuitivas y pueden matizar observaciones aparentemente obvias. Los científicos hacen uso de una mezcla compleja de observación, deducción e inducción. La relatividad, por ejemplo, no fue planteada por Einstein para explicar el resultado de ningún experimento, sino que surgió como respuesta a problemas teóricos resultantes de la interacción entre los dos resultados más importantes de la física clásica: las leyes de Maxwell sobre el electromagnetismo y la mecánica newtoniana. Este triunfo de la observación implicó, además, un triunfo sobre la autoridad. El resumen de Hume fue: “no hay razones que valgan contra los hechos.”742 Esta fue la esencia del debate entre Galileo y su inquisidor Roberto Belarmino. Lo importante para el inquisidor no era si la Tierra se movía o no, sino quién debía tener la última palabra en caso de conflicto: la autoridad eclesiástica o la observación. Según Galileo los conflictos entre la ciencia empírica y las alambicadas interpretaciones teológicas debían ser resueltos a favor de las observaciones. Galileo no era ateo, pero pensaba que las complejas deducciones teológicas podían encerrar algún error, mientras que la aproximación científica era un modo más directo de leer el libro de la creación. Sin embargo, Belarmino no podía admitir la posibilidad de que las interpretaciones se sometiesen a inspección pública ya que eso cuestionaba el poder vaticano, y esa era, precisamente, la raíz del conflicto con los protestantes. Belarmino consiguió ganar la batalla y arrestó a Galileo, sin embargo, los teólogos acabaron perdiendo la guerra, la ciencia moderna había mostrado cual era el camino más fructífero y ni siquiera el extraordinario poder eclesiástico consiguió impedir su avance. Un teólogo avezado puede conseguir disfrazar la imposición de la autoridad detrás de una larga cadena deductiva, pero los datos dejan pocos resquicios en los que esconderse y los inquisidores se vieron forzados a mostrar su verdadera cara al recurrir a la violencia. 9.15 Falibilismo Es una pena que Locke (1632-1704) y el resto de filósofos modernos muriesen mucho antes de la aparición de Les Luthiers porque su afirmación de que “La verdad absoluta no existe…y esto es absolutamente cierto” les habría hecho mucha gracia. Locke, como los escépticos helenísticos más avanzados, pensaba que la certeza absoluta es inalcanzable, pero que, al mismo tiempo, esto no debe preocuparnos demasiado puesto que para guiar nuestras acciones es suficiente con creer en lo razonable o probable.743 Los científicos deben aceptar que incluso la más contrastada de sus teorías siempre será susceptible de ser revisada en el futuro. Nuestro conocimiento siempre será hipotético, falible y sujeto a revisión.744 No es casual que los modernos adoptasen el término teoría para referirse a sus hipótesis más queridas. Theoría originalmente significaba en griego contemplación o meditación, de ahí nuestro término teatro, aunque con el tiempo pasó a utilizarse con el sentido de especulación. Es decir, que los científicos modernos se refirieron a sus mejores hipótesis utilizando el término reservado anteriormente para las especulaciones plausibles. Los modernos querían remarcar que una hipótesis, por muy bien que se comportase, nunca debía ser considerada como infalible. El sentido actual de hipótesis como conjetura susceptible de ser sometida a contrastaciones empíricas también es moderno. Para los astrónomos anteriores una hipótesis era un modelo matemático que no aspiraba a describir la física real subyacente. Por ejemplo, según el editor de la obra de Copérnico, el modelo heliocéntrico era una simple hipótesis, una herramienta de cálculo que no debía considerarse como real. David Wootton, en su magnífico The invention of science, atribuye el primer uso del término con el nuevo sentido a Thomas Digges, el astrónomo copernicano, en 1576.745 Esta terminología todavía hoy sigue causando una gran confusión. La palabra teoría, a veces, se utiliza en el sentido especulativo original. Sin embargo, este es un sentido muy alejado del significado que tiene para algunos científicos, que reservan el término para las hipótesis mejor contrastadas. Suele decirse que la teoría de la evolución, como la de la gravedad, son hipótesis muy contrastadas empíricamente. Aunque también hay que reconocer que los investigadores no somos consistentes en el uso de estos términos. El ejemplo más exagerado tal vez sea el de Francis Crick. El codescubridor de la estructura del ADN acuñó la expresión dogma central para referirse al sentido del flujo de la información de los ácidos nucleicos a las proteínas. Cuando se le preguntó por qué había utilizado la palabra dogma en un ámbito científico, respondió que pensaba que dogma significaba hipótesis en la que se tiene mucha confianza. Y, por cierto, a pesar de lo que creen muchos aficionados y profesionales, el dogma central sigue siendo tan válido como cuando lo planteó Crick, pero esto es una cuestión para ser tratada en otro momento. En filosofía de la ciencia el término teoría se utiliza en otro sentido, como un conjunto amplio de leyes o modelos. En este sentido la teoría de la evolución sería una teoría porque es un marco que nos permite engarzar numerosas observaciones y conclusiones biológicas. Por si esto fuese poco, el término teórico también se utiliza para marcar una contraposición con lo empírico. Empírico es lo observable, mientras que teórico es lo que nosotros terminamos concluyendo a partir de lo observado. La información que nos llega desde el territorio sería lo empírico y el mapa que elaboramos lo teórico. Para crear modelos del mundo externo estamos obligados a recurrir a hacer inferencias ampliativas. Hemos de ir más allá de las evidencias. Este es el motivo profundo por el que un modelo siempre será falible. Debemos asumir la posibilidad de que nuestra mejor teoría no sea la más adecuada y que en el futuro sea revisada. Y, además, tenemos que asumir que incluso los propios datos sobre los que se asienta son falibles. Esta aceptación de la duda fue un cambio filosófico muy grande respecto a las ambiciones de los mundos clásicos y medieval. Tradicionalmente el objetivo de la filosofía había sido la scientia, el conocimiento, y esto implicaba alcanzar la certeza absoluta.746 Este había sido uno de los motivos que llevaron a los filósofos clásicos a dudar de la percepción. Nuestros sentidos eran falibles por lo que difícilmente podían ser la base de un conocimiento infalible. En esto, los científicos modernos asumieron una mayor modestia intelectual y aceptaron la falibilidad del conocimiento del mundo natural como una limitación fundamental y decidieron explorar el mundo asumiéndola. De esta aceptación de la duda los modernos aprendieron que habían de ser cautos, pero no quedaron paralizados. Para Feynman un buen científico se caracteriza por sentirse cómodo con la duda, cree que “puede que sea así”, y actúa asumiendo esa creencia, pero es consciente de que su creencia es solo probable.747 A pesar de que estas fueron las conclusiones finales, no asumamos que no hubo debate. Galileo, por ejemplo, todavía defendió la postura antigua de que la ciencia podía y debía alcanzar la certeza absoluta.748 Esta es una actitud que no resulta extraña viniendo de un seguidor de Aristóteles y Arquímedes. Sin embargo, el falibilismo acabó adoptándose durante la revolución y no ha habido vuelta atrás, la certeza absoluta, especialmente fuera de los sistemas formales, es inalcanzable. El conocimiento pasó de ser definitivo a convertirse en un proyecto progresivo y colectivo que va avanzando con el esfuerzo de las distintas generaciones de investigadores. Para Auguste Comte, el primer positivista, la ciencia era una empresa progresiva que se iba aproximando a la verdad asintóticamente, sin llegar nunca a alcanzarla; una idea que compartió Russell al afirmar que: “La ciencia no intenta establecer verdades inmutables ni dogmas eternos. Trata de acercarse a la verdad por medio de aproximaciones sucesivas, sin sostener nunca que se ha arribado a un punto final de absoluta certeza”. Debemos aspirar a la verdad, pero conformarnos con el conocimiento aproximado. El investigador es un navegante que tiene como objetivo último la Ítaca metafísica, pero que se conforma con disfrutar de las enseñanzas del camino. Tenemos que aspirar a ser racionales, pero, al mismo tiempo, debemos aceptar, con modestia intelectual, que la verdad es un proyecto colectivo que nunca terminará de construirse. Esta aceptación no requiere que asumamos que el conocimiento es inalcanzable o que todas las opiniones son igual de válidas. Hay conclusiones que, como hemos comentado, están aquí para quedarse. Los objetos caen hacia el centro del planeta y las brújulas se orientan de un modo particular en la superficie de la Tierra y eso no va a cambiar. Incluso cuando unas teorías reemplazan a otras, hay una cierta estructura teórica conservada. Los helenísticos creían que la Tierra era esférica, nosotros tenemos modelos más refinados, pero nuestros actuales elipsoides de revolución son muy similares a una esfera y en el futuro no serán sustituidos por un tetraedro o un cubo. En cierto modo, que analizaremos con profundidad en próximos capítulos, las teorías se van matizando y no hay un cambio radical en su estructura. Las predicciones de la mecánica newtoniana sirvieron para enviar astronautas a la Luna a pesar de que ya se disponía de la relatividad general, una teoría más sofisticada, aunque prácticamente igual de precisa en lo que respecta al sistema Tierra-Luna. Tal vez sería conveniente distinguir dos sentidos en los que una teoría puede ser falible. En el primero, si consideramos las leyes científicas como candidatas a leyes fundamentales del cosmos, la ciencia sería profundamente falible. La gravedad newtoniana fue claramente desbancada como candidata a ley fundamental. Sin embargo, si consideramos las conclusiones científicas como meras descripciones del cosmos, la ciencia bien establecida sólo sería falible en el sentido de “más allá de toda duda razonable”. En este sentido mi confianza en la mecánica newtoniana continúa siendo, a día de hoy, tan elevada como mi confianza en la existencia de mi gata. En la sección dedicada a la metafísica volveremos a tratar este tema. 9.16 Resumen La ciencia moderna es rabiosamente empírica y moderadamente escéptica. A nivel filosófico el nacimiento de la ciencia moderna exigió compatibilizar la confianza estoica en la posibilidad de generar conocimiento del mundo natural, con las severas limitaciones expuestas por los escépticos helenísticos. La solución que se aceptó para no quedar paralizados por la duda radical consistió en aceptar aquello que estuviese más allá de toda duda razonable. De hecho, este escepticismo domesticado se convirtió en una de las principales herramientas científicas. La ciencia llega a aceptar consensos temporalmente, pero es hija de la suspicacia y esta desconfianza sólo puede superarse con rigor metodológico e, incluso en ese caso, las conclusiones siempre se considerarán falibles. El empirismo demostró ser el mejor aliado en la búsqueda del conocimiento científico. Esta aproximación no triunfó porque los filósofos consiguiesen superar las dudas escépticas, sino porque, en la práctica, demostró funcionar mejor que cualquier otra. Los exploradores contribuyeron más al conocimiento cartográfico que cualquier filósofo y los artesanos encontraron su lugar junto a los nuevos investigadores. Estos cambios llegaron acompañados de programas experimentales, laboratorios, instrumentación y cuantificación, así como, de la matematización de algunas ciencias. El empirismo triunfó y las hipótesis debieron someterse. La especulación teórica se relegó a un segundo plano y se confirió preeminencia a lo empírico. Este cambio también fue motivado por el escepticismo: incluso nuestros mejores pensadores pueden estar equivocados. De hecho, la mayor parte de nuestras ideas terminarán en la papelera. Es cierto que tanto las observaciones como las teorías son falibles, pero las primeras lo son menos porque están más cerca del mundo externo. Este es el motivo por el que la aproximación funcionó, si quieres estudiar el territorio no debes alejarte demasiado de él. El conocimiento científico se genera sometiendo a nuestras ideas a la purga empírica, es decir, seleccionando de entre nuestras hipótesis aquellas que mejor soportan el contraste experimental y desechando el resto. Lo fundamental no es que las evidencias se utilicen para construir las hipótesis durante la fase de descubrimiento, sino que la observación tenga la última palabra en la justificación. Mientras que la justificación de las hipótesis se base fundamentalmente en las observaciones estaremos haciendo ciencia. Como en la evolución, la generación de las propuestas puede ser más o menos libre, incluso podría llegar a dejarse al azar, pero la selección debe ser empírica y rigurosa. Este es otro de los aspectos escépticos que caracterizan a la ciencia, nuestras teorías mejor contrastadas no han de ser respetadas porque hayamos confiado en ellas, sino porque son las hipótesis supervivientes de una purga empírica inmisericorde. Este es el principal secreto de la capacidad de autocorrección de la ciencia. El triunfo de la observación representó también un triunfo sobre la autoridad, los datos tienen la última palabra y las creencias defendidas por la autoridad terminarán por caer si no están respaldadas por la evidencia. Las evidencias también sufrieron el filtrado escéptico: sólo las más fiables merecieron la atención de los investigadores. Los datos científicos han de nacer de la desconfianza. No se confía en la palabra, sino en las observaciones públicas e intersubjetivas. Incluso, si se puede, es mejor que las observaciones puedan replicarse, que puedan volver a hacerse, en cualquier momento y por cualquiera. La instrumentación y los experimentos, las observaciones controladas, contribuyeron a mejorar la fiabilidad de las evidencias. La ciencia no lo sabe todo, pero tiene observaciones robustas para justificar todo lo que sabe. Además, estas evidencias supervivientes de la purga escéptica, al ser robustas y duraderas, pueden ir acumulándose. Este es uno de los modos en los que la ciencia progresa: acumula observaciones y fenómenos que cualquier teoría deberá explicar. Puede que la relatividad general ya no hable de fuerzas gravitatorias, pero las órbitas que predice para los planetas siguen siendo muy próximas a las keplerianas. Sin embargo, y a pesar de los claros avances, en próximos capítulos, tendremos que hacer algunas matizaciones. Por ejemplo, la diferencia entre observación e hipótesis no es tan nítida. Las observaciones se construyen teniendo en cuenta la información que nos llega del mundo externo, pero, como nuestras teorías, también dependen, en parte, de nosotros, de nuestro punto de vista, de nuestro conocimiento previo y de nuestros sesgos. Cuanto más influya nuestra perspectiva interna en la observación, más nos arriesgamos a acabar viendo espejismos. Este es uno de los motivos que hacen que sea tan importante que nos esforcemos en analizar las limitaciones y los sesgos del propio proceso de investigación. Además, las conclusiones de unas investigaciones pueden convertirse en datos en la siguiente. Las leyes que elaboró Kepler a partir de las observaciones de Brahe fueron las evidencias de las que partió Newton. Sin embargo, a pesar de estas matizaciones, la distinción entre observación y teoría continúa siendo útil. La observación está más cerca del territorio, mientras que la teoría es el mapa que nos confiere una visión un tanto más alejada, más global. La medida del tiempo de caída de la bolita por el plano inclinado es un dato. Es cierto que depende, en cierto grado, de nuestro diseño experimental y de nuestros aparatos de medida, pero es algo bastante diferenciado de la teoría de la relatividad. Por otro lado, la vena escéptica de los científicos modernos les hizo asumir una buena dosis de modestia intelectual. El conocimiento del mundo natural es falible, esta es una limitación fundamental. Para crear modelos del mundo estamos obligados a hacer inferencias ampliativas, tenemos que dar saltos lógicos inválidos que nos dejan expuestos al error. La subdeterminación, por ejemplo, está al acecho; siempre es posible que hayamos ignorado una teoría mejor. Sin embargo, los modernos no quedaron paralizados por estas limitaciones, sino que concluyeron que debían ser cautos y muy rigurosos porque el camino del conocimiento es traicionero. Además, asignaron distintos grados de confianza a sus ideas. El conocimiento pasó de ser definitivo a convertirse en un proyecto progresivo y colectivo que, con el esfuerzo y el oficio de las distintas generaciones, va aproximándose asintóticamente a la verdad, aunque sin llegar nunca a alcanzarla. Debemos aspirar a la verdad, pero conformarnos con aproximaciones justificadas. Sin embargo, sería un error pensar que el hecho de que nuestras teorías sean falibles implica necesariamente que nuestras ideas vayan a ser completamente equivocadas. Aunque su ontología puede cambiar radicalmente, cualquier teoría futura, al menos en los territorios mejor explorados empíricamente, tendrá una estructura similar a la de las actuales. A esta cuestión también le dedicaremos espacio en capítulos posteriores. Por otro lado, que la justificación haya de ser eminentemente empírica no implica que la relación entre observaciones y teoría no sea sutil. La Tierra no parece moverse, pero nuestras teorías afirman con rotundidad que sí lo hace. Además, en ciencia podemos conformarnos con que las vacas sean esféricas a pesar de que existe una clara tensión entre rendirse a los datos y descartar aquellos que no parecen relevantes. Las observaciones se engarzan en complejas redes teóricas cohesionadas por la exigencia de coherencia lógica. Esto hace que la falibilidad de cada dato individual no sea tan relevante, pero complica el análisis filosófico de la relación entre observación y teoría y hace que la evaluación de los resultados sea difícil y sujeta a controversias. Además, como comentaremos, la justificación de las hipótesis no siempre será inmaculadamente epistémica y, en mayor o menor grado, podrán influir motivos no epistémicos. La comunidad hace la ciencia: juzga qué observaciones son fiables, qué teorías y justificaciones aceptables y, en última instancia, alcanza o no consensos. La comunidad, en principio, deberá seguir las recomendaciones y normas epistémicas que rigen la justificación de evidencias y teorías, aunque, como también comentaremos, estas normas, en muchos casos, exigen interpretación y la comunidad no siempre obedecerá incentivos perfectamente alineados con la generación de conocimiento. Por último, es importante recordar que la ciencia no es más que nuestro mejor intento colectivo de conocer el cosmos. Ciencia, como su etimología nos recuerda, no es más que conocimiento del mundo externo, por lo que si alguien dice oponerse a la ciencia está oponiéndose a ese conocimiento. Esto no implica que el crítico racional no tenga cabida, sino que, si se cree avalado por los datos y la lógica, debe buscar la confrontación con la comunidad de expertos, de no hacerlo estaría renunciando a participar en el proyecto colectivo de generación de conocimiento. "],["modernos_y_reaccionarios.html", "10 Modernos y reaccionarios 10.1 Ciudadanos modernos 10.2 Ilustración y progreso 10.3 La reacción 10.4 Los nostálgicos de la ignorancia 10.5 El romanticismo de la visión científica 10.6 Ciencia romántica 10.7 Ciencia y filosofía 10.8 Iglesia y religión 10.9 El lamento por los relatos 10.10 Ciudadanos del mundo", " 10 Modernos y reaccionarios Durante los siglos XVI, XVII y XVIII tanto la forma de hacer ciencia como las estructuras sociales sufrieron una profunda transformación. El mundo fue acostumbrándose a las noticias, cada vez más frecuentes, de nuevos descubrimientos geográficos, a los prodigios descubiertos por los filósofos naturales y a los creados por los artesanos en sus talleres como, por ejemplo, a los nuevos mundos mostrados por los microscopios y los telescopios. En paralelo, las viejas instituciones medievales iban dejando paso a un nuevo orden controlado por la burguesía. El mundo estaba cambiando y se revelaba extraño, pero los filósofos naturales confiaban en que la razón sería capaz de entenderlo. Newton publicó sus Principia en 1687 y escribió en ellos “Aquí demuestro la estructura del sistema del Mundo”. Los filósofos y pensadores decidieron replantearse el orden social, y para hacerlo tuvieron muy en cuenta los éxitos que la razón y la observación había deparado a los filósofos naturales. El asombro y la reverencia ante los éxitos de Newton fueron prácticamente unánimes, Alexander Pope, el poeta inglés del XVIII afirmó: La naturaleza y sus leyes yacían en la oscuridad de la noche y Dios dijo, sea Newton y se hizo la luz. 10.1 Ciudadanos modernos El mundo medieval fue relegado al recuerdo y la sociedad entró en la modernidad. Para ilustrar esta transición el autor David Wootton contrasta el mundo intelectual de un inglés educado en 1600 con el de otro de 1733. El ciudadano de 1600 “tenía un par de docenas de libros, creía en las brujas y en los hombres lobo (…), pensaba que Aristóteles era el filósofo más importante de la historia y que Plinio, Galeno y Ptolomeo eran las autoridades absolutas en historia natural, medicina y astronomía.”749 Mientras que el de 1733 “poseía cientos o miles de libros, no conocía a nadie sofisticado que creyese en las brujas (…). Creía que la Tierra giraba alrededor del Sol, había visto una máquina de vapor y estaba convencido de que la ciencia iba a transformar el mundo y que los modernos habían adelantado a los antiguos en todas las áreas del conocimiento.”750 El intelectual de 1700, despojado de las certezas medievales, se enfrentaba con confianza, y mediante la ayuda de la observación y la reflexión rigurosa, a la tarea de descubrir los secretos del mundo natural, de construir nuevos sistemas filosóficos y de plantear nuevos órdenes sociales. La filosofía disfrutó en esta época de su segunda edad de oro. Entre 1630 y la revolución francesa trabajaron los pensadores que sentaron las bases de nuestra filosofía contemporánea. Entre ellos se podría destacar a: Descartes, Hobbes, Spinoza, Locke, Leibniz, Hume, Rousseau o Voltaire. Estos intelectuales modernos aunaban un desprecio, probablemente excesivo, por la alambicada filosofía medieval con un profundo interés por las nuevas ciencias. Un interés que no se limitaba a la curiosidad, sino que, en muchos casos, hacía que las practicasen. No es casual que en nuestras asignaturas de secundaria y bachillerato estudiásemos a Descartes y a Leibniz tanto en las clases de matemáticas como en las de filosofía. La duda cartesiana suele iniciar los primeros cursos de filosofía moderna, mientras que su geometría es la piedra de Rosetta que relaciona la geometría con el análisis matemático. Y Leibniz, el codescubridor del cálculo diferencial e integral, fue un importante metafísico especulativo. 10.2 Ilustración y progreso La ilustración fue, a la vez, un movimiento social y un proyecto filosófico que pretendía aplicar los principios de la revolución científica a todos los aspectos de la sociedad.751 Su aproximación se basaba en aplicar el empirismo y el uso de la razón para repensar y superar las ideas medievales. Y esta refundación no pretendía abarcar tan sólo el mundo natural, sino, también, cualquier aspecto relevante, incluidos los sociales. Una de las obras más emblemáticas de este movimiento es La Enciclopedia. El objetivo de sus 17 volúmenes, publicados entre 1750 y 1760, era recoger todo el conocimiento de la época. Entre los referentes enumerados en la introducción por d’Alembert, uno de sus principales creadores, se encontraban tanto filósofos como filósofos naturales: Francis Bacon, Descartes, Newton y Locke. A pesar de lo que pudiese pensarse, los resultados de esta nueva aproximación se materializaron antes en el cambio social que en la tecnología. Newcomen no diseñó su máquina de vapor hasta 1712 y Watt propuso sus mejoras entre 1763 y 1775, mientras que la Declaración de independencia, fruto de la primera revolución política ilustrada, la americana, fue firmada el 4 de julio de 1776. Tampoco es casualidad que varios de los firmantes de esa declaración, profundamente laica y republicana, fuesen científicos aficionados.752 Los ilustrados compartimos una creencia firme, nuestro mundo puede ser mejorado mediante el conocimiento y nos proponemos revisar cada asunción intelectual puesto que, en innumerables ocasiones, los dogmas y las creencias erróneas han demostrado oponerse al progreso humano. Nuestras principales herramientas para conseguirlo son la observación, la razón, que tiene que incluir la cantidad precisa de duda y prudencia, y un profundo respeto por los seres humanos. La propia confianza en el progreso se convirtió en una de las fuerzas del cambio. Es cierto que antes de la modernidad ya eran sabedores de que el mundo había cambiado en el pasado. Los renacentistas, por ejemplo, distinguieron la antigüedad, la época posterior a la caída de Roma y el renacimiento como épocas claramente diferenciadas. Sin embargo, mientras que los renacentistas medievales asumieron el pasado clásico como la meta a la que aspirar, los ilustrados confiaban en que sus capacidades les permitirían llegar más allá. Además, existe una diferencia fundamental entre creer que ha habido cambios y pensar que uno puede influir en ellos. La idea de que el progreso es responsabilidad nuestra era nueva y también lo era el método propuesto para conseguirlo: observación, estudio riguroso, discusión racional y colaboración.753 Esta actitud nos convierte, para lo bueno y para lo malo, en responsables últimos de lo que ocurre. Ya no nos creemos estar a merced de la providencia de un padre invisible y mudo. El ilustrado asume su responsabilidad, nuestras acciones tendrán consecuencias, y cree que mientras nos abandonemos al prejuicio y al dogma, nuestro mundo retrocederá y sólo la disciplina intelectual y el respeto por lo humano nos harán progresar. Es difícil establecer paralelismos entre mundos intelectuales muy distintos, pero tal vez esta actitud ilustrada ante el progreso no fuese completamente nueva en la historia. Los sumerios eran conscientes de haber construido la primera ciudad, de haber fundado la civilización. Y, más recientemente, en el mundo helenístico también fueron conscientes del progreso tecnológico. El estoico Crisipo de Solos (281-208 a. C.) sabía que su tiempo estaba poblado por máquinas desconocidas para Aristóteles754 y Séneca (4 a. C.- 65 d. C.). Crisipo escribió: “Llegará el día en el que lo que desconocemos será traído a la luz (…) y nuestros descendientes se maravillarán de que ignorásemos los hechos más elementales.”755 Esta confianza en el progreso se hizo trágicamente patente en la figura del ilustrado Nicolas de Condorcet. Este matemático, mientras se encontraba escondido de los revolucionarios franceses en una pequeña habitación, y poco antes de ser atrapado y ejecutado, escribió una obra expresando su confianza en el progreso, su Bosquejo de un cuadro histórico de los progresos del espíritu humano. Ni el caos político ni el terror fueron capaces de destruir el convencimiento del ilustrado en el poder de la razón como fuerza de progreso. Podemos pensar que el optimismo de Condorcet fue exagerado, pero lo cierto es que tenía razón. Aquí estoy, dos siglos después de su muerte, rodeado de libros, con el conocimiento de la humanidad a mi alcance, acompañado por casi 8000 millones de personas, con unos índices de pobreza y analfabetismo extraordinariamente bajos y con una esperanza de vida inimaginable hace tan sólo cincuenta años.756 Son muchos los que intentan minimizar estos logros, pero me pregunto cuántos de ellos estarían dispuestos a volver a la época de Condorcet o a cualquier otra anterior en la que se viesen obligados a vivir sin internet, sin teléfonos, medicinas, comida o agua potable. Siempre estaré abierto a discutir sobre la relación entre el conocimiento y el progreso, pero advierto que pondré una condición, dado que me interesan mucho los diálogos racionales, pero poco las discusiones sin fundamento, exigiré que la discusión sea racional, que se aporten datos y no sólo anécdotas u opiniones. Que yo defienda la obviedad de que en los últimos dos siglos hemos mejorado material y moralmente no implica que esté asumiendo que el progreso sea automático o uniforme. El progreso siempre será un proyecto inacabado y plagado de problemas. Aunque nuestros esfuerzos han conseguido que mejoremos, también han tenido gravísimas consecuencias negativas. El cambio climático, la contaminación o la destrucción de los ecosistemas, por ejemplo, son responsabilidad nuestra y nuestra es también la responsabilidad de intentar limitar esos estragos sin destruir el bienestar que hemos obtenido. Conseguirlo no es sencillo puesto que cualquier acción encaminada a solucionar estos problemas puede, potencialmente, causar otras consecuencias negativas. Los sistemas de los que depende nuestro bienestar, como el agrícola o el sanitario, son muy complejos y difíciles de predecir. Y, además, en muchos casos, en un mundo de recursos limitados las acciones tomadas para mejorar algún aspecto pueden exigir compromisos. Lo que no es una opción válida es la inmovilidad o el desánimo, abandonar el timón y dejar el barco a la deriva sería una acción criminal. Muchos creyentes religiosos asumen que su destino no está en sus manos y se limitan a esperar el dictado de su ente sobrenatural preferido, pero recordemos que lo que la legendaria caja de Pandora guardaba en su fondo no era otra cosa que la esperanza. Los griegos clásicos creían que limitarse a confiar en una esperanza irracional tendría consecuencias nefastas y que un humano tenía el deber de tratar de labrar su propio destino. Nuestra rendición conduce al hambre y la enfermedad, pero si nos esforzamos por analizar racionalmente los resultados de nuestras acciones aprenderemos sobre nuestro mundo interconectado y tendremos la oportunidad de seguir progresando. Sin embargo, al mismo tiempo, el ilustrado asume que nunca deberemos olvidar que el progreso siempre será un proyecto inacabado y hace suya una crítica racional constante tanto a los objetivos como a los medios. La propia idea de que queremos progresar implica el reconocimiento de que no vivimos en el mejor de los mundos posibles. Sólo asumiendo nuestras limitaciones actuales tendremos la oportunidad de aprender y mejorar. Creo que las palabras de la historiadora y novelista Ada Palmer resumen perfectamente las enseñanzas de Condorcet:757 El progreso no es inevitable, pero está ocurriendo, no es diáfano, pero es visible, no es seguro, pero es beneficioso, no es lineal, pero es direccional, no es controlable, pero depende de nosotros. De hecho, depende sólo de nosotros. 10.3 La reacción Como era de esperar no a todo el mundo le entusiasmaron las ideas ilustradas. A la Iglesia Católica, por ejemplo, no le gustó que se cuestionases sus dogmas y que se propusiesen sistemas políticos laicos. E incluso dentro de las propias filas ilustradas hubo voces discrepantes. Una de las más relevantes fue la de Jean-Jacques Rousseau (1712-1778). Según Rousseau los seres humanos son buenos por naturaleza, mientas que la reflexión intelectual, las artes, las ciencias y la sociedad engendran vicios y corrupción.758 Sin embargo, los paseos campestres y el trabajo agrícola, que el propio Rousseau nunca practicó, sí serían buenos para el espíritu.759 Este intelectual caracterizó a la astronomía, por haber nacido a partir de la astrología, como hija de la superstición, a la física como curiosidad indolente y a la geometría como la formalización de la avaricia, y añadió que la ciencia conoce poco y yerra mucho.760 Por último, la tecnología, como era de esperar, sería, también según Rousseau, negativa. La imprenta, por ejemplo, no hacía más que reproducir los errores y las extravagancias de la mente humana (entre las cuales no sé si habría estado de acuerdo en incluir la suyas). Esta reacción ante las propuestas ilustradas sigue teniendo eco en la actualidad. Pocas diferencias aprecio entre las propuestas de Rousseau y los programas políticos y sociales de la mayoría de los pseudoecologistas actuales que, con la excusa de la defensa del medio ambiente, critican los resultados de dos siglos de progreso sin proponer más alternativa que las quimeras y el hambre. Hoy en día se observa en la sociedad una actitud que podría calificarse, cuanto menos, de ambivalente frente al conocimiento. Por un lado, cuando alguien está sano es común que se encomiende a charlatanes y pseudoterapeutas y, sin embargo, al enfermar seriamente es común que exija una respuesta rápida de la medicina “alopática”, mientras que, al mismo tiempo, asocia a la ciencia y a lo artificial con lo malo. Lejos queda la sensibilidad estética del conde de Buffon, uno de los principales naturalistas del XVIII, que relacionaba lo natural con lo peligroso y los jardines cuidados con lo bello.761 En nuestro mundo contemporáneo el Doctor Frankenstein y el monstruo fruto de su soberbia son una de las principales referencias culturales. Para calibrar las actitudes ante un grupo o un fenómeno social podemos observar el retrato que hace de ellos la cultura popular. Por ejemplo, durante décadas, el cine encasilló al colectivo homosexual en papeles cómicos, trágicos o criminales. Al lector interesado en repasar esa historia le recomiendo el excelente documental El celuloide oculto. Pensé en elaborar una lista de películas en las que el científico fuese un personaje negativo, sin embargo, como no quiero que esta sección se alargue durante páginas, y dada mi profesión, he preferido limitarme sólo a los genetistas. Podría comenzar con Frankenstein, La isla del doctor Moreau o Los niños del Brasil, pero seamos más estrictos con la definición de genetista. En El dormilón de Woody Allen fuimos los que creamos frutas y verduras gigantes que, por supuesto, estaban malísimas. En la distopía Gattaca, una actualización de Un mundo feliz, conseguimos erradicar la enfermedad mediante la selección de embriones, algo que, al parecer, debe de ser terrible porque interfiere con la libertad individual, y en Código 46 tres cuartos de lo mismo. En Blade Runner creamos esclavos y en El ataque de los clones el ejército clon. En Parque Jurásico trajimos de vuelta a los dinosaurios alterando el orden natural y causando el caos, primero en una isla y luego en el mundo entero. En Species conjuramos a la terrible Sil y en Doom: la puerta al infierno añadimos “cromosomas marcianos” a personas normales transformándolos en monstruos infernales. En el nuevo Spiderman la radiactividad se cambió por la ingeniería genética y Lagarto, uno de los supervillanos, es un ingeniero genético ataviado con bata. En Sense8, la excelente serie de Netflix, trabajamos para una corporación que está intentando acabar con la diversidad humana y en Resident Evil, a sueldo de otra empresa, sintetizamos el virus que convirtió a la humanidad en zombis. En Splice: experimento mortal creamos a la peligrosa Dren (empollón deletreado al revés en inglés) y en Detective Pikachu a Mewto, pero nos olvidamos de ponerle corazón. Menos mal que Pikachu es tan mono que consiguió convencer a Mewto. Lo de Dren acabó peor. Y, lo que más me duele, es que en el episodio 23 de Star Trek fuimos los padres de Kahn, uno de los villanos más terribles de esta serie humanista. Algunos payasos se quejaron de la imagen que It había dado de su gremio, sin embargo, yo estoy tan acostumbrado a ser el malo de la película que me hace hasta gracia reconocer el odio que subyace en la sociedad contra nosotros. Hemos llegado a ser un cliché tan grande, que en Venom, para que sepas quién va a ser el malo, te dejan claro que, aunque ahora se dedica a hacer cohetes espaciales, antes fue genetista. Resulta profundamente irónico que el único genetista hollywoodense positivo que puedo recordar aparezca en Contagio, la excelente película de Steven Soderbergh. En 2020 fuimos conscientes de que el futuro se parecía más a esta excepción que a la regla representada por Parque Jurásico, Doom o Detective Pikachu. En días conseguimos crear varias vacunas y en menos de un año las habíamos probado satisfactoriamente. No seré yo quien rechace el valor de la crítica racional ni quien niegue las enormes consecuencias negativas de la tecnología, pero criticar sin reconocer al mismo tiempo las ventajas de los avances que hemos conseguido no es racional ni justo. Además, una parte importante de estas quejas parten de un desconocimiento profundo de las áreas censuradas. Por ejemplo, llevamos décadas con un debate sobre los transgénicos que no puede calificarse más que de absurdo. Después de este tiempo, la profesión del mejorador genético sigue siendo desconocida para la sociedad. Aunque hemos perdido miles de horas en discusiones estériles, casi nadie ha aprendido que las variedades de fruta, verdura o cereales que compra en el supermercado son el resultado de un esfuerzo tecnológico sostenido que, entre otras cosas, ha conseguido multiplicar por tres la productividad de los campos de cereales desde los años 60. 10.4 Los nostálgicos de la ignorancia Otra de las reacciones negativas al conocimiento generado por las nuevas ciencias provino de una parte del movimiento romántico que reaccionó ante lo que percibían como la mirada fría de los filósofos naturales. Por ejemplo, según Poe (1809-1849), en Soneto a la ciencia, la investigación marchitaba el corazón del poeta, el ensayista Charles Lamb (1775-1834) escribió que Newton no creería en nada que no viese tan claro como los lados de un triángulo (algo que al parecer era negativo), John Keats (1795-1821) es famoso por recordarnos que Newton destruyó la poesía del arcoíris al reducirlo a un prisma y el poeta y pintor William Blake (1757-1827) se lamentó de que las matemáticas se hubiesen convertido en la prisión del petirrojo. Estos sentimientos podrían resumirse con las palabras del ensayista británico Thomas Carlyle que, en 1829, escribió en su Signo de los tiempos: “en la edad de las máquinas el romanticismo y el asombro están muriendo de mano de la medida y el número”. Antes de continuar es importante destacar que esta posición, como veremos, no fue uniforme entre los románticos, los poetas Goethe (1749-1832), Samuel Taylor Coleridge (1772-1834) o William Wordsworth (1770-1850), por ejemplo, estaban profundamente interesados por el conocimiento del mundo natural. Y es normal que lo estuviesen ya que el conocimiento, como enfatizó Feynman, no resta, sino que añade. Lo que Blake o Keats añoraban no era el arcoíris, sino la ignorancia. La belleza del arcoíris no se merma cuando alguien comprende su física, incluso me atrevería a decir que ese conocimiento añade belleza a su contemplación. Me resulta extraño que alguien se sienta atraído por la ignorancia. ¿Dónde reside la magia de la incultura? ¿Acaso no nos empobrece desconocer las cuestiones más básicas sobre el funcionamiento de nuestro mundo? Alexander von Humboldt (1769-1859), que podría ser considerado el epítome de la aproximación romántica a la naturaleza, dijo que la ciencia no podía matar la fuerza creativa de la imaginación, sino todo lo contrario, era portadora del asombro y la emoción.762 Tal vez parte del problema de los nostálgicos de la ignorancia se deba a que basan su visión del mundo en cuentos que saben frágiles, relatos que la razón puede llevarse con un ligero soplo.763 No es que les apene que Newton destejiese el arcoíris, sino que sus mitos sufriesen el destino de los unicornios o los centauros. Si uno elige postrarse ante simples figuras de madera llamándolas dioses, es normal que le siente mal que alguien las señale como fruto de la imaginación. En los antiguos relatos, el mundo estaba habitado por espíritus, sin embargo, la ciencia moderna encontró un mundo lleno de átomos no de seres sobrenaturales.764 El lamento de los nostálgicos de la ignorancia no es muy distinto de la pataleta del niño que acaba de darse cuenta de que Papá Noel no existe. Otra parte del problema, tal vez, surja de la dificultad de la visión científica del cosmos. Es fácil entender un cuento o un mito, ya que, al fin y al cabo, se crearon para tener dimensiones humanas, pero el logos es inhumano e indiferente y no hará ningún esfuerzo por acercarse a ti; eres tú quien tiene que estudiar con ahínco para recorrer el camino. Alguien, puede que fuese la fotógrafa americana Berenice Abbott parafraseando a Goethe, escribió que pocos son los que tienen la imaginación para la realidad. Las conclusiones científicas son, en muchas ocasiones, contraintuitivas, se oponen a nuestras intuiciones más básicas:765 los objetos se mueven aunque no actúe fuerza alguna sobre ellos, la Tierra no es plana y gira a una velocidad fabulosa, las especies cambian a lo largo de tiempos inimaginables y la noción de ocupar una posición concreta en el espacio carece de sentido en la escala atómica. La estructura del cosmos es inhumana y aproximarse a ella exige estudio e inteligencia. Entender el arcoíris, por desgracia, no es fácil, por lo que a uno puede tentarle rendirse y optar por elogiar su propia ignorancia. Sin embargo, es importante recordar que la principal víctima de esta renuncia no será el cosmos, sino nosotros mismos. Podemos elegir no hacer el esfuerzo de entender la evolución, pero quienes sufriremos la próxima pandemia seremos nosotros. La Tierra continuará girando independientemente del grado de nuestra estupidez. 10.5 El romanticismo de la visión científica Gracias a la ciencia conocemos la danza evolutiva que ha creado los virus, los colores de las flores y los ojos de los insectos y podemos maravillarnos con lejanas colisiones galácticas y microscópicos arabescos moleculares. El conocimiento no sólo no resta, sino que emociona. Cada vez que vuelvo a ver a Armstrong pisando la Luna por todos nosotros o a Goodall estudiando a los chimpancés, cada vez que imagino el día que Noether entendió las simetrías del logos o el momento en el que Galileo observó su primera parábola, siento una emoción reverencial. Estas experiencias nos acercan a lo sublime tanto como Beethoven o las pinturas paleolíticas de Chauvet y me apena que haya quien rechaza esta posibilidad de sentirse en comunión, en contacto profundo, con el cosmos, con algo mucho más grande que nosotros mismos. Habrá quien ante estas experiencias utilice términos tales como espiritualidad o trascendencia, sin embargo, yo prefiero evitarlos puesto que este deleite no requiere creencia alguna en lo sobrenatural. El reconocimiento del orden del cosmos, del logos, y de nuestro humilde rincón en él son más que suficientes para maravillarme. Sagan nos transmitió esta idea con maestría. Por otro lado, me entristece que este sentido de la maravilla se pierda cuando se enseña la ciencia en el colegio. Cada vez que un profesor resuelve un problema sobre planos inclinados sin explicar lo que significaron para Galileo me rompe un poquito el corazón. Los románticos estaban profundamente interesados por la naturaleza y por su relación con lo humano, por lo que no es de extrañar que muchos de ellos quisiesen conocerla. Los poetas románticos ingleses, Byron (1788-1824) y Shelley (1792-1822) estaban muy interesados por la ciencia y Coleridge y Wordsworth eran habituales de la Royal Society. Tal era la afición de algunos de ellos que, en algunos casos, la elección de recordar a un autor como poeta o como científico llega a ser un tanto convencional. Goethe estaba fascinado por la botánica y amasó una colección de dieciocho mil rocas,766 mientras que Humphry Davy (1778-1829), recordado hoy en día, con justicia, como un gran químico, era también poeta y en sus cuadernos de notas alternaba las descripciones de sus experimentos con su reacción emocional ante los mismos. La idea de las dos culturas me parece completamente absurda, si uno aspira a entender el mundo y nuestro papel en él, no puede permitirse renunciar a ninguna perspectiva. Las dos aproximaciones son complementarias y en ningún caso debemos considerarlas como aisladas. Uno puede no conocer a Cervantes, a Tolkien, a Galileo o a Noether, sin embargo, mientras en los dos primeros casos en nuestra sociedad se le considerará inculto, en los dos últimos podrá enorgullecerse de no saber de números. No son números, idiota, son las entrañas del logos que enmarca tu papel en el cosmos. Recuerdo con agrado una conversación entre el novelista Cormac McCarthy y el director de cine Werner Herzog, en la radio pública de Estados Unidos, discutiendo sobre detalles de física de partículas y sobre la hipótesis Riemann con el físico Lawrence Krauss; esta debería ser la norma, aunque, por desgracia, sea la excepción.767 Wordsworth expresó algo muy similar en el prefacio a las Baladas líricas que escribió junto a Coleridge: El poeta (…) estará dispuesto a seguir los pasos del hombre de ciencia (…), estará a su lado transmitiendo la sensación de los propios objetos de la ciencia. Los descubrimientos más remotos del químico, el botánico o el minerálogo, serán objetos del arte del Poeta” 10.6 Ciencia romántica Lo que sí hicieron los románticos fue proponer y utilizar una aproximación a la ciencia distinta a la de los primeros filósofos naturales modernos, una aproximación que podríamos denominar ciencia romántica y que en el mundo germano se conoció como Naturphilosophie. Probablemente el representante más destacado de esta actitud fue Humboldt, explorador, naturalista y logófago, que, apasionado por el mundo que le rodeaba, decidió recorrerlo, medirlo y clasificarlo. Humboldt fue un hijo típico de la ilustración que siempre defendió la libertad, la igualdad, la tolerancia y la importancia de la educación.768 Sin embargo, la actitud de los románticos frente al objetivo del conocimiento científico contrastaba con la de algunos filósofos modernos. Mientras que Francis Bacon defendía el estudio del mundo natural como medio para controlarlo, a él se le atribuye la frase “el conocimiento es poder,”769 Humboldt y los románticos perseguían el estudio de la naturaleza como un fin en sí mismo, algo mucho más próximo a la actitud helénica original. Aunque estas dos aproximaciones podrían plantearse como antagónicas, yo creo que son compatibles. La investigación del mundo natural nos permite apreciarlo de un modo más profundo, hace que podamos entender mejor nuestra relación con él y, además, que podamos modificarlo en nuestro beneficio. Sin embargo, esta relación no está exenta de tensión, es cierto que los seres humanos somos animales, pero también lo es que no somos simples animales. Los valores humanos están reñidos con el devenir natural; cada vez que rescatamos a un niño enfermo de la muerte utilizando tecnología médica estamos modificando el mundo natural. La selección natural es inhumana, pero nosotros no lo somos. Al mismo tiempo, los valores del humanista implican un compromiso, porque, aunque siempre deben supeditar el respeto del entorno natural al bien de los humanos, hemos de mantener el legado natural para nosotros mismos y para las futuras generaciones. Los otros seres que habitan el planeta no son nuestros iguales, pero son nuestra familia y no sólo les debemos admiración y cariño, sino protección. Una buena forma de juzgar a un humano es considerar sus acciones hacia los más débiles. Además, aunque debemos modificar el entorno natural en nuestro beneficio, no debemos olvidar que los humanos formamos parte inextricable del ecosistema, que sin agua, aire y nutrientes estamos condenados, una Tierra sin entorno natural sería un espacio muerto en el que los humanos desapareceríamos al instante. El planeta es nuestra casa y el ecologismo irrenunciable. No en vano la etimología de ecología es: el estudio de la casa. Este ecologismo siempre exigirá un equilibrio delicado entre las necesidades humanas y el respeto a los demás seres vivos por sí mismos. Es cierto que incluso aunque pudiésemos vivir completamente aislados, sería una monstruosidad acabar con nuestra familia, pero, por otro lado, aunque un modo de preservar los ecosistemas sería abogar por la completa desaparición de los humanos, esto es algo a lo que el humanista se opondrá con todas sus fuerzas. El mantenimiento de estos dos mundos, el humano y el natural, en un universo de recursos limitados, nos enfrentará continuamente a dilemas que requerirán conocimiento profundo, humildad intelectual, y una buena dosis de generosidad y sabiduría, algo que no alcanzaremos sin una buena educación tanto científica como humanística. El planeta es nuestra casa, debemos protegerlo y, a la vez, humanizarlo. La idea de los ecosistemas, por cierto, se la debemos a los científicos románticos y muy especialmente a Humboldt. Los ilustrados solían enfrentarse a un problema diseccionándolo en pequeñas partes, de forma que cada una de ellas pudiese ser resuelta con mayor sencillez. Esta estrategia funcionó muy bien para aquellas cuestiones en las que las partes eran relativamente independientes, pero está condenada al fracaso cuando el todo está compuesto por partes estrechamente interconectadas y esta fue precisamente la crítica romántica. Humboldt y la Naturphilosophie perseguían una comprensión global, no reduccionista, de la naturaleza. Mientras Descartes pretendía entender a los seres vivos como máquinas formadas por pequeñas piezas listas para ser analizadas, Goethe pensaba que era imposible entenderlos sin una comprensión sintética del conjunto. Humboldt llevó esta idea a su extremo lógico y estudió todo el mundo natural en su conjunto creando así la ciencia de la ecología. En la historia, como hemos visto, unas ideas suelen evolucionar a partir de otras y en este caso podríamos considerar a Spinoza (1632-1677), el gran filósofo racionalista, como el abuelo intelectual de la visión integradora romántica. Spinoza identificó al universo completo con Dios, algo que, a su vez, recuerda al antiguo logos griego. El romántico inglés Wordsworth recogió esta tradición al declararse adorador de la Naturaleza.770 En cualquier caso, estas críticas románticas no estaban dirigidas contra la ciencia, al fin y al cabo, su objetivo era estudiar el mundo natural con las mejores herramientas disponibles, es decir, su ánimo era hacer ciencia. El objeto de sus críticas era el exceso de reduccionismo. Aunque la disección es una estrategia fértil, debe complementarse con una visión del conjunto. Esta es una lección que la ciencia contemporánea no ha olvidado. En algunas ramas tradicionales de la ciencia, como la física o la química el reduccionismo ha funcionado muy bien, pero otras utilizan habitualmente visiones más integradoras. Campos como la física estadística, las teorías de redes y de la complejidad, la biología de sistemas o la ecología parten de visiones holísticas. El problema es que esta aproximación no siempre es fácil, puesto que los sistemas compuestos por numerosas partes estrechamente interrelacionadas suelen tener comportamientos difíciles de reconstruir a partir del análisis de sus piezas. En realidad, ambas perspectivas son complementarias, la microscópica y la global, la reduccionista y la holística. Para comprender el bosque necesitamos observarlo en su conjunto, pero si nos olvidamos de los árboles, poco será lo que hayamos entendido y la ciencia contemporánea no sólo aspira a comprender los árboles, sino, también, los mecanismos moleculares de las células que los componen y tampoco limita su ambición al bosque, sino que estudia el planeta completo en su conjunto. El del reduccionismo es un tema que volveremos a tratar cuando hablemos sobre la aproximación naturalista a la metafísica. Pero volvamos a Humbodlt y a los frutos que obtuvo gracias a la aplicación de estas ideas. Este romántico, fundador de la ecología, aprovechó sus largos y duros viajes de exploración para medir cada detalle del paisaje. Llegó, por ejemplo, a escalar el Chimborazo, una de las montañas más altas de la Tierra, pertrechado con un pesado barómetro para poder medir la presión atmosférica a distintas alturas. Y el conjunto de todas estas observaciones le permitió plantear una novedosa visión del mundo. Humboldt propuso, por ejemplo, que los árboles influían en el clima. Se dio cuenta de que, en los bosques, la evaporación aumentaba la humedad atmosférica y refrescaba el ambiente y de que las raíces protegían el suelo de la erosión. Descubrió, además, que el clima era un factor determinante en los tipos de vegetación de una región e ilustró esta conclusión con un famoso dibujo en el que se observan los distintos ecosistemas que pueblan la ladera del Chimborazo a diferentes alturas. Humboldt también fue el abuelo del ecologismo como propuesta política. Al darse cuenta de la capacidad de los seres humanos para alterar el entorno, nos previno de los problemas que podemos llegar a crear si utilizamos la tecnología sin comprender los sistemas implicados; una lección cada día más relevante. Nadie antes había descrito el impacto negativo de las actividades humanas sobre el medio ambiente y él lo ejemplificó con la deforestación que observó en la actual Venezuela. Se dio cuenta de que la tala masiva de árboles favorecía la erosión de un suelo que ya no volvería a ser fértil y que esto, a su vez, causaba sequías que acababan con las cosechas que se pretendían obtener cultivando el suelo deforestado. La conclusión de Humboldt fue que debíamos seguir trabajando para entender y conservar el mundo natural.771 La romántica es una época fascinante de la evolución científica, pero, por desgracia, bastante desconocida. Recomiendo al lector encarecidamente su estudio puesto que es de vital importancia acabar con la absurda idea de las dos culturas. Por fortuna, en los últimos tiempos han aparecido varios libros bien documentados, profundos y, a la vez, deliciosos que versan sobre esta época. Podrían citarse, por ejemplo: La invención de la naturaleza de Andrea Wulf, La edad de los prodigios de Richard Holmes y The enlightened Mr. Parkinson de Cherry Lewis. 10.7 Ciencia y filosofía Cuando discutimos la ciencia helenística, comentamos que algunos autores defienden que fue en ese momento cuando se separaron por primera vez ciencia y filosofía.772 Sin embargo, como muchos otros autores nos recuerdan, habría que hacer una matización: no fue hasta la Época Moderna, a partir del XVII, en un desarrollo paralelo al helenístico, cuando se consolidó esta división.773 Mientras la ciencia, el conocimiento riguroso del mundo natural, optó por centrarse en el empirismo, la filosofía continuó encargándose de las áreas más alejadas de la observación. Y, además de esta especialización, hubo una cierta tensión por dilucidar cuál de ambas ramas debía ser más fundamental y, por lo tanto, había de tener la última palabra en caso de conflicto. Descartes, por ejemplo, aún consideraba que la ciencia debía sostenerse sobre la metafísica. Pero el éxito de la física y el estancamiento de la metafísica hizo que esta actitud antigua terminase abandonándose. Fue en ese momento cuando la ciencia se emancipó de la metafísica especulativa definitivamente.774 Otros filósofos con actitudes más modernas, como, por ejemplo, Hume, llegaron a criticar duramente a la metafísica por ser oscura y poco rigurosa y por representar un obstáculo para el desarrollo de las ciencias.775 10.8 Iglesia y religión Los filósofos naturales no se hicieron ateos de la noche a la mañana en el siglo XVI,776 la mayor parte de ellos continuó creyendo en alguna entidad sobrenatural creadora del universo. Sin embargo, sí es cierto que hubo cambios profundos, tanto en los dioses como en las relaciones entre la filosofía natural, la teología y las iglesias. Por ejemplo, el papel de los dioses fue alejándose paulatinamente de los seres humanos y fue relegándose al de remotos creadores. De unos dioses cercanos y dispuestos a intervenir, pasaron a creer en otros más lejanos y fríos que abandonaban su creación una vez dictadas las inexorables leyes naturales.777 Esta creencia en dioses creadores hacía que los investigadores de la época entendiesen como complementarios los caminos de la teología y la filosofía natural. Al fin y al cabo, ambas vías estaban tratando de entender la misma creación, la primera gracias a la revelación y la segunda mediante las evidencias y la razón.778 Kepler, por ejemplo, creía estar acercándose a su dios al comprender las leyes de la creación,779 Galileo pensaba que el deber del científico era revelar la gloria de la creación divina780 y Boyle, uno de los padres de la química, al igual que Newton, estaba convencido de que el orden desvelado por la ciencia era un argumento en contra del ateísmo.781 Sin embargo, con el tiempo, fueron apareciendo contradicciones entre la filosofía natural y la teología y fue entonces cuando hubo que enfrentarse a la decisión de quién debía tener la última palabra. El problema es que estas dos aproximaciones, en caso de conflicto, son irreconciliables puesto que, mientras una aboga por la discusión abierta y la justificación basada en evidencias públicas, la otra se refugia en una revelación a la que sólo tienen acceso algunos individuos especiales y que, por lo tanto, no está sujeta a escrutinio público. Para la Iglesia romana la respuesta estaba clara, en caso de conflicto la última palabra debía tenerla la revelación, de hecho, había de tenerla su interpretación particular de las revelaciones que la propia Iglesia había elegido como válidas.782 Esta era una cuestión de vital importancia ya que, como había mostrado el protestantismo, su poder estaba en juego. Durante la Edad Media la Iglesia cristiana trató de reprimir a los profesores universitarios más entusiastas de los filósofos paganos prohibiendo, por ejemplo, algunas enseñanzas en la Universidad de París en 1277, pero la sangre no llegó al río783 y la filosofía aristotélica acabó por ser incorporada, una vez domada, dentro de la cristiana. Puede que esta actitud tibia y relativamente tolerante se debiese a la falta de contestación contra el poder eclesiástico, tanto por parte de los intelectuales, que en su mayor parte trabajaban para la propia Iglesia, como por parte de otras iglesias protestantes, que todavía no habían aparecido. Sin embargo, cuando Giordano Bruno y Galileo se empeñaron, a comienzos ya de la Edad Moderna, en defender el copernicanismo, las circunstancias habían cambiado. Los protestantes habían dejado claro que el poder basado en el consenso doctrinal podía sufrir importantes mermas cuando alguien rechazaba la autoridad religiosa. Además, muchos intelectuales habían pasado a trabajar directamente o indirectamente para la burguesía, por lo que ya no eran tan fáciles de controlar por parte de las autoridades religiosas. La Iglesia católica, en principio, fue bastante generosa con Galileo: comprendió y aceptó la mayoría de sus argumentos en favor del copernicanismo.784 Tan sólo le pidió prudencia y paciencia y le recordó que él, que era el máximo defensor del empirismo, no había presentado evidencias sólidas del movimiento de la Tierra. Y este fue precisamente el núcleo del debate: mientras que Galileo sostenía que el movimiento de Venus alrededor del Sol era incontestable y que su física hacía admisible que la rotación terrestre fuese indetectable, la Iglesia romana le respondía que un asunto tan trascendental no podía zanjarse sin unas observaciones claras. Sin estas evidencias empíricas definitivas el heliocentrismo no pasaba de ser una hipótesis. Galileo intentó medir el paralaje estelar, pero no lo consiguió, y tuvo que postular, de nuevo sin evidencias, que el universo era inimaginablemente grande.785 Posteriormente creyó encontrar en las mareas un apoyo definitivo a su propuesta, pero se equivocó.786 En ciencia, muchas veces, no es fácil conseguir evidencias suficientemente claras en favor de una hipótesis. Dados estos problemas, esta discusión podría llegar a contarse concediendo a la curia romana el papel de defensores del empirismo y a Galileo el de filósofo especulativo. Sin embargo, esto obviaría otro aspecto más profundo del conflicto entre la Iglesia y Galileo. En realidad, la cuestión fundamental no atañía a los cielos, sino al poder y no era otra que quién debía tener la última palabra en caso de enfrentamiento entre la teología y la filosofía. Y, como era de esperar la postura de la Iglesia Católica no podía ser más contundente: ella era la autoridad y si hacía falta quemar a alguien para aclarar la cuestión, había muchas plazas disponibles para organizar ajusticiamientos. La Iglesia y su interpretación de la Biblia no podían estar equivocadas.787 Sin embargo, Galileo, que era creyente, pensaba que, aunque las escrituras no podían estar equivocadas, la interpretación católica sí podía estarlo.788 Pero esto es algo que una curia romana herida por la traición protestante no podía admitir fácilmente. Galileo fue condenado, se le obligó a abjurar del copernicanismo, a ver como se quemaban sus libros prohibidos y a permanecer en arresto domiciliario el resto de sus días.789 Gracias a Dios decidieron no echar también a Galileo al fuego, por lo que todavía pudo escribir durante su arresto alguna que otra obra maestra, que fue escamoteada y publicada en la Holanda calvinista.790 Este lugar de publicación no es casual, en general la censura de la Iglesia Católica sobre los libros fue mucho mayor que la de los fundamentalistas protestantes. Sin embargo, la victoria de la Iglesia romana, tal y como Galileo temía, fue pírrica, el movimiento de la Tierra acabó siendo incontestable y este fallo la condenó al ridículo. La teología sobrevivió, pero, con el tiempo, acabó hundiéndose en la irrelevancia intelectual. Resulta sorprendente observar la magnitud del inmovilismo eclesiástico en este asunto. La enseñanza del copernicanismo no fue permitida hasta el siglo XIX791 y la publicación del libro no se permitió hasta 1968, el año del Apolo 5, el mayo francés y la fundación de Intel. Galileo, pero no Bruno, fue perdonado por fin en 1992.792 E incluso más recientemente, el cardenal, y posterior Papa, Joseph Ratzinger, dictó que el juicio a Galileo había sido razonable y justo.793 A pesar de esto, durante los siglos XVI, XVII y XVIII la convivencia entre religión y ciencia continuó siendo bastante tranquila, los conflictos factuales entre filosofía y teología no fueron demasiado importantes y, en general, los filósofos naturales continuaron siendo creyentes. No fue hasta el XIX cuando dos ciencias de aparición más tardía, la geología y la biología, levantaron la tormenta definitiva. Charles Lyell (1797-1875), uno de los padres de la geología, publicó en 1830 su Principios de geología, una obra que rechazaba que la Tierra hubiese sido creada recientemente.794 Esta crítica al mito de creación cristiano se unía al problema planteado por la inmensidad del espacio interestelar. Si los hombres éramos el centro de la creación, ¿por qué había hecho el dios cristiano un universo tan inhumano, tan inmenso, frío e inaccesible? Sin embargo, el golpe final estaba todavía por llegar. Desde tiempos inmemoriales el argumento principal para defender la existencia de los dioses creadores había sido el del diseño. Si el cosmos está ordenado debía de ser porque un diseñador así lo había decidido. Esta defensa del creador ya había sido criticada por Hume, que apuntó la obviedad de que el argumento no solucionaba problema alguno, ya que sólo lo sustituía por otro, ¿quién había diseñado al diseñador? La crítica de Hume no llegó más allá de los círculos académicos, pero la propuesta evolutiva de Darwin, publicada en 1859, se convirtió en un maremoto que cambió para siempre el terreno de juego. El origen de las especies es una obra en la que las evidencias se acumulan, una tras otra, en favor de un cambio lento y paulatino de las especies. Un cambio que no requiere de ningún diseñador porque hace uso de un mecanismo profundamente inmoral, la erradicación de los individuos peor adaptados. Además, y por si fuera poco, el ser humano dejó de ser una creación divina del paraíso y fue relegado a mamífero esforzado. De un plumazo Darwin nos dejó huérfanos, sin propósito trascendente y, a la vez, nos obligó a asumir nuestra madurez. No hay un propósito trascendente, ni más medida que la humana, por lo que tenemos que buscar nuestros propios objetivos y ser responsables de las decisiones que tomemos. 10.9 El lamento por los relatos La historia de la santísima trinidad es un relato, la teoría gravitatoria de Newton es conocimiento. Ambas creencias son fruto de un consenso, la primera de la comunidad católica, la segunda de la práctica totalidad de los expertos en física del mundo. Pero ambos consensos no son equivalentes, la diferencia fundamental entre ambos estriba en que mientras que los relatos, en muchas ocasiones, se blindan contra la influencia de la realidad externa, el conocimiento científico se construye buscando la contrastación empírica contra esa realidad. Esto no implica que las comunidades científicas sean absolutamente racionales, ni mucho menos, pero sí que, eventualmente, acaban por converger en unas creencias que reflejan, al menos aproximadamente, la estructura de la realidad externa. Esta convergencia es una diferencia clave entre el conocimiento y los relatos. Los conocimientos obtenidos por distintas áreas de la ciencia terminan por converger en una solución integrada. Esto sucedió, por ejemplo, con los físicos y los químicos en el tema de los átomos. Dalton propuso los átomos, a principios del XIX, para explicar las relaciones estequiométricas en las reacciones químicas, pero los físicos no los aceptaron como entidades físicas reales hasta principios del XX. Durante un siglo se mantuvo el desacuerdo, los físicos aceptaban que la idea funcionaba en las reacciones químicas, no discutían las evidencias, pero no pensaban que fuese necesario proponer la existencia de constituyentes fundamentales de la materia que se correspondiesen con esas proporciones químicas. Al final, se obtuvieron las evidencias físicas suficientes y se integraron ambas visiones. Sin embargo, con los relatos sucede lo contrario, la norma es la divergencia, es decir, la profusión de nuevos relatos. El relato cristiano surgió por una escisión del de los judíos, y, a su vez, dio lugar a numerosas nuevas variaciones. Mientras un grupo tuvo poder político suficiente como para acallar esas escisiones, la mayoría de la comunidad mantuvo un relato unificado, pero cuando este control flaqueó surgieron numerosas nuevas versiones, y versiones de versiones, que dieron lugar a una multitud de iglesias independientes. Esta diferencia entre convergencia del conocimiento y profusión de los relatos se debe a que, mientras que el relato se mantiene mediante la imposición o gracias al acuerdo tácito comunitario, el conocimiento tiende a converger adoptando una estructura análoga a la de la realidad externa que modela, una realidad que, por definición, es externa a las creencias de las comunidades que lo generan. Los ilustrados clasificaron la teología cristiana, que hasta el momento había regido el orden social y la discusión intelectual, como un relato más.795 Aunque d’Alembert y compañía no utilizaban el término “relato”, sino “prejuicio”. Diderot, por ejemplo, se divirtió bastante comparando el mito en el que Zeus, transformado en cisne, se aparea con la espartana Leda, con el del Espíritu Santo y la virgen María.796 ¿Por qué debe ser considerado mitológico el primero mientras el segundo se acepta como verdad revelada? Cuando, además, añadiría yo, el griego parece más verosímil, dado que los hijos nacen de un huevo, como corresponde a un padre emplumado. No todas las creencias son igual de eficaces. Si queremos vivir con un mínimo de bienestar la sociedad necesita conocimiento. Siempre ha sido así: ¿Cómo seguir una presa? ¿Dónde y cómo encontrar fruta? ¿Cómo encender fuego o tallar una piedra? En principio deberíamos optar siempre por el conocimiento, los relatos están bien como formas de entretenimiento o como legado cultural, pero confundirlos con la realidad puede llevarnos a tomar decisiones nefastas. Sin embargo, a pesar de esto, es necesario reconocer que la exigencia de rigor intelectual puede tener consecuencias negativas. Las religiones cumplen un papel social independientemente de que sus relatos se correspondan o no con la realidad, ya que lo relevante es que la comunidad que las profesa admita creer en ellos.797 El problema de socavar el cuento del diluvio universal es que al hacerlo se mina también parte del cemento comunitario, por lo que se debilita la estructura social. Rousseau criticó a los ilustrados, que se identificaban con la Humanidad en su conjunto, y no con una nación o con una comunidad religiosa concreta, diciendo que no tenían raíces.798 La mayoría de los seres humanos son profundamente sociales y aislados no pueden florecer, por lo que rendirse a la realidad tiene un coste que los ilustrados debemos reconocer. Este es uno de los motivos por los que la crítica a las creencias que cimientan las distintas comunidades humanas no suele ser bien recibida. Algunos pensadores plantean como alternativa la creación de comunidades basadas en la racionalidad, comunidades en las que la discusión racional sea bienvenida. En cierto modo Galileo o Diderot estaban haciendo algo mucho más radical que admitir la revolución terrestre, lo que estaban planteando era una nueva identidad que tuviese la búsqueda del conocimiento como denominador común.799 Esta es la identidad que yo he adoptado, aunque no sin problemas, ya que para los humanos la crítica, sea esta racional o no, suele tener un coste emocional. Un problema adicional importante es que no es fácil para una comunidad aceptar abiertamente su irracionalidad. Los seres humanos buscamos comprender la realidad, por lo que no admitiremos de buen grado estar siendo irracionales. Esto nos conduce a una paradoja ineludible. Si un católico admitiese que sus creencias son un mero relato arbitrario, estaría socavando su utilidad como argamasa social. Una identidad construida sobre la admisión de la irracionalidad no será fuerte. Por lo tanto, la estrategia más común es asumir el relato irracional como verdadero y, a la vez, defender la racionalidad de esa posición. Es cierto que algunos creyentes religiosos afirman creer sin motivo alguno, pero lo habitual es que traten de justificar su posición aduciendo evidencias. Esto parecería situarlos en el campo de los ilustrados, que estarán dispuestos a admitir cualquier creencia correctamente justificada. Sin embargo, el creyente religioso estará participando en un doble juego, ya que nunca podrá admitir una verdadera posibilidad de crítica a sus ideas, puesto que cualquier variación de sus creencias fundamentales lo alejaría de su comunidad. Es decir, a la vez que afirma estar participando, al menos en parte, en una discusión racional, debe blindarse contra las consecuencias de la misma. La duda, como dijo A. B., es ácido para el hombre (o al menos para el creyente religioso). Uno puede elegir comprometerse con la razón, un camino exigente y autocrítico, o puede rendirse, en mayor o menor grado, a la pereza intelectual y a la complacencia comunitaria e, independientemente, aunque nos decantemos por la irracionalidad siempre podremos seguir proclamando a los cuatro vientos nuestro compromiso con la razón. No hay dos caminos hacia el conocimiento de la realidad, razón o sinrazón, uno se esfuerza por entender el mundo del modo más riguroso posible o no lo hace; pero lo que sí puedes hacer es disimular y siempre estaremos tentados de hacerlo ya que casi todos preferimos ser reconocidos por nuestros pares como seres racionales. Esta actitud no sólo se da en las comunidades religiosas, también es muy frecuente, por desgracia, entre los científicos con los que me he relacionado a lo largo de mi carrera. Esto plantea la cuestión de por qué las comunidades científicas son capaces de generar conocimiento a pesar de que sus miembros están sujetos a algunos incentivos perversos. La respuesta, como veremos, es compleja. En primer lugar, no es igual de difícil conseguir conocimiento sobre todas las cuestiones: la física de los planos inclinados, por ejemplo, es mucho más sencilla que la historia evolutiva de las antiguas bacterias o que la macroeconomía. Además, hay una diferencia significativa entre las comunidades religiosas y las científicas, mientras que las primeras son muy vulnerables a los cambios en sus creencias, ya que basan su identidad en ellas, las segundas fundamentan su identidad en la creación de conocimiento y asumen que las respuestas son tentativas y pueden variar. El cambio de la física newtoniana por la relativista no tuvo como consecuencia la creación de dos comunidades irreconciliables de físicos, pero todas las modificaciones de los dogmas cristianos causaron cismas, guerras o represiones. 10.10 Ciudadanos del mundo Supongo que Rousseau diría que un ciudadano del mundo no es en realidad ciudadano de ninguna parte, pero esta es la propuesta ilustrada: los humanos tienen una naturaleza común y esta debe ser la base de su identidad. Un ilustrado se identifica fundamentalmente como perteneciente a la especie humana, no como miembro de una nación, de una religión o de cualquier otro colectivo concreto. Por lo tanto, la ilustración, como la república de las letras, como las comunidades científicas, es cosmopolita.800 Las identidades basadas en relatos arbitrarios, aunque es cierto que cohesionan a los individuos que los comparten, también los aíslan, al menos en parte, de los otros grupos. Además, los ilustrados defendemos el derecho de los individuos a construir su vida independiente de los designios de la comunidad en la que ha nacido. Por otro lado, si renunciamos a la defensa de la razón y a la identidad como humanos y aceptamos los relatos arbitrarios como principal sostén identitario, será imposible comparar los sistemas morales y legales que rigen las distintas comunidades. La ética colectiva y la legislación internacional son imposibles sin los valores ilustrados.801 Si renunciamos a la razón y a nuestra humanidad compartida, las culturas son inconmensurables y es imposible condenar la esclavitud o la ablación femenina. No niego que la cultura de una comunidad concreta no pueda ser relevante para los miembros de esa comunidad, lo que sostengo es que esa cultura nunca debe estar por encima de nuestra humanidad compartida ni de la razón. La ilustración nos permite, al mostrarnos el camino del diálogo racional, trascender la cultura en la que hemos nacido y nos impele a avanzar más allá de los horizontes que nuestros padres pudieron divisar.802 Diderot escribió que la reverencia por el pasado nos condena a la inmovilidad social e intelectual, algo que un firme creyente en la posibilidad de progreso nunca podrá aceptar. "],["la_perdida_de_la_inocencia_part.html", "La pérdida de la inocencia", " La pérdida de la inocencia "],["contra_el_metodo.html", "11 Contra el método 11.1 Inductivismo, el método moderno 11.2 Deductivismo vs inductivismo 11.3 Tipos de inferencias inductivas 11.4 El método hipotético-deductivo 11.5 Deductivo e inductivo 11.6 Investigación 11.7 Contra el método 11.8 Resumen", " 11 Contra el método Es común pensar que la ciencia se caracteriza por utilizar un método concreto y que es precisamente este método lo que la diferencia de otras aproximaciones al estudio del mundo externo. ¿Cuántas veces has oído que el secreto de la ciencia reside en su método? Por lo tanto, es normal que los filósofos de la ciencia hayan prestado atención a este asunto. Recordemos que Aristóteles y Arquímedes ya discutieron sobre los métodos a seguir para generar conocimiento. 11.1 Inductivismo, el método moderno El antiguo método deductivo aristotélico, o más bien su trasunto racionalista medieval, no se libró del cuestionamiento general moderno a las ideas medievales y muchos de los filósofos de la Edad Moderna terminaron decantándose por un nuevo método, el inductivo. Uno de los proponentes más ilustres de la nueva aproximación fue Francis Bacon. Este pensador escribió que el investigador habría de partir de los datos y, sobre ellos, mediante inferencias inductivas, debería construir sus teorías. En Novum Organum, su principal trabajo, Bacon proponía sustituir el antiguo Organum aristotélico. El objetivo principal de las críticas modernas era la especulación excesiva que caracterizaba a la mayoría de la filosofía escolástica. Recordemos que los autores medievales, en vez de buscar evidencias empíricas, solían afrontar sus investigaciones reflexionando sobre lo leído en antiguos tratados.803 El núcleo de la cuestión es que Bacon proponía que las investigaciones tenían que partir de las observaciones, no de nuestras ideas previas. Esto no implica que el filósofo natural no hubiese de llegar más allá de los datos, todo lo contrario, una vez obtenidas las evidencias empíricas tenía que construir sus teorías sobre ellas, pero debía partir de ellas, no de la teoría. Para explicarlo Bacon utilizó una analogía zoológica: las hormigas recogen observaciones dispersas por el mundo, pero no llegan más allá, las arañas tejen complejas redes teóricas a partir de sus propias entrañas, pero no se preocupan lo suficiente por las evidencias, mientras el ideal baconiano, las abejas, partiendo del polen obtenido en las flores, que equivaldría a los datos, son capaces de crear la miel.804 Según Bacon, un investigador debería hacer observaciones y experimentos cuidadosos y, a partir de los resultados obtenidos, proponer hipótesis que organizasen estas observaciones.805 A estos filósofos que proponían como clave del conocimiento del mundo natural la generalización a partir de las observaciones concretas se los denominó inductivistas. Tal vez esta aproximación se entienda mejor mostrando algunos ejemplos. El trabajo de Gilbert sobre el magnetismo, el paradigma del método experimental, podría constituir un buen ejemplo de la aproximación inductiva. Partiendo de una serie de experimentos concretos este investigador alcanzó un conjunto de conclusiones generales sobre el magnetismo, por ejemplo, que las brújulas apuntan al norte porque la Tierra posee un campo magnético. Varios filósofos de la ciencia del siglo XX han elegido como muestras del inductivismo otras investigaciones. Por ejemplo, el lógico y epistemólogo Carl Hempel (1905-1997) utilizó el caso del húngaro Ignaz Semmelweis (1818-1865).806 Este cirujano y obstetra observó que la clínica de sus colegas tenía una mortalidad de tres a cinco veces mayor que la clínica atendida por matronas.807 El cirujano se planteó diversas posibles causas para las fiebres mortales y fue evaluándolas mediante nuevas observaciones. Sopesó, por ejemplo, la posibilidad de que el exceso de muertes fuese debido al hacinamiento, al clima, al estrés emocional causado por las visitas del sacerdote, que acudía habitualmente a dar la extremaunción, o a la vergüenza causada en las parturientas por el hecho de que sus médicos fuesen varones. En 1847 Semmelweis hizo una observación clave, su amigo, el profesor Jakob Kolletschka, que murió tras cortarse con un bisturí cuando estaba realizando una autopsia, mostró lesiones muy similares a las de las embarazadas fallecidas. A partir de esta y otras observaciones Semmelweis infirió que los estudiantes debían de estar contaminando a sus pacientes con partículas cadavéricas. Los estudiantes de medicina se lavaban las manos con agua y jabón tras realizar las autopsias, pero el olor cadavérico persistía, por lo que Semmelweis instauró la práctica de frotarse las manos con hipoclorito cálcico y esta intervención sí consiguió reducir la mortalidad y eliminó las diferencias entre la clínica atendida por los futuros médicos y la de las matronas. Puede que, desde nuestra perspectiva, la aproximación de Semmelweis no llame demasiado la atención, pero fue completamente moderna. Un escolástico enfrentado al mismo problema habría optado por leer textos clásicos en busca de algún principio teórico general que explicase las observaciones. Sin embargo, la propuesta moderna sigue el camino contrario, parte de las observaciones y, en este caso, ni tan siquiera se llegó plantear una hipótesis definida sobre lo que estaba sucediendo más allá de proponer unas vagas partículas cadavéricas. Hay que tener en cuenta que en aquel momento la teoría de la infección causada por gérmenes aún no se había desarrollado. Este desconocimiento, junto a un posible corporativismo, fue uno de los motivos por los que la profesión médica no se tomó en serio las conclusiones de Semmelweis, que fue despedido y terminó sus días en una institución mental. Sus ideas no terminaron de aceptarse hasta que Louis Pasteur desarrolló la teoría microbiana. Otro de los grandes filósofos de la ciencia del siglo XX, Imre Lakatos (1922-1974), propuso la inferencia de la gravedad newtoniana como ejemplo de la aproximación inductiva.808 En este caso también se partió de las observaciones, concretamente de las de Tycho Brahe, que había recogido, noche tras noche, las posiciones de cada uno de los planetas visibles en el cielo. Brahe habría sido la hormiga baconiana. Estas observaciones astronómicas podríamos imaginarlas como una serie de puntos en un plano cartesiano. La posición de un planeta, por ejemplo, de Marte, observada en una noche concreta sería un punto en este plano y estos puntos constituirían la base de la primera inferencia inductiva, la que llevó a cabo Kepler, la primera abeja de esta historia. Este matemático trató de ajustar distintas curvas al patrón de puntos observado por Brahe. Ya hemos comentado que hizo varios intentos con círculos sencillos y con epiciclos antes de dar con una solución, la de la órbita elíptica, que se ajustaba con mayor precisión a las observaciones. Este resultado, reflejado en las leyes de Kepler, constituyó un primer éxito inductivo, la primera miel. Kepler, a partir de unas observaciones particulares, de unos puntos concretos, sin un marco teórico que le ayudase, obtuvo unas leyes generales. En realidad, lo que hizo Kepler fue resumir las observaciones de Brahe muy eficientemente, convirtiendo una larga serie de puntos en una sola curva. Sin embargo, este éxito, de nuevo, no se acompañó de propuesta teórica que explicase por qué las órbitas eran elípticas y no circulares. Posteriormente Newton, la segunda abeja de esta historia, infirió su ley gravitatoria partiendo de unas conclusiones previamente elaboradas: las leyes de Kepler. El inglés planteó su teoría de la gravitación universal, precisamente, para dar cuenta de esas leyes. Sobre si esta inferencia fue una deducción, tal y como pretendía Newton, que aspiraba a continuar la tradición aristotélica transmitida por Galileo, o una inducción ha habido bastante controversia entre los filósofos de la ciencia.809 Baste decir que el resultado newtoniano, aunque partió, efectivamente, de las leyes de Kepler, no se corresponde exactamente con éstas.810 En realidad, las órbitas planetarias calculadas usando la teoría newtoniana no son exactamente elípticas ya que unos planetas interfieren en las órbitas de los otros. Las leyes de Kepler son sólo correctas en primera aproximación. Este es un nuevo ejemplo de que, en ciencia, la relación entre observación y teoría puede ser muy sutil y en este caso, como en muchos otros, la teoría sólo se ajusta aproximadamente a los datos originales. A esto hay que añadir que el propio Newton, con un famoso Hyphotehsis non fingo, insistió, en que sus leyes eran descriptivas y que él tampoco se atrevía a proponer ninguna teoría profunda sobre por qué los planetas y las manzanas seguían esas leyes. Entendida de este modo, la teoría gravitatoria newtoniana sería una mera descripción sin ambición metafísica alguna. Esta modestia metafísica se deriva del empirismo moderno, uno puede llegar más allá de las observaciones, pero sólo hasta un cierto punto, y contrasta con la osadía de los racionalistas clásicos y medievales que, agarrándose a unas míseras intuiciones, no tenían el menor reparo en tratar de asaltar los cielos. La actitud del empirista moderno, en cambio, es más cauta: describamos lo observado eficientemente, pero limitemos la especulación teórica. A esta cuestión le dedicaremos una discusión más amplia cuando volvamos a hablar sobre metafísica. 11.2 Deductivismo vs inductivismo La aproximación aristotélica, al contrario que la inductivista, aspiraba a obtener mediante el uso de deducción, y partiendo de principios generales bien asentados, conclusiones relativas a observaciones concretas. Los deductivistas tienden a plantearse los problemas como cuestiones que deben ser enmarcadas dentro de una teoría general, mientras que, por el contrario, los inductivistas suelen pensar en cómo alcanzar conclusiones generales partiendo de un conjunto de observaciones concretas.811 La esperanza aristotélica era que si se partía de premisas verdaderas el edificio construido sobre ellas sería completamente sólido, el conocimiento sería absolutamente cierto.812 Sin embargo, la inducción, por ser ampliativa y, por lo tanto, deductivamente inválida, está sujeta a un problema lógico insalvable y sólo puede producir conocimiento falible. Los inductivistas, por otro lado, acusaban a los deductivistas de estar sesgados por sus ideas previas. Los inductivistas defendían que los datos hablasen por sí mismos sin que nuestros prejuicios teóricos enturbiasen nuestro juicio. El filósofo empirista John Stuart Mill (1806-1873), por ejemplo, recomendaba a los investigadores no tener en cuenta el conocimiento previo para evitar caer en el conservadurismo.813 El problema es que esta pureza inductiva también es inalcanzable puesto que, si insistiésemos en aspirar a no tener conocimiento previo alguno, no podríamos saber ni por dónde empezar la investigación. Esto implica que, como veremos, siempre habremos de prestar atención a los posibles sesgos que nuestras ideas previas puedan generar. A pesar de esta limitación, merece la pena recordar este ideal inductivista de favorecer los datos frente a nuestras ideas previas. El éxito del inductivismo en los ejemplos que acabamos de comentar, sin embargo, no implica que la ciencia haya abandonado por completo el uso la deducción para generar nuevo conocimiento. Por ejemplo, desde la antigüedad hemos asumido que el universo está ordenado, que sigue unas reglas coherentes, que es un cosmos, y esta premisa, hasta el momento, ha funcionado muy bien. Esta asunción convierte las reglas de la lógica en una herramienta extraordinariamente potente para descubrir nuevas leyes del mundo externo. Por ejemplo, Galileo basó su confianza en el sistema copernicano en una serie de deducciones. Recordemos que el pisano había observado que los proyectiles seguían una trayectoria aproximadamente parabólica y que, a partir de este movimiento y de otras consideraciones, había llegado al principio de inercia. Fue la asunción de este principio, que está íntimamente relacionado con el de la relatividad del movimiento, la que le permitió deducir que el heliocentrismo sería compatible con nuestra experiencia cotidiana puesto que si la Tierra orbitase alrededor del Sol este movimiento sería apenas perceptible. Es decir, que partiendo de la física de los proyectiles pudo deducir, al asumir un universo coherente, que el movimiento de la Tierra no sería fácilmente detectable. Newton también hizo deducciones en sus Principia. Asumiendo como premisas sus leyes, así como la unidad del cosmos, pudo deducir, utilizando una ley gravitatoria que había propuesto para explicar movimiento planetario, los principios de la caída de las manzanas y la dinámica del tiro parabólico. En el siglo XX la aproximación deductiva continuó utilizándose con éxito como método para buscar nuevas teorías físicas. Emmy Noether demostró, mediante una aproximación puramente deductiva, la relación entre los principios de conservación presentes en las leyes físicas y las simetrías de los sistemas físicos y Einstein llegó a sus teorías relativistas gracias a una larga cadena deductiva asentada sobre unas pocas premisas elementales, como que las leyes de la física deben de ser las mismas en cualquier sistema de referencia, que la velocidad de la luz es la misma para cualquier observador o que es imposible para un observador distinguir localmente entre gravedad y aceleración. En la ciencia, claramente, no se ignora la deducción. Los científicos, en realidad, suelen ser bastante pragmáticos y eligen una aproximación u otra dependiendo del problema planteado. Einstein, sin ir más lejos, para su otra gran contribución, la mecánica cuántica, utilizó un acercamiento inductivista. Esta revolucionaria física fue desarrollada por una comunidad internacional de investigadores guiada, en todo momento, por las observaciones experimentales, que, una vez tras otra, se obstinaron en desafiar las propuestas teóricas. En cualquier caso, aunque podríamos plantear que hay ciencias más deductivas, como la física, y otras más inductivas, como la biología, la conclusión moderna aplicable a todas ellas es que en el estudio del mundo externo la observación de ese mundo ha de ser el árbitro final. Este aspecto empírico es esencial en la aproximación científica. 11.3 Tipos de inferencias inductivas Las inferencias inductivas, o deductivamente inválidas, pueden dividirse en distintos tipos. La clase más sencilla sería la denominada inducción enumerativa o simple. A partir de la observación de una serie de ejemplos en los que siempre se observe lo mismo se concluye que lo observado será siempre verdadero. Recordemos: Sócrates es mortal, Platón es mortal, Aristóteles es mortal, por lo tanto, todas las personas son mortales. Esta es una inferencia ampliativa y, por lo tanto, lógicamente inválida. El resto de tipos de inferencias ampliativas pueden ser reducidos, en última instancia, a una mezcla de deducción e inducción simple por lo que la inducción simple suele considerarse fundamental. Sin embargo, sería un error pensar que la inducción simple fue la base del método propuesto por los inductivistas. Bacon, por ejemplo, calificó de infantil el uso de este tipo de inferencia como propuesta de método científico.814 Los métodos planteados por los inductivistas suelen ser más sutiles. De hecho, incluso en los razonamientos más elementales no debemos de estar utilizando la inducción simple. Por ejemplo, un niño no necesitará quemarse veinte veces con la estufa antes de concluir que las estufas son peligrosas,815 bastará una experiencia realmente desagradable para que infiera que las superficies calientes son peligrosas. En ciencia sucede lo mismo, una de las observaciones fundamentales utilizadas por Watson y Crick para inferir su estructura del ADN, la de Chargaff, se basó en muy pocos ejemplos. Este químico cuantificó la cantidad de bases nitrogenadas presentes en el ADN y llegó a la conclusión de que, en la mayoría de los seres vivos, el número de adeninas era igual al de timinas y el de guaninas al de citosinas. ¿Cuántos organismos utilizó Chargaff para llegar a su conclusión? Sólo once y, además, uno de ellos, el fago Phi X 174, no seguía la regla. Por cierto, me gusta hablar de Chargaff en mis charlas divulgativas o con los estudiantes porque es un ejemplo excelente de lo imprevisible que es la ciencia básica. ¿Quién podría haber pensado que el análisis químico del ADN del saltamontes iba a ser relevante en uno de los mayores descubrimientos científicos del siglo XX? Siempre me imagino a Chargaff llegando a casa después de un largo día: ¿hoy qué has hecho en el laboratorio Erwin? He extraído ADN de saltamontes. Ostras, Erwin, ¿no podrías hacer algo útil por la humanidad? Otro tipo de inducción, muy común en ciencia y en las investigaciones policiales, es la inferencia eliminativa. Esta es, por ejemplo, la base del método utilizado por Sherlock Holmes en algunas de sus historias. Se parte de una lista de hipótesis, en este caso de una lista de posibles sospechosos, y van eliminando una tras otra a medida que se acumulan las evidencias. Al final, cuando sólo quede una última hipótesis deberíamos encontrarnos frente al verdadero criminal,.816 Holmes, en El signo de los cuatro, lo resume así: “Es una vieja máxima mía que cuando hayas descartado lo imposible, lo que quede, por improbable que sea, debe ser la verdad”. El equivalente científico consiste en ir eliminando las posibles hipótesis alternativas hasta quedarse con una de ellas. Algunos científicos han llegado incluso a proponer este tipo de inducción como base del método científico.817 La inducción eliminativa si partiese de un número finito de hipótesis se convertiría, de hecho, en una inferencia deductiva, y, por lo tanto, lógicamente válida. El problema, claro está, es que siempre puede que haya alternativas que no hayamos contemplado. En mi experiencia este suele ser el problema habitual en mis investigaciones. Uno parte de unas hipótesis, por ejemplo, sobre la historia del tomate, que intenta comprobar o rechazar, pero la realidad es que al final ninguna de las hipótesis iniciales suele sobrevivir la criba y nos vemos obligados a hacer nuevas propuestas que nacen, al menos en parte, de las observaciones que hemos ido realizando durante el proceso. ¿Cómo llegan los científicos a esas nuevas hipótesis? Una posibilidad es que lo hagan mediante abducción, otro tipo de inferencia inductiva. En este tipo de inferencia se partiría de unas evidencias y, a partir de las mismas, se propondría una explicación para las mismas.818 Este es un tipo de inferencia muy común, la inferencia de Semmelweis, por ejemplo, fue una abducción. Otra abducción sería la que hicieron los geólogos, que partiendo de la observación de cantidades inusualmente elevadas del elemento químico iridio en estratos de hace 65 millones de años, propusieron como explicación el impacto de un meteorito.819 El descubrimiento de la estructura del ADN por parte de Watson y Crick fue otro ejemplo de abducción. Las evidencias principales que estaban manejando eran las siguientes: la estructura química exacta de los nucleótidos que componen el ADN, las reglas de Chargaff, las fotografías de difracción de rayos X, de las cuales se infirió que la estructura era helicoidal, y el hecho de que el ADN era el portador de la información genética y que esta información, de algún modo desconocido, debía de copiarse dentro de las células. A partir de estas evidencias es imposible deducir la estructura correcta, pero Watson y Crick hicieron lo que Maurice Wilkins (el de la polémica con Gosling y Franklin) denominó un inspired guess, es decir, tuvieron una idea inspirada, o una abducción genial, y plantearon su estructura para el ADN. Esta estructura explicaba las reglas de Chargaff: dado que la adenina siempre se aparea con timina y la guanina con la citosina. Además, y lo que es más importante, este apareamiento entre los nucleótidos de las dos cadenas sugería un posible mecanismo de copia de la molécula y, por lo tanto, de la información genética. Es decir, esta estructura explicaba el secreto de la vida. El problema de la abducción es que, en realidad, es un tipo de recomendación muy vaga. No es fácil saber qué cadena de razonamientos llevaron a Semmelweis, Watson o Crick a sus conclusiones e, incluso aunque pudiésemos hacernos una idea de cómo lo hicieron, esto no nos serviría como ejemplo para plantear hipótesis en otras investigaciones. De hecho, muchos investigadores, como Pauling o Franklin, que estaban trabajando en la estructura del ADN intentaron, a partir de las mismas evidencias, plantear una estructura correcta y fracasaron. La abducción suele ser una idea feliz, algo que no se diferencia mucho de los sueños de Kekulé. En ciencia ha de combinarse el rigor con la creatividad y eso no es sencillo. Otro término relacionado con el de abducción y que algunos autores proponen como sinónimo, aunque no lo sea del todo, es el de inferencia a la mejor explicación. Esta inferencia está relacionada con la aproximación estadística denominada de máxima verosimilitud y no se utilizaría para construir nuevas hipótesis, sino para elegir, de entre un conjunto de hipótesis dadas, aquella que pueda explicar mejor nuestras observaciones, aquella que haga más probable que hayamos obtenido esas evidencias Ladyman820. Es decir, de entre todas las hipótesis elegimos la que hace más probable que se haya observado el mundo que hemos observado. Este tipo de inferencia se utiliza habitualmente, por ejemplo, en los análisis filogenéticos. En este caso las evidencias pueden ser las distintas secuencias de un mismo gen en un conjunto de especies y el objetivo es elegir, de entre todos los árboles filogenéticos, el que mejor represente la historia evolutiva de esos organismos. El procedimiento, en este caso, consiste en plantear todos los posibles árboles, todas las historias evolutivas imaginables, y elegir aquel que haga las secuencias observadas más probables. Por ejemplo, sería muy improbable que los humanos y las vacas estuviesen más estrechamente relacionados que los humanos y los chimpancés puesto que las secuencias de los genes de humanos y chimpancés se parecen mucho más entre sí que las de humanos y vacas o que las de chimpancés y vacas. Por último, la analogía también puede considerarse como otra forma de inducción, este caso, basada en la similitud. Si disponemos de un conjunto de individuos o muestras muy similares, es decir, si estos individuos comparten muchas propiedades, por analogía podríamos inferir que compartirán otras características.821 Por ejemplo, si varios pacientes muestran los mismos síntomas, por analogía podemos concluir que tendrán la misma enfermedad. La conclusión de Gilbert relativa al campo magnético terrestre se basó en analogías entre el comportamiento de los imanes en sus experimentos y de las brújulas en la superficie de la Tierra. Si las brújulas cuando se sitúan sobre un imán esférico se comportan de un modo análogo a las brújulas en la superficie de la Tierra, debe de ser porque la Tierra también es un imán esférico. 11.4 El método hipotético-deductivo Los métodos inductivos se utilizan mucho en ciencia, pero cuando escuches hablar sobre el método científico sin más calificativos, lo más probable es que te estén hablando sobre el método hipotético-deductivo. El método hipotético-deductivo, a diferencia de algunos de los métodos inductivos que hemos comentado, como, por ejemplo, la inducción simple, la abducción o la analogía, no se utiliza para generar hipótesis durante la fase de descubrimiento, sino para evaluarlas. Por lo tanto, sitúa el foco de atención en un proceso distinto al tratado por el inductivismo que, recordemos, hacía recomendaciones relativas a la fase de descubrimiento, a la generación de hipótesis; concretamente dictaba que éstas debían construirse a partir de las evidencias. El método hipotético-deductivo, sin embargo, ignora completamente el modo de generación de hipótesis y se preocupa, exclusivamente, por evaluar si éstas son correctas o no. Podríamos considerar que esta aproximación no es más que una formalización de las recomendaciones galileanas de contrastar siempre las hipótesis generadas con nuevas evidencias. El método parte de una hipótesis, a la que podemos haber llegado de cualquier modo, por ejemplo, soñándola. A continuación, por deducción, planteamos predicciones empíricas que, posteriormente, procederemos a evaluar buscando nuevas evidencias.822 Disponer de una hipótesis sobre el funcionamiento del mundo nos permite hacer predicciones de lo que esperaríamos observar. Si planteamos que el mundo externo tiene una estructura determinada, en principio, habríamos de ser capaces de deducir cuál sería el comportamiento de ese cosmos si nuestras creencias fuesen correctas. La hipótesis es como un modelo de juguete con el que podemos trastear para deducir qué esperamos ver. Esta es la parte deductiva del método. Una vez disponemos de estas predicciones procedemos a compararlas con nuevas evidencias y, en función del éxito de esta comparación, nos planteamos qué hacer con la hipótesis que habíamos planteado. Por ejemplo, si mi hipótesis es que las enfermedades son causadas por algún tipo de partícula que los enfermos transmiten a los sanos puedo deducir que si interrumpo esta transmisión los sanos no enfermarán y, posteriormente, puedo comprobar si esto ocurre o no. Lo que plantea el método hipotético-deductivo es que cuando tengamos algún modelo sobre el funcionamiento del mundo, tal y como nos había recomendado Galileo, hemos de crear las condiciones que permitan a la información proveniente de ese mundo participar en la evaluación del modelo. Esta aproximación recoge un aspecto esencial del proceder científico: los científicos hacen muchas propuestas, pero sólo aquellas capaces de pasar el filtro de la contrastación empírica se mantienen, las demás son, eventualmente, descartadas.823 Este es un aspecto tan fundamental de la aproximación científica, que es eminentemente empírica, que algunos filósofos se refieren al método hipotético-deductivo como el método científico. Es, de hecho, esta insistencia en la contrastación de nuestras ideas con las observaciones del mundo externo lo que convierte a la ciencia en un proceso evolutivo en el que nuestras creencias van adquiriendo paulatinamente una estructura que refleja, aproximadamente, la estructura del mundo externo. Este método es una buena caracterización del proceder científico y una excelente recomendación, pero tenemos que entenderlo como una mera recomendación general. No es un algoritmo que indique detalladamente al científico cómo debe proceder al contrastar sus hipótesis. De hecho, cuando se intenta precisar el procedimiento, aparecen dudas e imprecisiones en múltiples puntos. Hemos dicho que las predicciones han de contrastarse con las nuevas evidencias, pero lo que no está tan claro es cómo hemos de hacerlo. Popper, como veremos, pensaba que debíamos tomarnos muy en serio el procedimiento deductivo. Es decir, que si habíamos tomado la hipótesis como premisa y las conclusiones de la deducción resultan no corresponderse con la realidad, tendríamos que descartar la premisa, es decir, la hipótesis. Sin embargo, como veremos, el problema del holismo confirmacional impide que la contrastación sea deductiva porque para generar las predicciones no usamos sólo las hipótesis que estamos evaluando. De modo que si la predicción falla no podremos decidir achacar el fallo a la hipótesis evaluada o a alguna de las hipótesis auxiliares sin recurrir a la inducción. Todo esto lo trataremos con detalle cuando hablemos de la falsación y, también, sobre bayesianismo, pero tal vez, por el momento, un ejemplo pueda servir para ilustrar el problema. Utilizando la mecánica newtoniana se había predicho la órbita de cada planeta. Sin embargo, cuando se observaron con precisión las órbitas de Urano y Mercurio resultaron no coincidir con las predicciones teóricas, por lo que si los científicos hubiesen aplicado estrictamente el método hipotético-deductivo deberían haber descartado la mecánica newtoniana. Esto es lo que apoyaría un popperiano estricto, pero las cosas son más complicadas. Las órbitas no se predicen utilizando sólo las leyes newtonianas, se necesitan también las posiciones, velocidades y masas de todos los planetas, por lo tanto, el fallo en la predicción podría ser debido a la existencia de planetas previamente desconocidos y no a que la mecánica newtoniana es incorrecta. Pero si el procedimiento a seguir cuando las predicciones fallan ha generado discusiones, aún más controvertido ha sido el asunto de qué debemos concluir cuando las predicciones se cumplen. ¿Acaso hemos de asumir en este caso que nuestra hipótesis es absolutamente verdadera? Esto sería un grave error, la ciencia nunca alcanza la certeza. Algo más suave sería concluir que el éxito predictivo de una hipótesis tiene que hacernos aumentar nuestra confianza en ella. Popper, sin embargo, como también veremos, se oponía a este incremento en la confianza. En mi opinión lo más prudente sería concluir que, al menos en las limitadas circunstancias exploradas por las observaciones que hemos realizado, la estructura de nuestra hipótesis parece corresponderse lo suficiente con el mundo externo como para que las predicciones sean aproximadamente correctas. Otra cuestión es qué pasaría si intentásemos extrapolar esta hipótesis más allá del territorio que han explorado nuestras observaciones actuales. Por último, es muy habitual que nuestras predicciones no sean ni completamente erróneas ni completamente acertadas. En muchos casos, nuestro conocimiento sobre el mundo externo es tan limitado que, cuando haces el experimento en el laboratorio, lo que obtienes no es lo que esperas, aunque sí se parece. En estos casos, modificar tus hipótesis aprovechando esa nueva evidencia es un arte. Lo primero que se suele escuchar después de hacer un experimento es: ostras qué raro y lo segundo: ah, pero igual es que… En cualquier caso, recordemos que, aunque el método hipotético-deductivo no es un algoritmo detallado sí que representa un aspecto esencial del proceder científico: cuando una hipótesis genera predicciones erróneas debemos plantearnos muy seriamente la posibilidad de modificarla o descartarla. 11.5 Deductivo e inductivo En realidad, si nos obligásemos a elegir entre una aproximación más deductiva o una más inductiva, estaríamos cometiendo un error, pues en ciencia se utilizan ambas. Es cierto que algunas investigaciones pueden ser más parecidas a los estándares inductivistas y otras a los deductivistas, pero lo habitual es encontrar una mezcla de las dos aproximaciones. Los científicos suelen ser bastante pragmáticos y terminan adaptando sus metodologías a cada uno de los problemas a los que se enfrentan y utilizan cualquier herramienta que les dé buenos resultados. Newton, por ejemplo, en una de las obras fundamentales de la ciencia moderna, los Principia, utilizó la deducción matemática como base de la justificación de su mecánica, sin embargo, cuando se enfrentó al estudio de la luz, en su Opticks, se decantó por una aproximación guiada por evidencias puramente experimentales mucho más cercana al inductivismo.824 Los primeros modernos ya entendieron que la ciencia requiere de una mezcla de aproximaciones inductivas y deductivas. Bacon, aunque siempre concedió más importancia a la observación, pensaba, como ya hemos comentado, que la investigación científica requería tanto empirismo como especulación racional.825 Según Bacon sólo mediante la colaboración de los teóricos y los experimentales se puede avanzar efectivamente. Bacon, que era abogado, comparaba el proceso científico con el legal. En un juicio el juez comienza por escuchar a los testigos y por evaluar las evidencias presentadas haciendo un esfuerzo por no ser influido por sus prejuicios y, a partir de estas evidencias, se planteará algunas conclusiones tentativas que le orientarán en sus nuevas pesquisas.826 Bacon representaba la interacción entre teorización y observación mediante una escalera que permite al investigador ascender desde los datos a la hipótesis y bajar desde la hipótesis a las nuevas observaciones.827 Algún tiempo después, el matemático y astrónomo John Herschel (1792-1871), hijo del gran astrónomo William Herschel, también recomendaba utilizar ambas aproximaciones combinando experimentos e hipótesis teóricas.828 También en el siglo XIX, William Whewell (1794 - 1866), el filósofo, teólogo e historiador de la ciencia que acuñó la palabra científico, propuso una aproximación iterativa. Según este inglés la ciencia tendría un aspecto empírico y otro más teórico.829 La generación de conocimiento sobre el mundo externo requeriría tanto el aspecto externo, la recopilación cuidadosa de evidencias, como el interno, la reflexión racional sobre las hipótesis generadas dentro del marco del resto de nuestro conocimiento. El científico puede generar hipótesis utilizando una larga cadena deductiva, como hizo Einstein con la relatividad general, o puede detectar un patrón en las observaciones, tal y como mostró Semmelweis. La propuesta de Whewell es muy similar al método científico que suele aparecer en los libros de texto: a partir de las evidencias disponibles inducimos una hipótesis que procedemos a comparar con el resultado de nuevas observaciones y experimentos cuyos resultados, a su vez, nos permitirán proponer nuevas hipótesis refinadas. La investigación sería un ciclo iterativo con algunas fases más teóricas y deductivas y con otras más empíricas e inductivas. 11.6 Investigación En cualquier caso, al investigar lo que debemos hacer es exponer nuestros modelos a las evidencias obtenidas a partir de la realidad externa, y muy especialmente a aquellas que pueden diferenciar entre distintas hipótesis o que amplíen las regiones más pobres en información empírica. El resultado de esta exploración lo utilizaremos para tratar de alinear la estructura de nuestros modelos con la estructura del mundo externo, el mapa con el territorio. A este proceso activo de búsqueda de evidencias y generación iterativa de hipótesis se le denomina investigación. Este término comparte su origen etimológico con vestigio. Vestigium, en latín, significaba planta del pie o marca dejada por la misma y, por extensión, significaba también serie de huellas. En inglés la palabra equivalente, clue, adquirió el significado de pista en el siglo XIX y deriva del hilo de Ariadna que Teseo utilizó para salir del laberinto del Minotauro.830 Clue, escrito como clew, originalmente significaba ovillo. De modo que un investigador tiraría del hilo hasta averiguar el misterio. Por cierto, que la palabra pista también tiene un origen relacionado con vestigio ya que en italiano significaba huella, o serie de huellas que deja un animal. La idea es que los investigadores sigan la pista hasta dar con la solución. Investigación y pista tienen su origen en la caza, en la acción de seguir a los animales buscando sus huellas.831 El científico estaría atento a las evidencias que lo guiarían hasta dar con la solución. Hume escribió que no podía haber dos pasiones más similares que la caza y la filosofía.832 Uno de los problemas de la analogía de la caza es que asume un final para la investigación, el equivalente de la verdad metafísica absoluta, algo que, en ciencia no debemos esperar ya que el conocimiento del mundo externo es falible. Nuestro viaje se parece más al de un Ulises que, poco a poco, va aproximándose a la Ítaca metafísica. Sin embargo, la analogía que yo prefiero es la del cartógrafo. El investigador sería un cartógrafo dedicado a la tarea de crear mapas cada vez más precisos. Cada nueva teoría sería un mapa más detallado de un área concreta del mundo externo y estos mapas nos servirían para planificar nuestras acciones futuras, para enviar exploradores a aquellas regiones menos conocidas. 11.7 Contra el método Dado lo que hemos comentado hasta el momento, podríamos proponer que el método científico consiste en obtener evidencias, que reflejan parte de la estructura del mundo externo, y que el investigador emplea para actualizar iterativa y cuidadosamente, nuestro conocimiento. Esta es una propuesta con la que supongo que casi todos los científicos y filósofos estarán más o menos de acuerdo, pero tiene un problema, no va más allá de ser una vaga declaración de intenciones. Imaginemos a un investigador concreto, a Juanjo, en un laboratorio enfrentado a un problema determinado, ¿le servirá este método como un algoritmo para tomar decisiones precisas? Lo cierto es que ni este ni ninguno de los métodos que hemos comentado especifican lo suficiente los pasos a seguir como para determinar cuál es la mejor reacción a un problema concreto. Ninguno de estos métodos podría programarse en un ordenador que sustituyese a Juanjo. (Lo cual no implica que en el futuro esto no vaya a poder hacerse). Las recomendaciones generales no indican cómo hemos de proceder para buscar ni para evaluar evidencias. ¿Cómo deberían distinguirse las inferencias rigurosas de las erróneas? ¿Cómo hemos de conjugar las nuevas evidencias con nuestro conocimiento previo? Es cierto que hemos recomendado a Juanjo que sea muy cuidadoso, pero, puesto que sabemos que estaremos obligados a utilizar inferencias ampliativas, ni siquiera podemos exigirle que utilice solamente inferencias formalmente válidas. Lo cierto es que, si por método entendemos un conjunto de reglas precisas que el investigador debe seguir para llevar a cabo su tarea, un algoritmo para la ciencia, nadie jamás ha conseguido detallar método científico alguno.833 Más allá de recomendar empirismo y rigor, el método científico es una entelequia, una criatura tan vaga como las formadas por las blancas nubes veraniegas. Una pregunta pertinente a plantear a cualquiera que crea en la existencia de un método científico es: ¿podrías detallarlo? Es cierto que hay filósofos que todavía hablan de métodos científicos, algunos de uno, otros de varios, pero lo hacen en el sentido de formas de aproximación generales que pueden servir como guías idealizadas, no en el sentido de procedimientos claramente definidos. El modo en el que las evidencias se acaban utilizando para construir el conocimiento científico es mucho más interesante, y problemático, de lo que los libros de texto de las asignaturas de ciencias suelen sugerir.834 Comparto plenamente la idea de Paul Feyerabend (1924-1994) de que la creencia de que la ciencia funciona siguiendo unas reglas fijas no es sólo falsa, sino dañina,835 y que yo coincida en algo con Feyerabend es notable ya que lo considero como una de las figuras más perjudiciales de la filosofía de la ciencia. Es cierto que en cada ciencia hay numerosas metodologías, es decir, técnicas y procedimientos para llevar a cabo los experimentos, interpretar los datos y testar las teorías.836 Son ejemplos de estas metodologías los ensayos clínicos de doble ciego o los métodos de secuenciación de ADN. Sin embargo, las metodologías no dictan cómo debe hacerse la ciencia, son, más bien, equivalentes a las herramientas que equipan el taller del artesano. Un buen artesano trabajará mejor si dispone de buenas herramientas, pero las herramientas no hacen al artesano, es su conocimiento, su saber hacer, su maestría, su oficio, lo que los angloparlantes denominan craft, lo que hace al artesano. Y un aspecto clave de este oficio es saber qué herramienta elegir en cada momento y cómo utilizarla. Además, conviene recordar que hay dos contextos más o menos diferenciados en la investigación: el del descubrimiento y el de la justificación. Esta es una distinción que, en el XIX, propuso John Herschel y que se convirtió en un estándar defendido por los positivistas lógicos.837 Muchos de los ejemplos inductivos que hemos comentado se han referido a la creación de hipótesis durante la fase de investigación como, por ejemplo, la abducción de Semmelweis. Sin embargo, recordemos que Aristóteles recomendó su método deductivo pensando en la justificación y no en el descubrimiento. Aristóteles, seguramente, descubriría usando aproximaciones mucho más libres. Para indagar sobre filosofía supongo que discutiría sus ideas en la Academia o en el Liceo con el resto de pensadores, mientras que en sus investigaciones zoológicas utilizó una aproximación inductivista: pasó largos periodos observando el mundo natural y diseccionando calamares y otros animales. Arquímedes en su Método, como ya hemos comentado, también explicitó esta distinción entre descubrimiento y justificación: la justificación debía ser deductiva, pero la investigación podía ser más libre. Arquímedes, por ejemplo, sugería utilizar analogías mecánicas durante la fase de descubrimiento. En mi opinión en ciencia no hay un método único ni para el descubrimiento ni para la justificación, pero, al menos para esta última sí pueden hacerse propuestas algo más definidas. Sin embargo, en la práctica, ni siquiera la justificación sigue un método preciso. Por ejemplo, Galileo y Newton en algunas de sus obras optaron por justificar sus hipótesis utilizando una aproximación deductiva, mientras que, en otras, usaron, incluso para la justificación, un acercamiento inductivo más moderno. En la actualidad las presentaciones de los trabajos científicos suelen aproximarse más a esta segunda propuesta. Primero se describen los resultados, es decir las observaciones y, a continuación, se discuten las implicaciones teóricas que podemos extraer de ellas. Además, se asume que la inducción a partir de los datos es suficiente para justificar las propuestas teóricas y que no es necesario recurrir a la deducción. Sin embargo, esta tampoco es una regla absoluta. Cuando intentaron enseñarme en segundo de la carrera de químicas, sin mucho éxito, física cuántica lo hicieron siguiendo una aproximación axiomática similar a la seguida por Euclides en Los elementos. El profesor partió de unas pocas premisas y a partir de ellas construyó deductivamente todo el edificio. Esta es una presentación del área completamente opuesta a las aproximaciones inductivas del Opticks newtoniano o de El origen de las especies darwiniano. Una opción más humilde es tratar de, en vez de plantear un método completo, proponer una lista de recomendaciones a tener en cuenta. Por ejemplo, hemos recomendado la regla propuesta por Popper: no hay que aceptar hipótesis que violen las evidencias empíricas. En general, no es una buena idea defender teorías que contradigan las observaciones, aunque Galileo ya nos avisó de que las teorías sólo son aproximadas y que, por lo tanto, no hemos de esperar que se ajusten por completo a la realidad. Feyerabend acertó al puntualizar que a lo largo de la historia de la ciencia se podían observar casos en los que los científicos han avanzado rompiendo todas y cada una de las reglas que uno pueda plantear.838 Los grandes científicos unen el rigor intelectual con la creatividad y es precisamente esa combinación la que hace que no sea fácil alcanzar la excelencia de Darwin o Faraday. Si la ciencia consistiese en aplicar un conjunto de reglas fijas cualquiera podría ser tan bueno como ellos. El problema de Feyerabend es que, partiendo de esta observación, en su ensayo Contra el método, hizo una propuesta, claramente absurda, que denominó anarquismo metodológico y que sostiene que en ciencia “todo vale.”839 Sin embargo, yo todavía no he visto a ningún científico que defienda que dos más dos son cinco o que los burros vuelan. Este filósofo criticó el estatus y el respeto alcanzado por la ciencia y defendió que este relato institucional ha desplazado a otras creencias previas, como las religiosas, no porque posea una validez epistémica superior, sino por un simple juego de poderes. No es de extrañar que Ratzinger, antes de ser Papa, citase a Feyerabend cuando defendió la justicia de la condena a Galileo. No obstante, sí pueden proponerse algunas recomendaciones generales que podrían ser útiles: desconfía de las hipótesis sin un amplio respaldo empírico, no te limites a buscar evidencias en favor de tu hipótesis, valora también la posibilidad de hacer observaciones que apoyen otras hipótesis alternativas y, sobre todo, trata de sopesar qué observaciones podrían desacreditar la tuya. Sólo cuando hayas evaluado con la máxima justicia todas las hipótesis alternativas que hayas podido encontrar y cuando la tuya haya superado un buen número de obstáculos dispondrás de una hipótesis que realmente merezca la pena. Las buenas hipótesis no deben ser sólo razonables, han de ser supervivientes de las mejores críticas que hayamos podido hacerles. Por otro lado, has de entender las metodologías utilizadas en tu área, especialmente cuáles son sus fortalezas y sus limitaciones. Aplicar una metodología sin haberte esforzado en comprenderla o sin que te guíe un experto en la misma te convierte automáticamente en un mal científico. Y no vale con que la metodología sea muy utilizada. Es común que durante un tiempo los artículos científicos se rindan a las modas o incluso que utilicen metodologías inadecuadas. Por ejemplo, en mi área, la genética de poblaciones, es habitual encontrar árboles filogenéticos en los artículos sin que se discutan sus profundas limitaciones en el campo de las poblaciones. Sin embargo, a pesar de estas recomendaciones generales recuerda que nadie ha conseguido establecer unas reglas precisas sobre cómo debe hacerse la ciencia, la ciencia es un arte que requiere maestría, oficio. Con esto no quiero decir que la ciencia sea un arte en el sentido utilizado por los artistas, sino más bien en el utilizado por los artesanos. En ciencia podemos evaluar la corrección de las respuestas estudiando el grado en el que coinciden con el mundo externo, algo que no sucede con las distintas expresiones artísticas. De la falta de un método, entendido en el sentido de un algoritmo, tampoco hemos de concluir que la ciencia no sea racional, sino, más bien, que los detalles de su racionalidad son difíciles de codificar.840 Además, hay muchas ciencias distintas y sus metodologías y aproximaciones generales son diferentes.841 No se hace igual física que biología. En algunas áreas, dominan los experimentos, mientras otras se limitan a las observaciones, algunas disponen de teorías generales que les permiten hacer predicciones precisas, mientras que otras sólo describen lo que ha ocurrido en el pasado. Por último, los métodos cambian con el tiempo, la forma más racional de aproximarse al estudio de un fenómeno en el siglo XVI no era la misma que en el XX o en el XXI; las metodologías y las aproximaciones se han ido refinando. Las metodologías se van revisando a medida que se descubren sus limitaciones o que son superadas por desarrollos posteriores más capaces. La ciencia consiste en el estudio sistemático del mundo externo, por lo que es deseable que sus metodologías vayan cambiando a medida que nuestras ideas sobre cómo proceder con rigor evolucionan. La ciencia evoluciona,842 esta es una idea compartida por muchos filósofos de la ciencia. Hilary Putnam, por ejemplo, propuso que la noción de investigación racional estaba en continuo progreso.843 No es sólo que unas metodologías sustituyan a otras, sino que las nuevas son mejores que las anteriores. Y esta evolución es posible puesto que sabemos cuál es nuestro objetivo final: crear metodologías que nos permitan desarrollar modelos más precisos y generales del mundo externo con mayor eficiencia.844 Esto es, en realidad, un método de segundo orden; hemos de ir revisando las metodologías científicas para disponer de herramientas más capaces. Recordemos que durante gran parte de la historia los artesanos, aunque desconocían las bases teóricas de la mineralogía o de la forja, pudieron crear tecnología y pudieron hacerlo porque fueron capaces de evaluar la bondad de sus resultados. Lo crítico es incorporar el contraste con las nuevas evidencias en el proceso de evaluación. La ciencia, en cierto modo, es análoga a nuestros sistemas perceptuales. Tanto nuestra visión como la ciencia tienen por objeto crear modelos aproximados del mundo externo basados en la información recopilada. Sin embargo, hay una diferencia fundamental entre ambos, mientras que nuestro sistema visual ha surgido por evolución biológica y difícilmente podrá superar las ilusiones ópticas que le acechan, cuando detectamos que nuestras metodologías científicas funcionan incorrectamente sí podemos refinarlas. Esta evolución cultural hace que la ciencia pueda evolucionar sistemas de creación de modelos mucho más rápidamente que la biología. Nuestro sistema visual nos permite ver, e incluso podemos entender en qué circunstancias produce ilusiones ópticas, pero no podemos cambiar este sistema innato. En ciencia, sin embargo, sí somos capaces de modificar las metodologías que utilizamos y eso nos permite diseñar nuevas herramientas que limiten los problemas que vayamos encontrando.845 La conclusión de Feyerabend: que es imposible estudiar con rigor el mundo externo,846 fue un profundo error. Es evidente, para cualquiera que tenga interés en pensar con un mínimo de seriedad, que, en muchas áreas, nuestro conocimiento ha avanzado. Que nuestros métodos no sean perfectos o que no sean fáciles de codificar no implica que sean completamente inútiles. Cualquiera que niegue los logros científicos conseguidos desde el siglo XVI a la actualidad y equipare a la ciencia con otros relatos culturales está haciendo mala filosofía, puesto que es evidente que no está pensando con rigor. Esta, por fortuna, es una actitud que, aunque gozó de bastante popularidad en las últimas décadas del siglo XX, actualmente es muy minoritaria dentro de la filosofía de la ciencia. Sabemos que el conocimiento avanza, podemos secuenciar virus, enviar cohetes a la Luna y construir aceleradores de partículas en los que obtenemos los resultados previstos. Algo debemos de estar haciendo bien cuando nuestras creencias nos permiten intervenir en el mundo externo de un modo tan preciso y exitoso. Además, resulta sorprendente que esos malos filósofos, que niegan la posibilidad del conocimiento científico, se atrevan a estar tan seguros de su propio conocimiento filosófico. Yo les recomendaría, cuanto menos, algo de modestia intelectual, especialmente si en algún momento de sus vidas han utilizado un teléfono o han ido al médico. Si yo fuese un constructivista radical supongo que los viajes en avión me causarían una gran ansiedad, uno nunca sabe cuándo el relato que domina la mente del piloto puede cambiar. Imagina que deja de creer en la fuerza de la gravedad y la dinámica de fluidos en medio del Pacífico. Además, como veremos, la ciencia no tiene unas bases epistemológicas distintas a las del conocimiento común. Por lo que si se hace una crítica del conocimiento científico deberemos concluir, junto con Pirrón de Elis, que el conocimiento cotidiano también es inalcanzable y tendremos que elegir entre quedar incapacitados para la acción, por el miedo de darnos un buen golpe cada vez que intentemos salir de casa utilizando la puerta, o mantener una impostura intelectual. Sin embargo, lo que sí es cierto es que no disponer de una formalización del método científico supone una limitación práctica importante. Por ejemplo, no podemos juzgar con absoluta objetividad cuándo los científicos están funcionando con rigor y cuándo no lo están haciendo. Está claro que la tecnología ha avanzado mucho gracias a la ciencia y que hay ciencias, como las físicas, en las que hemos obtenido teorías muy generales con un amplio respaldo empírico, pero en otras áreas podemos tener muchos más problemas. En biología evolutiva, por ejemplo, es común encontrar mala ciencia, pero, como no tenemos un método objetivo para detectarla, sólo los especialistas son capaces de darse cuenta de estos problemas y una gran parte de ellos no lo hará, bien por incapacidad o bien por no buscarse enemigos dentro de la comunidad. Las técnicas utilizadas para reconstruir la historia evolutiva de las poblaciones son muy complejas y no es fácil aprender a manejarlas con destreza. Es sencillo hacer un análisis instalando el software adecuado, pero es mucho más complicado saber interpretar los resultados obtenidos teniendo en cuenta las limitaciones de las metodologías utilizadas y la estructura de las propias evidencias. Por ejemplo, los árboles filogenéticos pueden servir para establecer hipótesis evolutivas dentro de las poblaciones, pero hay que ser muy cautos con su uso puesto que cuando hay hibridaciones, cruces entre distintas poblaciones, cosa que ocurre comúnmente, los resultados de estos análisis pueden ser completamente erróneos. Los humanos modernos, por ejemplo, somos el resultado de, al menos, un par de hibridaciones con varias especies extintas, los neandertales y los denisovanos. Estos procesos no pueden ser representados por un árbol filogenético, puesto que en un árbol las ramas una vez se separan no pueden volver a unirse. Los árboles asumen que las poblaciones una vez que se separan no pueden volver a cruzarse. ¿Existe alguna regla precisa sobre cuándo utilizar árboles y sobre cómo interpretarlos? No, los árboles filogenéticos, unas veces son útiles y otras engañosos. Hay numerosas recomendaciones, pero necesitamos experiencia y cautela para poder utilizarlos de un modo óptimo y mi opinión, como experto en el área, es que muchos de los artículos publicados actualmente sobre estos temas, incluso los publicados en revistas de alto índice de impacto, hacen un uso chapucero de estas técnicas. Además, como las implicaciones prácticas de concluir que los tomates se domesticaron en México o en Ecuador son nulas, no suele haber una gran presión por enmendar las conclusiones generadas por la mala ciencia en este campo. Esto no implica que no puedan hacerse buenos análisis o que con el tiempo no se llegue a un consenso racional, pero sí que la velocidad de avance será menor en estas áreas que otras más aplicadas. Esta es una acusación que, probablemente, Feyerabend estaría dispuesto a compartir y que exploraremos en capítulos posteriores. Pero una cosa es criticar los problemas de un área concreta y otra bien distinta es concluir que la ciencia no puede funcionar. Lo que implica la existencia de la mala ciencia es que, como ciudadanos, debemos ser especialmente cautos puesto que los malos científicos medran aprovechándose de nuestra confianza en la ciencia. Esta es una confianza que se ha generado gracias a los enormes éxitos tecnológicos de los que disfrutamos y que la mala ciencia aprovecha. Los malos científicos se esconden tras los éxitos de los ingenieros de la NASA o de Google. 11.8 Resumen Podría proponerse que el método científico consiste en proceder sistemáticamente tanto en la obtención de evidencias, como en la actualización y contrastación iterativa de nuestros modelos del mundo externo. Pero esta es una recomendación muy general, no hay un único método, un algoritmo detallado que indique al investigador como proceder, que vaya más allá de ser una referencia general sujeta a numerosas matizaciones y excepciones. Nadie ha detallado un método científico. Sin embargo, esta carencia no implica que no podamos plantear algunas reflexiones útiles. Por ejemplo, el proceder científico puede dividirse conceptualmente en dos fases: descubrimiento de las hipótesis y justificación de las mismas. Los investigadores suelen ser bastante libres y pragmáticos en la fase de descubrimiento. A veces infieren regularidades en las observaciones, como Kepler lo hizo en las medidas de Brahe, otras construyen complejas cadenas deductivas partiendo de evidencias exiguas como lo hicieron Maxwell o Einstein. Una vez hemos generado nuestras hipótesis debemos proceder a contrastarlas empíricamente. El mundo externo ha de tener siempre un papel fundamental en esta evaluación. Sólo merece la pena confiar aquellos modelos que han superado un buen número de contrastaciones empíricas. Para ello conviene primero pensar en qué evidencias podrían distinguir cada una de las hipótesis alternativas planteadas. En este paso, para intentar limitar los sesgos de nuestras ideas previas, es importante pensar tanto en qué evidencias podrían apoyar nuestras hipótesis como en aquellas que podrían refutarlas y es especialmente importante no olvidarse de estas últimas. Una vez dispongamos de las evidencias conviene inspirarse en el ideal bayesiano como estándar de justificación. En la práctica, como comentaremos, en la mayoría de las ocasiones, no podremos hacer inferencias bayesianas estrictas, pero este estándar de inferencia será una buena guía. Algo bastante común es que una vez dispongamos de las evidencias nos demos cuenta de que ninguna de nuestras ideas previas es suficientemente buena y que tengamos que volver a iniciar un nuevo ciclo de generación de hipótesis, búsqueda de evidencias y justificación. De este modo, iterativamente, el investigador puede que paulatinamente vaya logrando su objetivo de generar un modelo que refleje la estructura del mundo externo. En mi opinión, sería perjudicial creer que estas recomendaciones generales constituyen un algoritmo preciso. La ciencia requiere oficio y creer lo contrario puede hacer pensar a la ciudadanía que la mala ciencia no es posible o que los valores de compromiso con la búsqueda del conocimiento no son relevantes para el investigador. Pero lo cierto es que el científico dispone de una notable libertad, mucho más amplia que la que el método parece implicar y por ello debe ser considerado responsable. La ciencia es el oficio de la duda, no el algoritmo de la certeza. Estudiar con rigor el mundo externo es posible, pero exige esfuerzo y disciplina y los resultados no siempre tienen por qué ser ni llamativos ni gratos. Esto no implica que la ciencia no sea racional o que carezca de estándares, sino que los detalles del procedimiento son difíciles de codificar y que su evaluación requiere oficio y siempre estará sujeta a una cierta discrecionalidad que, dependiendo del problema investigado y de las evidencias disponibles, podrá ser mayor o menor. "],["el_problema_de_la_induccion.html", "12 El problema de la inducción 12.1 El salto lógico ampliativo 12.2 Tribulaciones de un pavo navideño 12.3 Utilizamos la inducción 12.4 El principio de la uniformidad 12.5 Subdeterminación 12.6 El sueño de la justificación deductiva 12.7 Otras reacciones 12.8 Resumen", " 12 El problema de la inducción Estemos más o menos a favor del inductivismo que defendían algunos modernos, lo que está claro es que obtenemos conocimiento útil sobre el mundo externo recurriendo, de un modo u otro, a inferencias ampliativas que, necesariamente, serán lógicamente inválidas. C. D. Broad, epistemólogo y filósofo de la ciencia, calificó a la inducción como la gloria de la ciencia y el escándalo de la filosofía.847 Recordemos: mientras que la deducción garantiza, dadas unas premisas verdaderas, la verdad de la conclusión, las inferencias ampliativas son lógicamente inválidas: incluso aunque todas y cada una de las premisas sean verdaderas la conclusión no tiene por qué serlo.848 12.1 El salto lógico ampliativo Los problemas causados por esta inevitable limitación lógica han sido explorados por los filósofos desde la época helenística. Por ejemplo, el epicúreo Filodemo de Gadara (110 a. C. - c. 37 a. C.) escribió que a partir de la observación de que hemos visto morir a muchos hombres, no podemos deducir que todas las personas sean mortales y, menos aún, que todos los animales hayan de serlo.849 Sin embargo, quien realmente situó esta cuestión en el primer plano filosófico fue David Hume (1711-1776), el gran filósofo moderno, en su Investigación sobre el entendimiento humano.850 La deducción es capaz de preservar la verdad puesto que no trata de ir más lejos de lo contenido explícita o implícitamente en las premisas. Sin embargo, las inferencias ampliativas van más allá de sus premisas. Nadie ha visto, ni verá nunca, que todas las personas sean mortales o que todos los días salga el Sol, por lo que para llegar a esas conclusiones generales hemos de dar un salto lógico, hemos de extrapolar las observaciones particulares disponibles. En ciencia, como no podría ser de otro modo, también interpolamos o extrapolamos. Como ejemplo podemos recordar las inferencias que Kepler realizó basándose en las observaciones de Brahe. Las órbitas elípticas keplerianas implican más que lo que Tycho había observado. En primer lugar, entre cualesquiera dos posiciones anotadas por Brahe para un planeta concreto en dos noches consecutivas se extiende un segmento que cubre infinitos puntos que nunca fueron observados y, además, Kepler no se conformó con interpolar, sino que extrapoló el comportamiento elíptico hacia el pasado y hacia el futuro e, incluso, llegó a proponer leyes que podrían aplicarse a otros astros todavía no observados. Es decir, Kepler hizo algo muy común, inducir una ley general a partir de unas observaciones concretas. Esto no implica que sus conclusiones fuesen erróneas, recordemos que una inferencia inválida no implica la falsedad de la conclusión, pero sí que, desde un punto de vista lógico, las leyes de Kepler no pueden deducirse de las observaciones. Esto debería preocupar a un empirista comprometido. Estas inferencias siempre implican un salto lógico ampliativo: disponemos de unas observaciones particulares, nuestras premisas, pero alcanzamos conclusiones generales.851 Podría parecer que estas cautelas son exageradas, pero la realidad es que los científicos suelen acabar teniendo problemas reales debidos a estos saltos lógicos. De hecho, incluso el aparentemente robusto edificio de la física clásica terminó cayendo por haber extrapolado sus leyes a territorios empíricamente inexplorados. 12.2 Tribulaciones de un pavo navideño Un caso muy comentado para introducir el carácter ampliativo de la inducción es el de los cisnes. Durante milenios, todos y cada uno de los cisnes que se habían observado en Europa eran blancos. Por lo tanto, habría sido irracional no concluir que los cisnes son blancos. De hecho, Aristóteles escribió que todos los cisnes son blancos.852 Aunque, todo hay que decirlo, el gran filósofo también consignó en sus obras algunos rumores zoológicos mucho más dudosos, como que los cisnes son animales muy musicales que cantan incluso al aproximarse su muerte. Pero dejemos de lado el asunto de la musicalidad escatológica y volvamos a la blancura del plumaje. Tras un gran tedio blanco que duró milenios, en 1697, los colonos ingleses, que se encontraban explorando un nuevo territorio, Australia, se toparon con una sorpresa: cisnes negros. Al final resultó que, a pesar de todas las evidencias previas, no todos los cisnes son blancos. Sexto Empírico que, como buen escéptico trataba de ser muy prudente, ya había avisado de que, si tratamos de alcanzar una conclusión general a partir de unos datos particulares, quedaremos siempre expuestos a que en el futuro se encuentren nuevos datos que contradigan la conclusión. El único modo de justificar deductivamente una conclusión general sería observar todos y cada uno de los casos implicados, pero esto, puesto que hay, potencialmente, infinitos casos, es imposible. Bertrand Russell (1872–1970) ilustró el problema con un cuento sobre un pavo cauto.853 Un buen día nuestro pequeño pavo es llevado a una granja y tras pasar su primera noche en ella, a las 9 de la mañana, le dan de comer. El pavo podría llegar a la conclusión de que en esa granja se alimenta a las aves a las 9 de la mañana, pero, como es un pavo cauto, prefiere reservar el juicio. El segundo día, el granjero repite la rutina y vuelve a alimentar a los animales a las 9. Y el tercero y el cuarto y el quinto continúa repitiéndose el patrón. Día tras día sigue confirmándose la regularidad. Sin embargo, a pesar de las evidencias, nuestro pavo, que confía en la inducción, pero sólo hasta cierto punto, prefiere mantener la cautela y se abstiene de alcanzar conclusión alguna. Al final, los meses de aburrimiento pueden acabar venciendo el escepticismo de cualquiera y el pavo cauto, el día 24 de diciembre, por fin induce la siguiente conclusión: “Todos los días me dan de comer a las 9 de la mañana”. Estoy seguro de que todos podemos inferir cuál será la inducción que servirá de cena en Nochebuena. 12.3 Utilizamos la inducción Podríamos decidir atender a las quejas de Sexto y tratar de abandonar las inferencias ampliativas, pero, en ese caso, nos encontraríamos con otro problema. La deducción funciona muy bien en sistemas formales, como los creados por la lógica o las matemáticas porque en ellos sólo nos interesa la validez de la inferencia. Uno es libre, mediante la deducción pura, de plantear cualquier sistema formal coherente que le plazca; puede, por ejemplo, construir distintas geometrías. Sin embargo, lo que nunca podrá hacer partiendo de las evidencias empíricas y sin recurrir a la inducción es establecer cuál de esas construcciones formales se corresponde con el mundo externo. El problema de la deducción es que siempre es válida, no depende de lo que ocurra en nuestro universo. La validez lógica, recordemos, es una propiedad meramente formal. El silogismo “todos los humanos son mortales, Sócrates es humano y, por lo tanto, Sócrates es mortal” sería válido incluso en universos en los que los humanos fuesen inmortales o en los que Sócrates nunca hubiese existido.854 La validez formal sólo garantiza coherencia formal. Las disciplinas formales, la lógica y las matemáticas, están interesadas por la validez, pero para la ciencia es crítico, además de que sus propuestas sean coherentes, que se correspondan con la realidad. La deducción no es ampliativa, por lo que no puede ser utilizada para alcanzar conclusiones generales a partir de observaciones particulares. Aunque podemos deducir que, si todos los hombres son mortales, Sócrates también será mortal, por muchos funerales que visitemos, nunca podremos deducir que todos y cada uno de los hombres presentes y futuros van a ser mortales. Las teorías científicas siempre se refieren a cuestiones generales, por lo que no pueden ser deducidas a partir de un conjunto finito de observaciones, siempre estaremos obligados a dar un salto lógico, a ir más allá de lo que hemos observado. Es necesario inducir siempre que queramos caracterizar el comportamiento general de un sistema partiendo de información limitada. Esto es, por ejemplo, lo que hizo Kepler al saltar de las observaciones concretas diarias de Brahe a sus órbitas continuas. Lo que sí podemos conseguir mediante la deducción, si asumimos un modelo astronómico con órbitas elípticas y una posición y velocidad para Marte y la Tierra, es calcular la posición en la que esperamos ver a Marte cada noche en el cielo. Recordemos, esta es, precisamente, la base del método hipotético-deductivo y, como veremos, será una parte importante de la inferencia bayesiana. Sin embargo, lo que nunca podremos hacer partiendo de unas observaciones particulares es deducir una órbita completa. Al atrevernos a plantear una hipótesis general sobre el comportamiento del mundo externo partiendo de información limitada, por ejemplo, la forma de una órbita, estamos obligados a dar un salto lógico ampliativo y, por lo tanto, quedamos necesariamente expuestos al error. A pesar de estas limitaciones, lo cierto es que inducimos continuamente tanto en ciencia como en nuestra vida cotidiana. En realidad, el problema de la inducción podría denominarse el problema de la generación de hipótesis razonables a partir de la experiencia.855 Alguien podría plantear que un modo de escapar del problema de la inducción sería limitar nuestras conclusiones a lo que hemos observado. Si Brahe observó Marte en unas posiciones concretas unos días concretos podríamos quedarnos con esos datos y no ir más allá. Sin embargo, esto no sólo acabaría con la ciencia, sino con nuestro conocimiento cotidiano, puesto que nos impediría generalizar. Siendo optimistas, podríamos concluir que ayer la sal me supo salada, pero no habría forma de determinar qué deberíamos hacer hoy para aliñar la ensalada a nuestro gusto. Renunciar a la inducción no sólo haría imposible, la ciencia, sino nuestra vida cotidiana. Al fin y al cabo, todo nuestro conocimiento del mundo, tanto el científico como el cotidiano, se basa en hacer generalizaciones sobre lo que no hemos observado basándonos en las evidencias disponibles. Recuerdo un chiste que me contaron en mis años de facultad sobre un grupo de estudiantes que divisan una oveja mientras viajan en tren por una pradera escocesa. Al ver la oveja el biólogo exclama sorprendido: anda, las ovejas escocesas son negras. A lo que su amigo químico, queriendo ser más cauto, responde: no, sólo puedes afirmar que hemos visto una oveja negra, pero el resto podría tener lana blanca. Mientras que el matemático, más prudente aún, apostilla: no, sólo podemos afirmar que hemos visto una oveja que tiene, al menos, la mitad del pelo, la que podemos ver, de color negro. Aquí acababa el chiste, pero podríamos añadir a un escéptico helenístico que añadiese: lo que podemos afirmar con seguridad es que nuestro sistema perceptual nos ha mostrado media oveja que, desde nuestro punto de vista parece ser negra. Y, por último, un solipsista puntilloso podría concluir diciendo que lo único que podemos afirmar con certeza es que recordamos haber visto una oveja, pero puede que todo, tren y amigos incluidos, sea un sueño o una alucinación. Este es un problema que comparten, incluso, nuestros sistemas perceptuales, que también generan modelos del mundo partiendo de la limitada información que les llega. Por ejemplo, la percepción de que mi gata está dormida junto a mí es un proceso muy complejo que crea modelos partiendo de la escasa información recogida por mis retinas y que para crearlos asume, implícitamente, la uniformidad de ese mundo externo. Los fotones que llegan a mis retinas son procesados aceptando que el mundo sigue teniendo tres dimensiones y que los objetos que hay en él ocupan un espacio y se desplazan de un modo continuo por él. Estas asunciones hacen que podamos disfrutar del cine a pesar de que en la pantalla no aparezcan objetos tridimensionales ni que el movimiento sea continuo y también son las responsables, cuando son violadas, de que aparezcan ilusiones perceptuales. La sombra de Kant es alargada. 12.4 El principio de la uniformidad Hume hizo otra puntualización importante: el éxito de la inducción siempre depende de una premisa implícita fundamental: el mundo externo se caracteriza por respetar unas ciertas regularidades, no es un caos absoluto. Además, solemos asumir que estas regularidades, al menos en lo que respecta a la física fundamental, son sencillas. A la creencia de que el comportamiento del universo es regular, de que los patrones del mundo externo responsables de las observaciones que hemos realizado son más o menos uniformes en el tiempo y en el espacio podemos denominarla principio de la uniformidad de la naturaleza.856 Por ejemplo, Kepler asumió, implícitamente, que los planetas siguen una órbita continua y sencilla. Esta es una premisa muy razonable, pero no es necesariamente cierta. Podría ser que viviésemos en un mundo gobernado por un dios muy caprichoso que se deleitase confundiendo a Brahe y Kepler y que hiciese aparecer los planetas sólo en el momento preciso en el que Brahe los observaba, pero que, el resto del tiempo, ni Marte ni Júpiter existiesen. Esta es la misma premisa que aplicamos al concluir que el mundo externo sigue existiendo mientras parpadeamos. Nuestras observaciones son perfectamente compatibles con que un enorme abismo vacío engulle el universo cada vez que cerramos los ojos. Por otro lado, también utilizamos la asunción de la uniformidad y sencillez del cosmos al concluir, tal y como apuntó Russell, que nuestra existencia no comenzó hasta hace 5 minutos.857 Todas nuestras observaciones son compatibles con que fuimos creados por un dios travieso hace 5 minutos, o el último jueves,858 que no sólo creó el universo con todos los objetos y todos los fotones en las posiciones que ocupan actualmente, sino que, además, tejió las conexiones de nuestro cerebro para crear nuestros recuerdos. Además, al hacer predicciones utilizando el conocimiento generado mediante evidencias recogidas en el pasado también estamos asumiendo que las leyes del cosmos y los patrones que observamos no van a cambiar abruptamente en el futuro inmediato. Cuando Kepler propuso que las órbitas planetarias son elípticas no pensó que iban a ser elípticas hasta el momento en el que Brahe había hecho sus mediciones, pero que después iban a cambiar de un modo irregular. Sin embargo, debemos recordar que este fue, precisamente, el trágico fallo del cauto pavo inductivista. El filósofo norteamericano Nelson Goodman propuso, en 1955, en su Nuevo enigma de la inducción, un problema relacionado con el anterior.859 Hasta el momento hemos observado que las esmeraldas son verdes, por lo que podríamos concluir que las esmeraldas son verdes, pero también podríamos concluir que son verdules. Se definen como verdules aquellos objetos que tienen la propiedad de aparecer como verdes hasta una fecha determinada, por ejemplo, hasta el año próximo, y como azules a partir de ese momento. Dadas las evidencias empíricas disponibles podríamos concluir tanto que las esmeraldas son verdes como verdules. No hay ninguna motivación empírica que favorezca la hipótesis verde frente a la verdul. La única diferencia entre ambas hipótesis es que la verdul es algo más compleja. Una opción es elegir, de entre las distintas hipótesis capaces de explicar las mismas evidencias, la más sencilla. Esta sencillez sería lo que los filósofos denominan una virtud superempírica de la teoría, es decir, un atributo de la teoría que va más allá de lo que podemos observar empíricamente. Sin embargo, conviene recordar que el mundo externo no tiene por qué seguir necesariamente las leyes más sencillas. Siempre habíamos pensado que era evidente que los objetos ocupaban una posición definida en el espacio. Una bola de billar está en una posición o está en otra posición. Sin embargo, cuando a principios de siglo XX se empezaron a hacer experimentos para indagar lo que sucedía a escalas subatómicas, la realidad se empeñó en mostrarnos que el comportamiento de los electrones, y del resto de partículas subatómicas, es mucho más extraño de lo que habíamos asumido. No está nada claro que tenga sentido hablar de las posiciones de los electrones cuando no estamos interaccionando con ellos. Hume planteó, correctamente, que no podemos deducir que el mundo sea uniforme, puesto que cabe la posibilidad lógica de que no lo sea.860 Esta conclusión, la de que el cosmos es uniforme, es sintética, no analítica, es decir, que no puede inferirse a partir de las definiciones de un sistema formal, sino que hace referencia al mundo externo y este, en principio, podría no ser uniforme.861 Podríamos tratar de justificar este principio por inducción: dado que en el pasado hemos observado que las leyes de la naturaleza se mantienen, podemos asumir que la naturaleza seguirá respetando este principio. Lo mismo es aplicable para las regiones del cosmos que no hemos explorado: dado que las regiones de las que sí tenemos evidencias empíricas se comportan de un modo determinado, el resto debe hacerlo también. Sin embargo, estas justificaciones no son suficientes. En primer lugar, un escéptico radical podría decirnos que, aunque nos parece haber observado que la naturaleza es uniforme, tal vez nuestra memoria nos esté engañando. No es trivial descartar rigurosamente el escepticismo radical. No es fácil justificar por qué es irracional concluir que el universo que vemos no es fruto de un elaborado engaño. La respuesta que han planteado muchos filósofos tiene que ver con la complejidad inherente a las hipótesis de los escépticos radicales. Cualquier engaño, haya sido éste perpetrado por las máquinas de Matrix o por un dios travieso, requiere un mecanismo muy complejo capaz de crear la ilusión de un universo con una historia coherente completamente inventada. Como ya hemos comentado, es razonable favorecer las hipótesis más sencillas. Es más sencillo plantear que el mundo se comporta como parece hacerlo, porque realmente es así, que postular que existe un mecanismo complejo tras las regularidades que hemos observado. Sin embargo, hemos de reconocer que esta no es una virtud empírica de las hipótesis, sino superempírica. Realmente podríamos vivir en Matrix. Otra opción, bastante razonable, consiste en no tratar de llegar más allá de las regularidades que hemos observado. El universo parece comportarse como se comporta y esto es suficiente para un empirista estricto, no necesita plantearse si la estructura que detecta es fundamental o no. Aunque, claro está, esta opción también requiere que asumamos el principio de uniformidad. Este punto lo comentaremos más extensamente cuando hablemos de los realistas y los antirrealistas. Sin embargo, aunque descartemos las críticas de los escépticos radicales seguimos teniendo el problema de justificar el principio de uniformidad. La naturaleza podría dejar de comportarse como lo ha venido haciendo hasta el momento, tanto en regiones que no hemos explorado, como en el futuro. Podríamos tratar de justificar este principio por inducción: hasta el momento hemos observado que el cosmos es uniforme, por lo tanto, concluimos que siempre será uniforme. Pero, claro está, este es un razonamiento que, tal y como Hume indicó, es circular. De hecho, podría ser que las regularidades que hemos observado hasta el momento dejen de mantenerse. Por ejemplo, a finales del siglo XIX la gravedad newtoniana había sido contrastada mediante evidencias empíricas obtenidas en múltiples escenarios, que abarcaban desde las manzanas a los planetas, por lo que parecía muy robusta. Sin embargo, la conclusión no se mantuvo, el cosmos no tenía exactamente la estructura que pensábamos y cuando nos acercamos a objetos muy masivos las predicciones de la gravedad newtoniana fallan estrepitosamente. Algún lector podría pensar que, como el cosmos en realidad sigue comportándose igual, la gravedad sigue funcionando igual, que lo único que ha cambiado ha sido nuestro conocimiento sobre ella. Es cierto que es probable que el cosmos no haya cambiado realmente, pero la cuestión es que nosotros no conocemos con absoluto detalle la estructura del cosmos, por lo que, incluso aunque la metafísica última del cosmos no haya variado, nuestras ideas sobre el mismo sí lo han hecho. El problema de la inducción es lógico y se aplica a cualquier caso en el que no dispongamos de una información completa del sistema estudiado. Una vez conocemos las reglas generales completas del sistema, de hecho, podemos prescindir de la inducción y hacer predicciones puramente deductivas. Podemos deducir predicciones a partir de un modelo. Además, aunque es posible que las leyes físicas fundamentales del cosmos sean realmente estables, no toda la ciencia es física fundamental. Hay áreas científicas que estudian sistemas en los que las condiciones pueden cambiar sin que los científicos se den cuenta. Por ejemplo, si hemos estudiado el comportamiento de un ecosistema durante décadas y hemos llegado a entender su funcionamiento, puede que ese conocimiento deje de ser aplicable cuando aparezca un nuevo factor, como una enfermedad desconocida o una especie invasora. En los sistemas sociales esto es todavía más relevante puesto que cambian a una gran velocidad y lo que aprendimos sobre su comportamiento ayer, probablemente, no será fácilmente extrapolable al futuro. A pesar de estas dificultades, Hume no recomendó que evitásemos la inducción. Entendió que la inducción es necesaria, tanto en nuestra vida cotidiana como en la ciencia.862 Esta es una conclusión compartida por la mayoría de los filósofos, que no suelen creer que el uso de la inducción sea irracional. Las inferencias ampliativas no son lógicamente tan sólidas como la deducción, pero no hay duda de que, en la práctica, suelen ser una buena herramienta.863 La cuestión no es plantearse si es racional pensar que el Sol saldrá mañana, sino preguntarse por qué es racional creerlo.864 En cualquier caso, es importante recordar que, al dar un salto lógico ampliativo, al ir más allá de lo observado, siempre quedaremos expuestos a equivocarnos. Esta es una limitación insalvable de la generación del conocimiento sobre sistemas de los que no tenemos información completa, por lo que es recomendable que nos esforcemos en ser rigurosos y que, al mismo tiempo, asumamos una cierta modestia intelectual. Las asunciones que hacemos al salir de casa por la puerta, y no intentando atravesar la pared, o al plantear teorías científicas, conllevan un cierto riesgo, pero parece que en el pasado hemos acertado lo suficiente como para que merezca la pena continuar esforzándonos por comprender el mundo externo. 12.5 Subdeterminación Los filósofos de la ciencia hablan de subdeterminación cuando disponemos de varias hipótesis compatibles con las evidencias disponibles. Este es un problema que ya planteó el pirrónico Enesidemo (80 a. C.-10 a. C.), pero que se popularizó tras el análisis que le dedicó el filósofo e historiador de la ciencia Pierre Duhem en su libro El objeto y la estructura de la teoría física (1906). Puesto que la dificultad aparece al tratar de explicar unas evidencias limitadas mediante unas hipótesis más generales, la subdeterminación es, en realidad, otra forma del problema de la inducción.865 Generar hipótesis subdeterminadas es muy sencillo. Por ejemplo, podríamos proponer teorías idénticas a las actuales, pero que planteasen que dentro de un año, o de dos o tres, el mundo pasará a estar regido por brujas. Este es, precisamente, el problema lógico que Goodman estaba tratando de evidenciar con sus esmeraldas verdules.866 También podemos ilustrar el problema con el ejemplo del ajuste de una recta. Dado un número finito de observaciones, por ejemplo, un número determinado de puntos en un plano cartesiano, podemos plantear un número infinito de hipótesis que se ajusten a los mismos. En este caso, las diferentes hipótesis serían líneas concretas, algunas rectas, otras curvas, que atravesasen el plano más o menos cerca de los puntos observados.867 Podría pensarse que esta limitación no tiene una gran trascendencia práctica. Al fin y al cabo, en la práctica, los investigadores solemos encontrarnos con el problema opuesto: dadas unas evidencias, no somos capaces de generar ni una sola hipótesis capaz de explicarlas. Por ejemplo, en la actualidad nadie ha conseguido, a pesar del enorme esfuerzo realizado por miles de físicos, plantear una teoría fundamental que unifique la mecánica cuántica con la relatividad general.868 No hemos sido capaces de postular ni una sola teoría que aúne la física de lo muy pequeño con la física de lo muy masivo. Sin embargo, concluir que la subdeterminación es un simple problema lógico que no afecta a la práctica científica sería un gran error. Ya hemos comentado, por ejemplo, el caso del modelo copernicano y el ticónico. A pesar de lo que muchos creen, una vez que Galileo realizó sus observaciones casi nadie volvió a defender el modelo ptolemaico; ni siquiera los astrónomos eclesiásticos lo hicieron. Las observaciones de Galileo, como hemos visto, hicieron que la mayoría de los astrónomos descartasen inmediatamente los epiciclos de Ptolomeo. Sin embargo, esto no implica que aceptasen que la Tierra se moviese, podían decantarse por la alternativa propuesta por Tycho Brahe. En este modelo los planetas giraban alrededor del Sol, pero el Sol se movía alrededor de la Tierra. A pesar de que una hipótesis era geocéntrica y la otra heliocéntrica, ambas eran, dadas las evidencias empíricas disponibles en aquel momento, indistinguibles. Por eso la Iglesia católica pudo, razonablemente, pedir a Galileo nuevas evidencias que permitiesen descartar la hipótesis ticónica de una Tierra inmóvil. Incluso si se aceptaba la observación de las fases de Venus, que había descartado al modelo ptolemaico, seguía siendo razonable, atendiendo a las evidencias empíricas, negar al movimiento de la Tierra. Lo mismo suele ocurrir en las investigaciones criminales. Imaginemos un asesinato y unas evidencias determinadas. Cada uno de nuestros sospechosos sería una hipótesis concreta. Para cada hipótesis, para cada posible asesino, podríamos deducir qué evidencias esperaríamos haber encontrado en la escena del crimen. Por ejemplo, si la víctima fue asesinada a golpes, esperaríamos que el sospechoso fuese alguien bastante fuerte. En base a esta predicción podríamos descartar a todos los alfeñiques. Sin embargo, esto no resolvería necesariamente el caso, puesto que podría ser que tuviésemos varios sospechosos muy musculosos. Nos encontraríamos, de nuevo, ante una subdeterminación. En ciencia también es común disponer de varias hipótesis capaces de explicar las observaciones disponibles. En estos casos el científico, como parte del proceso activo de investigación, suele buscar nuevas evidencias que le permitan discriminar entre las distintas opciones.869 Esto es lo que pidió la curia vaticana a Galileo. Dado que, tanto la hipótesis ticónica como la copernicana explicaban las observaciones astronómicas disponibles, los inquisidores demandaron a Galileo nuevas evidencias que permitiesen favorecer una de las dos opciones. Por desgracia nuestro pisano favorito no consiguió obtener evidencias capaces de aclarar la subdeterminación. No siempre es fácil resolver las subdeterminaciones y puede que durante un tiempo contemos con varias teorías capaces de explicar las observaciones. De hecho, para resolver ésta Galileo habría necesitado, por ejemplo, medir el paralaje estelar, pero las estrellas están tan lejos y el efecto es tan pequeño que no pudo medirse hasta 1838. Esto, sin embargo, no implica que hasta ese momento tan tardío los científicos siguiesen pensando que la propuesta de Tycho era razonable. La elección entre hipótesis, como comentaremos, es una cuestión más sutil. Además, tenemos otro problema aún más insidioso, el de las hipótesis no planteadas.870 Podría ser que el acusado que hemos encarcelado tras la investigación criminal fuese en realidad inocente. ¿Y si el culpable fuese el más debilucho de los sospechosos? Puede que, gracias a su ingenio, este alfeñique hubiese conseguido confundir a la policía. Estas hipótesis no consideradas son comunes en la práctica científica y, en ocasiones, se han hecho notar de un modo espectacular. Por ejemplo, a finales del XIX, dados los enormes éxitos predictivos de las teorías de Newton y Maxwell, se tenía una gran confianza en haber llegado al final de la física. En 1894 el físico Albert Michelson, el del experimento de Michelson y Morley que no consiguió detectar el éter, afirmó que ya se conocían todas las leyes relevantes de las ciencias físicas.871 Y, en 1878, el profesor alemán Johann Philipp Gustav von Jolly recomendó a uno de sus alumnos que no estudiase física diciéndole que “en este campo ya está casi todo descubierto y sólo quedan por solucionar algunos pequeños detalles sin importancia”. Su estudiante le replicó que estudiaría física puesto que no estaba especialmente interesado en hacer nuevos descubrimientos, sino, tan sólo, en comprender las teorías que explicaban el mundo.872 Ese estudiante era Max Planck y mientras investigaba uno de esos pequeños detalles, el espectro de emisión del cuerpo negro, es decir, el espectro de emisión térmica de los objetos, dio con un resultado que acabaría devorando nuestras certezas clásicas y arrojándonos a un mundo cuántico inesperadamente extraño. Y esto debería servirnos de lección. En la actualidad no disponemos de evidencias empíricas que no puedan ser explicadas por la relatividad general, pero es posible que el universo se comporte a nivel profundo de un modo distinto al planteado por Einstein. Siempre cabe la posibilidad de que la realidad se parezca más a una hipótesis que todavía no hemos considerado que a la actual. Y, además desde nuestra perspectiva presente es imposible determinar qué teorías actuales resistirán la criba y cuáles caerán. Esto es algo que sólo podrá saberse a posteriori. Este problema podría causar una cierta zozobra en algún lector que piense que puede que mañana nos despertemos con una imagen del cosmos completamente diferente a la actual. Sin embargo, es importante recordar que cualquier nueva teoría deberá dar cuenta de las observaciones actuales. Por ejemplo, cuando Einstein planteó la relatividad general, también explicó las evidencias que daban soporte a la gravedad newtoniana. Por lo tanto, al menos, tenemos la garantía de que las nuevas teorías se comportarán, en las regiones que ya hemos explorado empíricamente, de un modo similar al de nuestras teorías actuales. Recordemos: ninguna nueva teoría racional concluirá jamás que la Tierra es cúbica o plana. Por otro lado, también hay teorías que tienen una estructura indistinguible, que hacen predicciones empíricas completamente idénticas y que, por lo tanto, nunca podrán ser diferenciadas si nos limitamos a las observaciones. En este caso los filósofos de la ciencia hablan de subdeterminación fuerte. Hasta el momento habíamos comentado ejemplos de subdeterminación débil ya que, podía esperarse que, eventualmente, se encontrasen evidencias empíricas que resolviesen la subdeterminación, pero en el caso de la fuerte esto es imposible. Como ya hemos comentado, una hipótesis completamente indistinguible empíricamente que siempre podemos plantear es la de que el mundo fue creado hace cinco minutos con todo lo que vemos en él873 y otra es la de que vivimos dentro de Matrix. De nuevo el fantasma del escepticismo radical. En ciencia, aunque pueda sorprendernos, también hay casos de subdeterminación fuerte. Por ejemplo, en 1925 Heisenberg, Born y Jordan plantearon una formulación de la mecánica cuántica conocida como mecánica matricial que, por primera vez, era capaz de dar cuenta de los extraños resultados que los laboratorios experimentales se habían empecinado en producir. Muy poco después Schrödinger planteó una solución alternativa que también era capaz de reproducir esas mismas evidencias. Este es un caso de subdeterminación fuerte ya que las consecuencias empíricas de ambas formulaciones, tal y como demostraron Dirac y Von Neumann, son exactamente equivalentes. La estructura matemática subyacente de ambas teorías es, en el fondo, equivalente y, por lo tanto, no hay forma de distinguirlas.874 Los físicos concluyeron que se trataba de dos formulaciones matemáticas alternativas de la misma teoría. Sin embargo, esta equivalencia no ha de hacernos pensar que ambas teorías eran filosóficamente idénticas. Mientras que Heisenberg optó por una formulación basada en entidades observables en el laboratorio, Schrödinger planteó funciones de ondas con una existencia supuestamente real que, en la práctica, nunca podrían ser observadas. En la actualidad la situación teórica de la mecánica cuántica es incluso más compleja ya que hay distintas interpretaciones que, al menos con las evidencias actuales, están subdeterminadas. La interpretación de Copenhague, la más estándar, asume un componente aleatorio y una distinción, no muy claramente definida, entre sistemas cuánticos y clásicos y da lugar al problema conocido como de la medida. Otras de las dos interpretaciones alternativas más conocidas son las de Bohm, que incluye variables ocultas, pero que es completamente determinista, aunque no local, y la de los múltiples mundos de Everett. Según la bohmiana, el gato de Schrödinger estaría o vivo o muerto antes de abrir la caja y su estado estaría predeterminado por unas variables ocultas imposibles de medir, mientras que en la de Everett el evento cuántico haría que el estado del universo se dividiese en varias ramas, en algunas de ellas el gato estaría vivo y en otras muerto. Pero el caso es que, a pesar de postular realidades físicas tan diferentes, todas estas interpretaciones hacen unas predicciones empíricas completamente idénticas, están, por lo tanto, subdeterminadas y esta parece ser una subdeterminación fuerte. Nadie ha podido plantear, al menos de momento, ningún experimento que pueda diferenciarlas. Aunque esto podría cambiar en el futuro. Este tipo de problemas nos indican que disponer de una teoría empíricamente adecuada, que sea capaz de dar cuenta de las evidencias disponibles y de hacer predicciones correctas, no es ninguna garantía metafísica. En lo que sí podemos confiar es que ese modelo será siempre una herramienta que nos ayudará a desenvolvernos en el mundo. En los capítulos dedicados a la metafísica comentaremos la postura antirrealista que asume un compromiso radical con el empirismo y sus limitaciones y que, por lo tanto, cierra para siempre las puertas del cielo metafísico. A pesar de estos problemas, los antirrealistas ven el vaso medio lleno: disponemos de varias interpretaciones de la mecánica cuántica que explican las evidencias y que hacen predicciones extraordinariamente precisas con las que podemos desarrollar tecnologías y eso, según ellos, es suficiente. ¿Acaso tiene sentido establecer si quiera qué interpretación de la mecánica cuántica fuertemente subdeterminada se corresponde más con la realidad? Si todas dan cuenta de las mismas evidencias empíricas, ¿puede el empirista elegir entre ellas? Además, incluso las teorías físicas clásicas, aunque no sean las más avanzadas, siguen siendo útiles para la NASA. La utilidad es, desde luego, un gran valor en ciencia por lo que renunciar a la metafísica, tal vez, no sea tan grave. Sin embargo, los filósofos realistas defienden que la ciencia no tiene que limitarse a proponer teorías que se adecuen a las observaciones disponibles, sino que debe aspirar a determinar cuál es la realidad. A lo que los antirrealistas responden acusándolos de flirtear peligrosamente con una metafísica situada más allá del empirismo. A lo que los realistas replican pidiendo explicaciones a los antirrealistas de por qué se atreven a asumir el compromiso metafísico que implica defender la existencia de los gatos, pero se ponen tan nerviosos cuando se trata de electrones. Continuaremos con este debate en los últimos capítulos. 12.6 El sueño de la justificación deductiva Tanto Kant como Popper o Russell pensaron que el problema de la inducción era el mayor obstáculo jamás planteado al conocimiento y no es descabellado opinar que una gran parte de la filosofía de la ciencia del siglo XX, que poco a poco iremos desgranando, se constituyó como distintas reacciones a las limitaciones fundamentales derivadas del desafío humiano.875 Una posible opción para evitar el problema de la inducción consiste en abandonar toda esperanza de solucionar las dificultades relacionadas con la fase de descubrimiento, que, además, parece depender mucho de factores psicológicos y sociales, y limitarse a tratar de establecer una justificación deductiva de las hipótesis. Esta renuncia a hacer recomendaciones sobre la fase de descubrimiento podría parecernos una gran pérdida, pero no es una posición tan descabellada; si fuésemos capaces de establecer las normas racionales a seguir para elegir entre hipótesis habríamos avanzado muchísimo. Esta era, por ejemplo, la ambición de los positivistas lógicos, la racionalidad de una hipótesis debe depender de lo que dicha hipótesis implique, no de las circunstancias que favorecieron su nacimiento. Podríamos plantear la evolución biológica como una analogía extrema de esta aproximación. En la evolución, los distintos genomas, las distintas recetas sobre cómo actuar en el mundo, no se generan por inducción, sino que se crean completamente al azar, por mutación, es como si la fase de descubrimiento de los distintos diseños se hiciese a lo loco, pero luego la selección natural elige, de entre las distintas propuestas, aquellas que mejor funcionan y con esto basta para asegurarnos de que se obtendrá diseño final adecuado. Es decir, la evolución es capaz de crear conocimiento implícito sin realizar inducción alguna durante la fase de descubrimiento gracias a que la selección comprueba el desempeño de cada genoma durante la fase de justificación ante el mundo externo. La esperanza es que, aunque es difícil establecer qué motivos objetivos deberían llevar a un investigador a plantear que las órbitas son elípticas, tal vez sea más fácil y útil establecer normas que permitan justificar objetivamente las hipótesis planteadas. Una opción consistiría en seguir las recomendaciones aristotélicas y hacer una justificación puramente deductiva. Si pudiésemos conseguir una justificación puramente deductiva, es decir, lógicamente válida, de modo que la inducción quedase relegada a la fase de descubrimiento, habríamos solventado una parte fundamental del problema de la inducción. El problema de la propuesta aristotélica, como ya hemos comentado, es que sólo funciona bien para los sistemas formales. Cuando estudiamos el mundo externo, para que las conclusiones de las deducciones sean verdaderas, y no sólo válidas, hemos de partir, necesariamente, de premisas verdaderas. Además, en la práctica, tenemos el problema adicional de que podemos equivocarnos al hacer largas cadenas deductivas, pero obviemos esta segunda dificultad. Aristóteles se planteó cómo llegar a las premisas verdaderas, pero no resolvió la cuestión satisfactoriamente porque: ¿acaso no deben estas premisas generales ser inducidas a partir de observaciones concretas? Por ejemplo, supongo que Aristóteles habría aprobado la premisa: los líquidos fluyen a favor de la gravedad. Este no parece ser un punto de partida muy controvertido para iniciar una cadena de deducciones, al fin y al cabo, todos nosotros hemos observado muchos ejemplos de líquidos fluyendo a favor de la gravedad. Los ríos, por ejemplo, no escalan montañas, sino que bajan hacia el océano. Sin embargo, ¿podemos estar realmente seguros de que esto será verdadero para todos y cada uno de los líquidos? Puede que, a pesar de haber hecho muchísimas observaciones, tal vez, se nos haya escapado alguna evidencia clave. Recordemos el plumaje de los cisnes negros. No tenemos una garantía absoluta de que todos los líquidos vayan a fluir siempre a favor de la gravedad y, por lo tanto, no podemos saber si esta es una premisa válida en todas las circunstancias, por lo que no deberíamos usarla como punto de partida en una justificación que pretenda alcanzar un estatus de verdad infalible. Esto plantea un problema fundamental, si no podemos alcanzar las premisas referidas al mundo externo por deducción a partir de un conjunto finito de observaciones particulares, nunca podremos hacer inferencias deductivas infalibles relativas a ese mundo externo. Por muchos años o décadas que dediquemos a nuestros experimentos, nunca podremos observarlo todo y, por lo tanto, nuestras deducciones siempre estarán sujetas a la falibilidad de las premisas. Por cierto, aunque no hay ríos que corran desde el mar a las montañas, sí que hay líquidos, los superfluidos, capaces de fluir desafiando la gravedad.876 Aristóteles asumió que, de algún modo, nuestra mente debería ser capaz de intuir cuáles son las premisas verdaderas generales, pero esto es claramente insatisfactorio. Este es un problema que afectó especialmente a los filósofos naturales medievales, que pretendían seguir el ejemplo aristotélico, y, sobre todo, a los metafísicos escolásticos que depositaron una gran confianza en sus magníficos edificios deductivos, sin caer en la cuenta de que sus construcciones tenían los pies de barro ya que, entre otras cosas, partían de premisas obvias, como que todos los objetos ocupan una posición en el espacio, pero que no tenían por qué ser verdaderas. Popper, como veremos, también intentó solventar el problema proponiendo una justificación puramente deductiva, pero su propuesta fue muy diferente a la Aristotélica. No en vano habían transcurrido dos milenios de investigación filosófica. Por muchos datos confirmatorios que obtengamos nunca podremos estar seguros de que una hipótesis es verdadera puesto que puede que haya observaciones por hacer que evidencien su falsedad, pero, al menos, pensó Popper, podríamos descartar, deductivamente, aquellas hipótesis que no sean empíricamente adecuadas. Esta renuncia parcial implica que nunca podremos estar seguros de que nuestra hipótesis actual, en el futuro, no vaya a sucumbir, pero, al menos, si podríamos descartar deductivamente las hipótesis erróneas. Sin embargo, como comentaremos en el próximo capítulo, ni siquiera esto fue posible, ya que las ambiciones de Popper, a pesar de los sacrificios que implicaban, cayeron frente al problema del holismo confirmacional. En realidad, en la práctica científica el uso de la inducción es imprescindible y generalizado. Tanto durante la fase de descubrimiento, en la que las hipótesis se generan utilizando inferencias como la inducción simple, la abducción o la analogía, como en la de la justificación, en la que es común que se utilicen la inferencia a la mejor hipótesis, algún tipo de inferencia eliminativa o, en general, la inferencia bayesiana (que comentaremos más adelante). Es normal que así sea ya que siempre estaremos justificando una conclusión general basándonos en unas evidencias limitadas. La mayoría de estos tipos de inferencia son, además, ampliativos y, por lo tanto, lógicamente inválidos. La excepción es la inferencia bayesiana, que no es ampliativa. De hecho, este es uno de los motivos que la hacen especialmente interesante. En realidad, la inferencia bayesiana puede considerarse como una generalización de la lógica para el caso en el que asignamos grados de confianza a nuestras hipótesis y evidencias. La propuesta bayesiana recurre a la probabilidad. Russell ya defendió que lo racional sería establecer el grado de confianza en las diversas hipótesis basándose en las evidencias disponibles.877 En este caso la probabilidad refleja este grado de confianza. Esto es lo que formaliza, como exploraremos en el penúltimo capítulo, la inferencia bayesiana. El bayesianismo llegó a la ciencia de la mano del gran matemático francés Pierre-Simon Laplace (1749-1827), pero no se popularizó hasta el siglo XXI. La inferencia bayesiana plantea una lógica probabilística que incluye a la deductiva y a la inductiva en un marco común y que es capaz de distribuir la información contenida en las evidencias en la confianza final que nos merecerán las distintas hipótesis planteadas. El bayesianismo representa un gran avance ya que resuelve la cuestión de cómo debe un pensador racional actualizar la confianza en sus creencias dadas unas evidencias concretas. ¿Cuál habría sido el comportamiento racional del pavo cauto? Pues el marco bayesiano dicta cómo debe ir actualizando su confianza, día tras día, a medida que siguen poniéndole de comer cada mañana. A pesar de que el bayesianismo representa, sin duda alguna, un gran avance, no consigue solventar el problema de las hipótesis no planteadas ni la violación del principio de uniformidad. La inferencia bayesiana comienza asumiendo un conjunto de hipótesis a evaluar, pero no nos dice nada sobre cómo generar esas hipótesis ni sobre cuándo y cómo conviene modificarlas. Esta lógica sólo contempla cómo hemos de alterar nuestra confianza en nuestras creencias a medida que vamos obteniendo nuevas evidencias. De modo que ni Aristóteles, ni Popper, ni los bayesianos han sido capaces de librarnos del todo del problema de la inducción. La mayor parte de los filósofos de la ciencia cree que la inducción es imprescindible878 y que, por lo tanto, siempre que planteemos un modelo del funcionamiento de un sistema, a partir de información limitada, deberemos asumir el falibilismo que implican los saltos lógicos ampliativos. 12.7 Otras reacciones Otra opción al problema de la inducción que ha sido muy popular, especialmente en la segunda mitad del siglo XX, es la de Feyerabend y los relativistas: si no hay un modo absolutamente certero de justificar una creencia particular, todas las creencias son igual de válidas.879 Esta posición tiene su paralelismo en la filosofía antigua, en este caso en Protagoras y los sofistas, que concluyeron que si a mí me parece que el agua está fría es que el agua está fría. Esta conclusión encierra un error fundamental puesto que confunde el mapa con el territorio, mis ideas sobre el mundo con el mundo externo. Que a mí me parezca que el agua está fría sólo implica que a mí me parece que el agua está fría, la cuestión de la temperatura real del agua es otra bien distinta. Otra alternativa es regresar al escepticismo radical helenístico, defender la pureza del conocimiento y asumir que si la certeza absoluta es inalcanzable debemos renunciar a la posibilidad de aprender sobre el mundo externo. Tanto el escepticismo radical como el relativismo son defendidos en la actualidad por muy pocos pensadores serios. Las propias escuelas escépticas antiguas se dieron cuenta de que una renuncia honesta al conocimiento del mundo externo impediría la intervención en ese mundo, lo cual es incompatible con la vida. Además, resulta evidente que, si nuestras acciones funcionan, al menos parcialmente, debe de ser porque las predicciones generadas a partir de nuestras creencias deben de estar recogiendo, al menos en parte, la estructura del mundo externo. Y esto hace que la renuncia a la posibilidad de conocimiento sea claramente irracional. Uno siempre puede plantear dudas más allá de lo razonable, pero esas dudas serán, por supuesto, irracionales. La cuestión que debemos plantearnos no es si el conocimiento es posible o no, está claro que lo es, lo relevante es cómo conseguir mejorar su generación. Además, hemos de ser muy conscientes de que, aunque al menos sobre algunos aspectos del mundo externo, es posible generar conocimiento, no es menos cierto que ese conocimiento será falible y, por lo tanto, debemos estar abiertos a la posibilidad de que sea revisado en el futuro. Y lo que es peor, las consecuencias del problema de la inducción no se limitan a este tipo de falibilidad, el salto lógico de las inferencias ampliativas nos expone al error puro y duro. Una vez saltamos, si no tenemos mucho cuidado, podemos acabar con nuestros huesos en el asfalto. La inducción es una herramienta muy poderosa, pero su uso racional es un arte que exige del investigador responsable modestia intelectual y compromiso con la integridad intelectual. 12.8 Resumen Si queremos aprender sobre el mundo externo estamos obligados a hacer inferencias ampliativas y, por lo tanto, lógicamente inválidas. Nuestro conocimiento, más allá de las disciplinas formales, como la lógica o las matemáticas, siempre será falible. Siempre cabrá la posibilidad de que estemos completamente equivocados o, al menos, de que nuestras creencias hayan de ser matizadas en el futuro. Esta no es una simple posibilidad filosófica, sino que tiene profundas implicaciones prácticas. La física clásica de Newton y Maxwell, a pesar de sus enormes éxitos empíricos, hubo de ser abandonada como teoría fundamental porque otras teorías, que los investigadores clásicos no habían soñado plantear, demostraron ser más correctas. La física establecida cayó a principios del siglo XX de un modo espectacular y esa es una lección sobre la que los filósofos de la ciencia han estado reflexionando desde entonces. Las conclusiones las iremos desgranando en los próximos capítulos, pero hay algo que podemos adelantar: la NASA sigue usando la mecánica newtoniana para calcular la trayectoria de sus cohetes. Que una teoría ya no sea candidata a nuestra mejor teoría fundamental no implica necesariamente que sea completamente errónea. La mecánica newtoniana sigue siendo una excelente aproximación en la mayoría de los casos. Además, las nuevas teorías han de dar cuenta de los fenómenos empíricos que se utilizaron para justificar las antiguas y esto exige que las estructuras de las nuevas y las viejas sean muy similares en las regiones mejor exploradas. Podríamos decir que en estos casos la ciencia refina y matiza, no desecha. Por otro lado, en áreas que estudian sistemas más complejos, como la ecología o la epidemiología, puede que las conclusiones establecidas pasen a ser falsas sin previo aviso porque algún aspecto relevante de esos sistemas cambie. El conocimiento sobre un sistema asume que el sistema seguirá comportándose mañana como lo ha hecho en el pasado. La base de nuestro conocimiento es empírica, pero las evidencias, provienen necesariamente del pasado, de modo que si cambian las reglas de juego lo que hemos aprendido de ellas puede convertirse en papel mojado. Nuestra perspectiva siempre será limitada. Es posible generar conocimiento, pero el reconocimiento de nuestras limitaciones exige que seamos especialmente rigurosos y, a la vez, que recordemos que, incluso así, puede que estemos equivocados o, al menos, que nuestras ideas sean susceptibles de mejora. "],["es_falso.html", "13 Es falso 13.1 Falsación 13.2 Contra la inducción 13.3 Falsar o no falsar 13.4 El falsacionismo matizado 13.5 El holismo confirmacional 13.6 Resumen", " 13 Es falso Puede que Karl Popper (1902 - 1994) sea, junto a Thomas Kuhn (1922 - 1996), uno de los filósofos de la ciencia más conocidos por los científicos. Popper pensaba que, puesto que la ciencia aspiraba al máximo rigor intelectual, debía tratar de evitar el problema de la inducción y su receta consistió en intentar deshacerse de las inferencias no deductivas en el contexto de la justificación. 13.1 Falsación La propuesta de Popper está muy relacionada con el método hipotético-deductivo: utilizando la deducción generamos predicciones empíricas a partir de las hipótesis planteadas y, posteriormente, evaluamos esas hipótesis de acuerdo a los resultados obtenidos. Recordemos que este procedimiento, entendido de un modo más o menos laxo, es un pilar fundamental de la aproximación científica: las hipótesis propuestas se juzgan comparando sus predicciones con las evidencias empíricas.880 El matiz que Popper introdujo consistió en limitar este juicio: lo único que deberíamos hacer es descartar las hipótesis cuyas predicciones fallen. Esto puede parecer razonable, pero se deja fuera algo que también solemos considerar: Popper insistió en que si las predicciones acertaban no teníamos que incrementar nuestra confianza en ellas. Es decir, si nuestra hipótesis es que mañana saldrá el Sol y observamos diez mil amaneceres, cuando llegue el día número 10.001 nuestra confianza en que veremos un nuevo amanecer, según el falsacionismo, habría de ser exactamente igual a la del primer día, pero si un día no amaneciese habríamos de descartar la hipótesis de que todos los días amanece. Popper, además, introdujo un concepto muy interesante, la falsabilidad. Una hipótesis es falsable si existe un modo de establecer, haciendo observaciones y experimentos, que la hipótesis no se corresponde con la realidad.881 De modo que Popper planteó dos ideas: 1) que las hipótesis científicas habían de ser susceptibles de ser testadas empíricamente y 2) que el rechazo de una hipótesis podía y debía ser puramente deductivo. Lo primero continúa siendo una gran idea y, probablemente, es lo que hace que Popper sea tan popular entre los científicos. Lo segundo, como veremos, le llevó a un callejón sin salida, que, en mi opinión, mucho después, como también comentaremos, fue resuelto satisfactoriamente por otro tipo de inferencia no ampliativa, la bayesiana. Las hipótesis sin implicaciones empíricas no tienen valor en ciencia. Carl Sagan planteó un ejemplo muy conocido de pseudohipótesis: la del dragón invisible, incorpóreo y completamente indetectable que habitaba su garaje. Si lo que esperamos observar en el universo es exactamente lo mismo, independientemente de que aceptemos o no la hipótesis, esa propuesta no tiene ningún valor científico.882 Otra consecuencia de esta exigencia de falsabilidad es que las hipótesis tienen que ser lo suficientemente claras y precisas como para que puedan derivarse, a partir de ellas, predicciones empíricas capaces de falsarlas.883 Popper criticó, por ejemplo, las ideas freudianas y algunas versiones de las doctrinas marxistas.884 Aunque pueda parecer que las propuestas psicoanalíticas de Freud hacen predicciones comprobables sobre el comportamiento de sus pacientes, la realidad es que estas supuestas hipótesis sobre el funcionamiento de la mente, en la práctica, son tan vagas como el dragón de Sagan. Por ejemplo, supongamos que un psicoanalista llega a la conclusión de que los traumas de su paciente son debidos a que su padre lo llevó a un ritual satánico organizado por extraterrestres de Raticulín. ¿Habría alguna respuesta de su paciente capaz de falsar esta hipótesis? No parece que esto sea fácil. Si el paciente recuerda el episodio, a ojos del psicoanalista, la hipótesis quedará confirmada, pero si, por el contrario, el sujeto analizado niega haber estado jamás en manos de los grises, el psicoanalista concluirá que el trauma hizo que la memoria fuese reprimida. La respuesta del paciente, por lo tanto, es irrelevante, conteste lo que conteste la hipótesis será mantenida. A pesar de su apariencia de seriedad las hipótesis freudianas no serían verdaderas hipótesis científicas porque una hipótesis sólo tiene legitimidad científica si existe algún modo de que las evidencias empíricas puedan falsarla. Este es el tipo de problemas que Popper quería desenmascarar utilizando su criterio de falsabilidad. Sin embargo, los defensores del psicoanálisis podrían aducir que sus propuestas fueron elaboradas tras entrevistar a numerosos pacientes, es decir, que su construcción habría tenido en cuenta evidencias empíricas. Pero recordemos: las hipótesis deben ser justificadas por sus propios méritos, independientemente de cómo hayan sido descubiertas. Popper iría incluso más allá y descartaría las evidencias favorables obtenidas posteriormente como, por ejemplo, que algún paciente recuerde haber sido sometido al ritual satánico. Esta última observación puede que haya sorprendido a algunos lectores, ¿cómo es posible que Popper rechace las observaciones a favor de una hipótesis? Según este filósofo aceptar las evidencias confirmatorias conllevaría dos problemas: uno práctico y otro lógico. El práctico es que siempre es fácil conseguir tener evidencias confirmatorias si propones hipótesis lo suficientemente vagas.885 El psicoanálisis sería equivalente a los mentalistas, que hacen predicciones tan poco definidas que cualquier evidencia puede contar como confirmatoria.886 El problema lógico es que, según Popper, la confirmación exige que utilicemos la inducción y, recordemos que la propuesta popperiana era radical: debemos evitar el problema de la inducción renunciando completamente a ella. Según este pensador lo relevante es que la falsación puede ser deductiva y, por lo tanto, lógicamente válida. Popper, además de ejemplos negativos, también planteó paradigmas positivos sobre cómo debería hacerse ciencia y uno de ellos fue la relatividad general. Cuando Einstein propuso su teoría se esforzó por hacer predicciones concretas sobre qué observaciones podrían confirmarla o refutarla. Por ejemplo, según la relatividad general, la luz estelar que pasa cerca del Sol en su camino hacia la Tierra debería curvarse por el efecto del fuerte campo gravitatorio solar. Este efecto podría detectarse midiendo la posición de las estrellas cercanas al Sol durante un eclipse. Además, utilizando la relatividad general se pueden hacer predicciones muy precisas sobre la magnitud de este aparente desplazamiento astronómico. Por lo tanto, si se realizase esta medida, algo que Arthur Eddington hizo el 29 de mayo de 1919, y no se correspondiese con la predicción relativista, en principio, la relatividad general quedaría refutada.887 Popper llegó incluso a plantear la falsación como un criterio con el que distinguir la ciencia de la pseudociencia, de las disciplinas formales, como las matemáticas y la lógica, y de la metafísica.888 Una hipótesis sólo sería científica si se la jugase empíricamente, es decir, si fuese falsable. Una de las consecuencias de este criterio de demarcación es que, aquellas teorías capaces de acomodar cualquier observación, incluso aunque pueda parecer que están soportadas por una gran cantidad de evidencias, no serían, en realidad, informativas889 y, por lo tanto, no serían científicas.890 Popper propuso que el psicoanálisis, por ejemplo, pertenecería a esta categoría. A pesar de parecer estar soportado por muchas evidencias no sería más que un relato sin contenido informativo.891 Esta es una idea muy clara, interesante y atractiva, por lo que no es de extrañar que la falsación de Popper sea, junto a los paradigmas de Kuhn, una de las pocas propuestas filosóficas que suelen mencionarse en los pasillos de los departamentos de ciencia892 y puede que, de hecho, sea incluso más popular entre los científicos que entre los filósofos.893 La falsación, tomada con una pizca de sal, es una guía muy útil:894 las hipótesis deben jugársela empíricamente y una hipótesis sin consecuencias empíricas no es ciencia. Además, como ya hemos comentado, los científicos realmente proceden, al menos en algunos casos, falsando hipótesis.895 Recordemos que las observaciones de las fases de Venus sirvieron a Galileo para descartar el modelo ptolemaico. Sin embargo, esto no implica que los científicos entendamos los detalles y las limitaciones filosóficas de esta propuesta. Yo mismo hasta que hace unos años empecé a leer sobre filosofía de la ciencia no comprendía el alcance de la falsación. 13.2 Contra la inducción Como ya hemos mencionado, Popper pretendía recuperar el rigor lógico de la ciencia renunciando a la inducción y exigiendo que la elección de las hipótesis dependiese exclusivamente de inferencias deductivas.896 En esto Popper navegaba a contracorriente ya que la mayor parte de los filósofos de la ciencia y, muy en particular, los positivistas lógicos, consideraban, con acierto, que las inferencias no deductivas eran imprescindibles.897 La clave, según Popper, estribaría en una asimetría fundamental: mientras que ni siquiera un millón de cisnes blancos serían suficientes para confirmar que todos los cisnes son blancos, un sólo cisne negro bastó para refutar la hipótesis. Aunque no hay un modo lógicamente válido de comprobar definitivamente una hipótesis, según Popper, un solo contraejemplo podría servir para falsarla.898 Esta es la asimetría crucial sobre la que Popper construyó su propuesta filosófica y que, según él, permitiría a la ciencia liberarse del fantasma de la inducción. Las leyes científicas no pueden comprobarse definitivamente, pero, en principio, parecería que sí pueden falsarse gracias a la deducción.899 Este es el motivo lógico por el que la propuesta de Popper es negativa y se centra en la falsación y no en la comprobación. La actividad científica consistiría, según Popper, en plantear hipótesis e intentar refutarlas en base a sus predicciones.900 Feynman también planteó que la clave de la actividad científica consiste en que el investigador propone una ley, calcula sus consecuencias y si los experimentos contradicen esas consecuencias, la ley es errónea y se rechaza.901 El falsacionismo es, sin duda, muy útil como primera aproximación, aunque, el asunto es, en realidad, algo más sutil. Uno de los problemas de esa caracterización de Feynman es que no establece qué debería pensar el científico si los resultados experimentales sí coincidiesen con la hipótesis propuesta. ¿Debería el investigador aumentar su confianza en la ley? Según Popper esto sería erróneo puesto que este incremento en la confianza sólo podría hacerse inductivamente. Sin embargo, la mayoría de los científicos sí piensan que, de algún modo, un resultado positivo debería aumentar su confianza en la hipótesis y esta es una conclusión que comparten la mayoría de los filósofos de la ciencia.902 Los investigadores suelen pensar que las hipótesis no sólo se falsan, sino que también se confirman. Lo cierto es que, a lo largo de la historia, los científicos han confiado más en las teorías que han tenido un mayor éxito predictivo.903 Y esta confianza debe aumentar, especialmente, cuando se comprueba una predicción inesperada, como, por ejemplo, la predicción relativista de la curvatura de los rayos de luz debida a la gravedad solar.904 A pesar de esto, según Popper, el dato de que haya amanecido muchas veces en el pasado, no ha de hacernos aumentar, ni un ápice, nuestra confianza en que mañana volverá a salir el Sol. La confirmación sería un mito ya que, al renunciar a la inducción, todo lo que podemos hacer es asumir que, por el momento, no hemos falsado la hipótesis de que amanece todos los días.905 Según los falsacionistas estrictos, nuestra confianza en una hipótesis, por muchas evidencias que se acumulen en su favor, no debería aumentar lo más mínimo. A casi todo el mundo le parece que esta conclusión es muy extraña, pero Popper estaba tan preocupado por el trágico destino del pavo navideño que decidió no jugársela. Según este filósofo la teoría de la evolución o la relatividad serían conjeturas que, por el momento, no han sido falsadas, nada más. Popper era consciente de que la renuncia a la comprobación era problemática y, como alternativa, planteó el concepto de la corroboración: una hipótesis podría ser corroborada si hiciese una predicción muy novedosa que resultase coincidir con evidencias empíricas posteriores.906 Este habría sido el caso de la relatividad general, por lo que Popper, aunque no la consideraría confirmada, al menos, sí corroborada. Según Popper no deberíamos creer que una teoría más corroborada sea verdadera, pero, al menos, debería ser merecedora de una mayor atención, deberíamos esforzarnos más por intentar falsarla. El concepto de corroboración se enfrentó a dos fuertes críticas. Por un lado, la novedad es históricamente relativa. No es fácil justificar por qué el hecho de que un investigador conozca una evidencia en un momento dado deba influir en cuánto apoya esa evidencia su hipótesis. Este es un problema que se conoce como de la histéresis. Según Popper la órbita anómala de Mercurio sería una evidencia de un valor menor que la curvatura gravitatoria de la luz porque Einstein conocía el primer resultado experimental, pero no el segundo. Sin embargo, lo ideal, tal vez, sería considerar cualquier evidencia, independientemente de cuándo ha sido obtenida.907 Sin embargo, esta no fue la principal crítica. El problema principal, tal y como denunciaron los positivistas lógicos, es que la propia idea de la corroboración o bien está vacía o bien se refiere, veladamente, a la confirmación y, por lo tanto, hace uso de la inducción.908 13.3 Falsar o no falsar Evidentemente, no es suficiente con que una hipótesis sea falsable, de poco serviría esto si luego no actuásemos en consecuencia una vez se obtengan evidencias que contradigan sus predicciones. Algunas predicciones de los horóscopos son concretas y, por lo tanto, falsables. Sin embargo, no podemos considerarlos conocimiento porque cuando la realidad les contradice, los astrólogos ignoran el problema. Sin embargo, lo cierto es que los científicos tampoco abandonan sus teorías automáticamente nada más encontrar alguna evidencia que las contradiga.909 Es habitual que los investigadores continúen utilizando o, incluso defendiendo, una teoría a pesar de haberse topado con anomalías empíricas. En filosofía de la ciencia, para comentar ese asunto, suelen explicarse los casos de las órbitas de Urano y Mercurio. En la primera mitad del siglo XIX ya se había observado que ambos planetas tenían órbitas que no eran compatibles con los cálculos basados en la gravedad newtoniana. Sin embargo, los físicos no sólo no abandonaron la mecánica clásica, sino que continuaron considerando las teorías de Newton como uno de los grandes éxitos del estudio del mundo natural. Según el falsacionismo ingenuo, los físicos estaban siendo irracionales. Sin embargo, al menos en este caso, el que estaría equivocado sería el falsacionista ingenuo. La falsación es una buena idea, pero sólo si no se lleva al extremo. Decidir cuándo debe desestimarse una teoría es un asunto algo más sutil y complejo910 que trataremos en el próximo capítulo, y que, de hecho, no puede hacerse utilizando sólo la deducción. La idea original de Popper se basaba en que, si llegamos a una conclusión deductiva, en el caso científico a una predicción, partiendo de una premisa, es decir, de una hipótesis y, posteriormente, comprobamos que la conclusión es falsa estaremos obligados a rechazar la premisa/hipótesis. Sin embargo, a diferencia de la falsación, cualquier incremento en la confianza exigiría siempre utilizar inferencias no deductivas. El problema es que, aunque esta asimetría entre comprobación y falsación que es, hasta cierto punto, defendible, en realidad, no es tan absoluta como la tesis de Popper requería.911 Un fallo fundamental en la propuesta popperiana es que no es cierto que, dada una hipótesis, podamos hacer predicciones empíricas que nos permitan testarla.912 Por ejemplo, es imposible predecir las órbitas de los planetas basándose exclusivamente en la mecánica newtoniana. Para plantear una predicción no basta disponer de la hipótesis es necesario añadir algunas asunciones extra.913 En el caso planetario, se requiere conocer la posición, masa y velocidad de los principales cuerpos del sistema solar.914 Por lo tanto, si el test falla, ya no será posible decidir, deductivamente, si la culpa es de la teoría que estábamos tratando de comprobar, de las asunciones adicionales o de ambas.915 El planteamiento de este problema suele asociarse al físico Pierre Duhem (1861-1916) y al filósofo W. V. O. Quine (1908-2000). Duhem criticó, concretamente, la tesis de que, dado un resultado de un experimento crucial, siempre fuese fácil llegar a conclusiones claras.916 Recordemos que Francis Bacon había propuesto que estos experimentos claves eran ensayos empíricos que nos permitían elegir entre dos hipótesis, como, por ejemplo, las observaciones galileanas de las fases de Venus que permitieron descartar el modelo ptolemaico. Por desgracia, la conclusión que debe tomarse tras un fracaso predictivo no siempre es tan clara. Muchas veces se generan en el seno de las comunidades científicas duras discusiones sobre cuál debe ser la lección. Duhem asumió que los científicos, al final, serían capaces de determinar, en cada caso, si finalmente la teoría debía descartarse o no, pero, el problema es que esto exigiría utilizar alguna forma de inducción, algo que Popper estaba tratando de evitar. Puesto que la falsación popperiana exige que sólo se hagan inferencias deductivas, esta limitación supone un golpe fatal para esta aproximación entendida en sentido estricto.917 Esta es una dificultad que, de nuevo, no sólo afecta a la ciencia sino al conocimiento sobre el mundo externo en general. Imaginemos que quiero hablar con mi madre y, como creo que está en su casa, la llamo al teléfono fijo, pero mi madre no contesta. ¿Puedo deducir que mi madre ha salido? Evidentemente no. Esta es una opción, pero hay otras. Puede que estuviese escuchando música y no haya oído el teléfono o que el timbre del aparato esté estropeado y no suene o que, simplemente, no tenga ganas de hablar conmigo. Pero volvamos al ejemplo histórico de las órbitas planetarias. En 1788 se observó que la posición celeste de Urano tenía una desviación de 1/120 de grado sobre la predicción.918 Los astrónomos, sin embargo, no decidieron abandonar la mecánica newtoniana inmediatamente, sino que optaron por investigar el problema. Al final se dieron cuenta de que para predecir la órbita con suficiente precisión debían incluir en los cálculos no sólo la influencia gravitatoria del Sol, sino también la de Júpiter y Saturno. Esta corrección resolvió el problema y las observaciones volvieron a coincidir con las predicciones. Sin embargo, poco duró la alegría ya que en 1825 la posición observada para el planeta se había vuelto a situar por delante de la órbita predicha y en 1832 se había retrasado de nuevo.919 Para solucionar esta anomalía, en 1846, dos astrónomos, John Couch Adams y Urbain Le Verrier, postularon, independientemente, la existencia de un planeta desconocido que debía de estar empujando y tirando de Urano en distintos periodos. Le Verrier pidió ayuda al observatorio de Berlín y el 23 de septiembre de 1846 apuntaron un telescopio a la posición predicha y, efectivamente, se encontró un punto de luz que no se correspondía con ningún astro previamente catalogado y que, además, noche tras noche se movió siguiendo la predicción de Le Verrier.920 Este investigador hizo, precisamente, lo que Popper había criticado a los freudianos y a los marxistas; propuso una hipótesis ad hoc para justificar la anomalía empírica y, al hacerlo, lejos de hacer mala ciencia, demostró ser un astrónomo excelente ya que consiguió, usando papel, pluma y sus avanzadas matemáticas descubrir un nuevo planeta: Neptuno. Sin embargo, si Le Verrier hubiese sabido de la falsación popperiana y hubiese seguido sus recomendaciones, no habría propuesto la hipótesis ad hoc y no habría descubierto Neptuno. Una hipótesis ad hoc es aquella que se propone específicamente para explicar una anomalía predictiva, es decir, para salvar una teoría que se enfrenta a una evidencia contraria. En el caso de Urano resultó que la anomalía no se debía a la teoría, que es lo que la propuesta falsacionista más sencilla habría asumido. El problema radicaba en que, como para hacer la predicción se requería tanto la teoría newtoniana como la composición del Sistema Solar, la observación anómala podía implicar un error tanto en la teoría como en el conocimiento planetario y, además, era imposible decidir deductivamente a qué había de atribuirse el problema. Es evidente que un buen investigador es capaz de apostar por una u otra opción, pero esto requiere que utilice alguna forma de inducción, algo que Popper rechazaba. Le Verrier, sin embargo, se la jugó proponiendo una hipótesis ad hoc que incluía un nuevo planeta e hizo las predicciones empíricas correspondientes para contrastar esta nueva hipótesis. Satisfecho con el resultado, Le Verrier decidió buscar otros planetas aplicando el mismo procedimiento y encontró que el perihelio de Mercurio en vez de avanzar 5557 arcos de segundo por siglo avanzaba 5600.921 El astrónomo francés, confiado por el éxito anterior, volvió a apostar por la existencia de un planeta desconocido y, de nuevo, volvió a calcular su supuesta posición. En este caso, Vulcano, tendría un tamaño similar al del propio Mercurio y estaría localizado en una órbita muy próxima al Sol. Esta predicción, tal y como el propio Le Verrier admitió era bastante más arriesgada que la anterior ya que resultaba extraño que no se hubiese observado previamente un planeta de ese tamaño tan cercano al Sol.922 En las siguientes décadas algunos astrónomos afirmaron haber observado el planeta, sin embargo, ahora sabemos que el único Vulcano es el planeta natal de Spock y éste no pertenece al Sistema Solar. Para el falsacionismo el caso de Vulcano resultó ser todavía peor que el de Neptuno. La anomalía empírica quedó sin resolverse y, aun así, los físicos no sólo no descartaron la gravedad newtoniana, sino que la siguieron teniendo en gran estima. El problema de Mercurio, simplemente, quedó aparcado puesto que sin una teoría alternativa poco más podía hacerse.923 Descartar la mecánica newtoniana, una teoría que estaba funcionando muy bien en casi cualquier otro caso, habría sido absurdo. De hecho, lo habitual es que no se abandone una teoría falsada hasta que no se dispone de una alternativa mejor.924 En el caso de la anomalía de Mercurio esto sucedió cuando Einstein, que era consciente del problema del perihelio, realizó el cálculo de su órbita utilizando la relatividad general.925 Ahora sabemos que la cercanía de Mercurio al Sol lo somete a un efecto gravitatorio mucho más intenso que el de los otros planetas y esto hace más obvias las diferencias entre las predicciones newtonianas y relativistas. 13.4 El falsacionismo matizado Popper era consciente del problema planteado por Duhem926 y tuvo que matizar su posición. De hecho, admitió que las hipótesis ad hoc, siempre que sean limitadas y que hagan nuevas predicciones, son admisibles.927 Esto es, precisamente, lo que Adams y Le Verrier habían hecho, plantear un cambio ad hoc acompañado por una nueva predicción que, eventualmente, podía ser comprobada. Esta exigencia prevendría los abusos de los pseudocientíficos que plantean incalculables hipótesis ad hoc para excusar sus fallos predictivos. Plantear hipótesis ad hoc para dar cuenta de anomalías empíricas sería una buena práctica científica siempre que se acompañasen de nuevas predicciones. Imre Lakatos (1922-1974), discípulo de Popper y otro de los grandes filósofos de la ciencia, propuso distinguir entre falsacionismo ingenuo y sofisticado.928 Según Lakatos la clave consistiría en distinguir entre programas de investigación progresivos y degenerados. Un programa degenerado sería aquel que, una vez tras otra, va proponiendo modificaciones ad hoc para defenderse de las anomalías, mientras que uno progresivo sería aquel caracterizado por hacer predicciones novedosas exitosas. Un programa de investigación puede medrar, como muestra el caso del perihelio de Mercurio, incluso aunque incluya en su seno anomalías sin explicar. Sin embargo, cuando una hipótesis entra en conflicto repetidamente con las evidencias, eventualmente, debe acabar siendo rechazada.929 Esto no implica que la ciencia, en algunas ocasiones, no funcione siguiendo el modelo popperiano. Recordemos, por ejemplo, el caso de Galileo y las fases de Venus. Una sola anomalía clara, especialmente cuando se dispone de una hipótesis alternativa, puede ser suficiente para convencer a la comunidad de que la vieja hipótesis ha de ser abandonada. Simplemente, es importante recordar que, en otros casos, el rechazo de las hipótesis puede ser más complejo. Además, es evidente que, si un programa fracasa repetidamente en sus predicciones empíricas, eventualmente, tendrá que ser abandonado. Sin embargo, lo que no es tan fácil de establecer, es cuándo el apoyo a un programa degenerado deja de ser racional, cuando el investigador se convierte primero en un mal científico930 y, más tarde, en un pseudointelectual. No es fácil determinar en qué momento un ad hoc legítimo se convierte en una excusa irracional y pasamos de la ciencia a la pseudociencia. No existe un proceso sencillo o un algoritmo objetivo que nos permita separar quirúrgicamente lo razonable de lo irracional. La falsación, aunque es una guía útil, no cumple las expectativas de Popper y no puede utilizarse como un criterio de demarcación nítido entre ciencia y pseudociencia. La frontera entre la ciencia y la pseudociencia, como comentaremos más adelante, es más sutil de lo que muchos creen. Pero regresemos a los desacuerdos racionales legítimos. Ni siquiera el ejemplo estrella propuesto por Popper, el de la relatividad general, fue tan sencillo como podría pensarse. En 1911 Einstein publicó una predicción de la magnitud de la desviación de la luz debida al campo gravitatorio solar931 y en 1912 se hizo una expedición a Brasil para medir el efecto. Sin embargo, el día del eclipse, amaneció nublado y no pudo realizarse la observación. En realidad, esto fue una gran suerte para el prestigio de Einstein, porque su predicción era errónea y no habría coincidido con la medida. Finalmente, la versión completa de la relatividad general se publicó en 1915 y, para aquel entonces, Einstein ya había corregido sus cálculos, por lo que cuando, durante el eclipse de 1919, acabó haciéndose la observación se midió un valor que sí coincidía con la predicción. Desde entonces se han hecho muchas críticas a esta medida y se ha sugerido que Eddington, el investigador que la realizó, eliminó algunas observaciones para quedarse sólo aquellas que coincidían con lo esperado por Einstein. Sin embargo, estas sospechas parecen ser infundadas, ya que el astrónomo, simplemente, eligió las mejores observaciones y éstas resultaron coincidir con la predicción relativista. Incluso es cierto que, históricamente, muchas de las teorías más importantes han necesitado enmiendas ad hoc ya desde su nacimiento.932 Como ejemplo podemos recordar la defensa del copernicanismo frente al geocentrismo. La propuesta copernicana, en principio, implicaba que la posición de las estrellas debía cambiar a lo largo del año debido al paralaje ocasionado por el movimiento terrestre. Sin embargo, en un sistema Solar geocéntrico la posición relativa de las estrellas no debía variar entre el verano y el invierno. Este paralaje, aunque se buscó, no fue observado y, a pesar de esta anomalía, Galileo defendió el sistema copernicano. Para poder hacerlo, el pisano tuvo que aceptar una modificación ad hoc: las estrellas deberían estar tan lejos que sería imposible detectar su paralaje. Además, este fue un ad hoc del peor tipo puesto que no hacía ninguna predicción observable. Tal vez habría sido legítimo criticar este ad hoc porque parecía responder a la voluntad de ocultar el problema bajo la alfombra. Esto nos enseña que la aceptación o el rechazo de una hipótesis es un asunto complejo que, además, no tiene por qué limitarse necesariamente a evaluar la existencia de anomalías empíricas.933 Las hipótesis deben ser juzgadas valorando sus éxitos y sus fracasos en su conjunto y esto, en algunos casos, no es sencillo. Este será el tema del próximo capítulo. A pesar de esta matización, las ideas de limitar las hipótesis ad hoc y de exigir que las hipótesis hagan predicciones novedosas son bastante razonables y coinciden con propuestas anteriores. Francis Bacon, por ejemplo, ya había propuesto que las hipótesis que se plantean para explicar sólo las evidencias disponibles no suelen ser muy saludables, mientras que aquellas que tienen éxito haciendo predicciones que van más allá de las evidencias que se utilizaron para desarrollarlas merecen una mayor atención.934 Popper expresó la misma idea al exigir que una teoría debe ser testable independientemente. Es decir, que debe explicar las observaciones que se propuso explicar y, además, hacer nuevas predicciones que permitan compararla con la realidad externa. 13.5 El holismo confirmacional Quine formalizó los problemas que hemos estado comentando en su tesis del holismo confirmacional: las hipótesis no pueden testarse aisladamente, necesariamente deben comprobarse en grupo.935 Según la tesis de Quine nuestras creencias forman una tupida red que debe ser evaluada en su conjunto. Al hablar de Urano y Mercurio ya hemos mencionado que Duhem apuntó que era imprescindible hacer asunciones extra para poder plantear predicciones concretas. Sin embargo, la tesis de Quine podría llevarse mucho más allá ya que podría aducirse que la observación propuesta por Le Verrier sólo sería comprobable si se incluyesen las teorías ópticas relativas al funcionamiento de los telescopios, así como las hipótesis psicológicas relativas a la actitud de los astrónomos alemanes que realizaron la observación. Al fin y al cabo, existe la posibilidad lógica de que los colaboradores de Le Verrier utilizasen telescopios defectuosos o tratasen de engañarlo. El holismo confirmacional es otra forma de subdeterminación, siempre hay varias hipótesis que pueden explicar las evidencias observadas936 y el problema que plantea debe ser considerado por cualquier propuesta filosófica sobre el conocimiento.937 Sin embargo, una interpretación radical del holismo confirmacional, que la red siempre puede forzarse para acomodar cualquier conclusión que deseemos,938 nos condena, de nuevo, al escepticismo radical. Siempre será posible achacar nuestras observaciones a que vivimos en Matrix o a que las brujas nos engañan. Conviene recordar que existe la posibilidad de llevar el holismo confirmacional demasiado lejos, nuestra mente puede estar retorciendo en exceso nuestras redes de creencias para proteger alguna conclusión que nos es querida. Esto es, al fin y al cabo, lo que hace la pseudociencia. Recordemos al predicador que predijo el fin del mundo y que cuando pasó la hora, y no observó nada extraño, llegó a la conclusión de que el fin del mundo había sido psicológico, no físico. Si nos esforzamos por ser razonables el holismo confirmacional no suele ser un problema insalvable. Siempre podemos hacer experimentos en distintas condiciones para testar distintas regiones de nuestra red de creencias. Además, cuando una predicción falla no es igual de razonable achacar el problema a unas partes de la red teórica que a otras. Por ejemplo, Le Verrier podría haber achacado el fallo de la predicción de Vulcano a la óptica de los telescopios o a una conspiración por parte de la comunidad astronómica, pero esto habría sido mucho menos razonable que admitir la inexistencia del supuesto planeta. Recordemos, eso sí, que la crítica de Quine es completamente demoledora si nos empeñamos en limitarnos a hacer inferencias puramente deductivas. En este caso sería imposible valorar si el problema se debe a la conspiración de la comunidad astronómica o a la inexistencia del astro. Entendida desde un punto de vista estrictamente lógico el problema de la tesis de Quine no puede resolverse si no echamos mano de un marco que incluya inferencias no deductivas. Este es uno de los méritos de la propuesta bayesiana que veremos más adelante. Los bayesianos utilizan una lógica que no es ampliativa, que asigna grados de confianza, y que, además, puede tratar con redes de creencias. En la práctica los investigadores suelen utilizar la inducción y esto les capacita para establecer si la evidencia considerada está testando en la misma medida nuestras teorías sobre la óptica, sobre el movimiento de los astros o sobre la psicología de los astrónomos.939 Para comprobar las teorías ópticas en las que se basan los telescopios deberíamos realizar experimentos muy distintos a los planteados por Le Verrier. 13.6 Resumen Popper, motivado por su recelo ante la inducción, se atrevió a hacer una propuesta clara y osada puramente deductiva, pero que, posteriormente, se vio obligado a matizar. Y el problema es que estas matizaciones hicieron que sus ideas ya no fuesen ni tan absolutas ni tan claras y que, en el fondo, acabase viéndose obligado a admitir la inducción por la puerta de atrás. Además, de nuevo, nos enfrentamos al problema de que en la búsqueda del conocimiento no hay reglas absolutas. La valoración o la modificación de una hipótesis es un arte que exige combinar aspectos empíricos y teóricos de un modo, en muchos casos, sutil. A pesar de esto, la falsabilidad, tomada como recomendación general, continúa siendo útil. El investigador racional ha de huir de aquellas hipótesis vagas capaces de explicarlo todo. Una propuesta que pueda explicar cualquier cosa, en realidad, no explica nada y, por lo tanto, no es conocimiento. Debemos esforzarnos por tener una actitud crítica ante nuestras hipótesis, éstas deben posibilitar que hagamos predicciones empíricas precisas y hemos de buscar no sólo evidencias que puedan confirmarlas, sino, también, aquellas que sean capaces, potencialmente, de falsarlas.940 Además, hemos de considerar especialmente meritorias aquellas hipótesis que plantean nuevos fenómenos que, posteriormente, son confirmados experimentalmente. Las hipótesis ad hoc, especialmente aquellas que no conllevan nuevas predicciones, son peligrosas y su acumulación excesiva denota irracionalidad. Sin embargo, lo que no podemos hacer, por desgracia, es cuantificar con precisión cuándo lo razonable se convierte en excesivo, cuando el día se transforma en noche. El otro gran éxito de Popper radica, precisamente, en su fracaso. Es una lección valiosa entender que la renuncia completa a las inferencias no deductivas implica un coste inasumible.941 "],["eleccion_entre_hipotesis.html", "14 Elección entre hipótesis 14.1 Criterios epistémicos 14.2 Virtudes superempíricas 14.3 Motivos psicológicos y sociales 14.4 Resumen", " 14 Elección entre hipótesis Probablemente una de las actividades más importantes para el investigador sea la de elegir, de entre todas las hipótesis planteadas, la más adecuada.942 Para poder generar conocimiento sobre el mundo externo, es esencial disponer de unos criterios de elección entre hipótesis que dependan, esencialmente, de ese mundo externo. En este capítulo trataremos de analizar cuáles son los criterios que se utilizan en la práctica y cuáles son los que deberían usarse. 14.1 Criterios epistémicos Las hipótesis tendrían que ser seleccionadas, sobre todo, basándose en criterios epistémicos. Es decir, habríamos de considerar, principalmente, las evidencias empíricas disponibles, así como la coherencia lógica de la hipótesis.943 Una teoría debería ser, como mínimo, empíricamente adecuada, es decir, su descripción y predicciones relativas al fenómeno descrito deberían corresponderse, al menos hasta cierto punto, con las evidencias disponibles.944 Este concepto de adecuación empírica puede parecer trivial, pero el lector hará bien en recordarlo porque será fundamental cuando más adelante tratemos la cuestión de la metafísica naturalista. La adecuación empírica es uno de los objetivos fundamentales de las teorías científicas. Además, cuanto mayor sea la precisión de las predicciones mayor habría de ser el interés por la teoría. La relatividad general, por ejemplo, hace mejores predicciones que la newtoniana sobre la órbita de Mercurio y este es uno de los motivos por los que la preferimos como teoría fundamental de la naturaleza. La precisión es uno de los criterios más importantes que tienen en cuenta los investigadores a la hora de prestar su apoyo a una teoría o a otra.945 Un problema es que la comparación de la adecuación empírica entre distintas hipótesis no siempre es trivial. Una dificultad con la que, en la práctica, suelen encontrarse los investigadores es que una hipótesis rara vez dará cuenta de todas las observaciones. Es posible que algunas evidencias sean, simplemente, erróneas. Pero también hemos de tener en cuenta que las hipótesis suelen reflejar la estructura del mundo externo sólo aproximadamente, por lo que, en muchas ocasiones, algunas de las observaciones sí cuadrarán, pero otras no. Esto dificulta la comparación objetiva de distintas hipótesis. Incluso puede ocurrir que diferentes hipótesis den cuenta de aspectos complementarios del problema estudiado. En estos casos, si insistimos en elegir una de ellas estaríamos obligados a conceder una importancia relativa a unas observaciones frente a otras. Por fortuna, también es cierto que a medida que la investigación avanza las hipótesis se van reformulando, es decir, se van creando hipótesis nuevas que incorporan las enseñanzas de las anteriores y las colisiones con las observaciones y que, por lo tanto, acaban teniendo una adecuación empírica claramente superior que facilita la comparación objetiva. Aunque hemos de tener en cuenta que este proceso puede demorarse bastante tiempo y que, además, en algunos casos, nos conformamos con las vacas esféricas. Por otro lado, los científicos de entre aquellas teorías empíricamente adecuadas, suelen preferir las que tienen un mayor poder explicativo946 o fuerza empírica,947 es decir las capaces de describir un mayor número de fenómenos partiendo de menos supuestos. El poder explicativo sería el reverso positivo de las hipótesis ad hoc. La relatividad general, por ejemplo, es una teoría que puede construirse partiendo de muy pocos principios y que, sin embargo, es capaz de describir el salto de un gato o la órbita de un planeta o de predecir la existencia de los agujeros negros y el cambio en la frecuencia de giro de un sistema estelar binario debido a las ondas gravitacionales. Es, por lo tanto, una teoría que tiene un extraordinario poder explicativo. Esta preferencia por teorías con mayor poder explicativo, además, termina estableciendo una forma de progreso científico ya que, poco a poco, se van necesitando menos teorías para describir múltiples fenómenos que antes se consideraban como independientes. Uno de los grandes éxitos newtonianos, por ejemplo, fue unificar el movimiento de los planetas y las manzanas mediante una única teoría gravitatoria.948 Y el otro gran triunfo clásico consistió en unificar la descripción de los múltiples fenómenos magnéticos y eléctricos en sólo cuatro ecuaciones que, además, inesperadamente, también describían la luz como una onda electromagnética. Esta es una forma de progreso científico reconocida por la práctica totalidad de los filósofos de la ciencia. Incluso Kuhn, que, como veremos, no fue capaz de encontrar progreso en los supuestos bandazos metafísicos de la ciencia, asumió de buen grado que las teorías posteriores suelen explicar más fenómenos, tienen un mayor poder explicativo, que las anteriores.949 Sin embargo y a pesar de estos éxitos no hemos de pensar que algún día llegaremos a tener una única teoría capaz de explicar desde los átomos a los movimientos bursátiles. Actualmente, es difícil, incluso, predecir el comportamiento químico partiendo de la física fundamental. A lo que podemos aspirar es a tener un conjunto de teorías coherentes, cada vez más reducido, que no se contradigan entre sí, y que cada vez expliquen más fenómenos. Además, en muchos casos, las nuevas teorías suelen ser más productivas que las antiguas, es decir, que abren nuevas vías de investigación. Por ejemplo, el electromagnetismo de Maxwell, que acabamos de comentar, permitió predecir la existencia de las ondas de radio y, posteriormente, sirvió para integrar en el mismo marco descriptivo los rayos X, la luz infrarroja y la ultravioleta. La del poder explicativo, puede ser entendida como la capacidad que tiene una hipótesis de resumir las observaciones, es decir, como el poder de compresión de la información empírica disponible en unos principios teóricos mínimos. La relatividad general, por ejemplo, puede, partiendo de un marco teórico muy pequeño, explicar multitud de fenómenos, lo que equivale a decir que resume muy eficientemente la estructura detectada en multitud de observaciones, y esto es, sin duda, un aspecto positivo. Podríamos pensar en otra hipótesis planteada por Seinstein, el primo calvo de Einstein, que hiciese las mismas predicciones empíricas, pero que requiriese de muchas más asunciones. Esta teoría, a pesar de ser empíricamente adecuada, tendría una capacidad de compresión menor, y nos enfrentaría, en mi opinión, a un riesgo epistémico superior. Yo estaría más tranquilo planeando mis acciones futuras poniéndome en manos de Einstein que de Seinstein. Esto puede parecer llamativo puesto que ambas, como he dicho, serían capaces de explicar las mismas evidencias, pero creo que hay un riesgo epistémico relacionado con el problema del sobreajuste (en inglés overfitting). Cualquiera que intente extraer patrones a partir de un conjunto de observaciones debería ser consciente del problema del sobreajuste. En muchos casos, el mundo externo tiene un comportamiento complejo debido a la interacción de varios fenómenos. Por ejemplo, los objetos caen acelerados por la gravedad terrestre, pero, además, la estructura del mundo externo debida a este fenómeno es enturbiada por otros fenómenos secundarios, como el rozamiento con el aire o la rotación de los objetos durante su caída. Recordemos que Galileo nos recomendó ignorar algunos de estos detalles, que él consideró espurios, para centrar nuestra atención en los patrones principales. De algún modo, ignorar esos detalles le permitió describir un patrón, el gravitatorio, capaz de ser extrapolado a muchos otros casos por ser más fundamental y estable. Si, por el contrario, hubiese tratado de describir con absoluta precisión la caída de los cuerpos que estudió, habría obtenido algunas reglas empíricas difícilmente extrapolables, ya que habrían sido muy particulares, habrían dependido de cada cuerpo estudiado, así como, de las circunstancias de viento, presión, temperatura y rozamiento. Este es un ejemplo particular del problema del sobreajuste al que se enfrentan los métodos estadísticos de búsqueda de patrones. Imaginemos, por ejemplo, que tenemos un conjunto de puntos en un plano cartesiano que se ajustan, aproximadamente, a una recta, pero que han sido obtenidos por un método que tiene un pequeño error de medida. En este caso, lo más informativo sería describir el patrón como una recta, pero esto implicará que el ajuste obtenido no coincidirá con la mayoría de los puntos observados. Para reflejar el patrón relevante estaremos obviando parte de la señal como si fuese ruido. Si, por el contrario, tratásemos de conseguir un ajuste perfecto, una curva que pasase por todos los puntos, obtendríamos un patrón mucho más complejo, pero que no podríamos extrapolar con éxito a otros experimentos similares. Para evitar este problema del sobreajuste, los estadísticos que construyen modelos del mundo mediante técnicas de aprendizaje automático suelen dividir sus evidencias en dos grupos: uno que utilizan para generar el modelo y otro que emplean para comprobar las predicciones del modelo generado. De este modo evitan los modelos sobreajustados que sólo funcionan con el primer conjunto de datos, pero que no son extrapolables al segundo.950 Estos investigadores no se conforman con tener un modelo que resuma lo que ya sabemos, con inducir un modelo empíricamente correcto, sino que aspiran a obtener un modelo capaz de hacer predicciones válidas con las que guiarnos en el futuro y, para ello, tratan de evitar los detalles espurios que puedan estar enturbiando la estructura básica del fenómeno estudiado. Los modelos más complejos tienden a ajustarse muy bien a los datos de entrenamiento, pero suelen estar sobreajustados y eso hace que tengan una mayor tendencia a fallar después en el mundo real. Aunque, por otro lado, un modelo excesivamente simple puede que esté ignorando una estructura real.951 La ultima palabra sobre el nivel de simplicidad adecuado, en cualquier caso, la tendrá el comportamiento del modelo con nuevos conjuntos de datos. El poder predictivo suele ser una indicación de que el patrón que hemos generado a partir de los datos observados refleja una estructura profunda de la realidad que será extrapolable a otras circunstancias. No obstante, estas predicciones, por supuesto, pueden empezar a fallar sin previo aviso ya que al usar la inducción estamos asumiendo que el resultado sólo funcionará si la estructura relevante del mundo externo se mantiene en el futuro. Por otro lado, podría pensarse que la virtud del poder explicativo está relacionada con las evidencias disponibles en el momento en el que se planteó la hipótesis, pero esto sería problemático. En primer lugar, como ya hemos mencionado, ¿deberíamos tener en cuenta el momento en el que se descubre una evidencia, algo que es, hasta cierto punto, históricamente contingente, para juzgar una hipótesis? El ideal inductivo defiende la histéresis epistémica: nuestra confianza en una hipótesis no ha de depender de cuándo fueron obtenidas las evidencias. Lo que sí podríamos tener en cuenta es qué evidencias fueron consideradas para construir la hipótesis, independientemente del momento en el que fueron descubiertas.952 Por ejemplo, el problema del perihelio de Mercurio era conocido en 1906, pero Einstein no utilizó esta información para construir su teoría, por lo que su predicción del mismo puede considerarse un éxito de la relatividad general. Digamos que, como Einstein no hizo ninguna modificación ad hoc para acomodar este dato, podríamos considerar el cálculo de este efecto como una verdadera predicción de la teoría. Sin embargo, esto nos lleva a otro problema, ¿cómo podemos saber si Einstein tuvo en mente o no el problema del perihelio de Mercurio al desarrollar la relatividad general? Y, además, incluso aunque pudiésemos llegar a estar seguros de que no lo consideró, ¿debería este aspecto psicológico relacionado con el descubrimiento tenerse en cuenta a la hora de juzgar la justificación de la teoría? En principio, si respetamos el principio de la separación del contexto de descubrimiento y de justificación, este aspecto psicológico habría de ser ignorado. Aunque esto es algo que, como casi todo, acabaremos matizando. Es importante tratar de valorar las hipótesis en base a sus virtudes empíricas, ignorando los aspectos psicológicos o sociales que condujeron a su planteamiento, pero, el problema, es que, en algunas ocasiones, estos aspectos pueden haber sido relevantes. 14.2 Virtudes superempíricas Hemos insistido mucho en que el estudio del mundo externo ha de ser, eminentemente, empírico, por lo que alguien podría pensar que los criterios que tendrían que emplearse para elegir entre distintas hipótesis deberían ser exclusivamente empíricos y, sin embargo, esta es una posición que no defiende casi nadie. Podemos discutir si la virtud del poder explicativo, que acabamos de comentar, es empírica o no, pero no es la única que va más allá de la pura descripción de lo observado. Algunas de las virtudes superempíricas que suelen comentar los filósofos son la sencillez o la coherencia con otras teorías.953 Los científicos suelen elegir las teorías, en primer lugar, basándose en criterios empíricos, pero, sobre todo durante la fase de descubrimiento o, incluso, cuando se enfrentan a una subdeterminación, pueden elegir favorecer una teoría frente a otra basándose en estas virtudes superempíricas.954 Esto es lo que hicieron, por ejemplo, Aristarco o Copérnico al plantear sus hipótesis heliocéntricas. Los modelos que propusieron no describían mejor las observaciones disponibles, pero eran más sencillos. Esta virtud, la sencillez, es la que los investigadores suelen utilizar para resolver el problema lógico de las esmeraldas verdules. Los científicos, y muy especialmente los físicos, también suelen referirse a la belleza o a la elegancia de las teorías955 como guía para buscar nuevas teorías más profundas e, incluso, en algunos casos, como criterio para evaluarlas. Por ejemplo, Paul Dirac (1902-1984) alabó la belleza de una de sus creaciones, la fórmula que unía la mecánica cuántica con la relatividad especial. La belleza no es un concepto fácil de definir, ni en ciencia ni fuera de ella, y distintos investigadores pueden estar refiriéndose a aspectos diferentes cuando utilizan el término. Por ejemplo, podrían ser características de una teoría bella la simetría, el poder explicativo o la naturalidad. En muchas ocasiones los físicos hablan de elegancia cuando encuentran una teoría con un gran poder explicativo,956 es decir, que hace numerosas predicciones sobre fenómenos muy diversos. De algún modo, la teoría parece ofrecer una gran cantidad de frutos a pesar de ser parca en premisas. Por otro lado, la belleza también suele relacionarse con la simetría subyacente en las matemáticas de la teoría.957 Este sería un criterio relacionado con la simplicidad. Por ejemplo, Mendeléyev buscó un patrón simétrico para desarrollar su tabla periódica y lo mismo hizo Murray Gell-Mann al proponer la existencia de los quarks basándose en una simetría que denominó camino óctuple. En cualquier caso, las virtudes superempíricas, aunque pueden servirnos de guía a la hora de proponer nuevas teorías no deberían situarse por encima de los criterios meramente empíricos. Aunque podemos favorecer las hipótesis más sencillas, lo fundamental es que las teorías sean empíricamente adecuadas, que se correspondan con el mundo externo.958 Sin embargo, recordemos también los problemas del sobreajuste y de las vacas esféricas, la adecuación empírica no tiene por qué ser absoluta. 14.3 Motivos psicológicos y sociales Las virtudes empíricas y superempíricas son muy importantes, pero no constituyen, tal y cómo nos recordaron, entre otros, Kuhn959 o Lakatos960 un algoritmo preciso. A veces es fácil, basándose en ellas, desestimar una hipótesis; sin embargo, en otras ocasiones sólo constriñen el rango de conclusiones posibles, y, desde luego, no habríamos de pensar que en todos los casos determinan por completo la elección de una solución concreta.961 Por lo tanto, para elegir entre varias hipótesis también habrá que tener en cuenta, en mayor o menor grado, el criterio subjetivo de los investigadores. Hay una parte difícil de codificar en la actividad científica y, sin duda, también una parte irracional.962 En algunos casos puede que no haya suficientes evidencias empíricas como para que resulten ser determinantes y, en otros, puede que haya evidencias contradictorias o que distintos criterios, como la adecuación empírica y la simplicidad entren, parcialmente, en conflicto.963 Además, tal y como discutimos al hablar sobre Popper, a veces puede haber diferencias de opinión legítimas sobre si una anomalía es debida a la teoría o a las hipótesis auxiliares o sobre si las anomalías son lo suficientemente importantes como para que debamos descartar una hipótesis determinada. Por si esto fuese poco, como veremos, algunas evidencias empíricas dependen, al menos en parte, de las preferencias teóricas de quienes las generan, por lo que su papel como árbitro en la elección entre hipótesis está, al menos parcialmente, comprometido.964 Por si no fuera suficiente, en algunas ocasiones los investigadores, en la práctica, siguen criterios muy discutibles. En mi área de trabajo, por ejemplo, no es infrecuente que algunos científicos elijan las herramientas de análisis siguiendo la moda establecida por algún artículo especialmente relevante o la estela de algún investigador influyente. En estos casos, las dinámicas internas de la comunidad pueden llegar a ser muy relevantes y es entonces cuando los sociólogos tienen casi más que decir que los filósofos. Estas son cuestiones a las que dedicaremos un capítulo completo. Además, los científicos tienden a ser algo conservadores, suelen favorecer las teorías antiguas, las más familiares. Esto, en general, es una regla heurística que suele funcionar bien, al fin y al cabo, las teorías antiguas han demostrado ser capaces de convencer a muchos investigadores previos. Sin embargo, este criterio se convierte en un problema cuando alguien plantea una nueva hipótesis que entra en conflicto con creencias fundamentales antiguas, pero que, a pesar de esto, resulta ser correcta. Por ejemplo, en El origen de las especies Darwin escribió que aunque estaba convencido de la verdad de su propuesta, no pensaba que pudiese convencer a los naturalistas más mayores y que, por lo tanto, depositaba sus esperanzas en los jóvenes que podrían evaluar las viejas teorías y la suya con imparcialidad. Planck, que era muy conservador, escribió que la ciencia avanza de funeral en funeral. Es obvio que Planck exageraba un poco, pero su comentario sí que refleja el conservadurismo científico. La ciencia se mueve entre la búsqueda de nuevas hipótesis y la preferencia por las teorías que ya han demostrado su valía. Además, esta tensión tiene su reflejo en las propias comunidades científicas ya que hay científicos más aventureros y especulativos y otros más conservadores.965 Es probable que esta diversidad de estilos de pensamiento favorezca el avance de la comunidad en su conjunto. Estos conflictos suelen acabar resolviéndose, pero, durante un tiempo, pueden sesgar las discusiones. En algunos casos las nuevas hipótesis se encuentran con problemas, simplemente, por su dificultad. Puede que entenderlas requiera habilidades poco frecuentes en la comunidad. Por ejemplo, en mi área, la genética de poblaciones, suelo encontrarme con desarrollos estadísticos que la mayoría de investigadores, entre los que me incluyo, no somos capaces de entender. Esas propuestas no lo tendrán fácil para ser aceptadas y si se aceptan será, en parte, más por moda y confianza en los demás que por verdadero conocimiento. Aunque también es cierto, que, con el tiempo, estos problemas suelen corregirse ya que alguien termina por escribir un artículo de revisión en el que explica los problemas o las ventajas de las distintas aproximaciones de una forma más comprensible. En cualquier caso, es importante recordar que los científicos no sólo eligen sus hipótesis favoritas basándose en criterios empíricos y superempíricos. Algunos de los motivos que los guían son subjetivos y contingentes. Este es un aspecto en el que Kuhn puso el énfasis y que, posteriormente, fue llevado al extremo por algunos filósofos postmodernos, acompañados por los sociólogos del programa fuerte, que llegaron a sostener que, en realidad, los científicos cuando se deciden por una teoría, lo hacen movidos, exclusivamente, por motivos psicológicos y sociales y que los experimentos son tan sólo una pose.966 Estos criterios subjetivos suelen ser más relevantes en los casos más dudosos, cuando las evidencias son más pobres. Es entonces cuando el buen oficio del científico es más crítico. Galileo, por ejemplo, se decantó por la hipótesis de una Tierra en movimiento antes que la mayoría de sus colegas, cuando las evidencias todavía no eran absolutamente claras. Es en estos casos, cuando las observaciones aún no son suficientes, cuando todavía no se ha alcanzado un consenso comunitario, cuando debemos ser más cautelosos. Si los expertos en el área no se han puesto de acuerdo, los no expertos deberíamos reservar el juicio. Sin embargo, insisto, esto no implica que las teorías bien establecidas se elijan por motivos contingentes. Puede que Galileo se decidiese inicialmente por el copernicanismo por motivos parcialmente idiosincráticos, pero no es menos cierto que hoy en día la creencia de que la Tierra se mueve está extraordinariamente bien soportada por las evidencias y sería completamente irracional negarla. Kuhn se interesó, especialmente, por las razones que pueden llevar a unos científicos concretos, en un momento histórico particular, a cambiar de opinión, pero estos no suelen ser los motivos que acaban convenciendo a toda la comunidad. Las razones psicológicas o sociológicas que llevan a plantear una hipótesis son, en muchos casos, tortuosas, pero suelen ser muy distintas de aquellas que acabaron convenciendo a la comunidad en su conjunto de que una teoría está bien justificada.967 Estos son, en parte, los motivos por los que la historia de la ciencia puede ser apasionante, por los grandes aciertos y los notables fracasos de los individuos más arriesgados y por las respuestas, mesuradas o no, de las comunidades que recibieron sus propuestas. En cualquier caso, conviene recordar la distinción positivista entre los contextos de descubrimiento y justificación, que, aunque no es absoluta, sí es una buena referencia. 14.4 Resumen La elección entre hipótesis debería basarse, y en las comunidades científicas en la mayoría de los casos eventualmente acaba basándose, en criterios principalmente epistémicos. Es mejor la hipótesis que se corresponde con una mayor precisión con las evidencias disponibles. La relatividad general es mejor que la mecánica newtoniana porque se ajusta mejor a las evidencias. Además, hay que tener en cuenta la coherencia de las hipótesis con el resto del conocimiento, así como, su poder explicativo, es decir, la relación entre la cantidad de fenómenos explicados y el número de supuestos en los que se basa. El problema es que no siempre disponemos de evidencias suficientes y, además, en ocasiones, nos vemos obligados a evaluar evidencias aparentemente contradictorias. Por otro lado, tenemos que recordar que nuestros modelos no suelen aspirar a dar cuenta de todas y cada una de las evidencias, sino que suelen asumir que hay una cierta cantidad de ruido en las mismas y esto exige que tomemos decisiones sobre qué es y qué no es relevante en nuestras observaciones. Por lo tanto, evaluar el grado de adecuación empírica puede no ser trivial. Todo esto hace que los factores psicológicos y sociales tengan una cierta relevancia, es decir, que en ciencia los motivos subjetivos y contingentes, especialmente cuando las evidencias no son muy abundantes o claras, también juegan un papel. Esto no implica que las teorías bien establecidas hayan sido elegidas por motivos contingentes, pero sí que la historia de las discusiones científicas, que se dan típicamente cuando las evidencias aún no son sólidas, suele ser compleja e idiosincrática y que el estudio de las cuestiones más complejas es terreno abonado para el surgimiento de modas o de hipótesis defendidas más por motivos ideológicos que epistémicos. La lección que hemos de extraer de todo esto los no expertos es la de confiar en los consensos científicos, pero la de reservar el juicio cuando hay todavía discrepancias entre partes importantes de la comunidad. "],["cargados_de_teoria.html", "15 Cargados de teoría 15.1 Que hablen los datos 15.2 Cargados de teoría 15.3 Ideal positivista: las observaciones son independientes de nuestras teorías 15.4 Se aprende a observar 15.5 Hemos de elegir qué observaciones realizar 15.6 Aunque los datos son los datos 15.7 Estudios exploratorios 15.8 Las observaciones no pueden interpretarse sin teorías previas 15.9 Las medidas dependen de la teoría 15.10 Hay un continuo entre observación y teoría 15.11 ¿Son los datos objetivos? 15.12 Resumen", " 15 Cargados de teoría El conocimiento del mundo externo depende críticamente de las evidencias empíricas. Este es el motivo por el que los científicos clásicos fueron tan exigentes con las observaciones; idealmente, las evidencias utilizadas en ciencia tendrían que ser independientes de nuestros valores e intereses, deberían ser públicas, acordadas intersubjetivamente y habrían de reflejar, exclusivamente, el mundo externo.968 Además, según estas tesis clásicas, la ciencia tendría dos capas: la empírica y la teórica y, aunque podría haber discusiones respecto a las teorías, que, al fin y al cabo, son creencias nuestras, los datos, al depender casi exclusivamente del mundo externo, serían objetivos y estables. Galileo, Newton y Einstein no propusieron los mismos modelos teóricos, pero los tres estuvieron de acuerdo en que, en ausencia de resistencia, los cuerpos caen con una aceleración constante independiente de su masa. Sin embargo, no siempre es fácil alcanzar este ideal, las evidencias sobre las que asentamos nuestro conocimiento no son tan prístinas, dependen, en mayor o menor grado, del observador. Esto implica que no podemos descartar que algunas de las observaciones sobre las que se sustenta nuestro supuesto conocimiento no sean más que alucinaciones. 15.1 Que hablen los datos El ideal inductivista sería similar al descrito por Darwin en El viaje del Beagle. El investigador saldría al mundo con ojos limpios e inocentes, haría un largo viaje en el que recogería enormes cantidades de observaciones: fósiles, picos de pájaros, caparazones de tortuga, etc. y, tras su regreso, reflexionaría sobre lo visto y construiría sus hipótesis. Los inductivistas favorecían esta aproximación, construir la teoría después de disponer de los datos, porque temían que una apuesta demasiado temprana por una hipótesis concreta pudiese sesgar nuestro punto de vista. Deberíamos tratar de observar sin prejuicios ni sesgos.969 Sherlock Holmes en Un escándalo en Bohemia recoge la máxima inductivista de este modo: Es un error capital teorizar antes de poseer evidencias. Insensiblemente, uno comienza a deformar las observaciones para hacerlas encajar en las teorías en lugar de encajar las teorías con los hechos. Como veremos a continuación, este temor de Holmes es, precisamente, el problema que denunciaron, filósofos como Hanson o Kuhn. El problema es que incluso aunque obviemos la aspiración inductivista relativa al descubrimiento y nos limitemos al análisis de la justificación de las teorías, la división entre observación y teoría continúa siendo importante. Si asumimos que los datos van a ser los jueces de nuestras hipótesis, tenemos que ser muy escrupulosos con su independencia. Sería muy problemático que las observaciones no fuesen neutrales respecto a las hipótesis que van a ayudar a juzgar. 15.2 Cargados de teoría Norwood Russell Hanson (1924 - 1967) propuso que, en realidad, la observación siempre depende, al menos en parte, de nuestras ideas previas.970 Esta tesis suele conocerse como problema del theory-laden, un término que puede traducirse como cargado o teñido de teoría. Esta fue una preocupación que ya había mencionado Comte al comentar que no es posible realizar observación alguna sin que ésta sea dirigida e interpretada por una teoría previa.971 Sin embargo, quien popularizó el problema fue Thomas Kuhn en su La estructura de las revoluciones científicas. Esta es una tesis que, de forma más o menos matizada, ha sido asumida por la práctica totalidad de los filósofos de la ciencia actuales. La distinción entre observación y teoría no es tan nítida como los positivistas asumían y esto amenaza con socavar la objetividad científica.972 Si los datos pueden estar sesgados por las teorías, ¿cómo podemos considerarlos jueces imparciales de esas mismas teorías? Si nuestra investigación depende de nuestras ideas previas, ¿no podríamos caer en los círculos viciosos sobre los que Sherlock Holmes trataba de prevenirnos? Esta es una nueva limitación fundamental que deberemos añadir al problema de la inducción. Hume nos recordó que al derivar una teoría general de unas observaciones concretas estábamos dando un salto lógico inválido y ahora estamos cuestionando incluso esas observaciones. Algunos filósofos y, especialmente, muchos sociólogos de la ciencia llegaron a plantear que esos problemas corroen tan profundamente las bases científicas que era necesario reconocer que las conclusiones científicas no son más que un conjunto de relatos o mitos. Sin embargo, el lector no debe confundir ambas conclusiones: aceptar que la relación entre observación y teoría es más sutil y compleja de lo que pensábamos, no implica que debamos inferir necesariamente que la ciencia no es más que un relato sin una relación especial con la realidad. Lo que sí se perdió en el camino fue el ansia positivista de una justificación del conocimiento científico filosóficamente absoluta. Los positivistas lógicos de la primera mitad del siglo XX trabajaron en un programa de investigación filosófica que tenía por objetivo asentar la justificación de las teorías científicas sobre la observación y la lógica. Su ambición era distinguir los esfuerzos de Newton o Darwin de las especulaciones metafísicas escolásticas. El ejemplo que les inspiraba era el Principia Mathematica de Russell y Whitehead. A estos autores les pareció poco riguroso asumir sin más que 1 más 1 son dos y decidieron dotar de una justificación lógica robusta a la aritmética. Siguiendo este ejemplo, el programa positivista, asumiendo el empirismo, trató de establecer unas bases lógicas sólidas para la ciencia, pero tal y como admitieron sus propios participantes, el intento fracasó y la compleja relación entre observación y teoría fue una de las causas del fracaso. 15.3 Ideal positivista: las observaciones son independientes de nuestras teorías Según el ideal positivista las observaciones son completamente independientes de las teorías. Por ejemplo, si uno deja caer una bolita por un plano inclinado, la bolita caerá a una velocidad determinada independientemente de lo que nosotros pensemos. Por lo tanto, la relación del científico con los datos sería similar a la del buscador de setas; uno observa el mundo externo y recoge datos como quien recolecta champiñones. Sin embargo, las observaciones no son tan inmaculadas, están, hasta cierto punto, cargadas de teoría. 15.4 Se aprende a observar En primer lugar, esperamos del investigador que realice las observaciones utilizando las mejores metodologías disponibles y esto implica el uso de conocimiento previo. Por lo tanto, difícilmente podrá seguirse el ideal inductivista que nos previene contra la teorización previa. Un buen diseño experimental no sólo implica tener un objetivo previo, que puede ser más o menos general, sino que exige disponer de un amplio conocimiento de las metodologías disponibles. Observar y hacer experimentos no es trivial, se requiere una cierta capacidad que se adquiere, habitualmente, tras años de práctica.973 Muestra de esto es que es habitual en los laboratorios clasificar a los investigadores en dos grupos: el de los que tienen buenas manos y el de los que no. Los investigadores suelen aprender a realizar correctamente las manipulaciones que exigen los experimentos tras años de formación y los conocimientos adquiridos son, en muchos casos, tácitos, difíciles de transmitir con palabras. Además, los instrumentos que se utilizan en los laboratorios pueden llegar a ser muy complejos y su manejo, a veces, es casi un arte. El polímata Michael Polanyi (1891 - 1976) afirmó que la práctica científica no era una ciencia en sí misma, sino un arte que se adquiría mediante la relación con un maestro capaz.974 Uno aprende a desenvolverse en el laboratorio como quien aprende a ir en bicicleta, con la práctica. Leer sobre el tema ayuda, pero no es suficiente. Este aprendizaje requiere práctica e interacción con los maestros, con la comunidad. Aunque fue Kuhn, gracias a sus paradigmas, quien popularizó el interés por este tipo de cuestiones, Polanyi, a mediados del siglo XX, ya había reflexionado sobre ellas. Cualquiera que haya intentando ver a través de un humilde microscopio es consciente de que ni tan siquiera esto es trivial.975 Y la práctica científica cotidiana requiere capacidades aún más sutiles. Hay que aprender a juzgar la calidad de los datos, a tener buen criterio a la hora de achacar el resultado esperado a un fallo en el experimento o a nuestra hipótesis, a modificar las hipótesis en base a observaciones que, en la mayor parte de los casos, serán parciales e, incluso, a veces, engañosas. Incluso aunque prescindamos de los experimentos, la mera observación requiere de una gran formación.976 Cuando salgo al campo con un botánico, mi acompañante es capaz de estructurar la luz que llega a sus ojos de un modo completamente diferente al mío, que no soy capaz de distinguir un tomate de una berenjena. Lo mismo le sucede a quien lleva años viendo radiografías o estudiando imágenes de los telescopios. Este es uno de los motivos por los que admiramos a los grandes científicos, porque son capaces de distinguir lo que los demás no hemos sabido apreciar. Cuando yo analizo datos genómicos soy capaz de detectar, gracias a mi experiencia previa, patrones que yo mismo hace unos años habría pasado por alto. Eso me permite, por ejemplo, encontrar y descartar artefactos estadísticos o problemas con mis métodos de análisis. Estos filtros dependen, claramente, de mi conocimiento previo977 y, por lo tanto, violan el ideal inductivista de la independencia entre las observaciones y la teoría. Además, esta dependencia del oficio, del saber hacer del investigador, limita la capacidad de reproducir las observaciones y los experimentos,978 algo que, recordemos, dijimos que era esencial en la práctica científica. Esto queda reflejado en el hecho de que los científicos suelen asumir que el modo más rápido de poner en marcha una nueva técnica es visitar un laboratorio que lleve manejándola durante años. Nada mejor que pasar un tiempo con un experto, con un buen artesano, para empaparse de los sutiles detalles de los que depende el funcionamiento de una metodología. Sólo cuando las técnicas llevan siendo usadas durante décadas por mucha gente suelen estandarizarse en forma de instrumento o de kit fabricado por una casa comercial. A pesar de estos problemas, conviene recordar que dificultar no es lo mismo que imposibilitar. Puede que a un científico sin formación previa le cueste más reproducir un experimento, pero eso no implica que no pueda hacerlo. Los ejemplos de investigadores que han conseguido replicar independientemente un resultado son innumerables. David Wootton, en su magnífico The invention of science, como ejemplo explica el caso de la repetición de uno de los experimentos modernos paradigmáticos: el de Torricelli. Su rudimentario barómetro fue replicado, de forma completamente independiente, por parte de Pascal en Francia y de Valerio Magni en Varsovia.979 Lo habitual es que los científicos consigan, con más o menos esfuerzo, reproducir las observaciones y si, finalmente, en algún caso, esto resulta completamente imposible, como sucedió, por ejemplo, en el caso de la fusión fría,980 esos resultados suelen ser descartados o considerados con mucha cautela. Que la adquisición de los datos dependa, hasta cierto punto, de las capacidades de los investigadores, no implica necesariamente que éstos no puedan ser intersubjetivos o que no reflejen esencialmente aspectos del mundo externo. 15.5 Hemos de elegir qué observaciones realizar A veces los científicos se topan con fenómenos completamente inesperados. Por ejemplo, quienes descubrieron los púlsares, el fondo de microondas o las dorsales mediooceánicas no andaban buscando estos fenómenos. De hecho, al toparse con ellos por primera vez, algunos pensaron que no eran reales. Penzias y Wilson pasaron algún tiempo limpiando heces de paloma en su antena con la esperanza de eliminar ese molesto ruido de fondo, pero el cosmos se empeñó en que el fondo de microondas era una señal real y que, además, escondía secretos de tiempos remotos. Estas son observaciones que un positivista podría utilizar como ejemplo de que, al menos a veces, el investigador se limita a hacer observaciones, casi, pasivamente. Pero lo habitual es que nuestras ideas previas nos sirvan para planificar qué observaciones hacer durante la investigación. Es imposible hacer todas las observaciones posibles, por lo que estamos obligados a elegir cuáles realizar en función de su coste y de su utilidad esperada, por ejemplo, para discernir entre hipótesis alternativas. Sería el caso, por ejemplo, de un astrónomo que ha de elegir si se pasa la noche en vela buscando platillos volantes o asteroides. En la práctica, nuestras hipótesis previas suelen influir mucho en nuestras investigaciones;981 son las que sugieren, por ejemplo, qué observaciones pueden ser útiles a la hora de falsar o verificar nuestras ideas.982 Esta es, como ya hemos comentado, la base del método hipotético-deductivo. En otras ocasiones se plantean experimentos para estudiar fenómenos concretos. Por ejemplo, Galileo estaba interesado en estudiar la caída de los cuerpos y decidió construir planos inclinados y lanzar bolitas, algo que nadie había hecho antes. Esto le permitió crear unas condiciones en las que poder cuantificar la caída de los cuerpos con la rudimentaria instrumentación disponible en su época. Este experimento es fruto, por lo tanto, de las inquietudes teóricas galileanas. Aún es más, en muchos casos se crean fenómenos que no existen previamente. Es cierto que las piedras ya caían antes de que Galileo empezase a estudiar su caída, pero Aristóteles no sabía nada sobre tubos de rayos catódicos, motores eléctricos o plutonio radiactivo. La visión clásica suele asumir que los fenómenos existen independientemente de los investigadores y que estos, simplemente, los descubren, pero lo cierto es que muchos fenómenos han sido creados por los propios investigadores. En estos casos la teoría previa puede ser decisiva a la hora de crear los nuevos fenómenos. Por ejemplo, hasta el siglo XX no hubo teorías capaces de predecir la existencia de los láseres y, por lo tanto, no había láseres.983 Este fenómeno, como muchos otros, fue creado por los investigadores manipulando el mundo externo. Conviene recordar que esto es, precisamente, lo que Aristóteles temía. Su recomendación es que evitásemos alterar las condiciones del mundo externo. 15.6 Aunque los datos son los datos En realidad, cualquier empirista razonable ha de aceptar que las decisiones sobre qué observar dependerán de nuestras ideas previas.984 Sin embargo, esta restricción sólo tiene una importancia relativa. Es cierto que la disponibilidad de muchas evidencias, aunque no todas, depende de que hayamos elegido hacer unas observaciones y no otras, pero no es menos cierto que esto no las convierte necesariamente en subjetivas, puesto que varios observadores, incluso aunque favorezcan diferentes hipótesis, una vez hayan decidido estudiar un fenómeno concreto, observarán más o menos lo mismo. A partir del momento en el que se inventaron los láseres, todos los investigadores pudieron obtener los mismos resultados. Que los fenómenos sean creados mediante unas manipulaciones concretas del mundo externo no los convierte en subjetivos. De hecho, esta acumulación de nuevos fenómenos reproducibles representa otro de los modos en los que podemos decir que la ciencia avanza; a medida que pasa el tiempo acumulamos más fenómenos. 15.7 Estudios exploratorios Además, incluso aunque pudiésemos hacer miles de millones de observaciones nos encontraríamos con problemas durante su análisis. Uno de los grandes problemas en aprendizaje automático consiste en que cuando disponemos de una gran cantidad de datos es fácil encontrar patrones espurios. Imagina que hacemos miles de observaciones, en ese caso nos encontraríamos con que, si no tenemos una buena teoría previa que nos ayude a seleccionar las más relevantes, considerar miles de posibles características puede convertirse en una maldición. No es sólo que no vayamos a encontrar la aguja en el proverbial pajar, sino que después de analizar millones de posibles patrones puede que encontremos uno que nos parezca relevante pero que sea, realmente, debido al simple azar. Esta es, de hecho, la principal limitación de los estudios exploratorios. Una forma de seguir la recomendación inductivista de observar el mundo sin ser influidos por nuestras hipótesis previas consiste en hacer observaciones muy amplias para que la dirección de nuestra limitada atención no sesgue los resultados. En ciencia a este tipo de aproximaciones, que no dependen fuertemente de una hipótesis previa, se les suele denominar estudios exploratorios o expediciones de pesca. Este tipo de análisis es muy habitual, por ejemplo, en mi área, en genómica. Antes, debido a limitaciones técnicas, para estudiar qué genes cambiaban su expresión en unas circunstancias concretas, por ejemplo, durante el curso de una enfermedad, habíamos de tener unas hipótesis previas muy definidas que nos permitiesen elegir, de entre las decenas de miles de genes que componen un genoma, los pocos que podíamos permitirnos analizar. Esto era un problema puesto que si elegíamos el gen equivocado nunca nos daríamos cuenta de cuál era el gen verdaderamente relevante para el fenómeno. Por fortuna, en el siglo XXI la tecnología cambió radicalmente y, ahora, podemos analizar la expresión de todos los genes a la vez en un solo experimento. Esto ha hecho posible que se descubra mucha genética previamente insospechada. Sin embargo, estas expediciones de pesca no están exentas de problemas. Cuando hacemos miles de observaciones, tenemos que ser muy cautos puesto que muchas de las correlaciones que observemos podrían ser debidas al azar. Si jugamos una vez a la lotería es difícil que nos toque, pero si jugamos miles de veces es casi seguro que algo sacaremos. Por ejemplo, si comparamos la expresión de un gen concreto entre unos pacientes con cáncer de mama y unos controles sanos y vemos que el gen varía su expresión, lo más probable es que esta asociación sea real. Sin embargo, si tras estudiar decenas de miles de genes, encontramos un gen cuya expresión está asociada al cáncer de mama debemos considerar esta observación sólo como una hipótesis a comprobar en futuros estudios independientes. Imaginemos que elegimos dos grupos de cinco personas al azar y analizamos la expresión de todos sus genes. Es seguro que nos toparemos con genes más expresados en uno de los grupos de personas que en el otro. ¿Por qué? Porque la expresión génica tiene una cierta variación azarosa y, por lo tanto, si exploramos miles de posibles correlaciones alguna resultará ser aparentemente fuerte. Este es un problema que Bennett y colaboradores hicieron patente analizando la actividad cerebral de un salmón muerto mediante resonancia magnética funcional (fMRI).985 Evidentemente, los investigadores no esperaban que el salmón, dado su estado, respondiese de ningún modo a las imágenes que le enseñaron, pero los algoritmos utilizados en la época sí parecieron detectar áreas activas en el cerebro. Su objetivo era mostrar que cuando se analizan grandes cantidades de datos, como en el caso de la fMRI, hay que tener mucho cuidado con las correlaciones espurias. Este estudio es un ejemplo de cómo la crítica, incluso la ligeramente satírica, sirve para mejorar la ciencia ya que gracias a él se acometió un programa de mejoras en las metodologías estadísticas utilizadas para analizar este tipo de datos.986 Los análisis exploratorios sin hipótesis concretas previas pueden ser muy útiles para generar nuevas hipótesis, pero debemos considerar las correlaciones que encontremos como una evidencia interesante, no como una conclusión. Lo habitual debería ser utilizar estas asociaciones estadísticas para generar nuevas hipótesis que, posteriormente, tendrían que ser comprobadas mediante experimentos independientes. 15.8 Las observaciones no pueden interpretarse sin teorías previas Pero hay limitaciones todavía más serias, por ejemplo. no podemos interpretar el resultado de los experimentos sin recurrir a nuestro conocimiento teórico.987 Uno nunca encontrará un electrón acelerado con sólo salir a la calle ni sabrá qué hacer con una observación de un fenómeno eléctrico sin un complejo marco teórico previo. Cuando observamos el mundo y describimos lo que hemos visto no podemos evitar usar conjuntos de conceptos que estructuran nuestro conocimiento previo. En algunos casos, como en el de las bolitas y los planos inclinados de Galileo estos conceptos son muy elementales, parecen depender exclusivamente del mundo externo y es fácil asumir que las redes conceptuales requeridas surgen de un modo natural: como en la realidad hay bolitas, nosotros utilizamos el concepto de la bolita. Sin embargo, no debemos descartar los problemas asociados a la creación y la elección de los conceptos que decidimos utilizar. Este es un asunto al que los filósofos de la ciencia le han dedicado una gran atención. Las observaciones se hacen y se comunican utilizando un vocabulario concreto y los significados de las palabras dependen de nuestros compromisos teóricos e influyen, al menos hasta cierto punto, en nuestro pensamiento.988 Cuando un científico dice haber generado una corriente eléctrica en un conductor de cobre, lo hace utilizando un marco conceptual concreto que depende de sus modelos del mundo externo.989 Los conceptos que utilizamos para describir las observaciones no son independientes de las teorías. Este es un aspecto que suele pasar desapercibido,990 solemos asumir las redes conceptuales como si fuesen independientes de nuestras teorías, pero no lo son. El mundo externo es muy complejo y en muchos casos su categorización depende, profundamente, de nuestro conocimiento sobre el mismo. Por ejemplo, cuando yo me enfrento a un estudio sobre la estructura genética de las plantas de tomate, lo hago pertrechado con una taxonomía previa que va a sesgar mi mirada y que, en este caso concreto, ha hecho que durante años estuviese equivocado. En la clasificación aceptada actualmente se reconocen dos especies: Solanum pimpinellifolium y S. lycopersicum. S. pimpinellifolium habita las regiones más cercanas a la costa de Perú y Ecuador y es silvestre, mientras que S. lycopersicum se divide, actualmente, en dos variedades botánicas: S. lycopersicum var. lycopersicum, el tomate cultivado, y S. lycopersicum var. cerasiforme, una variedad intermedia entre la especie silvestre y la cultivada. Esta taxonomía guio mi mirada durante años y, a pesar de que había muchas evidencias que no encajaban con la misma, yo la acepté sin cuestionarla. No fue hasta el año 2019, quince años después de empezar a trabajar sobre el tema, que me di cuenta de que debía descartar esta clasificación y comenzar desde cero. Si quería entender las evidencias debía tratar de olvidar las categorías antiguas y guiarme, exclusivamente, por los datos genéticos, morfológicos, geográficos y ecológicos disponibles. El resultado, tras un año de análisis, reanálisis y discusiones dentro de nuestro grupo de investigación, fue comenzar a considerar a las cerasiforme mesoamericanas como antiguas y silvestres, mientras que catalogamos a las cerasiforme de Perú y Ecuador como híbridos formados por cruces entre las mesoamericanas y las silvestres andinas. Estoy seguro de que si la taxonomía hubiese sido distinta, por ejemplo, si se hubiese considerado todo como parte de la misma especie, habría sido más sencillo elaborar una hipótesis capaz de explicar todas las evidencias. Ahora sólo me queda convencer al resto de la comunidad de que estas evidencias son suficientemente claras como para descartar la taxonomía anterior, algo que no espero que vaya a ser sencillo. Nuestros conceptos implican una categorización que refleja, en mayor o menor medida, la estructura del mundo externo, pero que, al mismo tiempo, constituye parte de nuestras asunciones teóricas. En este libro ya nos hemos encontrado, previamente, con otro problema de este tipo. En los capítulos dedicados a la filosofía antigua yo diferencié tres periodos: helénico (Grecia clásica), helenístico (Alejandría) y romano. Sin embargo, esta es una caracterización atípica, puesto que lo más habitual es hablar del mundo clásico y del medieval. Esta última división implica que las diferencias entre los tres periodos que yo he utilizado deben ser, en general, muy pequeñas comparadas con la de cualquiera de ellos con la Edad Media. Sin embargo, como espero haber explicado con el detalle suficiente, las aproximaciones al conocimiento de los pensadores atenienses, alejandrinos y romanos fueron muy diferentes. Por ejemplo, las ideas de Platón, o del filósofo del período romano Plotino, fueron más cercanas a las del medieval Tomás de Aquino que a las del helenístico Arquímedes. Estos son unos matices que quedarían oscurecidos por una división estándar entre periodo clásico y medieval que agruparía a Platón, Arquímedes y Plotino frente a Tomás de Aquino. Las divisiones conceptuales que utilizamos provocan este tipo de sesgos. Dado que las categorizaciones han de reflejar la estructura del mundo externo, están expuestas a ser más o menos correctas, y, como, además, guían nuestra mirada, debemos ser cautos al aceptarlas. Sin embargo, en la mayor parte de los casos las admitimos sin cuestionarlas y estos sesgos pasan desapercibidos. El siguiente capítulo estará dedicado a los mecanismos que utilizamos para dividir el mundo externo en categorías. En algunos casos, las categorizaciones de algunos autores pueden llegar a ser tan distintas a las nuestras, que podemos llegar incluso a tener problemas serios para entender su punto de vista si no hacemos antes un esfuerzo previo por comprender su forma de ver el mundo.991 Este es un problema al que, como veremos, Kuhn le concedió una gran importancia. 15.9 Las medidas dependen de la teoría Cuando pensamos en una medida científica es común recordar nuestras clases de física o química elemental y pensar en posiciones de bolitas o en pesos de ralladuras metálicas. Estas medidas dependen de nuestras asunciones teóricas: no podemos medir la posición de la bolita sin asumir que el mundo externo está compuesto por objetos sólidos que ocupan una posición. Sin embargo, estas asunciones teóricas son tan elementales y tan bien asentadas que podríamos considerar que no son problemáticas. O que, al menos, no lo son si estamos estudiando la física de los objetos macroscópicos puesto que sí se convirtieron en un problema cuando los físicos se dispusieron a estudiar átomos. En ese momento sí sesgaron la mirada de los investigadores que trataban de averiguar cuál era la trayectoria seguida por el fotón en el experimento de la doble rendija. Sin embargo, en la práctica, este problema suele ser mucho más importante en las ciencias que estudian fenómenos más complejos y que se ven obligadas a trabajar con medidas que dependen de teorías peor establecidas o de edificios teóricos más intrincados. Por ejemplo, ¿qué están midiendo los economistas cuando afirman que el Producto Interior Bruto ha aumentado un 10% o los psicólogos cuando dicen que alguien tiene un alto grado de neuroticismo? Puede que estas medidas reflejen aspectos de la realidad, pero está claro que dependen de andamiajes teóricos bastante más alambicados que los requeridos por los planos inclinados. 15.10 Hay un continuo entre observación y teoría Por otro lado, aunque resulta útil distinguir entre observación y teoría, en realidad, existe un continuo entre observar e inferir.992 Un científico puede escribir en los resultados de su artículo que ha observado una corriente de tantos amperios en su experimento, pero, ¿la ha observado o la ha inferido? Lo que habrá visto realmente es unos números en un complejo aparato de medida, no una corriente. En 1781 Henry Cavendish observó que la magnitud del dolor que sufría al tocar una botella de Leyden dependía del grado de electrificación de la botella. Su conclusión fue que la corriente dependía de la electrificación (el voltaje). Entre 1825 y 1827 Ohm derivó su famosa ley observando esa corriente mediante el uso de un galvanómetro. Esta observación asumía ideas básicas sobre el funcionamiento del aparato de medida que Cavendish habría considerado conclusiones teóricas y no datos empíricos. Las conclusiones de un estudio concreto suelen convertirse en los datos del siguiente.993 Muchos filósofos de la ciencia, como, por ejemplo, Whewell994 o Hempel,995 también aceptaron que la distinción entre observación y teoría es sólo relativa y que varía a medida que la ciencia progresa. Para Kepler las órbitas elípticas fueron una conclusión, mientras que para Newton constituyeron un dato. 15.11 ¿Son los datos objetivos? Ante la cuestión de si los datos son objetivos podrían plantearse dos posturas extremas. Por un lado, tendríamos a los objetivistas, que defenderían que los datos sólo dependen del mundo externo, que una piedra caerá a una velocidad determinada independientemente de lo que nosotros pensemos sobre el asunto.996 En el otro extremo se encontrarían los constructivistas, que sostendrían que cualquier proposición que enunciemos reflejará, principalmente, nuestros intereses, necesidades, circunstancias sociales e ideas previas y que, por lo tanto, estará más relacionada con nuestra psicología y cultura que con el mundo externo.997 Si tratan de extenderse a todos los casos, ambas posturas extremas son difíciles de defender. Los objetivistas obvian que muchas evidencias dependen fuertemente de la perspectiva del observador. Sin embargo, el constructivismo radical tampoco está exento de problemas. Si todas nuestras ideas dependen, principalmente, de nosotros mismos, ¿cómo es posible que podamos llegar a ponernos de acuerdo, sin aparente dificultad, sobre la existencia de los gatos? Prácticamente cualquiera que estuviese ahora mismo a mí lado aceptaría como una evidencia clara que mi gata está dormida junto a mí. Esta intersubjetividad es inexplicable si asumo que ninguna de mis creencias depende fuertemente del mundo externo.998 No hay un modo de eliminar la observación como el modo fundamental de obtención de información sobre el funcionamiento del cosmos en ciencia sin, al mismo tiempo, acabar con el conocimiento cotidiano. El constructivismo radical implica una distancia tan grande entre nuestras ideas y el mundo externo, que es incapaz de explicar cómo es posible que nos desenvolvamos en ese mundo. El lector podría pensar que no es posible que ningún intelectual pretendidamente serio haya defendido el constructivismo radical incluso para las observaciones más elementales, pero se equivocaría. El mundo del constructivismo académico puede llegar a ser más extraño de lo que muchos hemos sido capaces de imaginar. Kuhn es famoso por haber defendido que las observaciones dependen del paradigma y que, por lo tanto, no hay observaciones independientes de nuestras ideas.999 Esto puede interpretarse como una mesurada crítica al optimismo positivista, que asumía la inmaculada concepción de las evidencias, o como un constructivismo radical de los datos en el que la realidad influiría poco y dos científicos comprometidos con paradigmas distintos vivirían en mundos distintos. Esto último es algo que Kuhn escribió literalmente.1000 Sin datos intersubjetivos desaparece la posibilidad de que nos aproximemos racionalmente al mundo externo y estamos abocados, de nuevo, a la imposibilidad del conocimiento y al escepticismo radical. Aunque, tal vez sea Bruno Latour (1947-), un filósofo y sociólogo de la ciencia francés, quien tenga el dudoso honor de haber defendido la tesis más absurda. Este supuesto pensador es famoso por sostener que atribuir la muerte de Ramsés II a la tuberculosis es un anacronismo del mismo calibre que decir que murió ametrallado.1001 Latour llegó a escribir que antes de que el médico prusiano Robert Koch lo nombrase, el bacilo de la tuberculosis no existía y, por lo tanto, nadie podría haber muerto por esa enfermedad. De todo lo que he leído sobre esta idea constructivista radical, el comentario que más me ha gustado es el del profesor de filosofía alemán Martin Kusch en el libro Phisolophy of Science: The Key Thinkers. Kusch declina criticar la posición de Latour y se limita a reflejar su incomprensión.1002 Lo que dice Latour es tan absurdo que criticarlo racionalmente, según Kusch, es imposible. Dado este nivel del discurso tal vez quien mejor pueda desfacer el entuerto sea Coco, el adorable personaje de Barrio Sésamo. Coco debería explicar en algún capítulo la diferencia entre territorio y mapa, puede que lanzando piedras a un Latour con los ojos vendados. Es posible que así nos ahorrásemos muchas estupideces pseudointelectuales. Sin embargo, no es menos cierto que también hemos de renunciar al sueño inductivista de una observación completamente pura. Esta propuesta puede ser reconfortante, pero es demasiado ingenua1003 y nos deja expuestos a ignorar numerosos sesgos. La dependencia de la observación de nuestras ideas previas y de nuestros sistemas perceptivos e instrumentales implica que los sesgos implícitos pueden comprometer la evaluación de las hipótesis que estamos analizando. En muchos casos estos sesgos pueden generar evidencias viciadas que pueden hacernos percibir una realidad ilusoria. En el caso extremo, los datos podrían terminar reflejando el mapa en vez del territorio y eso nos condenaría a que cada nueva evidencia apoyase nuestras ideas previas alejándonos de la realidad, del territorio. Sería importante estimar en qué medida las evidencias que manejamos y nuestras conclusiones dependen de nuestras ideas previas y en qué medida del mundo externo. Sin embargo, en muchos casos no es trivial realizar esta evaluación ya que sólo tenemos acceso al mapa y el acceso al territorio siempre estará mediado por nuestra perspectiva. Estamos encerrados dentro de nuestras mentes y de nuestras comunidades y, por lo tanto, debemos ser cautos ya que las evidencias podrían depender, al menos parcialmente, de nuestras ideas previas. Para poder hacer alguna contribución útil en botánica primero debemos convertirnos en especialistas en esa área1004 y esto, inevitablemente, guiará nuestra mirada en unas direcciones concretas. El filósofo y economista Otto Neurath (1882 - 1945), uno de los positivistas del círculo de Viena, utilizó la imagen de la reparación y mejora de un barco en alta mar como analogía de la construcción del conocimiento.1005 Nuestra misión es mejorar esa nave, pero no podemos comenzar desde cero, puesto que saltar por la borda implica la muerte. Es imposible construir un nuevo barco sin partir del anterior. Por lo tanto, lo único que podemos hacer es ir reemplazando madera por madera partes del barco actual. En todo momento habrá un barco apoyándonos, pero esto no impide que acabemos con un conocimiento mayor al inicial. Sin embargo, siempre estaremos expuestos al riesgo de que el punto de partida, el antiguo barco, haya sesgado parcial o totalmente el resultado final. En algunos círculos es común escuchar que para poder aprender algo radicalmente nuevo deberíamos antes despojarnos de todas nuestras creencias previas. Esta es una actitud que se refleja muy bien en una conversación entre el Dr. Strange y su mentora, la Anciana, en la excelente película de 2016, Dr. Strange. Cuando el neurocirujano Stephen Strange acude a la Anciana en busca de ayuda para curarse de unas heridas, que la medicina más avanzada es incapaz de sanar, esta pretendida sabia le dice que el primer paso que debe dar es olvidar todo lo que ha aprendido. Habría sido más adecuado pedirle al médico que reevaluase algunas de sus ideas, pero esperar que pueda olvidarlo todo es absurdo. Sin conocimiento quedaría incapacitado para comunicarse y si, además, recordamos que nuestros sistemas perceptivos incorporan un cierto conocimiento implícito entenderemos que Strange no podría ni tan siquiera ver u oír. Está claro que los productores de la película se gastaron una parte importante del presupuesto en dotar de una imagen llamativa a la Anciana, pero no parece que invirtiesen mucho en consultar con epistemólogos. Sin conocimiento previo no sabríamos ni cómo observar ni cómo utilizar el resultado de esas observaciones para crear modelos sobre el mundo ni cómo evaluar las hipótesis generadas. Sin conocimiento previo no podemos utilizar las señales que nos llegan del mundo externo para aprender.1006 Esto, evidentemente, plantea un problema, si ningún sistema es incapaz de partir de cero, ¿cómo es posible que se genere la primera semilla, el primer conocimiento inicial? Este es el motivo por el que este libro comenzó con un capítulo dedicado a la evolución. La evolución biológica fue capaz de crear seres con cerebros capaces de aprender sin partir de información previa alguna. Uno puede crear hipótesis por azar y si dispone de un medio para evaluarlas frente al mundo externo, con el tiempo, conseguirá conocimiento. Esto es, precisamente, lo que hacen la mutación y la selección natural. El problema es que esta hazaña conlleva un precio muy elevado, la ineficiencia. Sin mecanismos capaces de ayudarnos a generar eficientemente modelos que reflejen la realidad el proceso es muy lento. En el caso de la evolución natural se tardaron millones de años en acumular un conocimiento mínimo y, además, se condenó a muertes terribles a la inmensa mayoría de los que tuvieron la desgracia de nacer con un error. En realidad, sí se puede aprender sin tener conocimiento previo, pero el proceso es tan ineficiente y tan diferente que no suele denominarse aprendizaje sino evolución. Nuestro conocimiento previo nos expone al problema de los sesgos, pero renunciar a él sería contraproducente. Es cierto que nuestras ideas previas pueden sesgarnos, pero también lo es que son el resumen de lo que la humanidad ha aprendido durante milenios. Pretender que merece la pena prescindir de ese apoyo previo es erróneo. Lo que debemos hacer es ser conscientes de que esas ideas previas, en algunos casos, pueden ser erróneas por lo que deben ser revisadas periódicamente. Lo importante es que nuestro conocimiento previo no nos sesgue tanto como para impedirnos utilizar la nueva información recibida del territorio para generar mapas actualizados que sean un mejor reflejo del mismo que los antiguos. Hemos de iterar, pero, al hacerlo, tenemos que ser muy conscientes del riesgo de los círculos viciosos. El uso del conocimiento previo no siempre plantea problemas críticos. Por ejemplo, es común que nuestras observaciones dependan de teorías previas muy alejadas de las hipótesis que estamos tratando de evaluar. Este es el caso, por ejemplo, de las observaciones astronómicas más comunes. Es indiscutible que nuestras observaciones requerirán de amplios conocimientos sobre óptica, pero que un planeta aparezca en una posición o en otra no dependerá mucho de esos conocimientos. Aunque en este caso nuestras observaciones también estarán sujetas a nuestra perspectiva, esta dependencia será débil. Por otro lado, de todos los puntos del cielo que podrían haber observado los astrónomos berlineses en 1846, eligieron apuntar sus telescopios al lugar que Le Verrier les había indicado. La hipótesis astronómica hizo una predicción y la observación dependió, evidentemente, de esa predicción, pero lo hizo en un sentido débil. Es difícil imaginar que la hipótesis hubiese podido influir lo suficiente a los astrónomos como para que estos hubiesen alucinado colectivamente el puntito de luz en la posición esperada. Los constructivistas radicales suelen hablar de que la observación está cargada de teoría, pero no siempre precisan a qué se refieren exactamente. La propuesta de que cualquier conclusión depende, hasta cierto punto, de nuestras ideas y disposiciones implícitas previas es cierta, pero también es trivial y poco interesante. Sin embargo, lo que a veces parecen implicar los constructivistas radicales con sus palabras es que las evidencias empíricas siempre dependerán fuertemente de las teorías previas relativas a la propia área de estudio. Esta tesis, claramente, no es cierta. En muchas ocasiones, aunque no en todas, las observaciones no dependerán de las teorías aceptadas en un área concreta.1007 Algunos filósofos de la ciencia describen esta situación hablando de teorías de distintos niveles.1008 Las teorías relativas a la óptica de los telescopios serían para el astrónomo una teoría de nivel básico. El filósofo de la ciencia Larry Laudan explicó esta situación del siguiente modo: los diferentes astrónomos tenían distintas hipótesis y éstas dependían, en última instancia, de las teorías ópticas, pero lo hacían de un modo neutral puesto que todas las hipótesis dependían de la óptica exactamente del mismo modo y, por lo tanto, la óptica era indiferente en esta elección. Esta es una distinción importante, lo relevante no es que las observaciones dependan de algún conocimiento previo, sino que esta dependencia no sea neutral respecto a las hipótesis evaluadas. Además, también hemos visto que hay experimentos menos sujetos a algunas de estas limitaciones puesto que ni tan siquiera requieren que focalicemos demasiado nuestra atención ya que disponemos de técnicas que permiten explorar amplios territorios. Por ejemplo, hoy en día podemos hacer experimentos a escala genómica, y esto nos exime de utilizar nuestras ideas previas para elegir genes concretos a estudiar. Aunque, como también hemos comentado, observar todos los genes tiene sus propios problemas estadísticos ya que nos expone a la aparición de correlaciones espurias. En cualquier caso, limitar la influencia de las hipótesis que estamos intentando testar en el diseño experimental es una regla general que el investigador haría bien en recordar1009 porque el riesgo de los círculos viciosos es real. Si las observaciones, tal y como sostienen los constructivistas radicales, no dependiesen del mundo externo, sería muy difícil explicar que los científicos hayan conseguido generar modelos que nos permiten realizar intervenciones exitosas en ese mundo externo. Galileo observó la trayectoria de los proyectiles y, a partir de la descomposición de ese movimiento, aproximadamente parabólico, llegó a profundas conclusiones sobre la inercia, la relatividad del movimiento y la cinética gravitatoria que, con el tiempo, se transformaron en la primera ley de Newton y la ley de la gravitación universal. ¿Cómo explicaría un constructivista radical que al final del proceso se hayan podido enviar las sondas Voyager a los confines del sistema solar? Me llama la atención la incoherencia de los constructivistas que, al mismo tiempo que defienden que la ciencia no tiene una relación especial con la realidad, escriben sus tesis en computadoras digitales y hacen fotos de sus nietos con la cámara de su teléfono móvil. Por otro lado, no hemos de caer en el profundo error de creer que cualquier número reflejado en una tabla de un artículo científico o cualquier observación hecha por un investigador sea independiente de sus ideas previas. En muchos casos, las observaciones dependen fuertemente de nuestras ideas previas y es entonces cuando debemos ser especialmente cuidadosos, sobre todo si nuestras conclusiones no nos permiten realizar predicciones o intervenciones exitosas sobre el mundo externo. Cuando mi sistema visual me informa de la presencia de mi gata, las asunciones implícitas en el funcionamiento de ese sistema y mi conocimiento zoológico intuitivo tienen una influencia relativamente pequeña en la conclusión de que hay un pequeño animal dormido sobre el sillón.1010 Sin embargo, hemos de ser mucho más cuidadosos cuando estas condiciones se incumplen. Por ejemplo, cuando los términos en los que se describe la observación pueden influir fuertemente en nuestras conclusiones, como en mi estudio del tomate, debemos proceder con mayor cautela. Es obvio que la taxonomía aceptada del tomate influyó en mi pensamiento y me hizo asumir que debía de haber plantas silvestres de tomate en la región amazónica ecuatoriana. Y esto lo pensé a pesar de que quienes habían estado sobre el terreno me decían que nunca habían observado plantas silvestres en esos lugares. Sin embargo, cuando me informaban de que sí las habían visto en México, yo explicaba este detalle con la hipótesis ad hoc de que esas plantas debían de ser el resultado del asilvestramiento de plantas importadas. En este caso mis conclusiones dependían fuertemente de la categorización que yo había asumido y esto me sesgaba. Es cierto que este sesgo causado por la taxonomía del tomate no me impidió formular una hipótesis que violase esa taxonomía, pero sí lo dificultó. Tardé años en darme cuenta del problema y en decidir que para poder avanzar debía rechazar conscientemente la taxonomía aceptada y evaluar cualquier nueva propuesta en función de las evidencias disponibles más elementales. No debía aceptar que S. lycopersicum var. cerasiforme mexicano había derivado recientemente de sus parientes andinos, debía revisar en qué lugares había plantas silvestres, cuáles eran las diversidades genéticas de las distintas poblaciones, qué composición genómica tenía cada individuo, etcétera. Sólo así, descendiendo al nivel de las evidencias más crudas y menos influidas por mis ideas taxonómicas previas, pude avanzar sin el sesgo impuesto por la taxonomía establecida. Hemos de ser conscientes de que las categorizaciones que asumimos guían nuestra mirada, por lo que, a veces, tendremos que considerar una reevaluación de las categorías aceptadas. Esta es una lección especialmente pertinente para las ciencias en las que los términos con los que se describen las observaciones dependen muy fuertemente de las asunciones teóricas. Que las observaciones dependan, en parte, de nuestras creencias y expectativas no implica que no tengan nada que ver con la realidad o que no podamos utilizarlos para construir modelos útiles del mundo,1011 pero es recomendable ser más cuidadosos en estos casos. Además, es importante entender que la dicotomía entre el objetivista absoluto y el constructivista radical es una falsa. Existe un continuo entre los datos claramente intersubjetivos, y aquellos profundamente influidos por nuestras mentes. Estos últimos, en realidad, no merecerían el nombre de observaciones, sino, más bien, de alucinaciones. Hay un continuo entre la observación y la alucinación. Observar sin perspectiva alguna es imposible1012 y el conocimiento del mundo externo surge de la interacción de nuestras mentes y nuestra cultura con ese mundo, por lo que depende en parte del mundo y en parte de nosotros mismos.1013 La cuestión que habríamos de plantearnos en cada caso es en qué medida cada evidencia refleja la estructura del mundo externo y en qué grado nuestro conocimiento previo. Esta es una respuesta más sutil que las planteadas por el objetivista o el constructivista; de nuevo, nos encontramos con una cuestión difícil de formalizar. Nadie ha sido capaz de establecer un algoritmo que nos permita determinar en qué grado un dato depende del mundo externo y en qué medida de nuestra propia mirada. Ni siquiera tengo claro que la pregunta anterior tenga un sentido suficientemente claro. 15.12 Resumen Las observaciones están teñidas de teoría y esto representa un nuevo límite fundamental del conocimiento. El problema de la inducción era debido a los saltos lógicos ampliativos y éste a que es imposible aprender sin partir de unas capacidades y un marco teórico previo ya sea éste explícito o tácito. No se puede aprender sin partir de un conocimiento previo. No existe una fundación empírica absoluta sobre la que sostener el conocimiento del mundo externo. El edificio teórico no se sostiene sobre una sólida base de hormigón, sino, más bien, sobre un lecho pantanoso en el que se clavan algunos pilares, las percepciones más elementales, que, a su vez, sostienen la estructura sobre la que, gracias a la coherencia lógica de esas percepciones, se van construyendo teorizaciones cada vez más alejadas de la percepción.1014 No podemos defender que la ciencia funciona gracias a un absoluto filosófico. El conocimiento, incluso el dato más elemental, está expuesto a limitaciones fundamentales. Esto no impide que podamos aprender sobre el funcionamiento del mundo, pero sí implica que tenemos que ser muy cautos, puesto que a cada paso podemos quedar sumergidos en el fango. Estos problemas no son meras posibilidades filosóficas, sino que afectan a la práctica científica diaria. Por ejemplo, un investigador ha de aprender a observar. Las metodologías que se utilizan en ciencia han sido el resultado de un largo proceso de mejora y eso implica que conocerlas y dominarlas no es sencillo y, a su vez, que su diseño puede sesgar nuestros resultados. El científico aprende a reconocer patrones y a hacer experimentos en los que se estudian fenómenos antes desconocidos y esto, que hace posible que detecte fenómenos que una persona no entrenada no vería, también puede convertirse en un sesgo. Por otro lado, cuando el investigador busca evidencias no lo hace al azar, sino que ha de tratar de buscar datos que confirmen y rechacen las distintas hipótesis planteadas. Esto implica que es importante que estemos abiertos a la posibilidad de que haya evidencias que hayamos ignorado. Los datos se describen utilizando marcos conceptuales que son en sí mismos conocimiento previo que, para bien o para mal, dirige nuestra mirada, los conceptos que utilizamos para describir las observaciones no son neutrales. En algunas ciencias hay medidas basadas en constructos muy complejos que dependen de las mismas teorías que están siendo evaluadas, en estos casos hay que ser especialmente críticos y prudentes y conviene reconsiderar con mucho cuidado todas nuestras asunciones. En cualquier caso, no es posible hacer una separación quirúrgica entre observación y teoría y, además, esta distinción varia a medida que la ciencia progresa. Por ejemplo, lo que para Kepler eran conclusiones teóricas se convirtieron en datos para Newton. Estos problemas no implican que el conocimiento sea necesariamente imposible, pero sí que hemos de proceder con cautela y que tenemos que esforzarnos por buscar evidencias claras y lo más neutrales respecto a las teorías que estamos testando. El objetivismo y el constructivismo son dos extremos de un continuo. El problema es análogo al que planteamos al explicar que las asunciones implícitas en nuestros mecanismos perceptivos y nuestras expectativas pueden hacernos ver ilusiones ópticas y alucinaciones. Es muy importante evaluar el grado en el que los supuestos datos dependen de las hipótesis que se están evaluando, cuanto más dependan de ellas, más fácil será que acabemos encerrados en un círculo vicioso en el que las observaciones no sean más que alucinaciones debidas a nuestros sesgos. Es importante plantearse hasta qué punto cabe la posibilidad de que los datos que creemos haber observado dependen realmente de nuestras propias ideas y no de la información proveniente del fenómeno que estamos estudiando. Y, por supuesto, no debemos enamorarnos de nuestras teorías puesto que el compromiso emocional y los incentivos para aceptar una conclusión concreta nos acercan al círculo vicioso. Salirse de nuestra mente para adoptar una perspectiva diferente es imposible, pero podemos aprovechar la mente de los demás, tanto la de otros compañeros del área, como la de los investigadores de áreas más distantes. Hemos de seguir el ejemplo de la Academia platónica, nuestros críticos racionales no son nuestros rivales, sino nuestros ayudantes. Gracias a su punto de vista podemos reevaluar los aspectos más débiles de nuestra posición para construir así una conclusión más racional. Debemos convertirnos en buscadores de la verdad, no en defensores de nuestras ideas. Además, mientras las conclusiones terminan materializándose en predicciones concretas e intervenciones exitosas sobre el mundo externo, la ciencia suele avanzar a buen paso. Sin embargo, cuando no es posible predecir con éxito, los riesgos aumentan ya que se dificulta el testeo de las hipótesis y, como vimos, esta es una de las claves fundamentales del avance científico. La clave no reside en no equivocarnos, sino en ser capaces de detectar el error. Cuando nos encontremos en un área en la que sea difícil hacer intervenciones o predicciones exitosas y nos veamos forzados a echar mano de continuas hipótesis ad hoc para apuntalar nuestras teorías y, además, las observaciones dependan de esas mismas teorías, habremos de aceptar la poca utilidad práctica de esas hipótesis y plantearnos su sustitución. "],["ordenando_el_cosmos.html", "16 Ordenando el cosmos 16.1 Patrones y clasificaciones 16.2 Gachas y grumos 16.3 Ni necesarios y ni suficientes 16.4 Los individuos también se corresponden con patrones reales 16.5 Métodos taxonómicos 16.6 Características de las clasificaciones 16.7 Nominalistas y realistas 16.8 Resumen", " 16 Ordenando el cosmos Como hemos comentado, las observaciones dependen, hasta cierto punto, de nuestras ideas previas, entre otros motivos, porque dependemos de nuestras categorizaciones, del modo en el que dividimos el mundo en clases de elementos o categorías. Los seres humanos creamos categorías agrupando en clases distintos objetos o individuos: gatos, perros, mesas, sillas, etcétera. Esto lo hacemos creando incluso clases abstractas como ciencia, mala ciencia y pseudociencia. Estas clasificaciones, en muchos casos, las hacemos automáticamente, sin esfuerzo aparente, abrimos los ojos y en nuestra mente aparece un mundo organizado en distintas categorías y, sin embargo, este automatismo encierra procesos de clasificación muy complejos. Dado que estas clasificaciones forman parte de nuestro conocimiento sobre el mundo, que tienen características nada triviales, que influyen en nuestro pensamiento y que me han ocupado profesionalmente durante los últimos lustros, creo que merece la pena dedicarle un capítulo al análisis de la taxonomía. 16.1 Patrones y clasificaciones Esta vez voy a comenzar por hacer unas breves aclaraciones sobre el vocabulario que utilizaré a lo largo del capítulo. Hablaré indistintamente de clases y categorías. Una clase, o categoría, agrupa un conjunto de elementos y por elemento me referiré a un individuo o a cualquier objeto o entidad que estemos clasificando. Por lo tanto, las clasificaciones dividen los elementos en clases. Por ejemplo, yo soy un individuo, un elemento, perteneciente a la clase que incluye a todos los seres humanos y mi gata es un elemento de la categoría gato. También hablaré sobre patrones. Esta es la nomenclatura que ha popularizado el filósofo Daniel Dennett en su artículo Real Patterns.1015 Un patrón es una estructura que existe en el mundo externo y que es susceptible de ser descrita con economía. Es decir, un patrón es una estructura que mantiene un cierto orden, que no es completamente caótica. Este orden permite que el patrón pueda ser descrito utilizando una cantidad de información relativamente limitada. Por ejemplo, un cristal de sal de mesa, de cloruro de sodio, tiene una estructura muy ordenada que puede describirse muy económicamente: es una estructura formada por iones de sodio y cloro ordenados formando cubos. Las clases o los elementos no son patrones. Las clases y los elementos son parte de nuestras ideas sobre el mundo estudiado, no son el mundo externo en sí. Cuando me refiera a la estructura de ese mundo externo hablaré de patrones, no de clases, categorías, individuos o cosas. De nuevo, en esta ocasión, también resulta útil la analogía del territorio y el mapa. En el territorio hay patrones reales, mientras que los elementos y las clasificaciones forman parte de nuestros mapas. Nuestras clasificaciones tratan de reflejar los patrones que encontramos en el mundo externo para ayudarnos a pensar. Comprendemos el mundo organizando sus patrones en los elementos y las clases que nos parece detectar en el mismo.1016 Las distintas clases, por ejemplo, nos facilitan reflexionar utilizando analogías. No es necesario que hayamos visto todos y cada uno de los gatos del mundo para saber, cuando nos encontremos con un nuevo individuo de esa clase, que es muy posible que ronronee o que nos arañe (y que, en muchos casos, ambas acciones se sigan en rápida sucesión). En general, los elementos agrupados en una misma clase suelen compartir características, por ejemplo, todos los ejemplos de hortalizas tienen partes comestibles. Nuestras categorizaciones, son, en realidad, hipótesis sobre la estructura del mundo estudiado y, por lo tanto, pueden reflejar esa estructura con mayor o menor fidelidad, igual que un mapa puede corresponderse con mayor o menor aproximación con un territorio concreto. Estas cuestiones taxonómicas son tratadas directa o indirectamente por distintas áreas filosóficas. La semántica, evidentemente, está relacionada con las clasificaciones. Con esto no quiero decir que la semántica o, mucho menos, el lenguaje se limite a estas cuestiones taxonómicas; el lenguaje es un fenómeno muy complejo y este es sólo uno de sus aspectos. Como ya hemos mencionado, las clasificaciones también tienen que ver con la metafísica. Es normal que los problemas relacionados con la categorización de lo que existe en el mundo tengan que ver con las cuestiones relacionadas con la existencia. Aunque repito, este capítulo estará dedicado sólo a los aspectos relacionados con la taxonomía, a la metafísica le reservamos una sección posterior. Otra cuestión muy interesante, pero que tampoco voy a tratar aquí, es la de qué tipo de fenómenos crean esos patrones que existen en el mundo externo. Hay, por ejemplo, regularidades debidas a la estructura física del cosmos. Los campos cuánticos, por ejemplo, están descritos por la física fundamental y los ciclones y anticiclones por la física atmosférica. Por otro lado, los procesos de copia de información con pequeñas modificaciones crean patrones con estructuras fractales muy delicadas. Un fractal es una estructura geométrica que se parece a sí misma en distintas escalas. Por ejemplo, un cielo poblado por nubes o un árbol son estructuras fractales. La reproducción biológica y la copia y la transmisión de la información cultural producen estructuras fractales, aunque no en espacios físicos, sino en espacios abstractos. Hay muchos aspectos relacionados con la taxonomía y la clasificación que suelen entenderse bastante mal y esto genera todo tipo de confusiones. Por ejemplo, es muy común encontrar personas que creen que las clases están separadas nítidamente y que no tiene sentido proponer clases distintas, como ciencia y pseudociencia, cuando éstas no están completamente diferenciadas ya que la propuesta taxonómica implicaría que algunos elementos serían intermedios o de difícil clasificación. Es cierto que en algunos casos las clases pueden dividirse sin problemas. Por ejemplo, la división entre perros y gatos no causa dudas porque no existen perro-gatos, es decir, no hay elementos intermedios. Sin embargo, en otros muchos casos, las categorías son necesariamente difusas, tienen unos límites un tanto borrosos. Recordemos que no hemos dicho que el mundo externo esté formado por elementos claramente diferenciados, lo que hay en el mundo externo son patrones más o menos compresibles desde un punto de vista informacional. Las clasificaciones reflejan patrones que no tienen por qué ser nítidos y, por lo tanto, no tienen por qué limitarse a establecer clases absolutamente claras. Por ejemplo, aunque es útil hablar de hombres y mujeres, porque estas categorías reflejan un patrón real, es posible que haya elementos, como los individuos intersexuales, que no encajen fácilmente en esa clasificación. En estos casos se pueden plantear distintas clasificaciones, siendo unas más prolijas que otras, que consigan reflejar los patrones reales con distintos niveles de detalle. Esta es una solución análoga a la de los mapas de distintas escalas que reflejan el territorio con distinto nivel de detalle. 16.2 Gachas y grumos Creo que un buen modo de hacernos una idea de qué es un patrón real es pensar en unas gachas elaboradas con avena molida. Si las gachas son muy finas, no tendrán grumos, pero si no somos cuidadosos al hacerlas, puede que sí los haya. Estas estructuras, estos grumos, son análogas a los patrones que encontramos en el cosmos. Por ejemplo, podríamos pensar en la galaxia como en unas enormes gachas y, en este caso, las estrellas y los planetas serían los grumos. Aunque la analogía que trato de transmitir es algo más general y abstracta y no se limita al espacio real. Mi gata, por ejemplo, es un patrón constituido por átomos y el conjunto de gatos formaría una delicada estructura de grupos y subgrupos, como un conjunto de nubes y sub-nubes en un espacio abstracto, y esta estructura podría reflejarse en una clasificación utilizando subespecies o poblaciones genéticas. En este caso cada nube estaría formada por puntos y cada punto sería un individuo, un gato concreto. Visto de este modo, el problema de la clasificación consistiría en crear clases que recogiesen, de un modo simplificado, la estructura de ese espacio abstracto en el que cada grumo, cada región especialmente densa del espacio, sería una clase, una subclase o un individuo. Eliezer Yudkowsky en su Rationality: From AI to Zombies1017 lo explica describiendo un espacio abstracto que denomina espacio-cosa (Thingspace). En este espacio-cosa habría una dimensión por cada posible atributo imaginable. Por ejemplo, un individuo, un gato concreto, podría encontrarse en un punto del espacio-cosa y una clase, una raza concreta o el conjunto de todos los gatos, estaría constituida por una nube de puntos más o menos próximos en este espacio-cosa. Esto puede parecer muy abstracto, pero este es el tipo de espacios multidimensionales que he utilizado en las últimas décadas para hacer taxonomía vegetal. En mi trabajo, cada posición del genoma constituye una dimensión y, por lo tanto, una planta está representada por un punto en un espacio con millones de dimensiones. Los seres humanos no podemos visualizar espacios de más de tres dimensiones, de modo que hacerse una idea de la estructura de grumos en ese espacio no es trivial, pero los estadísticos han creado herramientas de análisis multivariante que nos permiten analizar, mediante distintas aproximaciones, las estructuras más relevantes de esos espacios multidimensionales. Una de estas herramientas, el análisis de componentes principales, hace una proyección de un espacio de dimensión elevada en un espacio de un número de dimensiones más manejable, por ejemplo 3. En los últimos años debo de haber hecho decenas de miles de análisis de componentes principales para hacerme una idea de qué estructura tiene la variación genética presente en los tomates. Normalmente lo que uno se encuentra al analizar una especie biológica utilizando estas herramientas es un conjunto de nubes en estos espacios abstractos. En principio, cada nube se corresponde con un grupo genético. Por ejemplo, en el caso de los seres humanos tendríamos una nube constituida, principalmente, por europeos, otra por americanos, etcétera. Una de las dificultades de la taxonomía viene dada por el hecho de que estas nubes, en muchos casos, no están completamente aisladas, suelen encontrarse individuos intermedios. De ahí que haya introducido antes la analogía de las gachas, tenemos grumos más o menos densos, pero, no necesariamente, están completamente separados entre sí por regiones completamente vacías. Además, como en el caso de las nubes reales, estas estructuras genéticas suelen ser fractales, las nubes están constituidas por sub-nubes, que, a su vez, están formadas por pequeñas sub-sub-nubes, etcétera. Por ejemplo, en el caso de los seres humanos la nube europea está a su vez dividida en regiones que se corresponden, a grandes rasgos, con áreas extensas del continente, como Italia o los países nórdicos. Y, a su vez, la sub-nube italiana se alarga formando un gradiente que va desde el norte al sur de la península itálica. La gran ventaja de crear categorías, de hablar de europeos, y de africanos, es la economía de la descripción. La alternativa sería detallar las características de cada uno de los individuos, pero esto, evidentemente, sería mucho más costoso. Por otro lado, resulta evidente que podemos generar distintas clasificaciones alternativas que reflejen de un modo más o menos fiel el patrón real subyacente o podemos plantear clasificaciones jerárquicas que reflejen el patrón a distintas escalas. En cualquier caso, una clasificación, normalmente, implicará una cierta pérdida de información. 16.3 Ni necesarios y ni suficientes Una vez definidas las clases es habitual que tratemos de caracterizarlas. Por ejemplo, ¿en qué se diferencian los mamíferos y las aves? Los mamíferos tienen glándulas mamarias y pelo, mientras que las aves tienen plumas y pico. Y, además, es habitual que utilicemos estas características diferenciales como definición de las clases: los mamíferos son una clase de vertebrados caracterizada por poseer glándulas mamarias y pelo. Este tipo de definiciones describen las reglas para clasificar los individuos en categorías. Esto está muy bien siempre que recordemos que lo que estamos haciendo es buscar unas reglas que nos permitan delimitar una región del patrón real. Sin embargo, lo que solemos pensar es que las clases tienen una existencia natural en el mundo externo y que se diferencian porque los individuos que las componen tienen unas propiedades esenciales que los caracterizan. Es habitual creer que los gatos, como especie, existen en el mundo externo y que se caracterizan por tener orejas triangulares y garras. Esto es, por ejemplo, lo que pensaban Sócrates, Platón o Aristóteles. Si asumimos la existencia de estas clases naturales es normal pensar también que cualquier individuo perteneciente a una de esas clases tendrá unas características determinadas necesarias para pertenecer a su clase. Es decir, cualquier individuo que pertenezca a la clase habrá de tener esa característica. Por ejemplo, cualquier mamífero tendrá mamas o columna vertebral. Por otro lado, habrá también características suficientes, es decir, peculiaridades que poseerán todos y cada uno de los individuos pertenecientes a la clase y nadie más. Es decir, que si un individuo posee las características suficientes es seguro que pertenecerá a la clase. En el caso de los mamíferos las mamas son una característica necesaria y suficiente. El pelo, por ejemplo, es suficiente, cualquier individuo con pelo es un mamífero, pero no es necesario, hay algunos ejemplos de mamíferos completamente lampiños. Por otro lado, la columna vertebral es una característica necesaria para ser un mamífero, pero no es suficiente ya que hay muchos individuos con columna vertebral, por ejemplo, los patos, que no son mamíferos. Cuando las clases reflejan patrones reales nítidamente separados es común encontrar características necesarias y suficientes, pero el problema es que hay muchos patrones reales que no están tan claramente perfilados y en estos casos el asunto tiende a complicarse. Por ejemplo, al hablar de Popper comentamos que trató de hallar una característica necesaria y suficiente que diferenciase a la ciencia de la pseudociencia. Es decir, intentó establecer una propiedad que compartiesen todas las ciencias y que no tuviese ninguna pseudociencia, pero fracasó. Aunque este suele ser nuestro objetivo cuando tratamos de definir clases1018 en muchos casos, no llegamos a alcanzarlo. En este sentido el ejemplo del Sócrates platónico es muy ilustrativo. Sócrates trata, una y otra vez, de aproximarse al análisis del mundo definiendo distintos términos en base a características necesarias y suficientes, pero fracasa en todas las ocasiones. Se dice que, siguiendo este procedimiento, en la academia platónica, un día, definieron a los seres humanos como animales bípedos y sin plumas. Se comenta también que Diógenes, el cínico, desplumó un pollo y arrojándoselo a los académicos les dijo: aquí tenéis a vuestro hombre. A lo que los académicos respondieron modificando su definición: bípedo sin plumas de uñas anchas. Esta anécdota refleja la dificultad de encontrar una definición que incluya todos los individuos que deseamos incluir, pero a ninguno más. El problema es que los patrones reales pueden ser bastante complejos y, por lo tanto, en muchos casos, no es fácil encontrar características necesarias y suficientes con las que crear definiciones bien diferenciadas. Estas dificultades causan problemas prácticos, algunos serios y otros que, si no fuese porque afectan a la vida de mucha gente, podrían calificarse como curiosos. Por ejemplo, actualmente las autoridades deportivas quieren establecer una definición que les permita decidir con justicia quién puede y quién no puede participar en las competiciones deportivas femeninas. ¿Qué caracteriza a los hombres y los diferencia de las mujeres? En principio estas no deberían ser dos clases muy difíciles de distinguir. Tal vez lo inmediato sería pensar en los genitales, pero nos encontraríamos con el problema de que hay personas intersexuales que tienen un órgano con una anatomía intermedia entre el pene y el clítoris. Dado que soy genetista, el lector podría pensar que yo me decantaría por la composición cromosómica: las mujeres tienen dos cromosomas X, mientras que los hombres tienen un cromosoma X y otro Y. Pero esto tampoco es cierto, hay, por ejemplo, personas que tienen una mutación en el gen SRY (Sex determining Region of the Y chromosome) y que, a pesar de contar con un cromosoma Y, son mujeres. Tras el fracaso de estos criterios, y tratando de regular casos similares a los de la campeona olímpica intersexual Caster Semenya, las autoridades deportivas decidieron aplicar un criterio basado en la concentración de testosterona. Sin embargo, esto tampoco zanjó la polémica ya que las mujeres también producen testosterona y, de hecho, aunque la mayoría de las mujeres tienen concentraciones menores a las de la mayoría de los hombres, hay bastantes casos de mujeres con concentraciones elevadas de la hormona. Este es un problema análogo al de la altura, aunque la media de la altura de las mujeres es inferior a la de los hombres, hay muchas mujeres que son más altas que muchos hombres. Este problema ha causado una avalancha de críticas a este intento de definición por parte de la Asociación Internacional de Federaciones de Atletismo. Si al final consiguiesen llegar a una definición completamente satisfactoria de las clases hombre y mujer agradecería al lector que me avisase y, de paso, que llevase unas flores a la tumba de Sócrates para que pudiese descansar definitivamente; el pobre rara vez terminó sus investigaciones con una definición satisfactoria.1019 En realidad, muchos filósofos piensan que para muchos conceptos interesantes será imposible encontrar definiciones nítidas basadas en características necesarias y suficientes.1020 Wittgenstein es famoso, entre otras cosas, por haber afirmado algo similar, no hay condiciones necesarias y suficientes que definan qué es un juego1021 y Daniel Dennett ha escrito que “nada suficientemente complicado como para ser interesante puede tener una esencia.”1022 Yo no sé si llegaría a tanto, porque los electrones me parecen interesantes y sí creo que pueden definirse con claridad, pero en otras áreas, como la biología o la filosofía, sí que pienso que es cierto que las categorías suelen ser un tanto difusas. De esto no hemos de concluir que el mundo no tenga estructura o que no sea razonable utilizar los términos hombre y mujer, sino que los patrones subyacentes son más sutiles de lo que solemos pensar y que, por lo tanto, no debemos esperar que nuestras definiciones vayan a reflejarlos con una fidelidad absoluta. Joel Spolsky, un programador norteamericano, resumió el problema perfectamente al escribir que: todas las abstracciones gotean,1023 (pero algunas son útiles). El problema surge porque las clases reflejan grumos, regiones especialmente densas, en algún espacio-cosa multidimensional. Ya hemos comentado que estos grumos no tienen por qué estar completamente aislados, perfectamente delimitados, y, además, los puntos que los componen no tienen por qué compartir características necesarias ni estar delimitados del resto por una lista de propiedades suficientes.1024 Es frecuente encontrar propiedades típicas en los miembros de una clase, pero esto no implica que todos tengan que poseerlas necesariamente. Normalmente los individuos que pertenecen a distintas clases tienden a compartir algunas características diferenciadoras, pero no siempre estas propiedades son necesarias o suficientes. Además, muchas de las propiedades que utilizamos para caracterizar a los elementos individuales suelen ser cuantitativas, como los niveles de testosterona en sangre o la altura, y las distribuciones para estas características en distintas clases pueden estar solapadas. Es lo que sucede, por ejemplo, con la altura de hombres y mujeres. Las diferencias entre ambos grupos no se deben a que cualquier hombre sea más alto que cualquier mujer, sino a que, en general, los hombres tienden a ser más altos que las mujeres. En estadística, en estos casos, se dice que las distribuciones están solapadas. Es muy común que esto suceda también con las características genéticas. La gente suele imaginar que hay diferencias absolutas entre europeos y asiáticos o entre tomates de un tipo u otro. Pero esto normalmente no es así. Las diferencias suelen limitarse a las frecuencias en las que los distintos caracteres (en este caso el término técnico sería alelo) aparecen en los diferentes grupos. El ateniense y estoico Crisipo de Solos (280 a. C. - 206 a. C.) fue el primero en escribir, en un tratado tristemente perdido, sobre otro problema relacionado con las propiedades cuantitativas. Es evidente que ni uno, ni dos, ni tres granos son suficientes para constituir un montón de arena, escribió, pero ¿cuántos se requieren? ¿Hay un número exacto que diferencie al simple conjunto de granos de arena de un verdadero montón?1025 Debemos aceptar esta relativa vaguedad, puesto que lo contrario implicaría una parálisis absoluta ya que no seríamos capaces de comprender nada. En la mitología nórdica se cuenta que el dios Loki, el padre de Hela, la encargada del inframundo, y de los gigantescos Fenrir y Jörmundgander, los monstruos del Ragnarök, la batalla del fin del mundo, se apostó la cabeza con los enanos Brok y Sindri. Al perder la apuesta Brok fue a cortarle la cabeza a Loki, pero éste le dijo: “Mi cabeza es vuestra, más no el cuello, cuidaos de hacerle daño porque incumpliréis el trato.”1026 A esto le siguió una discusión sobre dónde exactamente terminaba la cabeza y empezaba el cuello. El acuerdo sobre la definición resultó, como era de esperar, imposible y Loki conservó su cabeza. El político inglés Edmund Burke expresó la misma idea de este modo: “Nadie podrá marcar con precisión el límite entre el día y la noche, pero esto no implica que no sean distintos”. Podría pensarse que esta vaguedad convertirá nuestras clases en inútiles, pero esto sería un error. Nos encontramos en una situación análoga a la de la vaca esférica, ignorar ciertos detalles nos permite comprender el mundo externo lo suficiente como para hacer predicciones útiles. Lo que sí es problemático es creer que las clases han de tener definiciones nítidas caracterizadas por propiedades necesarias y suficientes ya que esto sólo puede conseguirse en algunos casos. Es importante recordar que las clases, las taxonomías, están en nuestras mentes, son parte del mapa, y que el territorio está constituido por los patrones reales y que estos patrones pueden ser relativamente difusos. Cuando estudiamos un fenómeno creamos clases para poder describirlo económicamente y esas clases, para ser útiles, deberían reflejar la estructura de los patrones reales relacionados con el fenómeno estudiado. En el caso de las personas, las clases más comunes son generadas por las redes neuronales de nuestro cerebro y las redes neuronales se caracterizan por utilizar criterios implícitos para determinar qué elementos pertenecen a una clase y cuáles no. Las redes neuronales, una vez entrenadas son capaces de clasificar cualquier elemento, pero no lo hacen en base a una definición explícita, como una lista de criterios necesarios y suficientes, sino como un conjunto de sinapsis, de uniones neuronales, más o menos fuertes. Esto añade aún más confusión al asunto puesto que nos parece muy evidente que existen los gatos y somos capaces de determinar qué es y qué no es un gato, pero cuando nos preguntan por la definición solemos tener problemas serios. Potter Stewart, un abogado y juez estadounidense, en 1964, zanjó el tema sobre qué era y qué no era pornografía sentenciando: “lo sabré cuando lo vea.”1027 La frase quedó para la posteridad y, aunque se puede criticar la decisión por prestarse a la subjetividad y al abuso, en realidad, este abogado estaba expresando un problema profundo inherente a las clasificaciones. 16.4 Los individuos también se corresponden con patrones reales Hasta este momento hemos discutido algunos de los problemas asociados a las clases que creamos al unir varios individuos similares, por ejemplo, las especies, pero, al hacerlo, hemos dado por buena la existencia de esos individuos sin más. En principio puede parecer que discutir la existencia del gato común, como entidad independiente del lince europeo puede ser más razonable que cuestionar la existencia de un gato individual concreto. En el cosmos hay algunas entidades, como mi gata o como el planeta Venus, cuya existencia parece fuera de toda duda. ¿Pero es la existencia de estas entidades esencialmente distinta a la de los niveles superiores que las agrupan? ¿Acaso no es mi gata un patrón real? Si nos detenemos a pensar con cuidado sobre la existencia de mi gata, veremos que, en realidad, tampoco ella está tan claramente definida. ¿Dónde empieza y acaba? Evidentemente, sus pelos le pertenecen, de hecho, sospecho que sin ellos no sería tan encantadora, pero, ¿si un pelo se le cae deja de ser parte de ella? ¿En qué momento? En el laboratorio a mis compañeros les llama la atención que el aura formada por los pelos de mi gata llegue a difundirse hasta allí. Tal vez, podríamos decidir que un pelo concreto forma parte del animal mientras esté pegado a él, pero que deja de pertenecerle en el momento preciso en el que se desprende. Pero esta propuesta nos sitúa en otro aspecto problemático, el temporal. Los animales se desarrollan y con el tiempo mueren y desaparecen. Este aspecto nos recuerda a la analogía del continuo fluir y el cambio apenas perceptible de un río. Heráclito dijo que no podías bañarte dos veces en el mismo río y son muchos los que piensan que el problema reside en el flujo del río, pero el cambio continuo afecta de igual modo al bañista. Ambos son patrones en el espacio y el tiempo. Y este problema no se limita a los gatos o los monos, las piedras también cambian con el tiempo, sólo que más lentamente. En el mundo todas las cosas empiezan a existir, cambian y terminan por desaparecer. Las cosas también son procesos. Un gato no es más que un patrón, un grumo en las gachas. Eso sí, ciertas cosas parecen corresponderse con grumos mucho más definidos, en el espacio y en el tiempo, que otras, este es uno de los motivos por los que asumimos su existencia como algo natural. De modo que la admisión del recambio de los pelos del gato nos ha llevado al problema del tiempo, pero, además, ni siquiera ha solucionado el problema del espacio. ¿En qué átomo preciso empieza y acaba mi gata? ¿Tiene sentido intentar delimitar al animal a escala atómica? Al fin y al cabo, si descendemos a esa escala no estaremos viendo más que interacciones electrostáticas, algo bastante ajeno a nuestra idea del gato. Los átomos que componen el mundo no están marcados. No existen átomos de gato y no gato a un nivel atómico. Los patrones existen en distintas escalas de tiempo y espacio: campos cuánticos, átomos, moléculas, células, tejidos, órganos, gatos, especies, géneros, órdenes, etcétera. La gran ventaja de describir el mundo utilizando gatos en vez de átomos es la economía de esta descripción. Si quisiese hacerme una idea de lo que está haciendo mi gata utilizando una descripción atómica debería especificar el estado de cada uno de sus átomos. Una tarea tan sencilla como comunicar su velocidad requeriría especificar una lista de varios quatrillones de átomos. Es evidente que resulta más económico hablar del individuo en su conjunto y decir, simplemente, que, ahora mismo, no se está moviendo porque, como es su costumbre, está echándose una siesta en su caja. Esto sería imposible en un mundo sin estructura. En ese mundo el conocimiento sería imposible. Sin embargo, nuestro cosmos está repleto de patrones que se prestan muy bien a ser descritos, al menos de forma aproximada, utilizando simplificaciones: objetos, individuos y clases. 16.5 Métodos taxonómicos Hasta el momento, hemos comentado los problemas que conlleva tratar de caracterizar las clases mediante listas de propiedades necesarias y suficientes, pero hemos de insistir en que estas listas no son un método de creación de esos elementos y categorías, sino, como mucho, una forma de clasificar nuevos elementos. Cuando exijo que un individuo tenga garras para poder clasificarlo como gato, estoy utilizando un criterio que se ha definido partiendo de las características compartidas por un conjunto de individuos que, previamente, había unido en una clase. Sólo estudiando la clase he podido determinar que los gatos tienen garras. De modo que las listas de criterios nos permiten determinar si un individuo pertenece o no a una clase previamente definida, pero no sirven para crear esas clases desde cero. Así que conviene tratar la cuestión de qué métodos pueden utilizarse para determinar las categorías que podemos utilizar para describir el mundo. Puede que a algunos lectores este planeamiento les parezca extraño porque, al fin y al cabo, los gatos existen en el mundo real y también existe la especie gato que engloba a todos los gatos individuales. Pero esta confianza se debe a un error causado por nuestros eficientes sistemas de clasificación automática. Es intuitivo pensar que los gatos y su especie tienen una existencia real, pero lo que existe en realidad son patrones que nuestros sistemas automáticos de clasificación han ordenado asignándoles categorías de individuos concretos y de especies. En realidad, definir la especie gato con precisión no es trivial, y muestra de ello es que los taxónomos han cambiado su definición hace pocos años. Podría decirse que algunas clasificaciones son tan naturales para nuestra mente que son como el aire para nosotros, están ahí, pero nos cuesta darnos cuenta de qué son. Nuestro cerebro crea una clasificación tras otra y las utiliza sin tregua: gato, vehículo, silla, persona, alimento, etcétera. Además, nuestra mente, como ya hemos comentado, utiliza criterios implícitos para hacer estas clasificaciones, por lo que este camino no nos va a ser de gran ayuda en el estudio de las categorías. Inspirados por el cerebro y equipados con un amplio aparataje matemático, los estadísticos y los informáticos han desarrollado distintos métodos de clasificación automática que sí pueden servirnos como buenos ejemplos metodológicos. En esta área, que tiene en la actualidad una utilidad práctica enorme, los algoritmos de clasificación se dividen en dos tipos (sí, esto es una clasificación concerniente a los métodos de clasificación): supervisados y no supervisados. En los métodos no supervisados podría decirse que uno parte de las gachas y busca grumos. Son algoritmos capaces de detectar agrupaciones particularmente densas en el espacio-cosa.1028 Una vez hayamos delimitado las agrupaciones en ese espacio tendremos nuestras categorías. Esta forma de proceder está motivada por nuestro objetivo de construir agrupaciones que describan el mundo económicamente. Es mucho menos costoso decir que hay hombres y mujeres que listar cada uno de los miembros de ambos grupos. ¿Cuáles son las dimensiones que definen los espacios de características en las que vamos a buscar las agrupaciones? Las que nosotros deseemos, esta es una decisión que nos compete. Somos nosotros quienes debemos determinar qué características pueden ser relevantes para crear las categorías útiles para nosotros. Por ejemplo, en el artículo que estoy escribiendo ahora mismo he clasificado los tomates de dos formas completamente independientes. En el primer análisis hemos utilizado como características las variaciones en distintas posiciones del genoma. Por lo tanto, cada característica genética es una dimensión en el espacio abstracto en el que busco las agrupaciones de puntos (y cada punto una planta de tomate concreta). El segundo análisis ha sido morfológico y las dimensiones se han correspondido con características que una experta ha medido en las plantas: tamaño del fruto, longitud del estilo, color del fruto, etcétera. El otro tipo de algoritmos de clasificación automática es el supervisado. En este caso se parte de individuos previamente etiquetados. Por ejemplo, podríamos tener una colección etiquetada de fotografías de perros y gatos. En este caso la misión del algoritmo es aprender a clasificar nuevas fotografías no etiquetadas basándose en lo aprendido a partir de los ejemplos originales. Imaginemos que queremos distinguir las ciencias de las pseudociencias. En este caso podríamos partir de unos cuantos ejemplos claros de ciencias y pseudociencias, caracterizarlos en base a unos parámetros y alimentar al algoritmo. Si todo va bien el algoritmo estará listo para etiquetar cualquier ejemplo futuro como ciencia o pseudociencia. Una vez hemos creado las clases podemos proceder a crear definiciones que diferencien las distintas categorías. Estas definiciones pueden servirnos para estudiar las características diferenciales entre clases o para razonar utilizando analogías. Incluso pueden convertirse en un método de clasificación que nos permita categorizar, en el futuro, nuevos elementos. Sin embargo, no hemos de pensar que todos los algoritmos de clasificación crearán listas de criterios explícitos. Recordemos que lo que les pedimos es que clasifiquen, pero no necesariamente que generen criterios explícitos para conseguirlo. Que obtengamos o no listas de características dependerá del método de clasificación concreto que utilicemos. En cualquier caso, una vez disponemos de un algoritmo de clasificación siempre seremos capaces de clasificar todos los elementos que necesitemos y, después, podremos analizar qué características los distinguen. Para esto podemos utilizar análisis estadísticos sencillos, como, por ejemplo, calcular con qué frecuencia aparece cada atributo en los elementos de cada clase generada o podemos echar mano de herramientas más sofisticadas como un análisis principal de componentes discriminantes. Estos análisis nos permitirán encontrar las diferencias entre grupos, pero no nos confundamos, estas diferencias no tienen por qué corresponderse con características necesarias y suficientes. En muchos casos las diferencias en una característica concreta se dan en la distribución de esa propiedad en los distintos grupos. Por ejemplo, las distribuciones en altura de hombres y mujeres son distintas, los hombres, en promedio, tienden a ser más altos que las mujeres, pero esto no implica que todos los hombres sean más altos que todas las mujeres. Además, en muchos casos la variabilidad en la característica entre distintos grupos puede estar muy solapada. Lo que hacen estos análisis estadísticos es buscar la parte de la variación que diferencia a los grupos y eso es lo que nos ofrecen, la diferencia, pero eso no implica que los grupos no compartan una gran parte de la variación. ¿Cómo es posible que dos grupos sean diferentes a pesar de tener una variación solapante en una característica? Porque hay otras características y es la agregación de todas ellas la que los distingue. Puede que un hombre sea muy bajito, pero que tenga una alta concentración hormonal y pene y por eso el sistema de clasificación lo cataloga como hombre y no como mujer. 16.6 Características de las clasificaciones De modo que el mundo externo tiene un cierto orden, es un cosmos, tiene patrones. Aunque estos patrones pueden ser bastante difusos y, por lo tanto, las clasificaciones que utilicemos para representarlos también deberán ser difusas, sobre todo si tenemos en cuenta que son representaciones aún más económicas que el propio patrón real original y, por lo tanto, tienen que descartar información. Recordemos: todas las abstracciones gotean, pero algunas son útiles. ¿Son las manzanas comestibles? En general sí, o al menos lo son cuando pertenecen a una variedad doméstica, están maduras, todavía no se han podrido y no tienen gusanos.1029 Las clasificaciones para ser útiles han de representar aproximadamente la estructura del mundo externo, pero también dependerán, hasta cierto punto, de nuestros intereses; podremos crear distintas clasificaciones para representar los mismos patrones dependiendo de nuestras necesidades. Por ejemplo, la herpetología es una rama de la biología que estudia a los reptiles y a los anfibios. Desde un punto de vista filogenético, de la historia evolutiva, esta área carece de sentido ya que estos dos grupos de animales no forman una rama común (técnicamente monofilética) de la historia de la vida. ¿Por qué existen entonces los herpetólogos si para los taxónomos el término es inadecuado? Pues porque la perspectiva filogenética no es la única útil en biología, la ecológica también es muy relevante y los animales estudiados por los herpetólogos tienen adaptaciones y comportamientos lo suficientemente similares como para que su estudio conjunto tenga sentido. Además, dado que nuestras clasificaciones serán una simplificación de la estructura del mundo real, podemos elegir el grado de esa simplificación, podemos decidir el nivel de economía de la representación. Es posible utilizar una vista de pájaro y hablar de plantas y animales o acercarnos más y distinguir entre tomates y patatas. A pesar de esto, rara vez una clasificación útil, por muy detallada que sea, será un reflejo exacto de la realidad externa que estamos tratando de representar, especialmente cuando esa realidad es muy diversa y compleja. Nuestras categorías gotean. Otra característica que suele causar confusión es la jerárquica. El rapero Jay Z en un momento de su canción Already Home dice sentirse mitad hombre, mitad mamífero, como si ambas categorías fuesen excluyentes. Esta es una confusión muy común. A mí me han preguntado muchas veces si me sentía valenciano o español. La respuesta es que la categoría por la que siento más afinidad, en este caso, es la de humano, me siento más cercano a los estudiantes de la Academia platónica que a algunos de mis vecinos, pero eso no excluye que también pueda decir que soy valenciano, español o europeo. ¿Por qué son tan comunes las categorizaciones jerárquicas? Porque reflejan muy bien las estructuras fractales, que, recordemos, son aquellas que tienen una geometría similar a distintas escalas. Los seres vivos se dividen en bacterias, arqueas y eucariotas, los eucariotas, a su vez, incluyen a los animales, las plantas y los hongos, los animales, están compuestos por los vertebrados y los invertebrados y, por último, dentro de los vertebrados hay peces, anfibios, reptiles y mamíferos. Por último, una característica fundamental de las clasificaciones es que pueden ser erróneas, pueden no corresponderse con el mundo real. Es cierto que, puesto que el mapa no se corresponde exactamente con el territorio, nuestras categorías siempre estarán parcialmente equivocadas, pero ese no es el problema al que me estoy refiriendo en este momento. Hemos de recordar que el mapa puede ser completamente erróneo, nuestras categorizaciones podrían no tener ninguna correspondencia con el territorio. Puedo hablar de unicornios rosas, pero no existe ningún patrón real que se corresponda con un unicornio rosa. Cometer este tipo de errores puede llegar a ser muy problemático. No tenemos acceso directo al mundo externo, sino que en nuestras mentes trabajamos con nuestras categorizaciones y esas clasificaciones pueden sesgar nuestros pensamientos. Por lo tanto, trabajar con un mapa erróneo nos conducirá a tomar decisiones equivocadas. Crear una categoría, por lo tanto, no es un acto neutral.1030 Últimamente estoy explicando que la agricultura ecológica no es ecológica. ¿Cómo puede ser? La etiqueta ecológico aplicada a la producción de alimentos es una marca comercial regulada por la Unión Europea. Un alimento puede ser legalmente etiquetado como “ecológico” cuando ha sido producido siguiendo esa reglamentación. Sin embargo, en esas leyes no se recoge que haya que comprobar que esos modos de producción sean realmente más ecológicos, es decir, que tengan un impacto medioambiental menor que los convencionales, por lo que se da la circunstancia de que, en muchos casos, la producción ecológica de alimentos es más perjudicial para el medio ambiente que la convencional. Es por eso que, de un modo deliberado, yo elijo hablar de agricultura pseudoecológica. Las categorías, necesariamente, implican una simplificación de la realidad externa y esto puede llevar a que nos confundamos, pero no es menos cierto que pueden ser utilizadas para difundir una falsedad completa. Definir categorías y utilizarlas también es un arte que requiere oficio e integridad intelectual. 16.7 Nominalistas y realistas Prácticamente desde el inicio de la filosofía se planteó la cuestión de dónde residían las categorías. ¿Es la gatunidad algo que existe en el mundo externo o sólo se encuentra en nuestras mentes? Los nominalistas defienden que somos nosotros quienes clasificamos y que, por lo tanto, en el mundo externo no hay nada que se corresponda con la gatunidad, sólo hay gatos, individuos.1031 Mientras que los realistas, como Platón o Aristóteles, defendían que las clases eran externas, naturales1032 y que los seres humanos, simplemente debíamos apreciarlas. Creo que la posición más defendible es intermedia entre ambas. Un término filosófico relacionado con estas cuestiones es el de los universales. Cuando decimos “Sócrates es humano”, ¿a qué se refiere el término general “humano”?1033 ¿Qué tipo de existencia tienen estos términos generales, que los filósofos antiguos denominaban universales? Recordemos que según la teoría platónica de las formas los gatos individuales no serían más que pálidos reflejos de la idea universal de la gatunidad, que sería el único ente con una existencia completamente real. El filósofo medieval Guillermo de Ockham fue uno de los pioneros del nominalismo. Para él, en el mundo externo sólo habría individuos que los seres humanos nombraríamos utilizando un término universal. Para Ockham el término “gato” no estaría refiriéndose a ninguna gatunidad con existencia en el mundo real, sino que sería una forma de nombrar al conjunto de todos los gatos individuales que pueblan el mundo. Ninguna de estas posturas extremas está libre de problemas serios. Por un lado, parece difícil conceder que la gatunidad existe como algo externo. Aceptar esto parece conducirnos a una metafísica extraña. Pero, por otro lado, rechazar que el término general “gato” se refiere a algo que existe independientemente de los seres humanos también parece absurdo. O, al menos, me lo parece a mí, ya que a algunos de los constructivistas sociales les parece erróneo incluso admitir la existencia de los gatos individuales. Según la tesis constructivista del molde de galleta (cookie-cutter) mi gata no existiría en el mundo externo, sería yo el que habría decidido delimitar, arbitrariamente, una región del espacio y el tiempo y denominarla Ada. Para un constructivista extremo los electrones tendrían la misma existencia que las constelaciones, serían, simplemente, una elección social sin ningún estatus especial.1034 Creo que es obvio que la tesis que sostiene que las categorizaciones sólo dependen de nosotros y que no tienen ninguna correspondencia con el mundo externo es claramente problemática. Yo podría elegir creer que en casa no vive un gato, sino un unicornio rosa, pero ese mapa no se correspondería con el territorio. Estas posturas pueden parecer demasiado extremas como para ser tenidas en cuenta, pero, por ejemplo, Kuhn fue interpretado así por muchos de sus seguidores. En La estructura de las revoluciones científicas se afirma que los científicos, tras una revolución, después de aceptar un cambio de paradigma, viven en un mundo diferente puesto que categorizan el mundo de un modo diferente. Esto, entendido de un modo suave es poco controvertido, por eso he defendido que es importante reflexionar sobre el arte de nombrar, pero llevado al extremo se puede llegar fácilmente al absurdo de concluir que el lenguaje es una cárcel de la que no podemos salir. Esta es una idea que permea una gran parte de la cultura de nuestro tiempo. En 1984 Orwell planteaba la destrucción del lenguaje como un método de control político, sin las palabras adecuadas la población sería incapaz de reflexionar sobre su condición. Ojo, una cosa es admitir que sería más o menos difícil reflexionar sobre algunos asuntos especialmente abstractos y otra, bien distinta, es que sería absolutamente imposible reconocer la penosa situación en la que se encontraban o, incluso, crear nuevos términos para describir sus cuitas. En la excelente película La llegada la lingüista protagonista tiene como misión aprender a comunicarse con unos seres extraterrestres. A medida que va aprendiendo su lengua empieza a tener visiones de tiempos futuros y cuando, por fin, consigue dominarla completamente, no sólo su visión del mundo cambia, sino que es capaz de hacer que su mente viaje en el tiempo. Esto está relacionado con la tesis de Sapir-Whorf que sostiene que nuestro lenguaje determina el modo en el que entendemos la realidad. Por cierto, esta no es la motivación original del relato original de Ted Chiang, en el que se basó el guion de la película; el cuento se escribió para reflexionar sobre el concepto físico de la mínima acción, una idea fascinante que subyace a la física clásica, la relativista y la cuántica. Pero dejemos el tema de la influencia de las clasificaciones en nuestra visión y volvamos a nuestra influencia en esas clasificaciones. Como ya he explicado, me parece evidente que las clasificaciones, como las observaciones y como las teorías dependen en parte del mundo externo y en parte de nosotros mismos. Esta es una conclusión que considero poco controvertida. Nuestras descripciones del mundo externo siempre dependerán, hasta cierto punto, de nosotros, pero, a la vez, si queremos que sean útiles para entender ese mundo, deberán reflejar, al menos aproximadamente, su estructura. La palabra gato no existe fuera de la cultura humana, pero si todos los seres humanos desapareciesen en este preciso instante, mi gata continuaría echándose la siesta tranquilamente hasta la hora de la cena. Podemos y tenemos que elegir cómo dividir el mundo en clases y estas clases serán, hasta cierto punto convencionales, pero esto no implica que sean arbitrarias, que no tengan nada que ver con la estructura de la realidad. Es legítimo discutir sobre la convención de cuándo comienza la noche, pero dudo que nadie aceptase que la noche está compuesta por las horas impares y el día por las pares. Esto sería una arbitrariedad inaceptable puesto que no sería útil para entender el mundo externo. 16.8 Resumen El cosmos tiene un cierto orden, en él se encuentran patrones. Por ejemplo, los átomos no están distribuidos uniformemente en el espacio, hay agrupaciones de átomos especialmente densas que denominamos planetas y estrellas, galaxias, cúmulos y supercúmulos. Nuestras categorizaciones tratan de reflejar aproximadamente esa estructura proponiendo objetos, individuos y clases para poder así comprender el mundo que habitamos. Los espacios en los que buscamos estas clasificaciones son abstractos, sus dimensiones son las distintas características que consideramos relevantes. En el ejemplo de las galaxias la propiedad utilizada ha sido la posición espacial, pero podríamos estar tratando con características genéticas, morfológicas o de cualquier otro tipo. Algunos patrones son especialmente nítidos y nuestra mente, que es una clasificadora compulsiva, nos muestra los individuos y las clases que los representan como clases naturales. Este es el motivo por el que no nos cuestionamos la existencia de los gatos individuales o de la especie que los engloba. Sin embargo, no todos los patrones ni las clasificaciones que los representan tienen por qué estar nítidamente definidos. Los grumos no tienen por qué estar completamente aislados para ser grumos. Además, nuestras clasificaciones son, en la mayoría de los casos, aproximadas, asumimos una cierta pérdida de información: las clasificaciones son útiles, pero gotean. Esta pérdida de información nos permite trabajar con facilidad y economía con los aspectos del mundo que más nos interesan, pero, al mismo tiempo, hace que ignoremos algunos detalles. Una vez creadas las clases podemos tratar de buscar propiedades que las distingan. En algunos casos se encontrarán características necesarias y suficientes, pero en general puede que esto no ocurra. Lo más habitual es que las clases sólo se diferencien porque la variación en sus propiedades no esté distribuida en ellas de un modo uniforme. Es común crear categorizaciones jerárquicas. Lo hacemos porque es habitual encontrar patrones con estructuras fractales y las jerarquías recogen bastante bien la estructura de estos fractales. Una clasificación es una hipótesis sobre la estructura del cosmos, por lo tanto, debe depender del cosmos, pero, al mismo tiempo, también es convencional, elegimos crear unos grupos u otros en función de nuestras preferencias y necesidades. Esto se traduce, por ejemplo, en que podemos plantear clasificaciones alternativas más o menos económicas para reflejar unos mismos patrones. Las observaciones están teñidas de teoría, en parte, porque dependen de nuestra categorización del mundo y este acto de clasificación no es absolutamente objetivo, depende, hasta cierto punto de nuestra perspectiva. Al mismo tiempo, si una clasificación, que es una hipótesis sobre la estructura del cosmos, no refleja el mundo externo, es errónea. Siempre se tolera una cierta pérdida de información y, por lo tanto, de error; pero no hay que olvidar que una categorización también puede ser completamente errónea o más errónea que otra, puede reflejar sólo nuestras ideas, ser arbitraria, e ignorar los patrones del mundo externo por completo; puede ser, simplemente, una alucinación. Si tomamos una clasificación errónea por verdadera estaremos trabajando con un mapa equivocado y eso nos llevará a tomar malas decisiones. Si queremos clasificaciones más útiles conviene reconocer que el acto de crearlas no es neutral y, por lo tanto, requiere oficio e integridad intelectual. "],["paradigmas_revoluciones_y_constructivismos.html", "17 Paradigmas, revoluciones y constructivismos 17.1 El giro histórico 17.2 Paradigmas y ciencia normal 17.3 Anomalías y revoluciones 17.4 Problemas paradigmáticos 17.5 Contribuir sin aceptar 17.6 Descripción y prescripción 17.7 Inconmensurabilidad 17.8 Inconmensurabilidad de temas 17.9 Inconmensurabilidad histórico-semántica 17.10 Inconmensurabilidad lógico-semántica 17.11 Inconmensurabilidad metodológica 17.12 Radical o mesurado 17.13 No te arranques los ojos, visita al oculista 17.14 Posmodernos y sociólogos radicales 17.15 La guerra por la razón 17.16 Confianza en los expertos 17.17 La filosofía importa 17.18 Resumen", " 17 Paradigmas, revoluciones y constructivismos En 1962 Thomas Kuhn (1922–1996) publicó uno de los libros más influyentes sobre filosofía de la ciencia: La estructura de las revoluciones científicas. Su influencia llegó a trascender los confines del reducido mundo académico de los filósofos de la ciencia y pasó a formar parte del clima intelectual de la sociedad en su conjunto. Kuhn, como cualquier otro autor, no surgió de la nada, su trabajo recogía críticas previas planteadas por filósofos tan diversos como Carnap, Quine,1035 Polanyi o Hanson, pero mientras que los análisis anteriores habían quedado circunscritos a los filósofos de la ciencia, La estructura se convirtió en un fenómeno popular. Ningún filósofo posterior ha podido ignorar las propuestas de este libro y su influencia en la cultura general también ha sido enorme. El periódico inglés The guardian, por ejemplo, lo calificó como uno de los libros más influyentes del siglo XX.1036 Hasta ese momento, en filosofía de la ciencia las discrepancias habían sido más o menos limitadas. Aunque Popper había criticado la defensa positivista de la inducción, en el fondo, los puntos de encuentro entre estos filósofos habían seguido siendo importantes: distinción entre los contextos de descubrimiento y justificación, limitación de la filosofía de la ciencia al análisis de este último y desprecio por las motivaciones psicológicas y sociológicas involucradas en el proceso científico;1037 y, además, solía admitirse una distinción clara entre observación y teoría.1038 Sin embargo, Kuhn hizo que estos consensos saltasen por los aires: como ya hemos comentado, las observaciones están teñidas de teoría y la elección entre hipótesis no es puramente racional, porque los factores psicológicos y sociológicos no pueden ser ignorados. 17.1 El giro histórico Para Kuhn fue muy importante reflexionar sobre qué lecciones podían derivarse de la espectacular caída de la física clásica ocurrida a principios del siglo XX.1039 Si una teoría tan bien fundamentada empíricamente como la newtoniana podía caer, ¿en qué podíamos confiar? Kuhn no comenzó su carrera como filósofo, sino como historiador de la física y su aproximación se basó en estudiar la ciencia como un fenómeno histórico.1040 Este es un planteamiento muy alejado del de los positivistas lógicos, que pretendían examinar la ciencia como un conjunto de proposiciones susceptibles de ser analizadas mediante la lógica formal. Tras el trabajo de Kuhn el positivismo pasó de moda y se popularizó la idea de que la filosofía debía aprender sobre la evolución histórica de la ciencia.1041 La escuela histórica sustituyó a la lógica y los análisis formales de Carnap y compañía fueron sustituidos por los históricos de Kuhn, Lakatos o Laudan. La esperanza de estos nuevos autores era que el cambio histórico encerrase lecciones sobre el funcionamiento real de la ciencia1042 que la lógica formal había ignorado. Sin embargo, esto no implica que las ideas positivistas fuesen completamente abandonadas. El bayesianismo actual, por ejemplo, está más cerca de Carnap que de Kuhn, pero sí es cierto que tras La estructura el análisis histórico se hizo más popular y que las antiguas certezas positivistas fueron duramente criticadas por los filósofos de la ciencia más relevantes de los 60 y los 70 como: Irme Lakatos, Norwood Russell Hanson o Hilary Putnam.1043 De hecho, la aproximación histórica fue la dominante hasta mitad de los 801044 y, además, algunas de sus conclusiones no habrían de ser olvidadas. Cuando en las carreras de ciencias o en la literatura popular se habla sobre la historia de la ciencia es habitual dar una visión muy simplificada y romántica.1045 La historia queda reducida a una serie de anécdotas, una progresión ininterrumpida de eurekas logrados por grandes científicos aislados e infalibles. Suele ignorarse que fueron las comunidades y no los genios aislados los que hicieron avanzar la ciencia y, sobre todo, se omiten los continuos errores y la complejidad del lento progreso científico. La historia de la ciencia no consiste en una acumulación continua de verdades; el avance, en muchos casos, pasa por abandonar teorías previamente aceptadas, como la del flogisto.1046 La evolución histórica suele ser compleja y contingente1047 y la caricatura histórica que se enseña a los alumnos les transmite una visión completamente irreal del devenir científico y, sobre todo, no les ayuda a aprender el valor de la discusión racional. Distintos filósofos, como Popper, Kuhn o Lakatos, propusieron varios modelos alternativos de esa evolución histórica. Popper, como no podía ser de otro modo, basó su propuesta en la falsación.1048 Según Popper el cambio científico sería sencillo: los científicos, en una primera fase, propondrían hipótesis que deberían ser consideradas como conjeturas tentativas1049 y que, a continuación, en una segunda fase, tratarían de falsarse. Una vez se encontrasen anomalías capaces de falsar las hipótesis disponibles, los investigadores propondrían nuevas conjeturas que deberían explicar todo lo que explicaban las anteriores, pero que, además, incluirían lo aprendido recientemente y este ciclo de conjeturas, cada vez más precisas, y de refutaciones se repetiría sin fin.1050 17.2 Paradigmas y ciencia normal Kuhn, por otro lado, propuso un modelo en el que los científicos se encontrarían trabajando dentro del marco de un paradigma que, habitualmente, no cuestionarían. Un ejemplo sería el paradigma newtoniano. Con el tiempo es posible que fuesen acumulándose anomalías cada vez más difíciles de explicar, cómo el problema de la órbita de Mercurio, y estos problemas eventualmente acabarían por causar una revolución. De modo que el desarrollo científico alternaría fases de ciencia normal y crisis revolucionarias.1051 La noción de paradigma de Kuhn está relacionada con el conjunto de ideas compartidas por la comunidad científica e incluye, tanto las teorías sobre como funciona el mundo, cómo las metodologías que debemos emplear para estudiarlo.1052 Dicho de otro modo, el paradigma podría definirse como el conjunto de principios teóricos, metodológicos y metafísicos aceptados por los científicos de una comunidad.1053 Más tarde, otros filósofos, matizaron estas ideas y propusieron otros conceptos relacionados con los paradigmas. Por un lado, Lakatos, un filósofo que aunó las propuestas de Popper y Kuhn, en vez de paradigmas, habló de programas de investigación y, posteriormente, Larry Laudan de tradiciones científicas.1054 Para poder entender las conclusiones de Kuhn, y de sus seguidores más extremos, es importante recordar que el paradigma incluye tanto las teorías como las metodologías e instrumentos utilizados en un área científica.1055 Este es un aspecto clave que no suelen tener en cuenta quienes utilizan el término de forma casual e implica que, según Kuhn, cuando los físicos abandonaron el paradigma newtoniano abrazaron, al mismo tiempo, una forma completamente distinta de hacer física. Como veremos, este será uno de los principales problemas de la propuesta de Kuhn. Además, en La estructura la noción de paradigma añadía al sentido comentado, que podría denominarse matriz disciplinaria, el de conjunto de investigaciones destacadas que se utilizan como ejemplos en una disciplina científica.1056 Este es el motivo por el que Kuhn denominó paradigmas a sus paradigmas: un paradigma es un ejemplo relevante de algo. La idea era poner el énfasis en que la ciencia se aprende de los maestros, pero que esta formación no es explícita en todos sus detalles, hay habilidades, formas de trabajar, que se transmiten implícitamente mediante ejemplos.1057 Sobre todo, el modo de hacer ciencia, el oficio, no se aprende explícitamente, sino siguiendo el ejemplo de otros colegas. Esta, hoy en día, no es una idea controvertida y, además, es aplicable a casi cualquier otra profesión, los artesanos y los técnicos también suelen aprender practicando en el taller. Es así cómo se adquiere la maestría. Es una pena que, fuera de las discusiones filosóficas técnicas, esta noción suela olvidarse, puesto que esta sí es una idea interesante. Aunque, también es cierto, que para las conclusiones a las que llegaron Kuhn y sus seguidores más entusiastas, ésta no es una tesis demasiado relevante. Por otro lado, también creo que las cosas nos irían mejor si nos esforzásemos en transmitir más ideas explícitamente. Esto permitiría que los científicos en formación tuviesen la oportunidad de reflexionar sobre lo que están haciendo. Creo que en la actualidad la formación metodológica y filosófica es más implícita de lo recomendable. La idea de las destrezas transmitidas implícitamente no es nueva. En capítulos anteriores ya mencionamos que Polanyi había discutido sobre la importancia de estos conocimientos tácitos, sin embargo, fue Kuhn quien popularizó esta tesis. A pesar de la existencia de estas aportaciones previas, en la primera edición de La estructura no se reconoció el trabajo de Polanyi.1058 Esto molestó a Polanyi, que hizo públicas sus quejas. Tal vez fuese este el motivo por el que Kuhn añadió, en la segunda edición, una nota referenciando su trabajo. La ciencia normal es otro concepto fundamental en la propuesta de Kuhn. Ciencia normal es aquella que se desarrolla en el marco de un paradigma. Si cuando voy al laboratorio lo hago con el ánimo de averiguar cómo han evolucionado los tomates, pero no tengo intención de cuestionar ni los principios de la genética ni de la teoría evolutiva ni las metodologías que estoy utilizando, lo que estoy haciendo es ciencia normal. Según Kuhn esto es lo que hacemos los científicos cuando no estamos inmersos en una revolución, algo que, por otro lado, también según Kuhn, sucede en muy pocas ocasiones. Lo que es indiscutible es que hay conclusiones teóricas y metodológicas que gozan de un soporte previo tan amplio que, a no ser que tuviésemos muy buenas razones, sería irracional cuestionarlas. Por ejemplo, si hago un experimento para amplificar el ADN de un tomate y el experimento falla, no concluyo que el tomate no tiene ADN, sino que algo en el experimento ha fallado. Sería irracional proponer que existen los tomates sin genes partiendo de la única evidencia de que en el experimento no he amplificado ADN. Esta idea está muy relacionada con el holismo confirmacional. Recordemos que cuando falla una predicción tenemos un problema serio puesto que el error puede ser atribuido tanto a la teoría que estamos testando, como a las hipótesis auxiliares que hemos necesitado para generar la predicción. La solución de Kuhn al problema es el paradigma. Mientras el científico esté haciendo ciencia normal nunca achacará los problemas que surjan a las teorías, metodologías y compromisos metafísicos que conforman el paradigma. Además, según Kuhn, los investigadores, en una fase de ciencia normal, se decantan por problemas que creen que podrán ser resueltos dentro del paradigma que han asumido. Por ejemplo, pueden enviar astronautas para estudiar la composición del regolito lunar o pueden intentar curar el cáncer. Estas actividades, a priori, no implican el cuestionamiento de las bases de la geología, la física o la biología. Más tarde comentaremos el tono en el que está escrita La estructura, pero podemos hacernos una idea leyendo lo que escribió sobre este asunto: “Las áreas investigadas por la ciencia normal son, por supuesto, minúsculas; el cometido tendría una visión drásticamente reducida”. Es decir, según Kuhn llegar a la Luna o curar un cáncer serían logros minúsculos. La ciencia normal de Kuhn escondía una crítica muy razonable a la pretendida crítica continua preconizada por el falsacionismo de Popper. En realidad no es habitual que los investigadores dediquen un gran esfuerzo a tratar de falsar los principios fundamentales de su disciplina.1059 Lo normal, y racional, es que el biólogo haga su trabajo asumiendo que la evolución biológica, la teoría celular o los principios fundamentales de la genética son correctos. Cabe la posibilidad de que, en algún momento, nos encontremos con algún organismo que no utilice ácidos nucleicos como material genético, pero esa no debe de ser la primera idea que ha de acudir a la cabeza de un biólogo cuando falla una extracción de ADN. Cuando los físicos obtuvieron en el experimento OPERA, en 2011, resultados compatibles con la existencia de partículas superlumínicas no concluyeron que habían falsado la relatividad especial. Los propios investigadores al publicar los resultados propusieron que lo más probable es que se debiesen a un error experimental. De hecho, meses después se comprobó que, efectivamente, ese había sido el motivo. Podría ser que, en algún momento, nos encontremos con una gran sorpresa que socave algunas de nuestras ideas fundamentales, pero no es fácil que esto suceda continuamente. Kuhn diría que Adams y Le Verrier propusieron la existencia de un nuevo planeta para explicar las anomalías orbitales de Urano porque se encontraban trabajando dentro del paradigma newtoniano. Además, Kuhn insistió en que el hecho de que los científicos de la comunidad compartan esta confianza en los principios más elementales facilita su entendimiento y colaboración y mejora su productividad puesto que no se pierde un tiempo precioso en tratar de falsar continuamente los principios fundamentales del área.1060 17.3 Anomalías y revoluciones De modo que los físicos de principios del siglo XX no estaban tratando de destruir la física clásica, pero, aun así, la física cayó. ¿Qué pasó? Pues, según Kuhn, lo que sucedió es que comenzaron a acumularse anomalías: observaciones y problemas teóricos que no podían ser explicados dentro del marco de física clásica.1061 Asimov dijo que en ciencia el momento más importante no es el pretendido Eureka, sino el más modesto: vaya, esto es curioso. Los físicos habrían ido haciendo acopio de observaciones anómalas que no cuadraban con las predicciones teóricas. Una anomalía importante fue, por ejemplo, el espectro de emisión del cuerpo negro. Así es como denominan los físicos a la radiación electromagnética emitida por un cuerpo por encontrarse a una temperatura determinada. Las teorías clásicas hacían predicciones claramente erróneas y Max Planck, que no pretendía iniciar revolución alguna, se enfrentó al problema de plantear una explicación del espectro observado. El resultado, obtenido en 1900, fueron la ley de Planck sobre la emisión del cuerpo negro y la constante de Planck, el número más importante de la física cuántica. Con esto no quiero decir que Planck elaborase por sí sólo la teoría cuántica, ni mucho menos. Planck era muy conservador y decimonónico. Kuhn diría que Planck estaba haciendo ciencia normal. Lo último que pretendía Planck con su descripción del espectro de emisión del cuerpo negro era destruir el edificio clásico. El proceso de desarrollo de la teoría cuántica se demoró décadas y fue muy complejo. Durante este tiempo los físicos fueron encontrando fenómenos que no podían explicarse clásicamente, como el efecto fotoeléctrico, por el que Einstein recibió el premio Nobel, o los espectros atómicos. En todos estos casos, la única forma de explicar los fenómenos fue adoptar reglas que, en principio, parecían un tanto arbitrarias y que contradecían principios clásicos. Finalmente, en 1925, Werner Heisenberg planteó la mecánica matricial y Erwin Schrödinger la ecuación que lleva su nombre. Estas fueron las dos primeras formulaciones de la mecánica cuántica. Leyendo el párrafo anterior podría pensarse que los físicos eran dogmáticos y no querían encontrar nueva física. Esta sería una conclusión errónea. Lo que los físicos pretendían era disponer de unas teorías que describiesen el mundo adecuadamente y ya disponían de ellas. Por lo tanto, Planck no veía la necesidad, como no la veían Adams y Le Verrier, de plantear nuevas teorías simplemente porque hubiese un nuevo fenómeno que todavía no hubiese sido explicado en el marco de las teorías existentes. Si cada anomalía que nos encontramos se tratase como una refutación potencial nos pasaríamos el día pensando que hemos encontrado organismos sin ADN. Esto, que es lo que plantearía un falsacionista radical, sería irracional y dificultaría el avance científico.1062 Hay que tener en cuenta que nuestra creencia en que todos los seres vivos del planeta Tierra utilizan ácidos nucleicos como material genético es una creencia justificada por una cantidad inmensa de observaciones. Un investigador podría invertir su tiempo en buscar evidencias de que efectivamente la persona que ha dado negativo en un test de amplificación de ADN realmente no tiene ADN, pero, muy probablemente, estaría perdiendo el tiempo. En el caso de la mecánica cuántica los investigadores no estaban tratando de destruir la física clásica, simplemente se encontraron con algunos fenómenos imposibles de explicar dentro del marco clásico. Fue el mundo externo el que se empeñó en despertar a los físicos lanzándoles desafíos empíricos. Sin embargo, no siempre se encuentran estas anomalías. Los físicos actuales, por ejemplo, llevan décadas buscando en el LHC fenómenos inesperados sin que, hasta el momento, los hayan encontrado. Están convencidos de que tiene que haber algo más allá de las teorías cuánticas de campos actuales, pero no están disfrutando de la suerte de disponer de una serie de anomalías empíricas que les indiquen el camino a seguir. Por desgracia, las teorías actuales son capaces de explicar con una precisión exquisita todos los fenómenos experimentales conocidos. En la actualidad, la anomalía es teórica, se da entre nuestras propias teorías: sabemos que nuestras teorías físicas más precisas, la de lo muy masivo, la teoría general de la gravedad, y la de lo muy pequeño, el modelo estándar, funcionan muy bien en sus respectivos ámbitos, pero son incompatibles, por lo que no pueden integrarse en una teoría unificada que sirva para entender fenómenos que sean a la vez muy masivos y que ocurran en escalas subatómicas (como, por ejemplo, el núcleo de los agujeros negros). Esta anomalía se traduce en que las teorías que componen el modelo estándar no pueden modificarse para dar cuenta satisfactoriamente de la gravedad, el fenómeno descrito por la relatividad general. Existe una incompatibilidad profunda en la estructura de ambas teorías y nadie ha conseguido planear una nueva teoría integrada capaz de hacer las predicciones correctas. Este es el motivo por el que los físicos actuales están desesperados por buscar nuevas anomalías empíricas; tienen la esperanza de que estas anomalías puedan iluminar el camino hacia una teoría que, por el momento, nadie ha sido capaz de formular. El problema es que la forma más directa de encontrar esas anomalías sería explorar objetos muy pequeños y muy masivos, pero carecemos de la tecnología capaz de crear y manipular pequeñas estrellas de neutrones en el laboratorio. Según Kuhn, en algún momento alguien llega a proponer una nueva hipótesis capaz de dar cuenta, tanto de las nuevas anomalías, como de la mayoría de los fenómenos explicados por la teoría anterior. Llegado este punto, la comunidad la discutirá y el resultado puede ser una revolución, un cambio de paradigma. Será la comunidad en su conjunto la que decidirá hacer suya, o no, la nueva propuesta. Este cambio de foco, del científico individual a la comunidad, fue una de las aportaciones más relevantes de La estructura. Por lo tanto, para que se dé una revolución se necesitan, tanto unas anomalías no explicadas por la teoría antigua, como una nueva hipótesis capaz de explicarlas. La órbita anómala de Mercurio no indujo, por sí misma, una revolución hasta que Einstein propuso una teoría capaz de explicarla. Esto es algo que Kuhn defendió1063 y que parece poco criticable. Mientras no tengamos una teoría mejor no tiene sentido abandonar la antigua, que puede que no lo explique todo, pero que, al menos, explica muchos fenómenos. Ahora mismo los físicos asumen que debe de existir una teoría capaz de unificar los fenómenos cuánticos y gravitatorios, pero mientras no dispongan de la nueva teoría continuarán utilizando las antiguas. De hecho, incluso cuando tengan la nueva puede que continúen utilizando las viejas. El rotundo éxito de la relatividad general no implicó un abandono de la mecánica newtoniana. Los ingenieros que enviaron los cohetes a la Luna prefirieron utilizar las matemáticas newtonianas que las relativistas porque eran más sencillas y porque, para ese problema, tenían una precisión más que suficiente. 17.4 Problemas paradigmáticos Kuhn habló de revoluciones y no simplemente de cambios porque lo que tenía en la cabeza eran grandes cambios, como la revolución copernicana o la relativista, cambios que afectaban a los modelos teóricos más fundamentales de la astronomía o la física de la época. Ésta, sin embargo, no fue una de las mejores ideas kuhnianas. Es indudable que ha habido grandes cambios, aunque después discutiremos si han sido simples cambios teóricos o si han sido cambios paradigmáticos en el sentido kuhniano, pero esos cambios no siempre han sido revolucionarios. Uno de los problemas de las tesis de Kuhn es que no todos los grandes cambios en ciencia implican un momento de crisis en el que la comunidad discute sobre el mérito de las distintas hipótesis. Por ejemplo, en genética hubo una transición gradual desde las ideas mendelianas, que a día de hoy continúan siendo válidas, y la genética molecular.1064 Este fue un gran cambio, pero podría describirse mejor como una acumulación gradual de pequeños cambios que como una gran revolución puntual. Esta es una tesis más cercana a las ideas positivistas del cambio científico gradual.1065 En el caso concreto de la transición de la genética mendeliana a la molecular, creo que el cambio fue tan gradual que ni siquiera los genetistas se dieron cuenta de la magnitud de lo que estaba sucediendo y terminaron utilizando un término, “gen”, para nombrar dos entidades completamente distintas: el gen mendeliano, que se refiere al control genético de variaciones entre individuos, y el molecular, que tiene que ver con los elementos funcionales en un genoma individual. A día de hoy en mi trabajo continúo utilizando diariamente lo que aprendimos sobre los guisantes de Mendel y las moscas de Morgan y en mis clases insisto en que debemos integrar esas aproximaciones con las nuevas herramientas moleculares. De Mendel a CRISPR pasando por la PCR sin que haya habido ninguna revolución kuhniana. Otra limitación del modelo de Kuhn radica en que, aunque es cierto que hay cambios que afectan a las grandes ideas teóricas, no es menos cierto que el trabajo cotidiano del científico, en muchas ocasiones, implica proponer pequeños cambios tanto teóricos como metodológicos. Por ejemplo, ahora mismo estoy escribiendo un artículo en el que cuestiono las herramientas estadísticas utilizadas para reconstruir la historia de las poblaciones porque he comprobado que no funcionan de un modo robusto cuando las migraciones son comunes, y propongo una nueva metodología. Esto, claramente, no es una revolución, pero sí es un pequeño cambio que espero que sea aceptado por la comunidad y que puede que contribuya a una mejora gradual de la genética de poblaciones. De modo que la distinción entre revolución y ciencia normal es una falsa dicotomía; hay cambios grandes, medianos y pequeños.1066 Es cierto que Kuhn admitió que en ciencia también existían pequeños cambios, pero, sin embargo, no dejó muy claro en qué modo afectaba esto a su propuesta de cambio científico. Una vez se admiten los cambios graduales, la distinción entre ciencia normal y revolucionaria deja de tener mucho sentido. Además, la noción de paradigmas claramente diferenciados, algo central en la propuesta de Kuhn, también es difícil de compatibilizar con el cambio gradual.1067 Kuhn habría tenido que dejar de hablar de cambios paradigmáticos para discutir la evolución de los paradigmas y esto no habría encajado bien con el resto de sus ideas ya que, como comentaremos en breve, para Kuhn los paradigmas son tan radicalmente diferentes que son incomparables, están tan alejados como conceptos pertenecientes a universos intelectuales distintos. Además, Kuhn insistió, por motivos filosóficos y no sólo históricos, en que el paradigma debía incluir el paquete intelectual completo: teorías, metodologías y compromisos metafísicos. Recordemos que Quine utilizando su tesis del holismo confirmacional había atacado las ideas de Popper y de los positivistas lógicos. Para poder hacer una predicción, por ejemplo, la posición de un planeta, necesitamos disponer de una red conceptual completa. Por lo tanto, cuando la predicción falla debemos considerar cómo modificar la red en su conjunto, no solamente una teoría concreta. Kuhn convirtió esta red en sus paradigmas y el estudio de los cambios en las grandes teorías físicas le llevó a proponer que la red, el paradigma, cambiaba por completo durante las revoluciones. Este es el motivo por el que el cambio gradual encaja tan mal en la propuesta kuhniana. Kuhn pensaba en redes conceptuales, completamente independientes, que no podían transformarse gradualmente desde una a la otra. Los paradigmas de Kuhn son la antítesis del barco de Neurath, que se iba modificando pieza a pieza hasta convertirse en una nave completamente distinta. Los paradigmas no sólo hacen suyo el holismo confirmacional, sino que lo llevan al extremo. Esto, como veremos en breve, ocasionó todo tipo de problemas para Kuhn y para la filosofía de la ciencia desde los años 70 hasta mediados de los 90. Kuhn, además, defendió que una comunidad científica sólo puede trabajar con un paradigma a la vez y que tan sólo en periodos de crisis habrá varios paradigmas en juego.1068 Para Kuhn la comunidad se define por el paradigma: forman una comunidad aquellos científicos que comparten una formación similar y unas ideas comunes sobre el funcionamiento del mundo.1069 La justificación de este criterio de delimitación comunitaria se debía a que sin un paradigma común sería muy difícil que los científicos pudiesen comunicarse efectivamente. Esta propuesta fue criticada inmediatamente.1070 Lakatos, un discípulo de Popper que se decantó por la aproximación histórica, propuso que una comunidad científica puede manejar varios programas de investigación, el equivalente a los paradigmas kuhnianos en la filosofía de Lakatos.1071 En realidad, las comunidades son mucho más heterogéneas e interdisciplinares de lo que la definición de Kuhn sugiere y pueden definirse por distintos factores como: la comunicación y colaboración entre sus miembros, los problemas abordados y las metodologías utilizadas. Además, hay individuos que están a caballo entre distintas comunidades. Yo trabajo en tomate, pero también, a veces en genética humana y, metodológicamente, estoy integrado en la comunidad bioinformática y genómica, no en la botánica o agronómica, como sí lo están la mayoría de mis compañeros. Publico artículos sobre tomate, pero no sé ni cómo se cultiva la planta ni cómo distinguir morfológicamente las especies silvestres de las que hablo en mis artículos. Todo esto hace que nos encontremos con comunidades bastante difusas y parcialmente solapadas. Estas redes difusas, solapadas y multidisciplinares favorecen la crítica, ya que aportan puntos de vista complementarios sobre el fenómeno estudiado.1072 Los programas de investigación de Lakatos serían grupos de teorías que son evaluados en conjunto,1073 una propuesta que, como la de los paradigmas, incorpora las redes de Quine, pero que no requiere que se añadan a ella todas las metodologías y las ontologías. La propuesta de Lakatos trató de incorporar las enseñanzas de Quine evitando los excesos de Kuhn. Según Lakatos algunos de estos programas estarían progresando, los que hacen predicciones exitosas, y otros degenerando, los que van acumulando anomalías, y, gradualmente, la comunidad iría variando su predilección por unos o por otros.1074 Lakatos pretendía, además, introducir un falsacionismo moderado; las anomalías, en algunos casos, podrían ser resueltas dentro del mismo programa, no implicarían la falsación inmediata del mismo. Esto es, por ejemplo, lo que sucedió en el caso de Neptuno. Sin embargo, un programa que se viese obligado a recurrir a una hipótesis ad hoc tras otra entraría en una fase de degeneración y, con el tiempo, iría perdiendo partidarios en favor de programas más exitosos.1075 17.5 Contribuir sin aceptar Larry Laudan (1941-), que utilizaba el término tradiciones de investigación, añadió una matización interesante: un científico podía participar en un programa de investigación aunque no lo aceptase.1076 Por ejemplo, Einstein no creía que la mecánica cuántica fuese una teoría realmente fundamental de la naturaleza; pensaba que tenía que ser posible proponer una nueva teoría más fundamental que evitase algunos de los problemas asociados a la cuántica. El asunto es un tanto técnico, pero se puede resumir diciendo que la mecánica cuántica propone descripciones para los sistemas físicos que no tienen por qué ser observables. Esta afirmación es muy abstracta y puede que al lector le cueste entender el problema, pero, tal vez, con un ejemplo se entienda mejor. Imaginemos un gato. Yo podría hacer la siguiente descripción del estado del gato: duerme en su caja. Es decir, el gato está en su caja, un lugar determinado, tiene una velocidad concreta, no se mueve, y está vivo. La descripción del sistema físico, del gato, incluye tres propiedades que pueden ser observadas, es decir, son observables: posición, velocidad y vitalidad (o está vivo o está muerto). Por lo tanto, la descripción clásica está compuesta por propiedades observables. Esto no ocurre en la mecánica cuántica. En la cuántica, en muchos casos, el estado del sistema no es observable. Schrödinger propuso el ejemplo del gato, precisamente, para ilustrar lo extraño del asunto. Según la mecánica cuántica la descripción del estado del gato puede no ser observable. ¿Está el gato de Schrödinger vivo o muerto hasta que abrimos la caja? Lo único que dicen las matemáticas es que el estado, mientras la caja esté cerrada, es decir, mientras esté aislada del resto del universo, no es ni de vida ni de muerte, sino de una superposición de ambas posibilidades, y, a la vez, prohíbe que este estado pueda ser observado. Podemos observar un gato vivo o muerto, pero no un estado compuesto por ambas posibilidades a la vez. Esta es una de las raíces profundas de la extrañeza cuántica y este es uno de los aspectos que molestaban a Schrödinger y Einstein. Según estos investigadores la descripción de los estados físicos tenía que referirse a algo observable, no aceptaban que la realidad profunda pudiese no ser observable. Pero volvamos al asunto que nos ocupaba: a Einstein nunca le gustó la teoría cuántica y, sin embargo, esto no le impidió participar en su desarrollo. Einstein se enfrascó en una larga discusión racional con sus defensores. Son famosas, por ejemplo, sus continuas discusiones con Bohr. Fruto de este proceso colaboró, junto a otros dos investigadores, en escribir un artículo en el que se proponía un experimento mental, llamado EPR, que parecía indicar que si se aceptaban los postulados de la mecánica cuántica debía violarse el principio de localidad, que establece que dos objetos separados por una distancia no pueden influirse instantáneamente. Posteriormente, el físico John S. Bell transformó esta crítica en un diseño experimental factible y este experimento fue llevado a cabo por Alain Aspect en 1981. El resultado fue que el mundo es más extraño de lo que Einstein se atrevió a pensar. En cualquier caso, Einstein contribuyó a avanzar nuestro conocimiento sobre la mecánica cuántica a pesar de que no creía que fuese correcta en un nivel fundamental. Esto es algo que, como veremos, deberían explicar los constructivistas más radicales, que sostienen que son nuestras preferencias personales y sociales las que dictan lo que las comunidades científicas acaban aceptando y no la lógica o las evidencias empíricas. Es decir, que rechazan que los motivos epistémicos sean relevantes a la hora de modificar nuestra visión sobre el mundo. Einstein murió demasiado pronto y no sabemos qué habría pensado de los avances de Bell y Aspect, pero me gustaría comentar otro ejemplo de un investigador que contribuyó a desarrollar una teoría en la que no creía y que sí llegó a ver el resultado. Thomas Hunt Morgan (1866 - 1945) fue uno de los padres indiscutibles de la genética moderna, pero en 1909 no creía ni en la teoría cromosómica de la herencia ni el mendelismo.1077 Morgan no pensaba que los cromosomas tuviesen nada que ver con la herencia ni que los factores mendelianos, que ahora llamamos genes, fuesen estables.1078 A pesar de ello, fue el laboratorio de Morgan quien hizo la observación clave que asoció, por primera vez, un gen a un cromosoma concreto. Además, también se descubrió en su laboratorio el entrecruzamiento cromosómico, lo cual le llevó a pensar que debería ser posible hacer mapas genéticos en los que se ordenasen distintos genes.1079 El primer mapa genético de la historia lo hizo Sturtevant, uno de sus estudiantes de doctorado. De modo que Morgan no sólo fue capaz de contribuir a una teoría en la que no creía inicialmente, la herencia cromosómica, sino que años después modificó esa teoría, sin cambiar sustancialmente el paradigma, creando el primer mapa genético. En su honor la unidad de mapa genético se denomina centimorgan. Esta es una herramienta que todavía utilizamos cotidianamente en la genética actual. Por cierto, insisto en que me gustaría escuchar la explicación de los constructivistas a estos episodios. ¿Cómo es posible que investigadores completamente opuestos a una teoría contribuyan a su desarrollo si el mundo externo no tiene nada que ver con las conclusiones científicas? 17.6 Descripción y prescripción En realidad, cuando se analiza la historia de la ciencia no queda más remedio que aceptar que las descripciones de Kuhn, aunque pueden funcionar como un boceto de trazo gordo en algunos episodios históricos concretos, no son correctas en general. El proceder científico es muy complejo y es imposible encerrarlo en un único modelo de desarrollo. A pesar de esto, si hacemos el esfuerzo de ignorar el tono radical de La estructura y descartamos los excesos encerrados en la idea de los paradigmas, el Kuhn moderado podría entenderse como una aportación complementaria al programa positivista.1080 Mientras los positivistas se habían centrado en hacer un análisis lógico, Kuhn dejó patente que del análisis histórico también podían extraerse conclusiones filosóficas. Los positivistas estaban interesados en la lógica de la justificación y en la estructura formal de las teorías, pero habían dejado de lado la descripción de la práctica científica, por lo que habían acabado teniendo una visión muy idealizada. Visto de este modo, la lección que podríamos extraer de La estructura no es que la ciencia es irracional, que es lo que concluyeron los constructivistas radicales, sino que, en la práctica científica, no sólo son relevantes los aspectos epistemológicos.1081 Sin embargo, muchos creyeron que esta relevancia de los aspectos no epistémicos convertía el proyecto científico en irracional.1082 En este punto es interesante recordar que La estructura se publicó como parte de una obra más amplia: La Enciclopedia Internacional de la Ciencia Unificada. Este fue un proyecto positivista en el que también se publicaron ensayos de grandes filósofos positivistas como: Neurath, Carnap o Hempel. Por supuesto, esta es una interpretación caritativa del mensaje de La estructura, pero es algo con lo que el Kuhn más maduro, probablemente, habría estado de acuerdo. Otro problema es que su libro no aclara, en absoluto, cuándo está intentando ser descriptivo y cuándo prescriptivo.1083 El trabajo de Kuhn no es una mera descripción histórica, sino que extrae conclusiones filosóficas y son algunas de estas tesis las que causaron la tormenta que acompañó a La estructura.1084 Esto viola una tesis filosófica fundamental: no se puede deducir un debe a partir de un es. Esta fue una de las numerosas contribuciones del gran Hume. Es imposible hacer una inferencia lógica válida en la que a partir de un conjunto de afirmaciones relativas a cómo son las cosas en la actualidad, o cómo lo han sido en el pasado, se derive cómo tendrían que ser. Yo puedo decir que hay o no hay esclavitud en el mundo, pero de eso nunca podré deducir que tenga que haberla o no. Para llegar al debe uno ha de añadir premisas relativas a sus valores. Por lo tanto, aunque la historia y la sociología de la ciencia nos pueden informar sobre cómo funciona la ciencia en la práctica, no pueden, por sí mismas, ser utilizadas para inferir cómo debería funcionar, esta es una labor reservada a la filosofía. Kuhn, a veces, parecía más interesado en describir cómo funciona la ciencia que en prescribir como debería funcionar.1085 La descripción tiene que ver con la psicología, la sociología y la historia, la prescripción con la lógica y la epistemología. Aristóteles, Popper o Carnap hacían recomendaciones normativas que, según ellos, cualquier investigador racional debería seguir, mientras que los historiadores y los sociólogos de la ciencia, muchas veces, tienen un ánimo meramente descriptivo. Kuhn, en ocasiones, parecía estar más interesado en entender cómo funcionaba la ciencia real que por proponer cómo debería funcionar. El problema es que esta distinción entre descripción y prescripción no es explícita ni clara en La estructura. La cuestión, además, es compleja porque, como hemos visto, no hay demasiadas reglas epistémicas absolutas. La ciencia depende demasiado del oficio y del buen hacer de los científicos como para que los filósofos puedan llegar a dictar normas muy específicas. Pero, por otro lado, ¿es ciencia cualquier cosa que haga un científico? ¿Hemos de considerar ciencia lo que hacen o lo que deberían hacer? Si un investigador manipula los datos para obtener un resultado llamativo, ¿está haciendo ciencia? Es evidente que tiene que haber un aspecto normativo; hay cosas que deben hacerse y cosas que no deben hacerse. El problema es que es difícil establecer normas mucho más concretas que: el investigador debe comportarse con absoluta integridad intelectual. Tal vez una de las aportaciones más relevantes de Kuhn haya sido obligarnos a reconocer que no podemos hacernos una buena idea del funcionamiento de la empresa científica sin la participación de la filosofía, que aporta algunos aspectos normativos, y de la historia y la sociología, que pueden indicarnos cómo ha funcionado en el pasado y cómo está funcionando actualmente el proceso de generación de conocimiento sobre el mundo externo. 17.7 Inconmensurabilidad Si paradigma es el término kuhniano más popular, inconmensurabilidad es, sin duda, el favorito del connaisseur constructivista. Varias veces me ha pasado que algún graduado en filosofía ha pretendido erosionar mi confianza en la ciencia apelando a la inconmensurabilidad. Por fortuna, una de las principales utilidades de leer buenos libros sobre filosofía es que te sirven de escudo ante la mala filosofía. Kuhn que, recordemos, empezó como historiador de la física, un buen día comenzó a reflexionar sobre cómo era posible que Aristóteles, una de las mentes más brillantes de la historia de la humanidad, hubiese propuesto una física tan errónea. La respuesta, como ya hemos comentado, es que, en realidad, cuando tenemos en cuenta el rozamiento, la física aristotélica no es tan errónea. Sin embargo, esto no es lo que pensó Kuhn. El autor de La estructura, como no podía ser de otro modo, llegó a la conclusión de que el problema de Aristóteles es que estaba pensando dentro de su propio paradigma, y que con unas evidencias muy similares Galileo, que trabajaba dentro de otro paradigma, llegó a unas conclusiones muy distintas. Además, según Kuhn dos paradigmas distintos son inconmensurables, no pueden ser comparados.1086 ¿Por qué no se pueden comparar los paradigmas? Recordemos que según la definición de Kuhn un paradigma no sólo incluye las teorías que creen los investigadores, sino también, y esto es fundamental, las metodologías que los científicos utilizan para buscar y justificar el conocimiento, así como las ontologías que asumen. Por lo tanto, si cada paradigma tiene métodos y vocabularios distintos, los investigadores que se adhieran a diferentes paradigmas no pueden ni comparar sus ideas ni entenderse, viven encerrados en mundos intelectuales diferentes y aislados. Kuhn es famoso por haber escrito que después de una revolución, de un cambio de paradigma, los científicos viven en un mundo distinto.1087 Este lenguaje hiperbólico es uno de los principales problemas de La estructura. No es lo mismo tener una perspectiva distinta sobre un asunto, que percibir el mundo de un modo radicalmente diferente. Lo segundo parece implicar que nuestras percepciones e ideas sobre el mundo externo son puras alucinaciones. Supongo que, poco a poco, va quedando clara la relación de Kuhn con los constructivistas. En varios libros he leído que no deben criticarse estas ideas haciendo notar que una piedra lanzada a la cabeza de un constructivista radical tendrá un efecto que no dependerá de lo que el constructivista crea, y seguramente es cierto que las críticas deben ser más sutiles, pero esta es la primera idea que me viene a la cabeza. Además, ¿qué significa realmente esto de que las visiones del mundo de Aristóteles y Galileo fuesen diferentes? En todo caso supongo que serían algo distintas, o bastante distintas, pero dudo que fuesen completamente diferentes. Asumo que ambos creían en la existencia de los gatos y las piedras y que podrían haberse comunicado esas ideas si hubiesen tenido la ocasión de hablarse. Galileo, de hecho, como ya hemos comentado, conocía la obra de Aristóteles y lo consideraba, junto a Arquímedes, uno de sus grades maestros. Por otro lado, igual que la piedra es parte del mundo externo para el investigador, los científicos son parte del mundo externo para Kuhn. Los constructivistas creen que los científicos no tienen una relación estrecha con la realidad externa, pero, al mismo tiempo, confían en que sus tesis reflejan el funcionamiento de la ciencia.1088 Este es un problema de coherencia interna de su filosofía análogo a los discutidos por los escépticos helenísticos hace más de dos mil años. Es decir, pretenden hacernos dudar de la física planetaria, pero asumen que hemos de confiar en sus tesis sociológicas y filosóficas. Que Kuhn pensase algo sobre cómo funcionaba la ciencia no implica que la ciencia funcione realmente así. De hecho, Kuhn no presentó ningún ejemplo claro de inconmensurabilidad.1089 Esto es algo que los constructivistas suelen olvidar. La inconmensurabilidad representa un ataque directo a la racionalidad y a la posibilidad de conocer. Si no existe un modo neutro o racional de comparar las hipótesis, el conocimiento objetivo es imposible. Si no podemos evaluar los méritos de las hipótesis de un modo mínimamente objetivo, lo único que nos queda es una especie de conversión religiosa.1090 Esta fue una de las tesis más controvertidas de Kuhn.1091 Dicho todo esto, creo que sí podemos aprender mucho analizando la inconmensurabilidad kuhniana. Para hacerlo basta con añadir un condicional. Si dos individuos, o dos comunidades, no comparten unas metodologías o un vocabulario común, no podrán participar en un proyecto conjunto de construcción de conocimiento. Esto es algo que sucede, por ejemplo, entre los físicos y los pseudocientíficos. Mientras que unos hablan de velocidades y masas los otros dicen estupideces sobre los chakras. Realmente ambas comunidades dicen habitar mundos intelectuales aislados, utilizar mapas diferentes, pero esto no implica que no habiten el mismo territorio, las piedras lanzadas a una cierta velocidad les afectan a ambos por igual. Este es el motivo por el que, en ningún caso, debemos asumir que ambas visiones del mundo sean equivalentes. Mientras que el mapa de los físicos refleja con detalle la estructura del mundo externo y permite hacer predicciones precisas sobre la trayectoria y velocidad de las piedras, el de los pseudocientíficos es un mapa que no tiene nada que ver con el territorio por lo que las predicciones hechas por sus usuarios no pueden llegar más allá de hacer misteriosos movimientos con las manos mientras te roban la cartera, la salud o ambas cosas. A pesar de estos grandes problemas, merece la pena repetir que sí podemos aprender de la tesis de la inconmensurabilidad, de modo que vamos a explorar los distintos aspectos que abarca. 17.8 Inconmensurabilidad de temas La idea habitual es que las nuevas teorías suelen ser más amplias que las antiguas. De hecho, hemos defendido que este poder explicativo es uno de los criterios que los científicos utilizan para elegir entre distintas hipótesis. Por ejemplo, la relatividad general describe todos los fenómenos previamente descritos por la gravedad newtoniana y algunos más. Kuhn planteó que cuando las teorías tratan de describir aspectos distintos es imposible compararlas.1092 Por ejemplo, la física aristotélica, en realidad, abarca cuestiones muy diferentes a las cubiertas por las mecánicas modernas ya que es una teoría sobre el cambio en general, no sólo sobre el cambio de posición o velocidad. Esta fue una propuesta de Kuhn que fue criticada inmediatamente. En primer lugar, es trivial que si dos hipótesis tratan fenómenos distintos no tiene sentido compararlas. Este es uno de los motivos por los que hay que ser muy cuidadosos cuando se comparan teorías tan distintas como la física aristotélica y las mecánicas modernas, sin embargo, esto no suele ser muy relevante cuando tratamos de comparar hipótesis que distan menos de dos milenios y medio.1093 Incluso la mecánica cuántica y la relativista, que se refieren a aspectos tan distintos como la velocidad de rotación galáctica y el estado energético de los electrones dentro de un transistor, son perfectamente comparables. Y lo cierto es que incluso los aspectos mecánicos de las teorías aristotélicas son comparables con la física newtoniana, de hecho, es algo que tanto Kuhn como nosotros hemos hecho. 17.9 Inconmensurabilidad histórico-semántica Kuhn, además, propuso que incluso aunque los fenómenos estudiados por distintos paradigmas sean comparables, puede que la descripción de los mismos sea tan distinta que sea difícil para un investigador inmerso en un paradigma comprender la otra descripción.1094 Esto es algo que, de nuevo, sucede entre teorías de mundos intelectuales muy distantes. Para poder comprender las tesis aristotélicas hace falta hacer un esfuerzo previo de estudio de su filosofía que nos familiarice con su punto de vista. De modo que sí que es cierto que habría dificultades de comprensión entre paradigmas tan diferentes si antes no hacemos el esfuerzo de adentrarnos en el contexto intelectual adecuado. Para entender las ideas químicas de Paracelso el historiador tiene que familiarizarse antes con el mundo intelectual que habitaba este alquimista medieval1095 y para comprender la mecánica newtoniana el estudiante ha de hacer varios cursos de física. La cuestión no es si tenemos que estudiar para comprender un marco intelectual, sino cómo de relevantes son estas dificultades en la práctica científica. Creo que si pudiésemos disfrutar del privilegio de hablar con Aristóteles podríamos entendernos con él y esto es posible porque hay un marco común basado en conceptos básicos elementales, como gato, piedra y movimiento. De modo que, aunque necesitaríamos algunos días de discusión previa con el maestro, en un tiempo relativamente corto podríamos explicarle cómo funciona la mecánica newtoniana y qué predicciones es capaz de hacer. Este proceso es, de hecho, equivalente al que sigue cualquier estudiante. Se comienza por conceptos familiares y, poco a poco, se va siguiendo el camino que nos adentra en regiones cada vez más alejadas que, al principio resultan extrañas, pero que, con tiempo, esfuerzo y práctica terminan siéndonos tan familiares como las piedras y los gatos. Esto es algo que incluso Kuhn reconoció, cuando hay voluntad se pueden establecer traducciones. Por lo tanto, ni siquiera Kuhn creía que la dificultad de entender puntos de vista tan distintos implicase una imposibilidad completa. En general, la conclusión de los historiadores de la ciencia es que los investigadores suelen ser capaces, después de un tiempo de estudio, de comprender distintos marcos teóricos.1096 17.10 Inconmensurabilidad lógico-semántica El sentido de un concepto teórico, estrictamente hablando, depende de su posición en la red conceptual, es decir, depende de la teoría completa. Por ejemplo, la masa en mecánica newtoniana se define en función de la fuerza y la aceleración, por lo que no es posible, en general, definirla en función de términos puramente empíricos. Esta es una tesis denominada holismo semántico y ha sido defendida por múltiples autores, entre ellos Quine, Kuhn, e incluso Carnap, el positivista lógico por excelencia.1097 Por lo tanto, desde un punto de vista lógico, las teorías sí son inconmensurables, ya que las afirmaciones en una teoría no son lógicamente traducibles a afirmaciones compuestas por los términos de otra teoría. No es posible expresar una teoría en el vocabulario de la otra; de lo que se sigue que ambas teorías no son lógicamente comparables.1098 Esto está relacionado con las dificultades que hemos mencionado en la sección anterior, pero en este caso la crítica es solamente lógica, no histórica. Incluso aunque Aristóteles llegase a entender las teorías newtonianas, no podría expresarlas utilizando su anterior marco conceptual. La inconmensurabilidad lógico-semántica es debida a la imposibilidad de separar, de un modo estricto, los términos teóricos del vocabulario de los relacionados con la observación.1099 Pero, aunque es cierto que la separación entre observación y teoría no es absolutamente nítida, no lo es menos que hay una diferencia entre aceptar que la observación está teñida de teoría y asumir que es imposible establecer que hay un gato sobre la mesa de un modo intersubjetivo si no formamos parte del mismo mundo intelectual. Esto último no sólo acabaría con la racionalidad en ciencia, sino que nos condenaría a una incomunicación radical en nuestra vida diaria. Son precisamente los términos relacionados con las observaciones más elementales los que permiten crear un área de intersección entre teorías, suficientemente amplia, como para poder compararlas. Otra cuestión es qué problemas podemos tener si tratamos de explicar desde un punto de vista lógico cómo hemos llevado a cabo la comparación. Estos problemas son especialmente serios para los términos teóricos, sin embargo, los términos más cercanos a las percepciones básicas suelen poder traducirse sin tantas dificultades. Aunque es imposible expresar la física relativista utilizando el marco conceptual de la mecánica newtoniana, lo que sí podemos hacer es comparar sus predicciones y esto es posible porque para llevar a cabo esta contrastación, sólo necesitamos que sean traducibles los términos más cercanos a la percepción como: regla y reloj. Es decir, aunque lógicamente no podemos convertir la estructura teórica de una teoría en otra, lo que sí podemos hacer es comparar sus predicciones, por lo que podemos comprobar qué teoría describe más adecuadamente los fenómenos que estamos estudiando. De modo que para poder comparar dos hipótesis no es necesario ser capaces de traducir lógicamente los términos teóricos de una en la otra, sino, tan sólo hemos de exigir que sean capaces de hacer predicciones empíricas. Incluso en el caso en el que desconozcamos por completo la teoría, podríamos hacer una comparación. Supongamos que una bruja dice poseer un conocimiento arcano sobre el movimiento planetario que no quiere o no puede transmitirnos. En este caso, podríamos pedirle que predijese la posición de Mercurio y si la predicción es adecuada, aunque no entendamos cómo lo ha hecho, lo que sí podremos afirmar es que la bruja es capaz de comprender el problema lo suficientemente bien como para hacer predicciones precisas. En cualquier caso, el problema lógico subyacente es real. Es fácil decir que se pueden hacer predicciones y experimentos para comparar teorías, pero, en términos lógicos el asunto es más peliagudo de lo que parece. Por ejemplo, imaginemos que hacemos los cálculos relativos a la caída de una bolita y establecemos que según Newton debería caer en 1 segundo y según Einstein en 1,0001 segundos. En principio parece que ambas predicciones son comparables, pero, desde un punto de vista lógico las cosas no son tan sencillas. ¿Qué es un segundo? La definición no es la misma en el paradigma newtoniano que en el relativista. De hecho, esta fue una cuestión clave en el descubrimiento de la relatividad especial. El tiempo para Newton era absoluto e independiente del observador, mientras que para Einstein no tiene sentido hablar de tiempo si no se propone una definición operacional que permita medirlo. Esto acaba haciendo que el tiempo, en la relatividad, dependa de la velocidad relativa de los observadores e, incluso, del campo gravitatorio en el que se encuentran. La definición del tiempo en Newton y en Einstein es muy diferente y, por lo tanto, desde punto de vista lógico no son fácilmente comparables. Fue el gran lógico Gottlob Frege (1848 - 1925) quien propuso que los términos adquieren su sentido por su posición en la red conceptual global1100 y este fue el punto de partida de Kuhn. En cualquier caso, llegar a la conclusión de que no podemos hacer un experimento con el que medir el tiempo que le cuesta a la bolita caer porque lógicamente no es fácil establecer cómo traducir unos términos teóricos en otros, es llevar nuestra confianza en Frege muy lejos. El problema es que no es nada fácil establecer una teoría satisfactoria general del significado y sin ella resulta fútil llegar a conclusiones demasiado generales sobre estos asuntos lógicos. Además, esta teoría debería incluir aspectos relativos a la vaguedad de nuestras intuiciones. El tiempo de Newton y de Einstein es diferente, pero también lo son nuestras intuiciones sobre el mismo. En cualquier caso, debemos recordar que, al fin y al cabo, como le dijo el maestro Fernando Senent a mi amigo Miguel Ángel: el tiempo es lo que miden los relojes. Es decir, que, independientemente de las cuestiones lógicas relativas a su definición, siempre podemos coger un reloj y comprobar si las manecillas acaban en el lugar en el que predice la relatividad o la mecánica newtoniana. 17.11 Inconmensurabilidad metodológica Como ya hemos comentado, los paradigmas incluyen también las metodologías y los estándares utilizados en un área de investigación.1101 Si aceptamos esta tesis estamos abocados necesariamente a una inconmensurabilidad metodológica. Si cada paradigma incluye las reglas mediante las que ha de ser juzgado y éstas son diferentes entre distintos paradigmas, no hay forma de hacer comparaciones racionales entre paradigmas. Esto implica, además, que las decisiones tomadas durante una revolución no pueden ser racionales. Sin un modo externo de comparar los distintos paradigmas, no hay forma de justificar por qué se elige uno frente a otro y, una vez desechadas la lógica y las evidencias, todo lo que queda es la psicología y la sociología.1102 La comunidad, según Kuhn, durante una revolución elige adoptar un nuevo paradigma por presión social, por moda o por algún otro motivo no epistémico. No hay estándares supraparadigmáticos que sirvan de guía durante las revoluciones por lo que estamos condenados a conformarnos con la preferencia personal y social.1103 Es decir, si no hay modo de comparar racionalmente dos paradigmas, uno no puede ser más correcto que el otro y el relativismo o el escepticismo radical son inevitables. Según Kuhn, los paradigmas condicionan nuestra percepción del mundo hasta tal punto, que fuera de ellos el juicio objetivo es imposible. Una hipótesis científica sólo podría ser aceptada o rechazada racionalmente durante un periodo de ciencia normal, es decir, dentro de un paradigma, pero un científico que profesase otro paradigma no tendría motivos racionales para llegar a la misma conclusión. Por ejemplo, según esta tesis la elección entre la mecánica newtoniana y la relativista no pudo ser racional puesto que era imposible para los físicos comparar ambas teorías dentro de un marco común. La tesis de la inconmensurabilidad implica, además, que la ciencia no progresa, simplemente cambia.1104 Por otro lado, como no hay una forma de decidir qué metodologías son mejores y cuáles peores, cualquier forma de reflexión sobre el mundo externo es equivalente, la ciencia no es más racional que el vudú o, al menos, esto es lo que escribió Feyerabend en su Contra el método.1105 Hemos de reconocer que Kuhn hizo algunas contribuciones meritorias a la filosofía de la ciencia; popularizó, por ejemplo, el problema de la dependencia parcial de la observación por parte de la teoría y contribuyó a que se reconociese el papel de las comunidades en el desarrollo de las ideas científicas. Sin embargo, la tesis de la inconmensurabilidad es completamente indefendible y no sirvió más que para fomentar el constructivismo radical. Podría haber dicho que, en algunas áreas de algunas ciencias, por ejemplo, en la macroeconomía o en la pedagogía, algunos de los problemas tratados son tan complejos y los supuestos datos tan dependientes de cada uno de los puntos de vista, que los cambios teóricos no tienen por qué ser siempre racionales y que pueden obedecer más a dinámicas sociales intracomunitarias que a la realidad externa. Yo habría estado completamente de acuerdo con esto, pero no es eso lo que se escribió en La estructura. Según Kuhn los cambios de paradigma no pueden deberse a motivos puramente epistémicos en ningún caso. La tesis de la inconmensurabilidad aplicada, por ejemplo, a muchos fenómenos físicos resulta completamente absurda. Los físicos no aceptaron la teoría de la relatividad como quien sufre una conversión religiosa, algo que Kuhn llegó a escribir, sino porque las medidas apoyaban las predicciones relativistas más que las newtonianas. Cuando los astrónomos eligieron abandonar el modelo ptolemaico, lo hicieron porque las fases de Venus se comportaban siguiendo las predicciones de un modelo heliocéntrico, no de uno geocéntrico. Cualquiera que se moleste en reflexionar, un poco, sobre lo que sucede fuera de su propia cabeza, se dará cuenta, inmediatamente, de que el constructivismo radical tiene serios problemas. Si lo que hacen los físicos no tiene nada que ver con el mundo externo, ¿cómo es posible que sus teorías se utilicen para crear tecnologías que funcionan realmente? Si la mecánica relativista es una simple elucubración surgida de un congreso de físicos, ¿cómo es que sus predicciones permiten ajustar las señales de los satélites de geoposicionamiento? ¿A qué se debe este enorme éxito operacional?1106 Si aceptásemos la tesis de la inconmensurabilidad no tendríamos forma alguna de comprender el éxito operacional de la ciencia. Sin embargo, si, por el contrario, asumimos que realmente el mundo externo tiene un papel decisivo en la elección entre hipótesis, este éxito, aunque seguiría siendo fascinante y meritorio, no sería extraño. Lo que para los constructivistas radicales es una sorpresa tremenda, para cualquiera que haya reflexionado de un modo mínimamente serio sobre el funcionamiento de la física o la medicina resulta, simplemente, esperable ¿Qué pensarán los constructivistas sobre el vuelo de los aviones? ¿Creerán que depende de la confianza del piloto en la religión de la aerodinámica? El fallo de la tesis constructivista es evidente: en muchas áreas de la ciencia los datos observados dependen, fundamentalmente, del mundo externo y disponemos de razones empíricas para elegir racionalmente entre hipótesis. Además, los cambios teóricos no implican, habitualmente, un cambio metodológico. Por ejemplo, no hubo ningún cambio metodológico cuando se abandonó el modelo ptolemaico; los astrónomos continuaron evaluando sus hipótesis basándose en las observaciones astronómicas. Por otro lado, aunque es cierto que, en un momento dado, Galileo introdujo el telescopio, un instrumento, una metodología, que antes no existía, esto no alteró la forma de hacer astronomía radicalmente, al fin y al cabo, los astrónomos continuaban observando los astros. Tampoco hubo ningún cambio metodológico cuando se aceptó la mecánica relativista. Se hicieron predicciones basándose en ambas teorías, se realizaron las observaciones y las medidas correspondientes y se eligió la teoría que mejor cuadraba con las predicciones. Aunque en capítulos anteriores he criticado la idea de que exista un método científico preciso, lo que sí podemos admitir es que este cambio teórico se encuentra mucho más cerca del ideal hipotético-deductivo que de una conversión religiosa irracional por parte de la comunidad física. En general, lo habitual es que las metodologías cambien independientemente de las teorías.1107 Por ejemplo, las metodologías estadísticas se han ido modificando con el tiempo, y esto es algo que ha afectado a muchas áreas de la ciencia independientemente de las hipótesis que se estuviesen evaluando en cada una de ellas.1108 Además, ni siquiera para Kuhn fue tan fácil abandonar por completo la idea de la objetividad. Según Kuhn existe un conflicto entre la relatividad general y la mecánica clásica, lo cual indica, en la práctica, que él mismo asumía que se podían hacer comparaciones entre paradigmas.1109 Con esta crítica a la tesis de la inconmensurabilidad no pretendo defender que todo lo que hacen los que se denominan a sí mismos “científicos” sea completamente racional, ni mucho menos. Este tema lo discutiremos ampliamente en próximos capítulos. Sólo digo que, al menos en algunas áreas, la ciencia sí funciona de un modo muy similar al modelo positivista: las teorías dependen fundamentalmente del mundo externo y acaban describiendo de un modo adecuado los fenómenos que se dan en ese mundo. Tal vez, en defensa de Kuhn haya que reconocer que, a pesar de la polvareda que levantó con sus paradigmas y su inconmensurabilidad, en una pequeña sección de La estructura sí admitió que los científicos son bastante racionales y que sus cambios teóricos tienen en cuenta la precisión de las predicciones y la potencia explicativa de sus teorías. De hecho, Kuhn tuvo en cuenta las reacciones a la tesis de la inconmensurabilidad, tanto las entusiastas, que le preocuparon, como las críticas, y dedicó gran parte del resto de su carrera a moderar sus tesis. Después de La estructura pasó a defender que la inconmensurabilidad no implicaba que los paradigmas no fuesen comparables, sino, tan sólo que, en algunos casos, la comparación era difícil.1110 Tal vez si hubiese reflexionado sobre esta cuestión antes de escribir La estructura en un tono tan exaltado nos habría ahorrado a todos mucha mala filosofía posterior. 17.12 Radical o mesurado Algo que me ha llamado mucho la atención al estudiar filosofía de la ciencia es que mientras que los comentarios sobre los textos de Popper o de los positivistas lógicos suelen ser más o menos uniformes, los dedicados a Kuhn varían muchísimo. Algunos autores hablan de él como un filósofo que, al criticar los excesos positivistas, hizo aportaciones fundamentales, mientras que otros lo tratan como un radical peligroso y lo mencionan, junto a Feyerabend, como un enemigo de la racionalidad. Resulta curioso que La estructura pueda leerse de formas tan distintas. Kuhn dedica la mayor parte del libro a hacer críticas feroces a la supuesta racionalidad científica, aunque, al mismo tiempo, de vez en cuando reserva unas pocas líneas para recordar al lector que, en el fondo, los científicos suelen comportarse racionalmente. En cualquier caso, es importante situar estos breves pasajes en el contexto de una obra que tiene un tono general muy radical.1111 En mi caso, gracias a la lectura de comentarios de varios autores, he aprendido a valorar las lecciones que pueden extraerse del libro, pero mi reacción inicial fue completamente emocional; La estructura me cabreó y me disgustó a partes iguales. El historiador y filósofo de la ciencia Peter Godfrey-Smith, que considera que La estructura es un gran libro, escribió que habría sido mejor para todos que el borrador del capítulo X se hubiese perdido en el asiento trasero de algún taxi.1112 Para que el lector se haga una idea de a qué nos referimos al afirmar que el tono era radical, merece la pena recoger aquí algunas de las afirmaciones que hace Kuhn. “No hay motivos racionales para distinguir una teoría de otra”. “Puede que debamos abandonar la noción, explícita o implícita, de que los cambios de paradigma científico nos van acercando poco a poco a la verdad”. “Un científico particular puede abrazar un paradigma por todo tipo de motivos y, habitualmente, por varios a la vez, algunas de estas razones, por ejemplo, la adoración al Sol, ayudaron a Kepler a hacerse copernicano”. Este comentario sobre Kepler me molestó especialmente puesto que Kepler es, precisamente, un ejemplo perfecto del científico que se rinde a unos datos que contradicen sus ideas previas. De modo que La estructura puede leerse como una crítica completamente destructiva o como una contribución a una discusión racional sobre la filosofía de la ciencia. Aunque, todo hay que decirlo, para entenderlo de este segundo modo hay que hacer un esfuerzo importante por ignorar muchas de las barbaridades que escribió Kuhn. Las afirmaciones más estridentes han sido, con el tiempo, purgadas de la filosofía de la ciencia profesional y han quedado sus críticas más razonables.1113 Sin embargo, probablemente, fueron sus salidas de tono las que más contribuyeron al éxito popular del libro en unos años 60 y 70 muy contestatarios. Además, las tesis más radicales fueron asumidas en aquel momento por grandes grupos de académicos, principalmente sociólogos y filósofos, completamente opuestos a la idea de que la ciencia tuviese una relación especial con la razón. Kuhn se arrepintió de haberse convertido en una figura clave en esta crítica extrema a la racionalidad y dedicó una parte importante de su carrera posterior a desdecirse de las afirmaciones más estrafalarias y a defender la racionalidad científica.1114 Según Kuhn, se le había malinterpretado. Sin embargo, esto no es lo que opinan muchos de sus críticos, que sostienen que, en realidad, se arrepintió de estar inmerso en un movimiento completamente radical y absurdo. 17.13 No te arranques los ojos, visita al oculista La estructura cayó en tierra fértil y sus críticas a la racionalidad, basadas en la relación entre observación y teoría y en la inconmensurabilidad, florecieron entre los años 60 y 90 y terminaron por convertirse en distintas tradiciones constructivistas radicales que negaban la posibilidad de toda conclusión firme, excepto, claro está, la suya propia. Para los constructivistas las teorías científicas simplemente reflejan preferencias psicológicas y sociales de sus proponentes que poco o nada tienen que ver con la estructura de los fenómenos estudiados.1115 Casi todo el mundo coincide en que los factores sociales son relevantes, pero esto puede ser entendido de formas muy diversas. El sociólogo clásico Robert King Merton (1910-2003), por ejemplo, entendía que el proceso científico podía funcionar más o menos eficientemente y que debíamos estudiar las comunidades científicas para evaluar qué estaba funcionando y qué no. Sin embargo, los sociólogos constructivistas concluyeron que los únicos motivos para elegir una hipótesis frente a otra eran sociológicos.1116 La ciencia, en ningún caso, podía ir bien. Para un constructivista la ciencia es una mera construcción, sería análoga a una moda en el vestir, algo puramente humano. Para estos nuevos relativistas cualquier conclusión siempre depende de nuestro punto de vista puesto que los estándares objetivos son una mera quimera. Además, es importante recordar que no es lo mismo encontrar limitaciones a la racionalidad que concluir que cualquier conclusión es igual de racional. Del mismo modo que es muy distinto reconocer que las hipótesis no pueden ser justificadas de un modo absolutamente racional y objetivo, que concluir que las justificaciones son completamente irracionales. La filosofía, claramente, nos indica que el conocimiento puede tener problemas, pero la cuestión es hasta qué punto estas limitaciones se dan en cada caso, y esta es una cuestión que no puede responder la filosofía independientemente de la sociología y la historia. La posición de los constructivistas me recuerda a la recomendación de Mateo 18:9: Y si tu ojo te hace caer, sácalo y échalo de ti; porque mejor te es entrar en la vida con un solo ojo, que teniendo dos ojos ser echado en el fuego del infierno. Los constructivistas encontraron algunos problemas que los positivistas habían ignorado y, en vez de decantarse por una conclusión mesurada, nos recomendaron arrancarnos los ojos. Renunciar por completo a los estándares epistémicos equivale a resignarse a vivir en la alucinación continua. Su razonamiento es que si los científicos pueden fallar, si el conocimiento es falible, todo es opinión y, por lo tanto, cualquier opinión es igual de válida. Durante la época helenística ya nos encontramos con escuelas filosóficas que llegaron a este tipo de conclusiones, y prácticamente por los mismos motivos. Debemos recordar, además, que esta renuncia no afecta sólo a la ciencia, sino que, si somos coherentes, niega la posibilidad de cualquier conocimiento. Los fundamentos epistémicos que me permiten afirmar que mi gata duerme junto a mí son, esencialmente, los mismos que los utilizados por la comunidad física al evaluar la relatividad, por lo tanto, si negamos la ciencia, y somos coherentes, no podemos escapar del escepticismo radical. Aunque es cierto que los científicos aplican esos principios epistémicos básicos mucho más sistemáticamente de lo que lo solemos hacerlo en nuestras vidas cotidianas, esto no implica que los principios no sean los mismos. De modo que los constructivistas deberían explicar por qué creen en los gatos, pero no en el movimiento planetario. Nuestras conclusiones dependen de factores externos e internos, de las evidencias y la razón y de nuestro conocimiento previo y de nuestras motivaciones.1117 Es indiscutible que el conocimiento humano es una construcción social, ha sido generado por un conjunto de comunidades,1118 pero la cuestión es hasta qué punto las respuestas provisionales que hemos alcanzado dependen de las dinámicas sociales y hasta qué punto de la realidad externa. Que la ciencia sea una construcción social no implica necesariamente que no sea verdadera.1119 La ciencia es una construcción social que, visto su éxito operacional, cuadra bastante con la realidad.1120 El conocimiento científico es, hasta cierto punto convencional, pero no es arbitrario. En todo caso, la respuesta correcta ante los problemas que los filósofos y sociólogos encontraron durante el siglo XX en la justificación científica no tendría que ser el relativismo absoluto, sino el escepticismo mesurado y esta acabó siendo, de hecho, la conclusión de la mayoría de los filósofos de la ciencia. Si yo tengo una creencia sobre un aspecto del mundo externo o bien mi creencia se corresponde con ese mundo externo o no lo hace. Si creo que existen los ponis rosas, o bien los ponis rosas existen o no existen. Si carezco de evidencias suficientes como para justificar mi creencia lo que debería hacer es suspender el juicio, asumir que no sé. Sin embargo, el relativista asume que está bien que yo crea en la existencia de ponis rosas al mismo tiempo que tú no crees en ellos porque cada uno tiene su verdad. Esta es una tesis completamente absurda, existe un único mundo externo, por lo que la verdad debe encontrarse en la relación entre nuestras creencias y ese mundo. Además, hemos de reconocer que, a lo largo de la historia, la ciencia ha tratado activamente de detectar sus sesgos y limitaciones para ir, poco a poco, mejorando sus metodologías y procesos, de modo que sus conclusiones dependan cada vez menos de factores internos.1121 La ciencia no es perfecta, pero ha demostrado funcionar bastante mejor que cualquier otro sistema de generación de conocimiento sobre el mundo externo.1122 En cualquier caso, lo que sí es cierto es que hay casos en los que lo racional es suspender el juicio, por lo que es muy importante aprender a evaluar cuánto hemos de dudar de una hipótesis concreta. La ciencia no es perfecta, pero hay grados de imperfección muy distintos.1123 Entre la cinemática galileana de los planos inclinados y la superchería de una parte de la pedagogía actual hay un abismo. 17.14 Posmodernos y sociólogos radicales Los constructivistas pueden clasificarse en varios tipos. Unos de los más famosos son los posmodernos. El posmodernismo no es un movimiento claramente definido. En algunas ocasiones se entiende como una forma extrema de relativismo y, en otras, como un conjunto de ideas extravagantes sobre la relación entre el lenguaje y la realidad.1124 Su origen es principalmente francés y está muy relacionado con el análisis del lenguaje. Entre los círculos filosóficos anglosajones a los autores posmodernos, como Lyotard o Derrida, se les suele considerar más bien críticos sociales y literarios que verdaderos filósofos. El programa fuerte es otra de las escuelas constructivistas más famosas. En este caso están relacionados con la sociología de la ciencia. El programa fuerte surgió a partir de tesis radicales propuestas por los sociólogos escoceses Barry Barnes y David Bloor.1125 Estos autores, que reconocieron la influencia de Kuhn en su rechazo a la racionalidad1126 y que, a su vez, fueron rechazados por el mismo Kuhn,1127 analizan la ciencia sin preocuparse en absoluto por el éxito o el fracaso empírico de las hipótesis propuestas.1128 Bloor, además, rechazó la definición clásica de conocimiento como creencia verdadera justificada y volvió a una de las definiciones que Sócrates había rechazado en el Teeteto: conocimiento es aquello que la gente cree.1129 Es decir, que si yo creo que el SIDA es causado por un virus, ese es mi conocimiento y si creo lo contrario, también. Por supuesto, si yo creo que el programa fuerte es una estupidez, eso también es conocimiento. Lo triste es que, a pesar de este claro absurdo, estos autores han tenido una influencia enorme en la sociología y la historia de la ciencia.1130 17.15 La guerra por la razón Entre finales del siglo XX y principios del XXI las ideas de los constructivistas radicales se filtraron fuera de sus limitados círculos académicos y llegaron a una población general que, irónicamente, dependía cada vez más de la tecnología. Mientras que Condorcet, escondido antes de ser asesinado, siguió confiando en la razón como herramienta de progreso, muchos de los habitantes de las sociedades más opulentas de la historia pasaron a criticar el predominante papel de la ciencia.1131 Según los ilustrados, la ciencia es progresista y antiautoritaria, pero según Feyerabend la ciencia es opresiva porque impone una visión única del mundo.1132 Además, según los constructivistas, esta visión unificada no es debida a que refleje la estructura del mundo externo, sino, simplemente, a que se le atribuye una autoridad especial. Esta es una batalla que se sigue librando a cara de perro en la cultura popular y de la que depende nuestro futuro. En las películas el científico suele ser el malo, pero, a la vez, el público espera que haya cada vez más tecnología y se asume que la medicina salvará finalmente al protagonista. En E. T. el científico jefe, la figura paterna, cargada con la responsabilidad de las llaves, está a punto de matar al indefenso extraterrestre y a su protector, que es un niño, no un adulto. Este argumento resume perfectamente el conflicto que se vive en nuestras sociedades. Los constructivismos tienen su origen cultural en el postcolonialismo y el antiautoritarismo de los años 60 y 70.1133 Las sociedades más poderosas habían abusado de su posición comportándose, en muchas ocasiones, como aves de rapiña y habían causado un enorme dolor innecesario. Esto, claro está, no es nada nuevo, es lo que a lo largo de la historia ha pasado cuando una sociedad más poderosa se ha encontrado con otra con recursos por explotar. La diferencia es que esta vez, los científicos, como parte del estatus quo, formaron parte de la ofensiva. Los posmodernistas transformaron la crítica a las injusticias causadas por los países más poderosos en un respeto paternalista e hipócrita por los conocimientos locales.1134 El problema es que las ideas constructivistas no sólo no solucionan los problemas, sino que los agravan. En primer lugar, en un mundo con 7000 millones de personas que se alimentan gracias a la reacción de fijación de nitrógeno de Born-Haber y que dependen críticamente de las vacunas, los antibióticos y del resto de tecnologías, negar la razón nos aboca a la catástrofe social. Los constructivistas, en muchos casos, abogan por llevarnos a un tiempo anterior a las revoluciones racionales y empíricas de los filósofos naturales clásicos y modernos y se alinean junto a los reaccionarios que se opusieron a ellas. Pero la realidad es que si cultivamos como nuestros abuelos, viviremos como nuestros abuelos. Además, la crítica social no ha de renunciar a conocer el mundo puesto que si tratamos de actuar en el mundo sin comprenderlo el resultado no será justicia social, sino un desastre. El único modo de comprender el mundo es esforzarse por utilizar la razón y esto, en el caso del mundo externo, por definición, es hacer ciencia.1135 Sin ciencia, sin razón, lo que obtendremos no es justicia social, sino miseria. Esto no implica que el conocimiento del mundo vaya a solucionar nuestros problemas sociales, en absoluto, para enfrentarnos a ellos el conocimiento es necesario, pero no suficiente, también hemos de esforzarnos por comportarnos con justicia. 17.16 Confianza en los expertos Por otro lado, es habitual que estas tendencias culturales pasen de la crítica a las figuras de autoridad al cuestionamiento de los expertos.1136 Si pensamos que la ciencia es, simplemente, una construcción social sin una relación especial con la realidad, sus supuestos expertos quedan convertidos en meras figuras que ejercen una autoridad arbitraria. De nuevo, si somos coherentes, esta cuestión no debería limitarse sólo a la ciencia. Nadie puede saber de todo y, por lo tanto, estamos obligados a confiar en los expertos en todos los ámbitos de nuestras vidas. Steven Novella, el escéptico y director del excelente The Skeptics’ Guide to the Universe suele responder de este modo cuando alguien le plantea dudas sobre esta cuestión: ¿Usted en qué trabaja? Imaginemos que su interlocutor es mecánico de automóviles o enterrador, cualquier profesión sirve igual. Inmediatamente Novella hace una segunda pregunta: ¿Cree usted que cualquier persona sabe lo mismo que usted sobre su profesión? ¿Le confiaría usted la reparación de su coche a alguien que ha hecho una consulta de 5 minutos en internet? Los científicos no son especiales, cualquier profesional es experto en su área y negarlo equivale a defender el absurdo de que el conocimiento está uniformemente distribuido. Sin embargo, tampoco debemos tratar a los expertos como oráculos omnisapientes, algo que, por desgracia, también tendemos a hacer. Los seres humanos tenemos ciertos sesgos y uno de los más relevantes está relacionado con el efecto halo. Es habitual tratar a un experto en un campo concreto como si pudiese tener opiniones informadas sobre cualquier asunto y esto es, claramente, un error. Yo sé sobre la domesticación del tomate, pero eso no me otorga ningún conocimiento especial sobre pedagogía o medicina. Sin embargo, a los premios Nobel, por ejemplo, se les suele consultar sobre asuntos alejados de su área de experiencia.1137 Linus Pauling, un gran químico que recibió dos premios Nobel fue, además, promotor de pseudoterapias ya que acabó convencido de que el cáncer podía curarse tomando vitamina C. Esta irresponsabilidad continúa, todavía hoy, causando la muerte de muchos enfermos. Otro problema relacionado con los expertos es el de cómo podemos juzgarlos. Ahora mismo estoy leyendo un libro sobre el funcionamiento de las centrales nucleares escrito por un supervisor de una de ellas. Como era de esperar, la visión que da sobre las mismas es muy diferente de la que he recibido por parte de las organizaciones autodenominadas ecologistas. Mientras que Alfredo García, el experto, insiste en que las operaciones llevadas a cabo en las centrales nucleares son seguras y que sus responsables están comprometidos absolutamente con la seguridad, los voceros de Greenpeace insisten en que los dueños de las nucleares están destruyendo el mundo. Como ciudadano me enfrento al dilema de elegir en quién confiar. La autoridad académica deja de ser relevante cuando tú mismo eres capaz de entender los argumentos y el contexto;1138 de modo que podría plantearme buscar información por mi cuenta, pero el problema es que esto no es tan fácil. Para juzgar racionalmente las afirmaciones del experto no basta con leer un par de libros, debemos convertirnos en expertos nosotros mismos y esto, evidentemente, no es algo que vayamos a poder hacer en demasiadas áreas, nuestras vidas son demasiado limitadas. De modo que, yo, alguien que no tiene ni idea de los protocolos de funcionamiento de una central nuclear, debo juzgar cuál es la información veraz. Me inclino a pensar que, dado que Greenpeace miente descaradamente cuando habla sobre mejora genética, un área que sí conozco profesionalmente, es muy probable que también esté mintiendo sobre la energía nuclear. Pero, de nuevo, estoy depositando mi confianza en un bando o en otro. ¿Hay alguna alternativa más racional? Es importante admitir que es imposible aprender sobre todos los temas, por lo que deberemos aprender a repartir nuestra confianza con sabiduría. Un área en la que sí habríamos de convertirnos en expertos es en pensamiento racional. Esto nos permitiría separar con mayor eficiencia el grano de la paja. Aunque, de nuevo, hemos de ser cautos, leer un par de libros sobre el tema no nos convertirá en expertos, recuerdemos el efecto Dunning-Kruger. Estoy aburrido de escuchar a escépticos que parecen olvidar que el pensamiento racional comienza por la autocrítica y que la razón exige mucha práctica. Por otro lado, tampoco debemos concluir que los expertos no deban rendir cuentas. La diferencia entre el experto y el profeta es que cuando al experto se le piden explicaciones, debe darlas, no puede aducir que debe confiarse en su palabra. Un experto tiene que ser capaz de justificar sus afirmaciones hasta llegar, en última instancia, a afirmaciones que no dependan más que de la epistemología más elemental. Un pretendido experto que no acepte una pregunta racional no es más que un pseudoexperto. Aunque, de nuevo te aviso, esto no implica que tú vayas a ser capaz de evaluar esas explicaciones, sólo otro experto podrá. Cuestionar a los expertos es muy loable, pero para hacerlo, antes debes convertirte en uno. Por ejemplo, yo, que soy experto en genética, podría convencerte de cualquier afirmación relacionada con la genética, podría defender tanto que existen las razas humanas, como que no existen, y sólo otro experto sería capaz de juzgar mi defensa de estas tesis racionalmente. 17.17 La filosofía importa Las polémicas y los problemas sociales que hemos comentado son una muestra clara de la importancia de la filosofía. Las consecuencias de popularizar unas ideas filosóficas u otras no son desdeñables. Lakatos pensaba que la influencia de Kuhn había sido destructiva para la sociedad1139 y yo estoy de acuerdo. Independientemente de que se reconozca su trabajo académico, la influencia de La estructura para la sociedad en su conjunto ha sido desastrosa y eso es, en parte, responsabilidad de la comunidad filosófica. La estructura suele utilizarse para enseñar filosofía de la ciencia, así que no me extraña que los científicos pasen del tema. Tras leer este texto, que es el más influyente en el campo, es normal que asuman que representa la opinión general de los filósofos de la ciencia profesionales y concluyan que los filósofos son una panda de mentecatos que no tienen ni idea de lo que hablan. De hecho, hay muchos científicos que piensan que podemos renunciar a la filosofía, que los científicos nos apañamos. El problema es que para diferenciar la buena ciencia de la mala estamos obligados a plantearnos cuestiones filosóficas. Ejemplos de preguntas filosóficas relevantes para el científico son ¿cuáles han de ser los objetivos del esfuerzo científico y cuál es el mejor modo de conseguirlos? Estas no son cuestiones que pueden resolverse haciendo física ni estudiando diseño experimental. Es cierto que para hacer buena filosofía de la ciencia hay que saber mucha ciencia, pero, al mismo tiempo, no es recomendable hacer ciencia sin tener ni idea del marco filosófico que estamos asumiendo ni sobre cuales son sus limitaciones. Normalmente los científicos aprenden sobre estas cuestiones implícitamente, interaccionando con sus maestros y sus pares, pero dadas las presiones financieras a las que están sometidas las comunidades científicas, y que analizaremos en el próximo capítulo, tal vez eso no sea tan buena idea. Yo, como ilustrado lo tengo claro, la cinemática de Galileo está muy alejada del vudú y tiene, y debe tener, un papel especial en los logros del pensamiento humano. Pero, a la vez, esta actitud implica una exigencia que suele ser olvidada por mis compañeros ilustrados. Si otorgamos a la ciencia un papel especial, debemos ser especialmente exigentes con ella y, sobre todo, debemos ser muy críticos con quienes utilizan su prestigio para esconder su desnudez. Los médicos deberían expulsar a los pseudoterapeutas de sus facultades, los economistas a los pseudoexpertos en macroeconomía, que hacen en los medios de comunicación continuas predicciones erróneas sin que nunca lleguen a disculparse por sus continuos fracasos, y los pedagogos tendrían que criticar con dureza las continuas modas infundadas que pueblan su área. Cualquier comunidad que no hace una crítica profunda de la mala ciencia que hay en su seno traiciona la confianza que la sociedad deposita en ella y no debería extrañarse que luego la comparen con el vudú. 17.18 Resumen Thomas Kuhn propuso sus famosos paradigmas, hasta cierto punto, porque el científico aprende parte de su oficio implícitamente, estudiando y observando ejemplos. Esta es una conclusión muy defendible, pero algunas de las asociadas al otro sentido del término son más problemáticas. También se entiende como paradigma kuhniano el conjunto de compromisos teóricos, metodológicos y ontológicos aceptados por un científico o una comunidad. Kuhn insistió en que una comunidad se compromete con un sólo paradigma hasta que, tras una revolución, lo reemplaza por otro. Pero ni es cierto que las metodologías sean cambiadas cuando se reemplazan las teorías ni que, en general, en ciencia unas teorías sean sustituidas por otras de forma revolucionaria; el cambio gradual también es muy común. Tal vez sea más útil recordar el barco de Neurath que las revoluciones de Kuhn. Además, las tesis de Kuhn suponen un ataque a la racionalidad puesto que según este autor distintos paradigmas no son comparables racionalmente, son inconmensurables, y esto implica que la elección entre varios de ellos no puede ser racional. Encontrar límites o problemas a la racionalidad no implica que cualquier conclusión haya de ser igual de aceptable. Sin embargo, a pesar de lo radical de las tesis kuhnianas, es mucho lo que podemos aprender de ellas. Por ejemplo, si dos individuos o dos comunidades no comparten un vocabulario y unas metodologías comunes no podrán participar en un proyecto conjunto de construcción de conocimiento y, dado que generar un vocabulario no siempre es trivial, esto puede convertirse en un impedimento práctico relevante. En el caso de la ciencia la solución suele pasar por descender a un vocabulario más cercano a lo empírico. Por ejemplo, los físicos pueden hablar de relojes, reglas y medidas. Según los positivistas las observaciones son independientes de nuestras ideas teóricas y la justificación de las teorías científicas se basa en los datos y en la lógica. Sin embargo, es necesario reconocer que las observaciones, en mayor o menor grado, están teñidas de teoría y que el proceso de elección entre hipótesis no tiene por qué ser completamente racional. Los datos más cercanos a la percepción suelen ser menos problemáticos: es fácil aceptar que una bolita cae por un plano inclinado a una velocidad, pero medir el grado de neuroticismo de una persona depende más claramente de compromisos teóricos muy alejados del empirismo elemental. Además, también es importante reconocer que las motivaciones y los incentivos de las comunidades científicas, que son las que hacen ciencia, no siempre son epistémicamente puros, de modo que merece someter las conclusiones científicas a un cierto escrutinio. En particular, el proceso de descubrimiento y de discusión está en muchos casos muy alejados del ideal racional que algunos pueden tener en la cabeza cuando piensan en las investigaciones científicas. Las dinámicas de las comunidades científicas son complejas y los factores psicológicos y sociológicos son relevantes. Es un mérito de Kuhn haber señalado estos problemas que habían sido ignorados por los positivistas que, hasta el momento, se habían ocupado sólo por las evidencias y la lógica, pero que habían descuidado los aspectos históricos y sociológicos por considerarlos irrelevantes en el contexto de la justificación. Es siempre importante recordar la distinción entre el es y el debe, entre la descripción y la norma. Mientras que la historia y la sociología, e incluso la ciencia en general, se ocupan por describir cómo es la realidad, la filosofía tiene una ambición normativa. Por ejemplo, dicta qué normas habría de tratar de seguir un investigador racional. Sin embargo, también es necesario reconocer que, dado que no hay demasiadas reglas epistémicas absolutas y que la práctica real de la ciencia depende del oficio y buen hacer de los científicos, ignorar los aspectos psicológicos y sociales conllevará que acabemos teniendo una visión muy idealizada de la empresa científica. Sin normas sería imposible decir qué es mala y buena ciencia, pero, al no disponer de un método, de un algoritmo, científico, al no disponer de normas muy concretas, no podemos recomendar algo mucho más preciso que: el científico debe esforzarse por comportarse con integridad intelectual. Es evidente que el conocimiento humano es una construcción social, pero esto no implica que no tenga relación alguna con el mundo externo. Sin embargo, es importante recordar que una conclusión de un área científica cualquiera no tiene por qué ser un reflejo exacto del mundo externo y que, en algunas ocasiones, puede llegar a ser un delirio comunitario. En especial, debemos preocuparnos cuando las observaciones dependan mucho de los marcos teóricos y cuando no haya evidencias abundantes y variadas. Un modo de separar el grano de la paja es evaluar el éxito operacional de las propuestas científicas. Cuando un área o teoría ha conseguido materializarse en intervenciones exitosas sobre el mundo externo, como predicciones contrastadas o tecnologías concretas, podemos confiar en que sus conclusiones tienen algo que ver con la realidad. En el resto de casos haremos bien en ser más cautos. Lo que en ningún caso debemos hacer es aceptar el relativismo; cuando desconocemos la estructura del territorio es absurdo aceptar cualquier mapa, lo racional es hacer una prudente y escéptica reserva de juicio, admitir, simplemente que no sabemos o que nuestro conocimiento es muy tentativo. "],["sistemas_epistemicos_y_magisterios.html", "18 Sistemas epistémicos y magisterios 18.1 Pluralismo de los sistemas epistémicos 18.2 ¿Existen sistemas epistémicos alternativos? 18.3 La religión como sistema epistémico alternativo 18.4 Los dos magisterios 18.5 Resumen", " 18 Sistemas epistémicos y magisterios En el capítulo anterior tratamos algunos aspectos de los constructivismos y los relativismos. Según los constructivistas nuestras ideas obedecen más a factores psicológicos y sociales que a la información que nos llega del mundo externo. Sin embargo, existe un modo aún más radical de defender el relativismo: todos los puntos de vista son igual de válidos puesto que existen formas radicalmente diferentes de conocer el mundo.1140 No es ya que la ciencia pueda equivocarse o no al caracterizar un fenómeno del mundo externo, sino que según algunos autores hay otras formas de conocer alternativas que son igual de válidas. 18.1 Pluralismo de los sistemas epistémicos Esta tesis podría denominarse pluralismo de los sistemas epistémicos: existen distintos sistemas epistémicos, distintos modos de conocer el mundo externo, igualmente válidos.1141 Un sistema epistémico es el conjunto de normas por las cuales juzgamos que una creencia está justificada.1142 El filósofo Richard Rorty (1931 - 2007) sostenía que no podía justificarse quién tenía más razón en el conflicto entre Galileo y Belarmino puesto que el filósofo natural y el inquisidor estaban utilizando diferentes sistemas epistémicos.1143 Según esta posición, Galileo sólo tendría razón si se aceptasen las reglas del juego impuestas por la ciencia, pero Belarmino estaría haciendo uso de un sistema epistémico alternativo, que incluiría también la revelación, por lo que, para poder conceder la razón a Galileo antes habría que justificar que el sistema epistémico científico es más correcto que el religioso. Otro ejemplo de sistema epistémico alternativo sería el utilizado por los Azande, un pueblo del centro-norte de África, que en su forma tradicional de exploración del cosmos incluye el oráculo. Por lo tanto, para los Azande, basta con la refrenda por parte del oráculo para que una creencia esté justificada. Los defensores del pluralismo de los sistemas epistémicos podrían recordarnos que en el mundo occidental también hemos utilizado distintos sistemas; al fin y al cabo, la revolución científica cambió la forma de estudiar el mundo natural.1144 Además, es indudable que las metodologías científicas evolucionan: los artículos publicados por la Royal Society en el siglo XVIII, hoy en día, no serían aceptados por ninguna revista científica seria. A estas alturas es posible que el lector piense que las conclusiones a las que puede llevarnos este hilo argumental pueden ser absurdas, pero recordemos que una de las principales utilidades del estudio de la filosofía es aprender a defendernos de la mala filosofía. Además, estas ideas, aunque no se defiendan explícitamente, indirectamente, son asumidas por una gran cantidad de científicos e instituciones científicas. De hecho, fue mi falta de una respuesta articulada a algunas de estas propuestas la que me llevó hace seis años a empezar a estudiar filosofía de la ciencia. Por si fuese poco, no es tan fácil justificar que un sistema es superior a otro. Por ejemplo, es imposible justificar, deductivamente, dentro de un sistema epistémico ese propio sistema epistémico.1145 De modo que si somos incapaces de justificar las reglas que aceptamos dentro del propio sistema, debemos asumir que estamos aceptando esas reglas por motivos ajenos al sistema. Lewis Carroll expuso este problema en el diálogo Lo que la tortuga le dijo a Aquiles (1895). Por ejemplo, podríamos cuestionar nuestra confianza en el modus ponens. El modus ponens es una regla elemental de la lógica deductiva: “Si P implica Q y P es verdad, entonces Q también es verdad”. Por ejemplo, cuando está soleado (P) es de día (Q), como realmente está soleado (P), es de día (Q). En el diálogo, la tortuga le plantea a Aquiles que si aceptamos el modus ponens cualquier deducción similar a la anterior será válida, pero, ¿por qué habríamos de aceptarlo? En principio, deberíamos poder justificar la conveniencia o la necesidad de aceptar esta regla lógica, pero es imposible hacerlo dentro del propio sistema lógico. Este problema es equivalente a justificar las reglas del ajedrez, los jugadores no pueden justificar las reglas dentro del propio juego, simplemente las aceptan y las utilizan para jugar. Este problema, el de la circularidad de la justificación, ya fue adelantado por los escépticos helenísticos. Sexto Empírico se lo atribuyó a Agripa,1146 el supuesto autor de Los cinco caminos de la duda. Una posible opción sería aceptar algunas creencias como fundamentales, sin más justificación. Algunos posibles candidatos serían las tesis metalógicas, las reglas fundamentales con las que se construyen las distintas lógicas. Aristóteles, por ejemplo, propuso: el principio de identidad, toda entidad es idéntica a sí misma, el principio de bivalencia, una proposición es verdad o no lo es, el principio de no contradicción, una proposición y su negación no pueden ser verdad al mismo tiempo, y el principio del tercero excluso, si existe una proposición que afirma algo y otra que lo contradice, una de las dos tiene que ser verdad y, además, no existe otra posibilidad.1147 En nuestros razonamientos cotidianos estos principios suelen ser aceptados. Sin embargo, también es cierto que eligiendo alguno de estos principios y añadiendo otros se pueden construir diferentes sistemas lógicos complementarios.1148 Un principio respetado por cualquier sistema lógico serio es el de la coherencia, un sistema incoherente no es aceptable.1149 Nadie en su sano juicio ha rechazado este principio1150 y esto constituye una restricción muy importante a la creación de nuevos sistemas lógicos y epistémicos. Debemos aspirar a que nuestras creencias sean coherentes aunque esta condición, en la práctica, no sea tan fácil de cumplir. Por ejemplo, nuestros modos de razonar intuitivos no suelen ser coherentes. 18.2 ¿Existen sistemas epistémicos alternativos? Es cierto que no podemos justificar deductivamente un sistema epistémico dentro de sí mismo y que podemos plantear distintas lógicas alternativas, pero esto no implica, necesariamente, que haya distintos sistemas epistémicos coherentes fundamentalmente distintos. En realidad, plantear un nuevo sistema coherente radicalmente diferente no es una tarea sencilla. Como ya hemos comentado varias veces, la ciencia no se diferencia fundamentalmente de nuestros razonamientos cotidianos. La diferencia entre ambas aproximaciones radica, simplemente, en que cuando hacemos ciencia nos esforzamos por ser mucho más sistemáticos en la aplicación de los principios epistémicos básicos.1151 Las operaciones intelectuales elementales que utiliza el científico son las mismas que las que utiliza cualquier otra persona. Todos creamos modelos del mundo externo, todos basamos nuestras creencias, en mayor o menor grado, en lo que percibimos y todos intentamos respetar principios lógicos similares.1152 T. H. Huxley, un biólogo y filósofo, amigo de Darwin, dijo que la ciencia no es más que sentido común entrenado y organizado. Por ejemplo, en ciencia se insiste en que no debemos falsear las evidencias, pero este es un principio que también aceptamos fuera de la ciencia. La única diferencia es que los estándares de los científicos son mucho más rigurosos, por ejemplo, incluyen comprobaciones estadísticas de los datos que no solemos planteamos en nuestro día a día. Este rigor científico no es arbitrario, se ha impuesto para superar las debilidades del razonamiento cotidiano, especialmente su incoherencia.1153 Esto, por supuesto, no implica que las conclusiones a las que vaya a llegar la ciencia hayan de ser necesariamente intuitivas. Sólo estamos diciendo que los principios que utiliza el razonamiento científico parten de principios epistémicos intuitivos que se resumen en: observación, inducción y deducción.1154 A pesar de este punto de partida común, acaban apareciendo conflictos entre la visión científica y nuestras ideas cotidianas. Estos conflictos son debidos a que, gracias a la sutileza y el cuidado con el que llevamos a cabo el análisis científico, somos capaces de desentrañar regularidades del cosmos que, a simple vista, están ocultas. Históricamente, en realidad, no se han planteado sistemas epistémicos radicalmente diferentes. Simplemente se han propuesto pequeñas modificaciones del que teníamos de partida. La ruptura última sin estándares carece de sentido. pdnaipdnansdu R·ER)EJV))EW)uw e8hfap#@∞. Ni el relativista más radical aceptaría esta forma de escritura. ¿Por qué? Porque es más fácil decir que vas a romper todas las reglas que hacerlo. El sistema epistémico que utilizaba Belarmino tampoco era fundamentalmente distinto al de Galileo, simplemente añadía a nuestro sistema habitual el principio de la revelación.1155 Ni tan siquiera nuestros propios sistemas perceptuales son sistemas epistémicos fundamentalmente distintos: recogen información del mundo externo y utilizando un conjunto de reglas, en este caso inducciones implícitas, crean modelos que nos permiten hacer predicciones y actuar sobre ese mundo externo. A nuestros ojos llega luz y basándose en esta señal nuestros sistemas neuronales generan modelos que nos indican que tenemos un pequeño animal acurrucado frente a nosotros y esto nos permite acariciarlo. Cualquier sistema epistémico debe crear modelos que nos permitan actuar sobre el mundo. Los que crean modelos completamente erróneos o alucinaciones que nos llevan a actuar ineficientemente en el mundo, con el tiempo, son descartados. Esta es la metaregla que ha permitido la evolución de nuestros sistemas cognitivos, de nuestra mente y que, ahora, nos sirve para evaluar distintas modificaciones de nuestros sistemas epistémicos. De modo que un sistema epistémico alternativo debería esforzarse por ser coherente y habría de crear modelos adecuados del mundo externo. Estas restricciones no son fáciles de satisfacer, por lo que crear un sistema epistémico radicalmente distinto no es tan sencillo. Analicemos el caso de la religión revelada. 18.3 La religión como sistema epistémico alternativo Analicemos la afirmación de que Belarmino, el inquisidor, utilizaba un sistema epistémico radicalmente diferente y, por lo tanto, imposible de comparar con el que utilizaba Galileo. En esta sección, y en general en el resto del libro, a no ser que indique lo contrario, cuando hable de religión me estaré refiriendo a religión revelada, no a religión como conjunto de prácticas, ya que en este último sentido existen algunas religiones que rechazan cualquier revelación. Belarmino decía echar mano de la revelación y de la fe y aquí nos topamos con el primer problema: el término “fe” es muy ambiguo.1156 La palabra griega original utilizada en el antiguo testamento era pistis (πίστις) y puede traducirse como creencia o confianza. A veces la fe se utiliza en el sentido de esperanza: “tengo fe en que Condorcet no será ejecutado”. La fe también suele entenderse como confianza en una creencia falible, que no puede ser probada con una certeza absoluta.1157 En este sentido yo tendría fe en la gravedad newtoniana. En cualquier caso, estos usos son confusos, ya que fe tiene otros significados, por lo que, para mantener un discurso claro, conviene evitarlos utilizando en su lugar términos como esperanza o confianza. Fe también se utiliza en un sentido muy diferente: confianza en la revelación. Es decir, confianza en una creencia que no tiene otra justificación válida y que, por lo tanto, requiere de la revelación. Esto exige que depositemos nuestra confianza en un libro o en un profeta por motivos meramente religiosos. Este es el sentido que hace que la filosofía y la religión revelada sean incompatibles puesto que la filosofía no tendrá inconveniente en aceptar cualquier afirmación relativa al mundo externo o a un sistema moral siempre que esté debidamente justificada, pero, sin embargo, no tolerará aceptar propuestas cuyo único mérito sea haber sido formuladas o defendidas por una fuente concreta. En realidad, no es habitual que los creyentes admitan creer en un libro u otro, simplemente, por motivos arbitrarios, sino que, en realidad, suelen tratar de justificar sus creencias. Por ejemplo, según un estudio financiado por la fundación Templeton el 45% de los estadounidenses afirma creer en que su dios interviene activamente en nuestro mundo y el 20% cree tener evidencias de una intervención milagrosa de su dios en el mundo.1158 Estas supuestas evidencias son para muchas personas religiosas uno de los pilares de la justificación de sus creencias. Podríamos pensar que dado que estas evidencias, referidas normalmente a curaciones supuestamente sorprendentes, son evidencias circunstanciales y débiles, pero este no es el único problema. Incluso aunque admitamos que realmente las curaciones fueron milagrosas, ¿cómo saben los creyentes a qué ente sobrenatural adscribir cada curación? Los creyentes suelen también justificar su creencia en un creador racional y benevolente aduciendo que el mundo natural está repleto de diseño. Pero esta línea de justificación fue destruida por Darwin al proponer un mecanismo completamente natural e irracional capaz de crear diseño. Además, la avalancha de evidencias en favor de la evolución demuestra, más allá de toda duda razonable, que el diseño en el mundo biológico ha aparecido gracias a un mecanismo cruel: la evolución por selección natural. Otro motivo que suelen aducir los creyentes para justificar sus creencias es la experiencia personal.1159 Teresa de Jesús, por ejemplo, tuvo experiencias que le hicieron pensar que había estado en contacto con su dios. Un problema de estas experiencias es que no son intersubjetivas. Es decir, que son privadas, no son compartidas. Mi observación de que hay un gato dormido junto a mí es intersubjetiva porque los demás pueden ver el mismo gato. De hecho, si me dijesen no verlo, seguramente, llegaría a la conclusión de que mi creencia en el gato está basada en una alucinación. El premio Nobel John Nash, por ejemplo, en algunos periodos de su vida, escuchó voces que nadie más podía escuchar. La conclusión cuando una voz falla el test de la intersubjetividad, como el propio Nash aceptaba, es que las voces son debidas a un problema mental y que, por lo tanto, no están causadas por el mundo externo. Nuestro cerebro genera un rico mundo mental y algunos aspectos de este mundo reflejan la estructura del mundo externo, pero es importante distinguir qué aspectos tienen una causa fundamentalmente interior y cuáles mayoritariamente exterior. Según Teresa de Jesús sus experiencias eran motivadas por la interacción con un ser sobrenatural que, a parte de estas fuertes experiencias privadas, no tenía otros efectos claros en el mundo externo. El problema es que la falta de esos otros efectos evidentes hace mucho más probable la hipótesis de que esas experiencias fuesen, simplemente, fallos de la mente de Teresa de Jesús. Los profetas dicen haber recibido mensajes de seres sobrenaturales. Por cierto, que esto es algo que también le sucedía a John Nash. La cuestión, de nuevo, es si estos mensajes tienen un origen externo o interno. Es muy significativo que distintos profetas transmitan mensajes diferentes. Podríamos pensar que o bien el ser que los envía es un tanto juguetón, que hay varios seres, que hay ruido en las vías de comunicación o que los mensajes son creados por la mente de los propios profetas. Dada esta diversidad de mensajes, el creyente debería tomarse muy en serio el modo de elegir entre ellos. ¿Por qué debemos confiar en la palabra de un profeta y no en la de otro? Para poder elegir racionalmente el creyente debería disponer de criterios externos al propio mensaje. Esto haría que la revelación fuese irrelevante y reduciría su sistema epistémico al del no creyente. Sin embargo, en la práctica, parece que la elección del creyente es debida, principalmente, a la conformidad con el grupo social al que pertenece. Lo mismo es aplicable a los textos sagrados o a los distintos dioses, ¿por qué confiar en unos y no en otros? ¿Por qué he de creer en un dios cristiano o en alguno de los dioses hindúes? Cualquier creyente es ateo de los dioses de las otras religiones. Por lo tanto, la cuestión es por qué no es ateo de todos los dioses.1160 Lo que es cierto es que la gente suele creer en los dioses de sus padres. Aun así, los textos sagrados y los profetas disponen de medios sencillos para justificarse. Por ejemplo, la Biblia podría haber predicho con precisión la estructura del modelo estándar de la física de partículas, pero lo cierto es que las revelaciones no suelen acertar y que los profetas no predicen nada que no pueda saberse en su tiempo.1161 Además, incluso aunque obviásemos estos problemas, las revelaciones suelen tener graves incoherencias internas que han de ser resueltas echando mano de criterios externos a las mismas. Por ejemplo, el filósofo y teólogo medieval Pedro Abelardo (1079–1142), en su tratado Sic et non (Sí y no), expuso numerosas contradicciones teológicas.1162 Esto es común en los textos sagrados. Por ejemplo, la Biblia, nada más empezar, ya muestra varias contradicciones: el hombre se creó por la palabra o por el barro y la mujer fue creada independientemente o partiendo de la costilla de Adán.1163 La Biblia, además, está llena de consejos contradictorios: ama a tu vecino, pero mata a todos sus hijos y siembra sus tierras con sal.1164 Esto obliga a quien dice creer en ella a recurrir a criterios externos para resolverlas. Esto es lo que deben de estar haciendo la mayoría de los cristianos actuales que, menos mal, no suelen seguir las recomendaciones morales más atroces de su texto sagrado. Los católicos resuelven la cuestión pasando la pelota a la Iglesia Católica y al Papa, que son quienes tienen autoridad última en estas cuestiones. Es decir, que, en principio, un católico elige qué partes de la Biblia creer y cuáles no porque confía en el criterio del Papa que, a su vez, dice tener un contacto especial con su dios. Sin embargo, los protestantes no parece que estén muy convencidos de que este sea un buen método. En cualquier caso, en ausencia de criterios externos no hay muchas alternativas al consenso social o a la coacción por parte del poder. Es curioso que las religiones terminen elevando una opinión concreta a la categoría de ortodoxia, cuando, lo más habitual, es que esas mismas opiniones hayan nacido siendo heterodoxias de religiones previas.1165 Las actuales ortodoxias protestantes, por ejemplo, surgieron como heterodoxias cristianas. Este es un patrón típico de la evolución cultural que ya comentamos al hablar del cuento de la Caperucita Roja. Los relatos culturales suelen adquirir variaciones y se van diferenciando poco a poco. La ciencia, sin embargo, aunque también es un fenómeno cultural sujeto a evolución, presenta el patrón contrario: los modelos, poco a poco, van convergiendo porque gracias a las evidencias empíricas se van pareciendo cada vez más al mundo externo. Por ejemplo, dos fenómenos aparentemente independientes, la respiración y la combustión, terminaron por unirse gracias a la química en una explicación común: la oxidación de la materia orgánica.1166 Resumiendo, las religiones no plantean sistemas epistémicos alternativos, sino que, simplemente, añaden la revelación al sistema estándar, pero esto crea todo tipo de contradicciones que, dado el carácter privado de la revelación, no pueden ser resueltas sin apelar a criterios externos, es decir, al sistema epistémico estándar del que partían. En realidad, cuando Galileo se enfrentó a la inquisición lo más relevante no fueron los argumentos que cada una de las partes aportó para defender su tesis o que Belarmino estuviese utilizando un sistema epistémico radicalmente diferente, sino que el inquisidor tenía el poder de acallar al disidente. De hecho, las ideas astronómicas de Belarmino no eran muy distintas a las de Galileo. La cuestión fundamental era que si el inquisidor admitía que alguien podía justificar sus creencias sin apelar a la revelación, que estaba controlada por la Iglesia, la Iglesia perdía poder. Conceder este punto a Galileo habría implicado dar un golpe mortal a una Iglesia Católica que ya había tenido bastante con Lutero y los protestantes.1167 Por cierto, mientras que a Galileo lo condenaron a Belarmino, en agradecimiento por los servicios prestados, lo hicieron santo y doctor de la Iglesia, y esto último no ocurrió en el siglo XVI, sino en el XX. 18.4 Los dos magisterios A pesar de todo, la ciencia y la religión parecen ser compatibles o, al menos, lo son en la mente de muchos investigadores. Una encuesta del Centro de Investigaciones Pew llevada a cabo entre los miembros de la Asociación Estadounidense para el Avance de la Ciencia en 2009 concluyó que la mitad de los científicos creían en alguna deidad o poder superior. Además, como hemos comentado en varias ocasiones, a lo largo de la historia la mayor parte de los investigadores han sido creyentes. En el público general, ciencia y religión también parecen convivir. En el estudio de la fundación Templeton que he mencionado antes, que se realizó entre 2010 y 2015 y que consistió en 320 entrevistas personales y 10.000 encuestas, se concluyó que el 85% de los estadounidenses adultos están interesados por los descubrimientos científicos y, a la vez, una buena parte de ellos se declaran como moderadamente religiosos o como muy religiosos.1168 A lo largo de esta sección citaré algunas de las observaciones de este estudio, llamado Religion vs science. Merece la pena mencionar que el objetivo principal de la Fundación Templeton consiste en acercar la ciencia y la filosofía a la teología. También es relevante que, en este informe, se califique la persecución de Galileo por parte de la iglesia como supuesta persecución.1169 Me pregunto si lo de Bruno también fue una supuesta hoguera. Stephen Jay Gould, que fue un excelente divulgador del conocimiento biológico, es famoso por popularizar la tesis de los dos magisterios: no hay conflicto posible entre la religión y la ciencia puesto que, mientras que la ciencia trata de entender empíricamente el universo, la religión busca valores morales y significado espiritual.1170 Es decir, la ciencia trataría con datos y la religión con valores y, por lo tanto, no entrarían en conflicto. Esta es una buena muestra de las consecuencias que tiene escatimar en el estudio de la buena filosofía. La producción de mala filosofía no es sólo achacable a los filósofos profesionales, en ciencia es común encontrarse con gente que se atreve a tratar temas filosóficos sin preocuparse antes por formarse lo suficiente en el área y los resultados no suelen ser agradables. Resulta sorprendente que muchos científicos y aficionados a la ciencia renieguen de la filosofía mientras discuten temas profundamente filosóficos. En realidad, que algunos científicos crean en algún dios no debería sorprendernos, al fin y al cabo, son seres humanos y, por lo tanto, sus creencias no tienen por qué ser demasiado coherentes. Sin ir más lejos, yo soy científico y creía que Greenpeace era una organización honesta interesada principalmente por la defensa de la naturaleza. En este punto también podríamos tratar las cuestiones relativas al naturalismo metafísico y metodológico, pero dejaremos esta discusión para la sección dedicada a la metafísica. La idea básica es que la ciencia sólo puede estudiar fenómenos naturales y, por lo tanto, debe abstenerse de decir nada sobre la existencia de entes sobrenaturales. Esto, aparentemente, también podría dividir el conocimiento en dos magisterios independientes, pero implicaría algunas asunciones difíciles de aceptar. En primer lugar, si el ser sobrenatural interacciona con el mundo natural pasaría a ser un objeto legítimo de estudio científico. Por lo tanto, sólo estarían más allá del estudio científico aquellos seres sobrenaturales que no interaccionasen, en modo alguno, con el mundo natural. Esto sería difícil de compatibilizar con que, al mismo tiempo, interaccionasen con los seres humanos, ya que nosotros formamos parte del mundo natural. Además, habría que postular un mecanismo que nos permitiese adquirir conocimiento sobre estos seres que están más allá de lo natural. Algunos metafísicos, como ya hemos visto, plantean que esto puede conseguirse mediante la razón pura, pero, como ya hemos comentado, el fracaso de esta aproximación ha sido absoluto. Pero volvamos a Gould. La ciencia y la religión, a pesar de lo que diga este biólogo, tienen un buen número de conflictos irreconciliables. En primer lugar, tal y como nos recuerda Feynman, el científico está obligado a dudar razonablemente y esto implica reservar el juicio mientras no se tengan evidencias empíricas suficientes.1171 Por lo tanto, un científico que crea en Thor, el Dragón Invisible de Sagan, el Gran Poni Rosa o la Tetera de Russell no ha entendido cómo se hace ciencia o ha decidido no aplicar el escepticismo científico a los aspectos de su vida más alejados del laboratorio.1172 Es decir, del hecho de que haya científicos creyentes no debemos inferir que la ciencia y la religión sean filosóficamente compatibles, sino, simplemente, que hay muchos científicos que no razonan coherentemente; discuten racionalmente de lunes a sábado, pero desconectan el módulo crítico los domingos por la mañana. Además, históricamente la mayoría de las religiones nunca han asumido el principio de los dos magisterios.1173 Supongo que si el santo y doctor de la Iglesia Roberto Belarmino, levantase la cabeza se reiría de Gould y que Galileo entraría en cólera. Incluso los autores del estudio Templeton reconocen, probablemente a su pesar, que hay tensiones claras entre ciencia y religión.1174 Las religiones hacen afirmaciones sobre cómo funciona el cosmos y este es, precisamente, el objeto de estudio de la ciencia. La Tierra o se mueve o no se mueve, los seres humanos fueron creados gracias a una intervención divina o son el fruto de una evolución puramente natural, Adán o existió o no existió, el diluvio ocurrió o no ocurrió, la Tierra tiene miles o miles de millones de años, los seres humanos somos animales o no lo somos. La estrategia de las religiones, cuando no tienen el poder de suprimir la heterodoxia, suele consistir en asumir que las revelaciones de sus textos sagrados, o al menos las que les van interesando en cada momento, son simples cuentos edificantes. Esto, evidentemente, es una forma de ir escondiendo a sus dioses en los huecos del conocimiento.1175 Esta táctica funciona muy bien para conflictos factuales alejados de lo humano, como la edad de la Tierra o la muerte de los dinosaurios durante el diluvio. Al fin y al cabo, admitir que ha habido errores de interpretación durante la lectura de los textos sagrados, aparentemente, no exige un sacrificio teológico demasiado elevado. Pero el mayor problema para los creyentes es que hay otros conflictos que están demasiado cercanos a los aspectos teológicos más relacionados con lo humano y esos son irreconciliables. Por ejemplo, los católicos basan su teología en la idea del pecado original, pero si la genética de poblaciones afirma que no hubo un único hombre primigenio, un Adán, ¿quién cometió ese pecado? Las teologías cristiana y judía, que no parecen caracterizarse por su modestia, afirman que los seres humanos están hechos a imagen y semejanza de su dios. Entonces dijo Dios: Hagamos al hombre a nuestra imagen, conforme a nuestra semejanza; y señoree en los peces del mar, en las aves de los cielos, en las bestias, en toda la tierra, y en todo animal que se arrastra sobre la tierra. Y creó Dios al hombre a su imagen, a imagen de Dios lo creó; varón y hembra los creó. (Genesis 1:26-27) En general, para los creyentes, suele ser muy difícil digerir la propuesta científica de que los seres humanos son, simplemente, un animal más surgido por selección natural. El problema es que esto nos acerca a los animales y nos aleja de la divinidad.1176 Incluso aquellos creyentes que aceptan la evolución suelen considerar que su dios intervino en algún momento para conferir una esencia especial a los seres humanos que los distinguió de los animales y los acercó a la divinidad. Personalmente, después de vivir durante años con una gata no entiendo cómo alguien puede pensar que somos emocionalmente muy distintos de cualquier otro mamífero social. El otro conflicto factual importante percibido por los entrevistados en el estudio Templeton es el relativo a los milagros. Como ya hemos comentado, para muchos creyentes los milagros constituyen una evidencia fundamental en favor de la existencia de su dios particular. Por lo tanto, para muchas de estas personas es muy importante que la ciencia deje espacio para una intervención activa de sus dioses en el mundo natural.1177 Es decir, que para estas personas la religión y la ciencia no entran en conflicto mientras los científicos se limitan a enviar cohetes a la Luna o a hacer hornos microondas, pero les es más difícil aceptar cualquier conocimiento que indique que los seres humanos son monos calvos, engreídos y charlatanes, o que las lágrimas del retrato de Jesús son, en realidad, una solución acuosa. Estos son, según el estudio Templeton, los conflictos irreconciliables entre ciencia y religión1178 y, recordemos, esta conclusión se encuentra en un estudio financiado por una entidad dedicada a apoyar la compatibilidad entre la ciencia y la religión. De modo, que es obvio que sí hay conflictos factuales entre ciencia y religión. Pero este no es mi único problema con la tesis de los dos magisterios. Gould contrapone las observaciones científicas con los valores religiosos y esto, como ilustrado, me parece muy problemático. Las cuestiones morales deben ser justificadas en el ágora, es decir, de un modo laico. Para decidir si la pena de muerte es admisible o no, debemos recurrir a la filosofía, no a la religión. Del mismo modo que no es aceptable que alguien pretenda que creamos que el Sol se mueve alrededor de la Tierra simplemente porque lo afirma un texto o lo dice una persona respetada, es inadmisible que alguien pretenda imponer su moral sin justificarla más allá de aducir que proviene de una supuesta comunicación privada con su dios particular. Tanto en ciencia como en ética hemos de considerar solamente proposiciones justificadas. Como ya discutimos ampliamente, es este requisito de justificación pública lo que hace especiales a la filosofía y a la ciencia frente a las aproximaciones religiosas. Por último, no es sólo que existan conflictos factuales, sino que nuestras creencias sobre la organización del cosmos y nuestro papel en él influyen en nuestras posiciones filosóficas. No es lo mismo creerse un ángel caído que un mono calvo y engreído. Darwin no sólo propuso un mecanismo que explicaba cómo se generaba el diseño en la biosfera, sino que alteró radicalmente nuestra visión de nosotros mismos. Esto es algo que algunos todavía no le han perdonado. No les gusta verse como animales. Para mí, sin embargo, es difícil entender mi vida y mis emociones sin esta referencia. 18.5 Resumen La crítica más radical que puede hacerse al conocimiento científico es que hay otros modos igual de válidos de generar conocimiento sobre el mundo externo, que hay conjuntos de normas epistémicas alternativas que no son ni mejores ni peores que las utilizadas en ciencia sino, simplemente, diferentes. Es cierto que no es posible justificar un sistema epistémico dentro de sí mismo. La adopción de un sistema implica la aceptación de unos principios que no tienen justificación dentro del propio sistema y, por lo tanto, en principio podrían plantearse distintos conjuntos de normas epistémicas. El problema es que, en la práctica, esto no es tan fácil de llevar a cabo porque las normas sobre las que se asienta la ciencia son tan fundamentales que resulta difícil rechazarlas: nuestros sentidos crean representaciones que tienen una relación estrecha con la estructura del mundo externo y cualquier sistema lógico debe aspirar a ser coherente. La ciencia, simplemente hace uso de sistemas epistémicos que sistematizan estos principios. Dadas estas restricciones no es fácil plantear un sistema epistémico radicalmente distinto. Por ejemplo, podemos tratar de añadir la revelación o los oráculos a nuestro sistema habitual, pero cómo hemos de actuar cuando aparezca una incoherencia entre lo revelado y lo que vemos, ¿a qué debemos hacerle caso? Una vez aceptadas unas reglas básicas podemos incluso comparar distintos sistemas y esto nos permite ir mejorándolos con el tiempo, que es lo que se hace en ciencia. Queremos conocer el mundo externo, entre otras cosas, para actuar sobre él. Esto implica que los sistemas que utilicemos serán mejores o peores en función de si crean mapas del territorio más o menos útiles. Al final queremos utilizar un sistema epistémico que determine correctamente dónde está la puerta de casa porque lo contrario implica pegarse un golpe contra la pared cuando queramos salir a la calle. Por otro lado, la tesis de los dos magisterios, que sostiene que no es posible el conflicto entre la religión y la ciencia puesto que una trata sobre valores morales y significados espirituales y la otra sobre afirmaciones factuales es completamente equivocada. Es cierto que para muchos investigadores la ciencia y la religión son compatibles, pero nadie sostiene que los científicos sean seres completamente racionales y coherentes. Por ejemplo, también es común que los investigadores no entiendan los p-valores aunque los utilicen en sus investigaciones y nadie piensa que esto sea recomendable. Recordemos, no puede derivarse un debe de un es, una norma de una descripción de la realidad; descripción no implica prescripción. Además, los conflictos factuales entre ciencia y religión a lo largo de la historia han sido, y siguen siendo, comunes. O somos mamíferos sociales o no lo somos o estamos hechos a imagen de un dios o no lo estamos o tenemos un alma inmaterial o no la tenemos. Y por si esto no bastase, hay otro conflicto fundamental: el científico tiene el deber de esforzarse por pensar racionalmente y esto implica reservar el juicio cuando las justificaciones no sean sólidas. Y esto no es aplicable tan solo a las afirmaciones factuales, los sistemas morales compartidos por la sociedad también deben ser justificados. Es cierto que uno es libre de tener unas preferencias morales privadas, pero cuando se trata de decidir normas por las que hemos de regirnos todos no es suficiente con afirmar que a mí me parece que algo está mal porque me lo ha dicho un profeta o un libro. Las normas sociales tienen que ser el fruto de un diálogo racional sobre las justificaciones aducidas por todos. Lo contrario del laicismo es la imposición arbitraria e injustificada. En este sentido, es erróneo contraponer a la religión con la ciencia, la comparación adecuada es con la filosofía en general. Por último, nuestra visión de nosotros mismos será muy distinta si uno acepta las conclusiones científicas, somos mamíferos sociales que habitan un pequeño oasis fértil en un cosmos hostil, que si uno cree en un relato religioso que afirma que eres hijo del creador del universo y que tu relación con el mundo material es sólo tangencial. Nuestra visión sobre nuestro papel en el cosmos no debería ser ajena a la realidad. "],["agoras_cortes_y_bazares.html", "19 Ágoras, cortes y bazares 19.1 Analicemos las comunidades 19.2 Prescripciones morales 19.3 El ágora 19.4 Búsqueda de conocimiento y prestigio 19.5 Cortes y traiciones 19.6 Los problemas de Goodhart 19.7 El ideal del ágora 19.8 El bazar 19.9 Objetivismo y constructivismo 19.10 Resumen", " 19 Ágoras, cortes y bazares Los positivistas lógicos, y muchos científicos, pensaban, o todavía piensan, que en ciencia sólo importan las evidencias y la lógica, pero esta es una posición que es necesario matizar.1179 Hemos visto que la inducción presenta limitaciones fundamentales, que la observación depende, hasta cierto punto, de nuestro punto de vista y que no existe un algoritmo único para la ciencia: ni para elegir entre hipótesis, ni mucho menos, para generarlas. Todo esto implica que, aunque es posible generar conocimiento, la eficiencia del proceso dependerá, en gran medida, de los investigadores. Dado que la ciencia es un arte que exige oficio, hemos de reconocer que, al menos en parte, estamos a merced de los artesanos que lo practican y que analizar los factores psicológicos y sociológicos que influyen en la generación de conocimiento es importante. 19.1 Analicemos las comunidades Los filósofos, tradicionalmente, han centrado sus reflexiones en las fortalezas y las limitaciones de la lógica y el empirismo, pero habían ignorado el estudio de las comunidades que son las que, en última instancia, hacen la ciencia.1180 Fue Kuhn quien situó los aspectos sociológicos en el centro de la discusión y esto propició un gran desarrollo de la sociología de la ciencia durante la segunda mitad del siglo XX.1181 Las aproximaciones filosóficas, sociológicas e históricas deberían ser complementarias. Mientras que la filosofía trata de analizar cuestiones tales como qué es el conocimiento y cómo debe justificarse, la sociología y la historia estudian cómo se genera ese conocimiento en la práctica. Los sociólogos tratan de analizar cómo la estructura social de la comunidad influye en el proceso de generación de conocimiento, o, al menos, esa es la teoría, puesto que, en la práctica, muchos sociólogos concedieron tanta importancia al estudio de los factores sociales, que llegaron a concluir que estos eran los únicos relevantes. Esta es una idea típicamente constructivista y completamente opuesta a las tesis positivistas que asumían que las conclusiones científicas dependían exclusivamente de la lógica y de las observaciones empíricas. En cualquier caso, lo que resulta evidente es que, si el proceso de generación de conocimiento depende de las comunidades, resulta crítico estudiar los valores, los incentivos y la estructura de esas comunidades. 19.2 Prescripciones morales El sociólogo de la ciencia Robert K. Merton (1910-2003), en los años 40, describió los valores que, según él, deberían regir las comunidades científicas: comunismo (comunalism), universalismo, escepticismo organizado y desinterés.1182 Comunismo: los resultados de las investigaciones científicas deben ser colectivos y los derechos de propiedad intelectual habrían de ser muy limitados.1183 Esta prescripción no es demasiado sorprendente, al fin y al cabo, comunidad, etimológicamente, no significa otra cosa que poner en común. Por ejemplo, esta fue, como ya hemos comentado, una de las principales diferencias entre la alquimia, que era profundamente privada y amante del secreto, y la química moderna, que era completamente abierta.1184 Al lector poco familiarizado con los entresijos de la ciencia actual puede que esta recomendación de Merton no le llame demasiado la atención: por supuesto que el objetivo es de generar conocimiento público y libre. Sin embargo, supongo que a la mayoría de los científicos les parecerá, en el mejor de los casos, un ideal a seguir y, en el peor, una prescripción profundamente ingenua. En primer lugar, hay que reconocer que hoy en día una gran parte de la investigación aplicada es llevada a cabo por empresas privadas1185 que sólo verán con buenos ojos la difusión de aquellos resultados que no puedan ser utilizados por su competencia para generar ventajas estratégicas. En realidad, esto no es demasiado sorprendente, al fin y al cabo, la generación de conocimiento es cara y es normal que los actores privados traten de convertir esa inversión en ventajas competitivas guardando o protegiendo los resultados de sus investigaciones. Sin embargo, hay un segundo aspecto mucho más llamativo, actualmente la protección legal de los resultados financiados con dinero público también está fuertemente incentivada. Para los centros de investigación públicos esta privatización del conocimiento se ha convertido en una fuente adicional de ingresos que puede ser utilizada para cubrir una parte de sus gastos. Muchas veces me pregunto por cuál sería la opinión de los ciudadanos, que están sufragando mediante sus impuestos el grueso del coste de la generación de esos resultados, si fuesen conscientes de la prevalencia de esta tendencia. Un ejemplo actual de este fenómeno lo constituyen las guerras legales CRISPR en las que se hayan inmersas varias universidades estadounidenses. Se asume que CRISPR será una herramienta importante en genética y que las patentes relacionadas con esta tecnología podrían generar enormes dividendos, por lo que estas universidades pretenden convencer a la judicatura de que dieron el paso definitivo en un proceso de investigación que, al fin y al cabo, es comunitario, complejo y que abarcó muchos laboratorios repartidos por todo el mundo. La siguiente de las prescripciones de Merton es el universalismo: las ideas deben ser juzgadas independientemente del origen, sexo, religión o cualquier otra condición de su proponente.1186 El conocimiento ha de ser impersonal y universal, no puede existir una ciencia cristiana y otra atea o negra o blanca. Nuestros modelos sobre el mundo externo son conocimiento o no lo son dependiendo de la medida en la que se corresponden con ese mundo, no de nuestra perspectiva. Las bolitas caen por los planos inclinados tal y como describió Galileo o no lo hacen y esto puede ser evaluado independientemente de si Galileo era blanco o negro, hombre o mujer, barbudo o lampiño o calvo o melenudo. Para juzgar la bondad de la cinemática galileana tan sólo necesitamos un plano inclinado, una bolita, un instrumento de medida y conocimiento matemático. Esta es una característica fundamental, aunque también es cierto que hemos de reconocer que no todas las ideas generadas por las comunidades científicas son tan independientes de los factores sociales ni pueden ser evaluadas con la misma sencillez. Sería un error enorme creer que todas las propuestas etiquetadas como científicas gozan del valor epistémico de la cinemática del pisano. Como iremos viendo a lo largo de este capítulo y del próximo, algunos resultados científicos sí dependen fuertemente de factores psicológicos y sociales y, por lo tanto, podrían no ser tan universales. 19.3 El ágora La tercera de las recomendaciones de Merton puede que sea la más importante: el escepticismo organizado. Este es un valor socrático compartido por todas las comunidades filosóficas clásicas más relevantes. Recordemos las palabras atribuidas a Aristóteles: mi maestro es mi amigo, pero la verdad me es más querida. Casi todos los pensadores que han reflexionado sobre la generación del conocimiento han concluido que esta es la cuestión clave. John Stuart Mill, por ejemplo, escribió que la mejor ciencia resulta de la crítica comunitaria.1187 En primer lugar, el científico debe ejercer la autocrítica y, en segundo, ha de entablar un diálogo racional con los demás para tratar de superar sus propias limitaciones. Tal vez, lo más relevante no es que la ciencia consiga avanzar, sino que lo haga a pesar de las limitaciones intelectuales de sus practicantes. Recordemos que no hace tanto que los antepasados de Galileo o Newton todavía eran supersticiosos cazadores-recolectores.1188 El diálogo racional es, precisamente, la herramienta más efectiva para superar las limitaciones cognitivas que tenemos seres humanos tenemos. Gracias a este diálogo conseguimos alcanzar conocimiento objetivo,1189 o, al menos, intersubjetivo, sobre arcanos aspectos del cosmos. Para referirse a esta idea algunos autores hablan de crítica racional, de comunidades críticas o, como Merton, de escepticismo organizado. Es importante recordar que cuando recomendamos crítica racional no estamos pidiendo que se critique a los demás, sino que tratemos de criticar nuestras propias ideas, y las de los demás, para encontrar sus debilidades. El objetivo no es denigrar a los demás, sino avanzar juntos. Como alternativa podríamos utilizar el término discusión racional, sin embargo, yo prefiero diálogo racional ya que “diálogo” no implica enfrentamiento, como sí lo hace “crítica”, o desconfianza, como podría hacerlo “escepticismo”. Aunque es cierto que la crítica y el escepticismo son necesarios, lo son, antes contra nuestras creencias que contra las de los demás. Además, lo fundamental es que el diálogo sea racional, así que carece de sentido criticar sin aportar argumentos sólidos. Tan sólo tendríamos que plantear una crítica cuando ésta sea justificada. El pensador racional no ha de criticar con el ánimo de denigrar, sino con el de progresar en la búsqueda común de lo racional.1190 Sin embargo, este no es el sentido habitual del término “crítica”. En una discusión racional, a diferencia de en un debate común, los contrincantes no tienen por objeto ganar la contienda, sino construir colectivamente la posición más racional posible utilizando los mejores argumentos expuestos durante el diálogo. Si en algún momento nos sorprendemos a nosotros mismos buscando formas de desacreditar al rival habremos de recapacitar puesto que estaremos alejándonos de la racionalidad. Los científicos, como el resto de los humanos, nos equivocamos continuamente, por lo que debemos agradecer el esfuerzo que hacen nuestros críticos racionales en pos de aliviar nuestros errores. Esto, por supuesto, no implica que todas las puntualizaciones que nos planteen nuestros críticos vayan a ser meritorias; en algunos casos puede que seamos nosotros quienes tengamos razón. Además, tampoco estamos obligados a prestar atención a la opinión de cualquier crítico; nuestro tiempo es limitado y, por desgracia, es demasiado común encontrar personas que no se han esforzado lo suficiente por conocer el fenómeno estudiado y por ser autocríticas. Por otro lado, a pesar de que existe un espectro continuo entre el escéptico razonable y el negacionista, es importante distinguirlos.1191 El crítico razonable mostrará una buena disposición a resolver la diferencia de opinión1192 y aceptará que su conocimiento es incompleto, mientras que el negacionista suele tener una confianza absoluta en sus posiciones1193 por lo que ninguna evidencia le hará cambiar de opinión.1194 En ciencia es la comunidad la que progresa, pero no hemos de pensar que todas las comunidades acumularán conocimiento al mismo ritmo. Frente al ejemplo del ágora podríamos plantear el de la catedral. Los grandes teólogos dedicaron un gran esfuerzo a reflexionar sobre sus posiciones y, aun así, durante siglos siguieron discutiendo sobre banalidades, como el modo en el que se combinan las tres personas divinas en la Santísima Trinidad. ¿Cómo es posible que pensadores tan rigurosos y excelsos como Tomás de Aquino dedicasen una gran parte de su precioso tiempo a reflexionar sobre cuestiones equivalentes al tono preciso que tendrá la iridiscencia de la cola del gran Poni Rosa? Para que una comunidad avance eficientemente en el estudio de cualquier cuestión, es muy importante que se comprometa con el diálogo racional.1195 Las comunidades deberían fomentar el diálogo racional como el modo principal de cambiar sus ideas, pero, por desgracia, no todas lo hacen.1196 Además, la actitud individual del científico tiene que ser la de optar por la integridad intelectual radical y esto implica, entre otras cosas, la autocrítica. Richard Feynman recomendaba que la exposición de los resultados e hipótesis debía siempre acompañarse de sus limitaciones. Por ejemplo, si una teoría es capaz de explicar la mayoría de las evidencias, esto debería contarse, pero, también, habría que enumerar que otros datos la contradicen.1197 Platón, que estaba comprometido con esta actitud, siempre acompañaba sus propuestas de la lista de problemas que no había conseguido solventar. Tal era su grado de autocrítica que en la actualidad los filósofos todavía discuten si el gran filósofo defendía realmente una metafísica platónica. Platón no estaba interesado en tener razón, sino en avanzar el conocimiento filosófico y esto lo convierte, independientemente de que sus conclusiones tentativas hayan sido descartadas o no, en una de las referencias fundamentales tanto para los filósofos, como para sus discípulos más interesados por el estudio del mundo natural, los científicos. Entre los científicos también hay grandes ejemplos de esta actitud. Darwin en El origen de las especies incluyó dos capítulos completos dedicados a explicar los problemas de su propia teoría: Dificultades de la teoría y Objeciones a la teoría de la selección natural. Este, claro está, no es el modo en el que solemos funcionar los seres humanos en general. Ni tampoco los científicos que, en muchos casos, lo que tratamos de conseguir en nuestros artículos es publicitar nuestras ideas para que sean aceptadas por la comunidad. La autocrítica racional es una virtud a la que aspirar, no un comportamiento natural en los seres humanos, por lo tanto, la comunidad debería reconocer e incentivar el esfuerzo por la autocrítica y castigar la propaganda.1198 En cualquier caso, hemos de recordar que, aunque nos esforcemos por ser autocríticos, lo máximo a lo que podemos aspirar es a pulir nuestras ideas utilizando nuestros propios filtros internos, que siempre serán mucho más limitados que los disponibles en la comunidad en su conjunto. Por este motivo, una vez que hayamos examinado nuestras propuestas con rigor tenemos el deber de exponerlas al escrutinio público, no sólo esperando que sean aceptadas, sino con la esperanza de que alguien realice críticas justificadas de las que podamos aprender.1199 En las comunidades científicas existen mecanismos institucionales que tratan de favorecer la discusión racional. Tal vez el más famoso de ellos sea la revisión por pares. En principio, un grupo de expertos revisa los artículos científicos antes de que se publiquen. Es común escuchar que esta revisión es la clave del avance científico. Sin embargo, casi cualquier científico os dirá que el proceso es menos glamuroso de lo que suele pensarse. Creo que lo único que puede esperarse de la revisión por pares es que consiga purgar los errores más llamativos, por lo que no debemos asignar a los artículos revisados un marchamo especial que los acredite como verdades científicas. Incluso me atrevería a decir que, en muchos casos, los revisores llegan incluso a empeorar el manuscrito original puesto que hacen críticas inmerecidas que los autores aceptan para no disgustar a quienes pueden decidir si su trabajo ha de ser aceptado. Además, es muy importante recordar que lo que se publica, por muy revisado que esté, no tiene por qué ser cierto ni haber alcanzado nada parecido a la verdad; la publicación en una revista sólo es un paso más en el proceso de evaluación comunitaria. En la actualidad el proceso de publicación científica, que llevaba tiempo sin sufrir cambios sustantivos, está inmerso en una transformación muy rápida. La realidad es que actualmente la mayoría de los artículos se hacen públicos en servidores de pre-publicaciones como ArXiv antes de ser revisados. Más tarde, algunos de ellos, esperemos que los más meritorios, son revisados y publicados por revistas más o menos tradicionales. Lo bueno de este nuevo sistema es que permite a los científicos del área disponer de esos resultados antes de ser publicados oficialmente por las revistas, que suelen tardar meses en revisar y aceptar los artículos. Voy a dar un ejemplo que puede ilustrar algunas deficiencias del sistema de revisión por pares. Heng Li es unos de los investigadores más destacados en mi área de trabajo, la bioinformática relacionada con la genómica. Según la Wikipedia dos de sus artículos, el de las SAMtools y el del mapeador BWA han sido citados más de 16.000 veces.1200 En 2013 Li envió el manuscrito Aligning sequence reads, clone sequences and assembly contigs with BWA-MEM a la revista Bioinformatics. La revista, siguiendo el procedimiento clásico, lo remitió a tres revisores expertos y, tras recibir las respuestas, Li entró en cólera. El cabreo de los autores tras recibir las revisiones es bastante habitual, pero no es tan común que el investigador haga pública su opinión al respecto1201 y mucho más extraño aún es que decida no publicar el artículo. Según Li el primer revisor aceptó al artículo proponiendo un par de pequeños cambios. Esto, en el gremio, se interpreta como una palmadita en la espalda. El segundo revisor, también según Li, cometió errores elementales en su revisión y, además, fue completamente hostil. Esto, por desgracia, es bastante habitual, hay que tener en cuenta que las comunidades científicas, como todas las demás, están llenas de pequeñas y grandes rencillas personales, que el proceso de revisión suele ser anónimo, por lo que es una gran oportunidad de clavar un puñal por la espalda, y que, además, el revisor puede que no sea especialmente brillante. Por último, el tercer revisor intentó que Li incluyese en su artículo una comparación con otra herramienta que, según Li, era muy inferior. No conozco el motivo de esta sugerencia, pero también es bastante común que los revisores traten de influir en el autor del trabajo revisado para que incluya referencias a artículos previos del propio revisor. Además, Li reconoce haberse sentido especialmente molesto al leer que un revisor le acusaba de deshonestidad científica. No sé si este tipo de acusaciones son normales, pero a mí un revisor me acusó de plagio y cuando le pedí que me indicase qué parte había copiado cambió su discurso y me acusó de no saber inglés. A pesar de la gravedad del asunto, la falsa acusación no tuvo consecuencias puesto que el revisor era anónimo y el editor de la revista lo dejó pasar sin más. Heng Li, sin embargo, decidió hacer algo inaudito, hizo pública su opinión sobre el desastre, renunció a publicar el artículo y recomendó que se citase la copia que había subido originalmente al servidor de pre-publicaciones.1202 Hay que tener en cuenta que, en ese momento, Li ya era una de las figuras más importantes del campo, por lo que tener una publicación más o menos no era tan crítico para su carrera. Supongo que el editor de Bioinformatics debió pasar una temporada debajo de una piedra para recuperarse del incidente; BWA-MEM acabó convirtiéndose en una herramienta fundamental y ha sido citado, según Google Scholar más de 3500 veces. Espero que esta anécdota le sirva al lector para hacerse una idea de cómo suele funcionar en la práctica la, a veces mitificada, revisión por pares. Últimamente, para evitar estas situaciones, hay revistas que han adoptado la política de hacer públicos tanto los nombres de los revisores como las propias revisiones. Aunque esta forma de proceder tiene ventajas, tampoco está exenta de problemas. Yo he hecho revisiones públicas y, en esos casos, eres muy consciente de que incluso una crítica honesta y justificada puede cabrear a alguien que, en algún momento, puede que tenga poder de decisión sobre el destino de tus artículos o de tu financiación. Pero dejemos la revisión por pares para mencionar otro mecanismo de crítica mucho más informal y menos conocido, pero que es común en algunos grupos de investigación y que me llamó poderosamente la atención cuando empecé mi carrera: el journal club. La idea es hacer reuniones regulares para comentar y criticar los trabajos más relevantes publicados recientemente. El objetivo es entrenar el espíritu crítico buscando las limitaciones de los mejores artículos. ¿Os imagináis cómo debe de ser dar un seminario exponiendo tu trabajo a un grupo de personas que se reúne regularmente para buscar las limitaciones de las mejores investigaciones del área? Platón se sentiría orgulloso. 19.4 Búsqueda de conocimiento y prestigio Comentemos ahora la última de las recomendaciones de Merton, el desinterés. Es innegable que uno de los objetivos de los científicos es la búsqueda del conocimiento.1203 Henry Cavendish, el físico y químico del XVIII que pesó la Tierra y averiguó la composición del agua y del aire, es uno de mis investigadores favoritos. Como misántropo que era no parece que Cavendish estuviese muy interesado por mejorar su posición en la comunidad y, además, tampoco parece que le preocupasen las posibles aplicaciones prácticas de sus investigaciones, de hecho, ni siquiera se molestó en publicar la mayoría de sus descubrimientos. Su motivación parece haber sido, únicamente, el estudio de los fenómenos que le fascinaban. El neurólogo Oliver Sacks propuso que este interés puro, tal vez, estuviese relacionado con que Cavendish fuese autista.1204 Aunque, es necesario recordar que, dado que el trastorno fue etiquetado por Asperger por primera vez en 1938, habría sido imposible diagnosticar a Cavendish con esta condición. (Por cierto, si no has leído nada de Sacks, estás de enhorabuena porque tienes la oportunidad de descubrir a un autor fabuloso). El amor por la investigación también está relacionado con la pasión que los trabajos creativos inspiran en muchas personas. El proceso de creación es, para muchos, uno de los pilares de su realización personal. Merton alababa este desinterés y recomendaba que los investigadores no tuviesen como objetivo obtener beneficios personales o medrar en la comunidad;1205 aunque, como era de esperar, también reconocía que la mayoría de los científicos no son Cavendish y que no pueden comprenderse las dinámicas de las comunidades científicas sin asumir que hay otras motivaciones mucho menos elevadas en juego, especialmente la búsqueda del prestigio.1206 Al fin y al cabo, las comunidades científicas están compuestas por mamíferos sociales y entre éstos Cavendish es una excepción. El filósofo de la ciencia Philip Kitcher habla de investigadores epistémicamente puros, es decir, motivados únicamente por la pasión del conocimiento1207 y de científicos más o menos impuros ya que, además de estar interesados por la búsqueda del conocimiento, también persiguen el prestigio personal. Para un mamífero social la reputación es un bien preciado y haremos bien en recordar que los investigadores están jugándose, en todo momento, su posición dentro de la comunidad y que, además, son muy conscientes de que su carrera depende de ello. Hay algunos científicos, muy pocos, más cercanos al ejemplo de Cavendish, a otros les motiva, principalmente, el prestigio, y la mayoría se encuentra en una posición intermedia. Si en algún momento quieres cabrear a un científico dile que su posición entre los firmantes de uno de sus artículos fue inmerecida. Ojo, no te atrevas a sugerir que no mereció haberlo firmado; si lo haces te expones a ser asesinado en el acto. Para muchos científicos hay pocas cosas más importantes que el orden de firma en los artículos. Para que se entienda por qué esto es tan relevante, tal vez deba explicar que implica el orden de firma. Los artículos, en la mayoría de los casos, son fruto de la colaboración de varios investigadores y, cuando se publican, la contribución de todos ellos se reconoce gracias a su firma. Además, y esto es muy importante, el orden de esas firmas no es casual, está estrictamente regulado en la comunidad. Habitualmente, el primer firmante es el que más trabajo experimental ha hecho y el último el que ha dirigido el trabajo. Las discusiones por ocupar estos dos puestos suelen ser causa de monumentales peleas y de enemistades que se recuerdan durante décadas. Como muestra de la importancia que se les atribuye a estas firmas mencionaré una anécdota reciente. Un compañero y yo decidimos no firmar una publicación en la que habíamos participado porque no estábamos de acuerdo ni con la metodología empleada ni con algunas de sus conclusiones. Esto debería ser aceptado con normalidad en una comunidad académica, pero en el Instituto se nos llegó a decir que era una extravagancia no firmar un artículo que iba a publicarse en una revista prestigiosa simplemente por no estar de acuerdo con el resultado. En todo caso, incluso para los científicos menos interesados por su reputación, ésta conlleva unas implicaciones fundamentales. De tu reputación dependerán tu carrera profesional, tu financiación, y, por lo tanto, la viabilidad de tu investigación y la estabilidad del personal de tu laboratorio, así como la atención que te dedique el resto de la comunidad. Desde un punto de vista epistemológico la preocupación por el prestigio, en principio, no tendría por qué ser relevante, pero el problema surge porque hay una tensión clara entre la preocupación por la posición social y el rigor intelectual. Interesarse por el prestigio no tendría por qué ser problemático, pero convertir esta motivación en el objetivo principal sí lo es.1208 Los incentivos asociados con el prestigio presionan en favor de la rebaja del nivel de rigor y autocrítica y del aumento de la autopromoción y la propaganda. La tentación de olvidar el ejemplo de Platón o Darwin es enorme en entornos muy competitivos. Además, a esta presión por publicar hemos de añadirle unas evaluaciones de las carreras científicas que, en muchos casos, son muy superficiales y que incentivan la publicación de trabajos apresurados y de mala calidad.1209 19.5 Cortes y traiciones Entre los mamíferos sociales una forma prácticamente segura de comprometer tu posición jerárquica es molestar a tus pares o a tus superiores. Basándonos en nuestros instintos sociales los seres humanos hemos creado complejas estructuras como familias, clanes, grupos de amigos, tribus, naciones o comunidades científicas. Entre los escépticos actuales, que se caracterizan por su defensa de la racionalidad, suele decirse que las ideas han de ser criticadas sin atacar a la persona que las defiende. Esta, al menos, es la teoría, en la práctica los humanos solemos interpretar los ataques a nuestras ideas como ofensas personales, especialmente si las creencias cuestionadas nos son muy queridas o forman parte de nuestra identidad. El diálogo racional entraña crítica y, por lo tanto, en cierto modo traición. La palabra traición se originó a partir de la latina traditio (entrega, transmisión). Traición, por lo tanto, hace referencia a la entrega de algún bien o ventaja al otro bando, al enemigo. El crítico está dando argumentos a los rivales y, por lo tanto, está traicionando al grupo. Lo de la integridad intelectual radical puede quedar muy bien como lema para una camiseta, recordemos, “mi maestro es mi amigo, pero la verdad me es más querida”, pero lo cierto es que los atenienses no se tomaron demasiado bien el continuo cuestionamiento al que los sometió Sócrates. Por lo tanto, curiosa comunidad es aquella que pretende construirse sobre el fomento de la traición. Un ilustrado podría aducir que cuando un amigo ayuda a otro a salir de su error no lo está traicionando, sino todo lo contrario, pero eso no es tan fácil de digerir para un mamífero social jerárquico. Reconozcámoslo, incluso Kirk, en el siglo XXIII, tenía que hacer un acopio continuo de paciencia para aguantar a Spock. Tengo la impresión de que los científicos estamos más acostumbrados a la crítica que otros profesionales y creo que esto suele causarme problemas con mis conocidos. Cuando estoy con mis amigos o mi familia, por ejemplo, tiendo a aplicar la actitud de crítica desapasionada, pero implacable, que cultivamos en nuestro laboratorio y eso no siempre es bienvenido por todo el mundo. Supongo que quienes me rodean deben de hacer un esfuerzo por aguantarme, aunque, aun así, al final, algunos acaban perdiendo la paciencia. Sin embargo, tampoco hemos de pensar que los científicos somos seres ultrarracionales que disfrutamos siendo criticados. Yo todavía siento una punzada en mi orgullo cada vez que un colega señala un fallo en uno de mis trabajos. Es posible que un investigador concreto pueda llegar a acostumbrarse a la crítica en mayor o menor grado, pero eso no implica que no le duela emocionalmente. Además, recordemos que en las comunidades científicas hay mucho más en juego que las emociones de los investigadores. La aceptación de tus artículos, tu presencia en congresos relevantes y la financiación de tu laboratorio dependen, en un grado muy importante, de tu prestigio en la comunidad, y criticar severamente a tus compañeros, incluso de forma justificada y con la mejor de las intenciones, no es el modo más directo de trabajar en favor de ese prestigio. Es mucho más sencillo llegar a ser querido esforzándote por ser agradable, por ejemplo, sonriendo y adulando en las pausas para el café de los congresos, que haciendo críticas demoledoras, especialmente si las críticas se dirigen a investigadores muy relevantes en el área. Me atrevería a afirmar que, en mi área y supongo que en otras, hay numerosos científicos que disfrutan de carreras, más o menos mediocres, gracias a su buen hacer durante esas pausas para el café. Tengo la impresión de que el nivel de crítica en las comunidades científicas en las que me he movido ha ido descendiendo a lo largo del tiempo. En los últimos años he llegado a escuchar afirmaciones claramente pseudocientíficas, por ejemplo, sobre los alimentos funcionales o sobre la agricultura ecológica, en congresos relevantes y estas afirmaciones no han sido cuestionadas por nadie, ni siquiera por mí que estaba presente y profundamente molesto. ¿Por qué no dije nada? Porque incluso yo, que soy casi un paria social, tengo inhibiciones psicológicas a la hora de iniciar una discusión delante de 400 expertos que han preferido callarse. Pero cuando en un congreso científico ni siquiera se critica la pseudociencia o, lo que todavía es peor, cuando se promociona, algo muy negativo está sucediendo. Creo que este descenso del nivel de crítica se debe a que los investigadores son plenamente conscientes de que criticar genera enemigos. Últimamente cuando reflexiono sobre las comunidades científicas lo que me viene a la mente no es un grupo de pensadores racionales discutiendo en el ágora a la sombra de la estoa, sino, más bien, un conjunto de serviles cortesanos peleándose por migajas de poder en las cortes de los reyes absolutistas. Las necesidades de mantener la carrera profesional y la financiación promueven el favoritismo y las distorsiones ideológicas.1210 Los modos en los que afecta al científico su posición en la jerarquía comunitaria son muy variados y permean por completo su quehacer cotidiano. Por un lado, la cantidad de atención disponible en una comunidad es limitada, se publica muchísimo más de lo que puede leerse y en los congresos sólo unos pocos pueden ser oídos. Esto hace que estar a buenas con los editores de las revistas más prestigiosas y con los organizadores de los congresos más relevantes sea vital para el desarrollo de una carrera científica. Las ideas deberían ser atendidas en función de su valía, pero, en la práctica, tu posición en la comunidad tiene una gran influencia en las decisiones relativas a las publicaciones. Y lo que es aún más importante, la decisión sobre cómo se distribuye la financiación depende, en una medida sustancial, de la posición en la comunidad y esto inhibe la crítica puesto que nadie quiere enemistarse con quien, en el futuro, pueda decidir sobre tu financiación. Un aliado o un buen contacto pueden facilitar la financiación, son capaces de propiciar una firma en un artículo importante o una revisión tolerante de uno de tus manuscritos. Mientras que una discusión, por muy racional que uno intente ser, te expone a futuras represalias. Criticar tiene un coste y aunque, en teoría, los científicos tengamos el deber de agradecer la crítica racional, los humanos no solemos ser tan ecuánimes, especialmente cuando nuestras carreras están en juego. El escritor socialista estadounidense Upton Sinclair dijo una vez: “Es difícil hacer que una persona entienda algo cuando su salario depende de que no lo entienda”. Yo, en bastantes ocasiones, me he enfrentado en mi carrera al dilema de criticar una actitud o una hipótesis sostenida por un científico muy relevante en la comunidad y he sido perfectamente consciente de que eso iba a tener un efecto negativo en mi carrera. Además, dada la enorme presión por publicar, seguir el ejemplo de Platón y Darwin y exponer las limitaciones de tu investigación, aunque es un deber deontológico, en la práctica, está desincentivado. Un artículo que expone sus propias debilidades tiene menos posibilidades de ser aceptado que un trabajo que sólo enumere las virtudes de los resultados descritos. Reto a cualquier científico a revisar el último número de la revista más importante en su área y contar cuántos artículos siguen el ejemplo platónico. Cuando la autocrítica entra en conflicto con la financiación, la tentación de no escribir esos párrafos críticos es difícil de ignorar. Hace poco un grupo de jóvenes investigadores me invitó a dar una charla en un congreso para doctorandos. Les expliqué que a lo largo de su carrera se enfrentarían a una tensión continua entre la integridad intelectual y la tentación de la mala ciencia y les detallé algunos de los mecanismos técnicos, como, por ejemplo, el p-hacking, que iban a utilizar, casi sin darse cuenta, para sesgar la balanza en favor de la mala ciencia. Después de la charla muchos me comentaron que era la primera vez que alguien les hablaba sobre este problema y que por fin entendían la discrepancia que habían detectado entre lo que se les explicaba que debían hacer, por ejemplo, en los cursos de estadística, y lo que se les pedía que hiciesen para poder presentar sus tesis doctorales con un número suficiente de publicaciones. Aunque todos me dijeron estar muy agradecidos por la reflexión compartida, me pregunto en qué medida les influyó. Una de las consecuencias de estos incentivos perversos es que muchas instituciones científicas se comportan más como publicistas que como intelectuales rigurosos, están más cerca del ejemplo de P. T. Barnum, el empresario circense, que de Platón. La tentación de maquillar un resultado para que sea más llamativo no es desdeñable y, además, la psicología humana típica está diseñada para que consideremos que nuestro desempeño es superior al real. Recordemos que la mayoría de los conductores creen conducir mejor que la mayoría de los conductores, algo que es, obviamente, imposible. Es decir, no sólo estamos incentivados para exagerar nuestros resultados, sino que estamos diseñados para hacerlo. Uno de los efectos de la inhibición de la crítica y del fomento de la autopromoción es la publicación de trabajos mediocres o defectuosos. Creo que en ciencia también es aplicable la ley de Sturgeon: el 90% de lo que se genera en cualquier área es basura. A pesar de esto, seguramente engañar al resto de expertos no sea tan fácil, pero cuando se trata de comunicar los resultados al público general muchas de las oficinas de prensa de los centros de investigación parecen compartir la máxima atribuida a Barnum: “Cada minuto nace un idiota”. Yo me crie con Sagan, pero hoy en día cuando leo las noticias científicas en los medios de comunicación generalistas, dado el nivel de exageración, parto de la posición de que mucho es, cuanto menos, engañoso. En divulgación, confío en muy pocas fuentes. La generación de conocimiento y la sociedad en su conjunto tienen unas relaciones cada vez más complejas. Por ejemplo, los organismos financiadores, normalmente, eligen qué temas deben ser investigados. Está claro que quien paga debería beneficiarse de los resultados de la investigación y esto suele traducirse en que los organismos financiadores tienen una gran influencia en el abanico de temas a investigar. Esto, hasta cierto punto, no sólo es aceptable, sino deseable. Es normal que un organismo tenga la capacidad de decidir si le interesan más el cáncer, las energías no contaminantes o el comportamiento sexual de los camarones. Los valores sociales deben ser tenidos en consideración, especialmente cuando los financiadores son los contribuyentes.1211 Sin embargo, esto conlleva un problema, el público general no es experto y puede decidir que se investigue sobre alguna cuestión que no le beneficiará. Por ejemplo, en mi área los organismos europeos y locales financian la agricultura pseudoecológica, una agricultura que sabemos que tiene un mayor impacto ecológico que la agricultura convencional, puesto que requiere más tierra, y que, además no puede alimentar a la humanidad puesto que renuncia al uso de fertilizantes de síntesis química. Esta es una conclusión admitida por la mayor parte de los expertos. Sin embargo, las instituciones públicas financian la investigación de esta vía absurda con la esperanza de estar favoreciendo el medioambiente, algo que sabemos que no está sucediendo. Los científicos deberían comportarse con independencia de los organismos financiadores, pero la tentación de renunciar a la integridad intelectual a cambio de un puesto de trabajo o de una financiación que permita continuar con tus investigaciones es evidente. Esto conlleva un efecto adicional, muchos expertos temiendo que la crítica pública a ideas socialmente aceptadas, como la agricultura pseudoecológica, vaya a acabar con su financiación deciden callarse. Incluso, quienes son conscientes de que este no es el camino correcto para reducir el gran impacto ecológico de la agricultura, deciden bajar la cabeza y callarse para poder seguir pagando al personal de su laboratorio. El científico tiene el deber de criticar las ideas equivocadas sostenidas por la sociedad en la que está inmerso.1212 Sin embargo, cuando este deber entra en conflicto con la financiación, la tentación de traicionar el espíritu socrático y de convertirse en un sofista es grande. Todos somos conscientes de que morder la mano de quien te da de comer tiene consecuencias desagradables. Esto es, por supuesto, una traición, no sólo al rigor intelectual, sino al propio público que confía en la integridad de los investigadores. Además, el deber de los científicos no es equiparable al de otros miembros de la sociedad, dados nuestro papel ejemplar y la confianza que se deposita en nosotros, nuestra responsabilidad es mucho mayor.1213 Algo similar sucede cuando es la industria la que paga la investigación, los estudios resultantes suelen tener un sesgo hacia los resultados favorables.1214 Este es un efecto esperable, pero inaceptable; una vez obtenida la financiación las únicas cuestiones relevantes deberían ser las epistémicas.1215 En todo caso, a pesar de que creo que estos problemas existen, no me gustaría que el lector se quedase con la idea de que las comunidades científicas están completamente podridas. Sí, pienso que la inhibición a la crítica es un problema serio, pero, al mismo tiempo, opino que, aunque la estructura y los incentivos presentes en las comunidades científicas en las que he participado podrían mejorarse, también hay que reconocer los aspectos positivos, como el reconocimiento de la excelencia intelectual. Tan sólo quiero hacer notar que, por desgracia, el grado de excelencia científica no es la única fuerza que opera en estas comunidades. 19.5.1 Tradición Otro de los sesgos principales a los que se enfrenta el investigador racional es el excesivo respeto a la tradición. Es curioso que traición y tradición compartan etimología. La traición hace referencia a las entregas al enemigo, la tradición honra lo que nuestros predecesores nos entregaron. El respeto a la tradición no tiene por qué ser negativo; mientras no dispongamos de evidencias adicionales seguir la tradición es una idea excelente; al fin y al cabo, si algo funcionó bien en el pasado, y no tenemos motivos para dudar de ello, es posible que siga funcionando ahora. Las comunidades científicas suelen ser bastante conservadoras y está bien que lo sean. Ya hemos comentado previamente que, en este aspecto, Kuhn estuvo mucho más acertado que Popper. Mientras el primero sostenía que los científicos durante las épocas de ciencia normal funcionan asumiendo unas teorías como ciertas, el segundo abogaba por la crítica continua mediante la falsación. La tradición sólo se convierte en un problema cuando nos impide evaluar los nuevos datos con justicia. Por ejemplo, en el siglo XIX asumir que la tradición newtoniana era la mejor forma de describir el movimiento de los planetas era racional, pero habría sido irracional negar en el siglo XX que la teoría relativista era empíricamente más fuerte, que era capaz de explicar más fenómenos, y que, además, las evidencias que podían distinguir ambas propuestas favorecían a la segunda. No creo que las comunidades científicas actuales suelan respetar la tradición en exceso. Es cierto que los científicos suelen ser muy conservadores, pero no suelen estar enamorados del pasado. Los problemas aparecen cuando en una comunidad se exige más respeto a la tradición que a las evidencias. Esto es común, por ejemplo, en las comunidades religiosas. 19.6 Los problemas de Goodhart Dado que en las comunidades científicas existen dinámicas sociales que dificultan la generación del conocimiento, el estudio de las mismas, en un mundo ideal, debería conducir al desarrollo de un conjunto de incentivos capaz de favorecer las mejores actitudes. Los incentivos influyen en el comportamiento de los individuos y esto, a su vez, debe de afectar a la eficiencia del proceso de generación de conocimiento. Es muy posible que haya conjuntos de incentivos mejores que otros y, además, es evidente que hay incentivos perversos, por lo tanto, sería importante implementar incentivos que promuevan la discusión racional. Además, dado que nuestra naturaleza social tiende a interpretar la crítica como una traición, creo que siempre será necesario favorecer incentivos que promuevan activamente la defensa de la discusión racional. Puede que la clave consista en establecer incentivos que alineen los intereses individuales de los investigadores con los objetivos epistémicos. El problema es que no es fácil definir cuáles habrían de ser estos incentivos ya que las consecuencias que pueda llegar a tener un incentivo concreto no tienen por qué corresponderse con nuestra intención inicial. Es habitual que, en una organización compleja, ya sea esta una entidad pública o una gran empresa, el objetivo que guio la implantación de unos incentivos y el resultado conseguido finalmente no estén completamente alineados.1216 Por ejemplo, un modo habitual de establecer incentivos que no sucumban fácilmente a la influencia de los individuos más poderosos es establecer objetivos basados en variables mensurables y cuantitativas. Estos indicadores suelen medir resultados deseables de un modo más o menos objetivo y se convierten en objetivos para los miembros de la organización.1217 Por ejemplo, un gestor puede tratar de mejorar la calidad de los resultados científicos exigiendo que se consideren índices bibliométricos cuantificables cuando se contrata a un investigador. Suelen medirse, por ejemplo, el número de artículos que publican los investigadores y el número de citas que reciben. El problema es que estos incentivos bienintencionados generan algunos resultados perversos ya que promueven que los investigadores se aprovechen de los resquicios del sistema publicando numerosos artículos de mala calidad que, además, tratarán de vender como si fuesen maravillosos. Este es un problema recogido por el principio de Goodhart: cuando una medida se convierte en un objetivo, deja de ser una buena medida.1218 Una vez que se recompensa un indicador concreto, la gente suele encontrar el modo de aumentar esta medida, independientemente de que mejore lo que se pretendía originalmente. Por desgracia la distorsión y la corrupción son habituales cuando los indicadores cuantitativos se convierten en objetivos. Dados estos problemas, algunos investigadores proponen sustituir en las evaluaciones de las carreras científicas las medidas objetivas por el criterio de un comité de expertos del área. En mi opinión, esto sería todavía más problemático; no quiero imaginarme qué sucedería en un sistema completamente endogámico y trufado de redes clientelares, como el de la universidad española, si no hubiese medidas cuantitativas. 19.7 El ideal del ágora A pesar de estos problemas, puede que las comunidades científicas, junto con algunas filosóficas, sean las agrupaciones humanas más cercanas al ideal representado por las ágoras que construyeron Platón y Aristóteles. Los científicos discutimos muchísimo. Conviene recordar que convencer a la comunidad de la validez de una crítica a una teoría establecida es una forma excelente de incrementar el prestigio científico. Además, los científicos somos muy dados a embarcarnos en discusiones bizantinas sobre los detalles más nimios. Por ejemplo, la cuestión del tamaño de los tomates mesoamericanos neolíticos ha llegado a suscitar en mi entorno enemistades personales. Sin embargo, a pesar de que esto es cierto, también es importante recordar que hay presiones que desincentivan la crítica y que las comunidades que valoran la discusión racional son excepciones que debemos cuidar. Ojalá amar más a la verdad que al grupo fuese fácil, pero no lo es. Alice Dreger se pregunta en Galileo’s middle finger si podremos rescatar nuestras comunidades de los incentivos perversos de las publicaciones, las notas de prensa y la financiación y yo comparto su preocupación.1219 Esta discusión sobre los incentivos me parece relevante puesto que creo que el grado en el que el diálogo racional es bienvenido en una comunidad está muy relacionado con la eficiencia en la generación del conocimiento. Cuanto más racionales seamos más conocimiento generaremos. En el extremo opuesto, una comunidad rendida por completo a la humana tendencia del respeto al superior jerárquico correrá el riesgo de terminar adorando al Gran Poni Rosa y, como en la serie de Chernobyl, negando haber visto grafito a pesar de que el reactor a explotado. En cualquier caso, es fundamental defender y promocionar, tanto dentro de las comunidades científicas, como en la sociedad en general, el valor del diálogo racional, el ejemplo del ágora. De hecho, tal vez esta sea la aportación más valiosa que la ciencia pueda hacer a la sociedad.1220 Es cierto que es más fácil vender un móvil de última generación que transmitir el gusto por el diálogo racional, pero la sociedad en su conjunto tendría que tomar a las comunidades científicas como ejemplo1221 y éstas, a su vez, habrían de tomarse muy en serio su papel ejemplar. El científico debería asumir su compromiso con las evidencias empíricas y la lógica. De hecho, esto es, simplemente, lo que se espera de un verdadero intelectual.1222 Por supuesto, sería ingenuo ignorar que parte de este compromiso implica asumir las consecuencias que pueda conllevar la autocrítica y la crítica racional, tanto dentro de la comunidad científica, como en la sociedad en su conjunto, pero cualquier investigador que no se rija por estos principios no es más que un impostor y un sofista que está aprovechándose del prestigio social de la ciencia para medrar. Feynman, para describir a los compañeros que optan por traicionar el código deontológico, echaba mano de la imagen de los cultos del cargo (cargo cult ).1223 Los cultos del cargo, o del cargamento, aparecieron en Nueva Guinea después de la segunda guerra mundial. Algunas de las personas que vivían allí nunca habían tenido contacto con el mundo tecnológicamente desarrollado y, de repente, durante un tiempo, vieron como máquinas aparentemente mágicas, los aviones del ejército, traían cargamentos maravillosos a sus islas. Un día, tan súbitamente como habían aparecido, esas máquinas y sus cargamentos desaparecieron y algunas de estas gentes desarrollaron la idea de que creando pistas de aterrizaje, torres de control y aviones hechos de ramas, cuerdas y hojas podrían invocar la vuelta de John Frum, el profeta de la nueva religión, y sus cargamentos mágicos. Los creyentes en los cultos del cargo se esfuerzan por construir estructuras muy similares a las que habían visto durante la guerra, pero falla la esencia, los aviones de madera no vuelan, el cargamento no llega y John Frum no vuelve. Feynman pensaba que muchos científicos miden y hacen cálculos, pero que carecen de lo esencial, el compromiso con el rigor y la integridad intelectual. El problema es que estos científicos de medio pelo, estos sofistas, sí tienen la capacidad de confundir a la ciudadanía y que, incluso, en muchos casos, medran en las comunidades. Feynman sostenía que la integridad intelectual va incluso más allá que la honestidad, puesto que no se trata tan solo de ser honesto, de no robar y no engañar, sino de comprometerse con el esfuerzo de no engañarse a uno mismo.1224 No podemos librarnos por completo de nuestros sesgos, pero tenemos el deber de esforzarnos por minimizarlos.1225 La crítica y la autocrítica tendrán un coste social y profesional, pero evitarlas constituye una traición a nuestra integridad intelectual. Nikolái Vavílov vaticinó que su compromiso con la nueva ciencia de la genética terminaría por llevarlo a la pira. Arderemos, dijo y, a pesar de ello, no se retractó. Tras años de tortura terminó muriendo de hambre en una cárcel comunista. Ardió tal y como había predicho, pero los que le escucharon crearon una agricultura capaz de alimentar a 7000 millones de personas y los soviéticos que lo quemaron tuvieron que comprar alimentos durante la guerra fría a sus enemigos. Aunque no creo en la justicia divina, ya que todo es más prosaico y terrenal, me consuelo pensando en los barcos llenos de grano que navegaban desde Estados Unidos a Rusia honrando, sin que casi nadie fuese consciente, la memoria de Nikolái. 19.8 El bazar A estas alturas puede que el lector esté un tanto confuso. ¿Son los científicos superhéroes íntegros o falsos profetas? ¿Son capaces de generar las comunidades científicas algún conocimiento entre tanto incentivo perverso? Tratar estas cuestiones requerirá todavía algo más de espacio, pero, tal vez, sea útil introducir una nueva imagen: el bazar. Eric S. Raymond, uno de los principales historiadores y sociólogos del movimiento del software de código abierto y de la cultura hacker, nos brindó esta ilustrativa imagen en su trabajo más famoso: La catedral y el bazar. En este ensayo analiza las dinámicas sociales de unos movimientos formados por desarrolladores independientes que, con una coordinación limitada, han creado las herramientas sobre las que funciona internet. Raymond compara esta comunidad con un bazar en el que la revisión del software se hace de un modo completamente descentralizado y un tanto anárquico.1226 Antes del desarrollo de Linux, que fue el primer sistema operativo que se creó siguiendo este modelo, la opinión generalizada era que para construir un software tan complejo se requería un diseño y un control centralizado muy cuidadoso por parte de un pequeño grupo de grandes ingenieros. Sin embargo, Linus Torvalds y su horda de voluntarios demostraron que del aparente caos del bazar podía surgir código elegante y funcional.1227 Este bazar representa muy bien a las comunidades científicas, cientos de individuos con diferentes motivaciones y capacidades que colaboran en un proyecto común proponiendo pequeños o grandes cambios que son aceptados o rechazados en función de sus resultados: los que mejoran el producto final se quedan y los que no, se eliminan. El software funciona o no funciona, los servidores web son capaces de responder a decenas de miles de peticiones por segundo o no, las librerías de cálculo científico pueden hacer inmensos cálculos matriciales con corrección o no. El proceso, por supuesto, es complejo, pero Raymond condensó su esencia en lo que denominó ley de Linus: dado un número suficiente de ojos (de revisores) los errores se vuelven obvios.1228 Es en esta posibilidad de evaluar los problemas y las correcciones propuestas donde reside la clave de que el bazar sea capaz de generar un software tan maravilloso y yo creo que la analogía con el progreso científico es cercana. El proyecto avanzará, a pesar de las limitaciones impuestas por los intereses espurios de los científicos, mientras que sea sencillo testar empíricamente las nuevas propuestas; sin embargo, cuando la contrastación empírica sea difícil las dinámicas sociales internas tomarán más protagonismo. En el modelo de desarrollo de Linux el software no se hace público tras someterse a un largo ciclo de pruebas que garantice su buen funcionamiento, sino todo lo contrario, se publica cuando todavía no se ha testado demasiado y se hace así para que sea la comunidad en su conjunto la que evalúe y mejore el resultado. De forma análoga, en ciencia lo crítico no es que los artículos que se publican sean correctos en todos sus detalles, sino que puedan ser evaluados por la comunidad. Cuando la evaluación empírica de las distintas propuestas es clara y sencilla, el progreso no sólo es posible, sino que el bullicio del bazar puede lograrlo incluso con más eficiencia que la cuidadosa planificación. Esta es una idea que tal vez Popper podría compartir, lo importante no es evitar que se publiquen hipótesis erróneas, sino que estas sean eliminadas sin piedad.1229 Cuando existe una forma intersubjetiva de decidir si un resultado concreto es más o menos correcto, incluso aunque la evaluación no sea perfecta, podemos avanzar. El desarrollo de Linux, la evolución tecnológica en la antigüedad o el progreso científico son en este sentido análogos. Sin embargo, esto no exime al investigador de respetar sus obligaciones deontológicas y de, por lo tanto, comportarse con integridad. Recordemos que la eficiencia del proceso puede ser muy variable, no queremos esperar miles de años para desarrollar una nueva tecnología. Los aviones acabarán volando sobre los océanos, pero lo harán más rápidamente si los técnicos de Boeing se comportan con integridad. Es mucho mejor que el bazar esté compuesto por comerciantes honestos que por vendedores de humo. 19.9 Objetivismo y constructivismo Una vez discutidos estos asuntos, tal vez, podamos entender mejor por qué al hablar sobre las observaciones y la elección entre hipótesis nos encontramos, por un lado, con los constructivistas radicales, que sostenían que las dinámicas sociales y los sesgos psicológicos son todo lo que importaba, y, por otro, con los objetivistas que defendían que la fuerza de las evidencias y la lógica eran suficientes para acabar venciendo. Es evidente que el objetivismo extremo es indefendible, las dinámicas internas son relevantes y esta relevancia depende tanto de la comunidad como del problema planteado. Para los constructivistas las evidencias y la razón nunca pueden ser suficientes, las conclusiones siempre dependerán en gran medida de motivos irracionales y no del fenómeno investigado, siempre habrá aspectos importantes que dependerán de los humanos que están haciendo la investigación.1230 Kuhn, por ejemplo, puede interpretarse de este modo. Mi opinión es que el asunto es complejo y que depende de cada caso. ¿Creo que las dinámicas sociales tuvieron una influencia relevante en la forma final de las leyes de la cinética relativas a la caída de los cuerpos que Galileo desarrolló? No ¿Pondría la mano en el fuego para defender que las motivaciones psicológicas y sociales no han influido en algunos trabajos en genética de poblaciones de plantas, el área en la que trabajo? Ni borracho. En sociología de la ciencia hay bastantes proponentes del programa fuerte: la ciencia es una mera construcción social y sus resultados dependen, fundamentalmente, de dinámicas comunitarias internas y no del mundo externo.1231 Volvemos al relato y al vudú.1232 Según estos constructivistas radicales la ciencia sería un fenómeno cultural que no tendría una relación especial con el conocimiento y los resultados científicos serían completamente contingentes. Dos sociedades distintas construirían propuestas científicas distintas, del mismo modo que construyen mitologías prácticamente independientes.1233 Los resultados científicos dependerían, simplemente, de la presión social, la retórica, la persuasión y la autoridad.1234 Esta conclusión, aplicada a la ciencia en su conjunto, es tan absurda que parece increíble que haya académicos serios que la defiendan. Sin embargo, Feyerabend propuso esta equivalencia entre el vudú y la ciencia. Aunque también es justo reconocer que la seriedad de Feyerabend es discutible. Otro constructivista, Harry Collins, también parece haber escrito que “el mundo natural tiene una influencia muy pequeña o inexistente en la construcción del conocimiento científico.1235 Me fascina que esta gente esté tan segura de sus reflexiones sobre el comportamiento científico y, sin embargo, dude tanto sobre las conclusiones de los propios científicos. Me pregunto si estarán tranquilos cuando compren su nuevo teléfono móvil. Yo creo que hay áreas científicas más objetivas y otras más cercanas a las tesis constructivistas. Por ejemplo, si considerásemos la sociología como una rama científica, yo estaría dispuesto a admitir que las conclusiones de muchos de sus miembros dependen más de la retórica, la persuasión y la autoridad que de la realidad. ¿Cómo si no puede explicarse que, a pesar de los obvios éxitos tecnológicos, todavía haya que estar discutiendo sobre estas cuestiones en pleno siglo XXI? Sin embargo, esto no implica, en modo alguno, que todo lo que se hace en ciencia sea objetivo. Muchas de las conclusiones de los investigadores de algunas áreas tienen el mismo valor que el etéreo resplandor nacarado del cuerno del gran unicornio rosa. En mi área, la reconstrucción de la historia de las poblaciones, el rigor de muchos de los trabajos, incluso de los publicados en las mejores revistas, brilla por su ausencia y sus conclusiones algunos días me mueven a la risa y otros al llanto. La influencia de las virtudes empíricas en la elección de las hipótesis depende críticamente de la fuerza de las evidencias y de la dificultad de conseguir nuevos datos. Sostener que la física de los planos inclinados no es objetiva es tan absurdo como defender que los científicos se comportarán siempre con una integridad intelectual absoluta. Sin embargo, cuando los investigadores discuten sobre el tamaño de los tomates mexicanos de hace tres milenios debemos ser mucho más prudentes. No digo que estas cuestiones sean necesariamente irresolubles. No quiero volver a caer en el error de Comte que, en 1842, escribió que jamás sería posible encontrar evidencias que nos permitiesen averiguar la composición química de las estrellas. No, lo que digo, simplemente, es que hay fenómenos sobre los que, en la actualidad, disponemos de evidencias muy pobres, como las relativas al tamaño de los tomates neolíticos mesoamericanos, mientras que, sobre otros, como el tamaño de los tomates valencianos actuales, disponemos de abundantes observaciones. Por lo tanto, las hipótesis relativas a los primeros serán mucho más susceptibles de ser influidas por factores sociales que las relativas a los segundos. Por otro lado, hay cuestiones que tienen una estructura más compleja que otras: la física de los planos inclinados, por ejemplo, es mucho más sencilla que las reglas que rigen el desarrollo de la economía mundial. Cuando es fácil obtener evidencias, se está estudiando un problema con una estructura sencilla y los miembros de la comunidad se toman en serio su compromiso con la integridad intelectual, la obtención de conocimiento avanza con mucha más facilidad que cuando las cuestiones son complejas y existen importantes presiones sociales. Es indudable que el consenso científico refleja una gran cantidad de conocimiento y, por lo tanto, no es equiparable al vudú, pero, al mismo tiempo, creo que es importante que desterremos la idea de que todas las conclusiones que leemos en cualquier artículo científico son puramente racionales. 19.10 Resumen En ciencia las evidencias y la lógica son fundamentales, pero no lo son todo: las observaciones están teñidas de teoría, la inducción es necesaria, pero implica un salto lógico inválido, la generación de hipótesis es bastante idiosincrática, en la elección entre hipótesis influyen, al menos en parte, motivos no epistémicos y, finalmente, no existe un método, un algoritmo, claramente codificado que nos permita juzgar objetivamente el desempeño de los investigadores. Todo esto hace que el buen oficio de los científicos sea un factor relevante en la empresa científica y que, por lo tanto, sea necesario considerar sus valores, así como los incentivos que moldean sus comunidades. La crítica es un elemento fundamental del diálogo racional: tanto la autocrítica, como la búsqueda de la crítica de nuestros colegas a nuestras ideas son herramientas fundamentales para superar nuestras limitaciones cognitivas y, además, tenemos el deber de criticar las ideas de los demás. Pero la crítica conlleva un coste porque siempre implica una cierta traición y los seres humanos, como mamíferos sociales y jerárquicos que son, no tienen tendencia natural a tomársela bien. Incluso dentro de las comunidades científicas, que están más acostumbradas a la misma, el coste es notable. Una crítica puede dañar la posición de un investigador en la comunidad y es necesario recordar que de su prestigio dependen su carrera profesional, la financiación de sus investigaciones y la atención que le presta el resto de la comunidad. Esta dependencia del prestigio hace que el científico esté tentado de renunciar a la autocrítica y a la búsqueda activa de la crítica comunitaria y pase a convertirse, de hecho, en un publicista. Por otro lado, los expertos también tienen el deber de criticar las creencias erróneas relativas a su área que detecten en la sociedad en su conjunto. Sin embargo, como su financiación y carrera profesional dependen de instituciones íntimamente ligadas a la sociedad en la que viven estarán incentivados para convertirse en sofistas que, para no enemistarse con el poder, aplaudirán incluso las ideas que sabe erróneas o, al menos, optarán por callar. De modo que existen incentivos opuestos al diálogo racional y a la crítica justificada que pueden alejar a las comunidades científicas del ideal del ágora racional acercándolas peligrosamente a cortes de propagandistas y cortesanos. Es importante reconocer que la construcción del ágora siempre implicará, al menos en cierta medida, una traición que puede dañar a los compañeros. Por lo tanto, las ágoras racionales son excepciones que debemos mimar y cultivar; es necesario buscar el modo de incentivar el diálogo racional compensando el desgaste que conlleva la crítica. Sin embargo, tampoco es sencilla la tarea de diseñar buenos esquemas de incentivos. Los cuantitativos están sujetos al problema de Goodhart, cualquier medida que se utilice para evaluar el desempeño de un conjunto de personas estará en grave riesgo de ser manipulada, y, por otro lado, los juicios subjetivos son muy vulnerables a los favoritismos y a las enemistades. También podemos pensar en las comunidades científicas, además de como en ágoras o cortes, como en bazares bulliciosos en los que se negocia con ideas. Habrá mejores y peores propuestas en el mercado, pero si disponemos de la capacidad de evaluarlas fácilmente frente al mundo externo, del ajetreo del bazar acabarán surgiendo mapas adecuados para el territorio. Sin embargo, cuando la contrastación empírica sea difícil, bien porque se carezca de evidencias, porque éstas estén muy cargadas de teoría o porque los sistemas estudiados sean complejos y no se presten a la predicción, habremos de ser especialmente cautos puesto que esta falta de contrastación externa puede hacer que tomen un gran protagonismo las dinámicas sociales internas: los favoritismos, las presiones sociales, la retórica o la autoridad. Cuando los factores internos predominen sobre los externos nuestros modelos puede que sean poco más que meras alucinaciones que dificulten la acción efectiva. Por eso hemos de exigir integridad radical a los investigadores; cuanto más epistémicamente puros sean, más resistentes a los factores internos, más probabilidades de éxito tendrán al afrontar el estudio de fenómenos difíciles. "],["ciencias_y_malas_hierbas.html", "20 Ciencias y malas hierbas 20.1 Ciencias históricas y ahistóricas 20.2 Ciencias duras y blandas 20.3 Problemas difíciles y cautela 20.4 Mala ciencia y fraude científico 20.5 Pseudociencias 20.6 Entre el día y la noche 20.7 Resumen", " 20 Ciencias y malas hierbas Ciencia y pseudociencia, claramente, no son lo mismo, como no lo son el día y la noche, y el análisis de esta distinción, ya que implica preguntarse por qué es la ciencia, podría plantearse como una de las cuestiones fundamentales para la filosofía de la ciencia.1236 Sin embargo, distinguir la ciencia de otras actividades como la pseudociencia, las matemáticas o la filosofía, como a estas alturas podríamos esperar, no es trivial. La ciencia, por ejemplo, se confunde, hasta cierto punto, con la mala ciencia y ésta, a su vez, con la pseudociencia. Además, la ciencia tampoco es una actividad uniforme, hay ciencias naturales y sociales, experimentales e históricas, duras y blandas. Al explorar estas cuestiones no vamos a llegar a establecer unas definiciones absolutamente nítidas que resuman sin ambigüedad unas realidades tan complejas, pero el proceso nos servirá para reflexionar sobre qué características son relevantes cuando estamos considerando la relación entre las actividades científicas y las no científicas. En primer lugar, no viene mal recordar que hay actividades perfectamente defendibles que no son ciencia. Esto debería ser obvio, pero suele imbuirse el término ciencia de una legitimidad tan grande que algunos comentarios parecen dar la impresión de que cualquier desarrollo intelectual o cultural que no sea científico es de segunda categoría. Sin embargo, aunque la novena sinfonía de Beethoven no sea ciencia, merece muchísimo más la pena que la mayor parte de los trabajos que producen los científicos. En segundo lugar, y esto es algo que puede sorprender todavía más, hay mucho conocimiento sistemático que no es científico: matemáticas, lógica y filosofía.1237 Las matemáticas y la lógica son herramientas que se utilizan en ciencia y en filosofía, pero su desarrollo no implica estudiar el mundo externo, la realidad, y, por lo tanto, no suelen englobarse dentro de la ciencia. Por otro lado, aunque ya tratamos en un capítulo anterior la compleja y estrecha relación entre la ciencia y la filosofía, resumo aquí mi postura: la filosofía podría definirse como el estudio intelectualmente riguroso de cualquier cuestión, ya sea esta moral, estética o natural. Si aceptásemos esta definición, la ciencia sería la rama de la filosofía, eminentemente empírica, dedicada al estudio del mundo externo. Además, ambas actividades comparten el ideal de la honestidad y el rigor intelectual. Sin embargo, en la práctica, existe una especialización profesional que hace que la filosofía y la ciencia sean llevadas a cabo por comunidades profesionales bastante diferenciadas. Otra alternativa, bastante común y no jerárquica, consistiría en considerar a la ciencia como la hermana empírica de la filosofía. En realidad, yo prefiero remarcar la estrecha relación de ambas y, además, hay áreas de contacto muy estrecho en las que la práctica filosófica y científica llegan a confundirse. Este es el caso, por ejemplo, de las distintas filosofías dedicadas a estudiar áreas concretas de la ciencia como: la filosofía de la física o de la biología. 20.1 Ciencias históricas y ahistóricas Las ciencias son muy heterogéneas, tanto en objeto como en método.1238 El cometido de los físicos teóricos de partículas y de los psicólogos o de los epidemiólogos se parece bastante poco. Tal vez sería más claro hablar de ciencias, en plural, que de ciencia. El problema es que si hablásemos de ciencias deberíamos enfrentarnos a la delimitación de las distintas ciencias, algo muy complejo dado que hay áreas de estudio claramente multidisciplinares. Por ejemplo, yo trabajo en genética, pero mi objeto de estudio se solapa con el de la bioquímica, la biología molecular, la botánica, la zoología, la microbiología, la ecología, la historia de la vida, la historia de los seres humanos y la evolución. Hay ciencias, como la física de partículas, que tienen por objeto estudiar fenómenos que, al ser independientes de la historia, pueden darse en cualquier momento, mientras que otras, como la cosmología o la biología evolutiva, son históricas puesto que sus objetivos incluyen la reconstrucción y comprensión del pasado.1239 Mientras que los físicos y los químicos hacen experimentos para comprender y, eventualmente, predecir el comportamiento del mundo externo, los paleontólogos o los arqueólogos buscan vestigios que les permitan reconstruir algo que sucedió en el pasado y que, en la mayor parte de las ocasiones, no podrá volver a repetirse.1240 De modo que hay ciencias históricas, como la paleontología, parcialmente históricas, como la geología y completamente ahistóricas como la física fundamental o la química.1241 Además, las ciencias experimentales suelen tratar con sistemas lo suficientemente sencillos como para que se puedan hacer buenas predicciones sobre su futuro,1242 mientras que, las ciencias históricas, como la paleontología, no suelen hacer predicciones precisas sobre la evolución de los fenómenos estudiados.1243 Sin embargo, sí es habitual que, en las ciencias históricas, se hagan predicciones relativas a los vestigios del pasado que se esperan encontrar. Por ejemplo, si desenterrásemos fósiles felinos en estratos datados en el periodo ediacárico, hace unos 600 millones de años, nuestras teorías sobre la evolución de la vida en la Tierra quedarían seriamente comprometidas. Los paleontólogos hacen predicciones de este tipo continuamente. Por ejemplo, los fósiles de tiktaalik, un pez transicional con cuello y cuatro extremidades similares a las de los anfibios, no se encontraron por casualidad. El equipo de investigación fue a una región canadiense perfectamente delimitada, rica en sedimentos devónicos, y buscó allí durante varios años hasta dar con el primer fósil. Eligieron ese lugar como destino de sus exploraciones porque habían predicho que fue precisamente durante el devónico cuando la Tierra debió de estar habitada por ese tipo de criaturas. 20.2 Ciencias duras y blandas Hay autores que distinguen entre ciencias duras, como la física y la química, y blandas, como la psicología y la sociología.1244 En realidad, esta distinción está relacionada con la complejidad del objeto de estudio. La mente humana es mucho más compleja que los planos inclinados y, además, la posibilidad de realizar experimentos controlados es mucho mayor en las primeras. La física fundamental trata con sistemas muy simples, mientras que la psicología o la economía estudian fenómenos muy complejos. Puede darnos la impresión de que la física es muy difícil, pero esto es porque los fenómenos que estudia, en muchas ocasiones, están alejados de nuestra realidad cotidiana1245 y porque sabemos mucha física,1246 no porque sus objetos de estudio sean complejos. Los planos inclinados son sistemas sencillos, pero Galileo los utilizó como evidencia en favor de que la aceleración gravitatoria es independiente de la masa, algo que es completamente contraintuitivo. Además, los sistemas estudiados por la física, en muchos casos, no están fuertemente acoplados, unas partes no interaccionan estrechamente con otras y esto nos permite hacer simplificaciones, como, por ejemplo, despreciar la fricción. En un sistema complejo fuertemente acoplado, como el clima, el metabolismo o la economía, en el que unas partes pueden influir sobre otras, no es fácil hacer simplificaciones sin perder la esencia del comportamiento del sistema y esto nos condena a trabajar con modelos mucho más complejos. En las predicciones meteorológicas las vacas esféricas tienen un papel más limitado que en los planos inclinados. Además, en un sistema complejo las causas no tienen por qué ser sencillas, pueden ser multifactoriales y esto dificulta muchísimo hacer predicciones fiables del comportamiento de esos sistemas. En física la varianza experimental suele deberse al error de medida, pero en sistemas complejos, como los estudiados por la ecología, la varianza experimental está más relacionada con variables no controladas por los investigadores.1247 Estamos acostumbrados a que la ciencia consiga generar conocimiento, pero si el sistema estudiado es muy complejo, ese conocimiento podría ser muy difícil de alcanzar. A los problemas relacionados con la complejidad hay que añadir los relativos a la posibilidad de realizar experimentos controlados. Cuando esto no es posible, como en epidemiología o en muchas áreas de la economía, perdemos una herramienta muy importante en el estudio de las causas. Los experimentos controlados son el modo fundamental de analizar la influencia causal de una variable sobre un sistema. Imaginemos que observamos que una enfermedad infecciosa está asociada a la concentración de vitamina D en sangre. Incluso aunque asumamos que la correlación es cierta, sería muy arriesgado concluir que tener poca vitamina D nos hace más susceptibles a la enfermedad. Es difícil llegar a conclusiones fiables sobre las causas a partir de meras correlaciones. Tal vez la falta de vitamina D y la gravedad de la enfermedad dependan de una tercera variable. Por ejemplo, puede que la gente más mayor tienda a ser deficiente en vitamina D y sea la edad, y no la concentración de vitamina, el factor determinante. Sin embargo, si pudiésemos realizar un experimento en el que pudiésemos infectar a personas cuya única diferencia fuese la concentración de vitamina sí podríamos determinar la influencia de esta variable. La falta de experimentos puede paliarse mediante distintos conjuntos de correlaciones independientes o, alternativamente, gracias a los llamados experimentos naturales en los que un sistema es sometido a manipulaciones que serían imposibles de plantear por motivos éticos o prácticos. En estos casos, varios sistemas que comparten prácticamente las mismas circunstancias son afectados diferencialmente por una variable, por ejemplo, por la aparición de una nueva enfermedad, y esto nos permite estudiar el impacto de esta causa.1248 Pero, en cualquier caso, cuanto más difícil sea hacer experimentos controlados, más difícil será la labor del investigador y más cauto debería ser éste en sus conclusiones. 20.3 Problemas difíciles y cautela En este libro, en contra de la opinión de los constructivistas, hemos defendido que las comunidades científicas suelen alcanzar conocimiento fiable. Sin embargo, cuando el área de estudio trata con fenómenos muy complejos y, además, no puede hacer experimentos controlados, hay que ser muy cauto puesto que las dinámicas internas de las propias comunidades científicas sí podrían ser muy relevantes. Además, en estas áreas las observaciones suelen estar muy alejadas de la percepción elemental y es habitual que no sean neutrales respecto a las hipótesis evaluadas. Por ejemplo, los psicólogos hablan de personalidades y los economistas de PIB, pero una personalidad o un PIB son constructos mucho más abstractos, de definición más compleja y más alejados de la percepción que la posición de una bolita en un plano inclinado y, además, dependen de planteamientos teóricos muy cercanos a los que están siendo contrastados. En estas áreas tenemos que ser especialmente cautos y escépticos porque las influencias de las dinámicas comunitarias, si no somos extraordinariamente rigurosos, pueden ser decisivas. En estos casos, algunas conclusiones tendrán poca relación con la realidad del fenómeno estudiado. Por otro lado, en un área compleja, como la macroeconomía, en la que es casi imposible hacer predicciones fiables, la contrastación empírica de nuestras hipótesis es difícil y la tentación de imponer nuestras propias narrativas previas sobre el fenómeno estudiado puede llegar a influir mucho en las conclusiones. Los practicantes de estas disciplinas deberían ser especialmente cautos puesto que, de no serlo, corren el riesgo de convertirse en sofistas y charlatanes. Recuerdo que cuando era pequeño me llamó la atención que el economista que comentaba las noticias económicas, independientemente de la salud de la economía, siempre llegaba a la misma conclusión: había que bajar los sueldos. Cuando la economía iba mal había que bajar los sueldos para evitar que las empresas sufriesen y se entrase en un círculo vicioso que aumentase el paro, si, por el contrario, las cosas marchaban bien, había que bajar los sueldos para que no se sobrecalentase la economía y nos empobreciese la inflación. Siempre me maravilló que la bajada de sueldos fuese una receta universal. Con el tiempo, aprendí que esos economistas no son capaces de hacer predicciones válidas sobre la influencia de sus recetas macroeconómicas. Ahora me pregunto si, en realidad, esas hipótesis suyas, que retroactivamente parecían capaces de explicar cualquier acontecimiento económico, pero que no eran capaces de predecir nada, no eran más que puro humo. Recordemos que a Popper algunos marxistas le sirvieron de inspiración para proponer el principio de la falsabilidad. Cuando una hipótesis puede explicarlo todo, incluyendo lo que ha ocurrido y, también, lo contrario, tal vez, no está explicando nada. Con esto no quiero decir que considere que no pueda generarse conocimiento en el estudio de la economía, nada más lejos de mi intención. Lo que creo es que en áreas los incentivos y las dinámicas sociales tienen más posibilidades de jugarnos malas pasadas. Si un físico trata de colar una nueva teoría gravitatoria, el resto puede comprobar si sus predicciones fallan y descartarla rápidamente, pero esto no es tan fácil en economía porque al estudiar fenómenos complejos causados por múltiples factores, el fallo de las predicciones siempre puede achacarse a una u otra causa y esto hace que las hipótesis sean muy difíciles de desbancar. En mi propia área de estudio sucede algo similar. Confío mucho más en las conclusiones relativas a la localización de genes mendelianos relacionados con caracteres sencillos que en los resultados obtenidos por complejos modelos estadísticos sobre la historia de las poblaciones. Mientras que en el caso del control genético de los caracteres sencillos el científico es consciente de que sus conclusiones entrañan predicciones que pueden ser contrastadas con relativa facilidad, en el caso de la reconstrucción de la historia de las poblaciones lo que se obtiene es un relato que, en muchas ocasiones, no hace predicciones empíricas fácilmente contrastables. No es fácil saber qué tamaño tenían los tomates mexicanos hace tres milenios. Como ya he dicho en otras ocasiones, la tecnología es menos susceptible de caer en dinámicas sociales perversas porque las manipulaciones sobre el mundo externo o funcionan o no funcionan, los aviones vuelan o no vuelan, o como dirían los filósofos, hay éxito operacional o no lo hay. Además, recordemos que los investigadores están sujetos a incentivos que limitan la autocrítica, por lo que no es de extrañar que se nos acaben presentando algunas conclusiones como fiables cuando, en realidad, no están debidamente justificadas. Es muy difícil publicar un artículo en el que se diga que después de estudiar un fenómeno durante años no hemos conseguido alcanzar ninguna conclusión sólida y esto hace que el investigador esté tentado de relajar su escepticismo y su integridad. Un modo de evaluar el desempeño de las distintas áreas es observar qué disciplinas avanzan, ya sea en éxito operacional o en poder explicativo, y cuáles tienden a quedarse dando círculos sin fin o a moverse arrastradas por el viento de las modas.1249 Por ejemplo, me parece muy sospechoso que algunos pedagogos planteen programas de implantación de métodos de aprendizaje revolucionarios año tras año, pero que mis alumnos parezcan saber menos cada curso. Cuanto menos progresiva sea una disciplina más escépticos deberían ser sus practicantes, pero lo cierto es que, en muchos casos, lo que se acaba viendo es mucha literatura y poca cautela. Cuando un área de estudio es demasiado difícil, tal vez deberíamos limitarnos a hacer filosofía continental o literatura. Esto no lo digo con ironía, creo que la literatura es una buena herramienta para explorar áreas que son demasiado relevantes como para ignorar su exploración, aunque sean complejas.1250 La psicología humana fue estudiada por literatos y filósofos mucho antes de que William James fundase la psicología científica a finales del XIX. El problema no es hacer literatura, sino confundir conclusiones tentativas con conocimiento fiable. Hemos de abstenernos de disfrazar la literatura de ciencia; la literatura es legítima y necesaria, pero la pseudociencia es una impostura intelectual. 20.4 Mala ciencia y fraude científico Confías en la ciencia porque te han dicho que Galileo fue genial, y lo fue, y porque los ingenieros diseñan máquinas capaces de transportarte con seguridad a través del océano y todo eso es cierto y haces bien en confiar. Pero no toda la ciencia es Galileo. El investigador y médico John Ioannidis en Why Most Published Research Findings Are False, basándose en un análisis de mal uso de la estadística relacionado con los p-valores, llegó a la conclusión de que la mayor parte de los resultados publicados son falsos. Posteriormente, puesto que la cifra de estudios espurios depende de la tasa de hipótesis incorrectas planteadas por los científicos, y esto es difícil de establecer,1251 otros autores han matizado esta conclusión, pero nadie que yo conozca sostiene que las malas prácticas científicas no abunden. Por desgracia, no es fácil conocer la magnitud del problema puesto que, hasta fechas muy recientes, se ha dedicado un esfuerzo relativamente pequeño a estudiar este asunto.1252 Cuando hablo de mala ciencia no me estoy refiriendo a conclusiones que, eventualmente, van a ser falsadas; eso es lo esperable en una ciencia progresiva que poco a poco va comprendiendo con mayor detalle el funcionamiento del mundo externo. No, mala ciencia es aquella que no se hace con rigor, que utiliza protocolos experimentales deficientes, que hace análisis estadísticos inapropiados o que llega, a partir de unas evidencias dadas, a conclusiones indefendibles. La mala ciencia está constituida por aquellas actitudes que Feynman comparaba con las religiones del cargo. Existe un continuo entre la mala ciencia y el fraude científico, los dos fenómenos están diferenciados. Decidir no mostrar algunos datos que no encajan con tu hipótesis porque los crees erróneos, puede ser mala ciencia, pero mentir inventándose unos datos inexistentes es un claro ejemplo de fraude. Las metodologías científicas actuales son muy complejas y exigen una gran preparación técnica por parte de los investigadores. En mi área, por ejemplo, es extraño cruzarse con científicos que entiendan realmente las limitaciones de los modelos estadísticos que están utilizando. Eso no implica que sus artículos estén necesariamente mal hechos, puesto que, en muchos casos, echan mano de especialistas que sí los entienden o, en su defecto, hacen algo más problemático, utilizan análisis que han visto aplicar en circunstancias similares en otros trabajos. Esto último aumenta mucho las probabilidades de que algo salga mal. Además, si a la posibilidad de que se haga mala ciencia le sumamos la presión por obtener resultados llamativos y por publicar1253 obtenemos como resultado que una parte importante de la producción científica es metodológicamente muy pobre, a veces intelectualmente poco íntegra y, en unos cuantos casos, directamente fraudulenta. Hemos de exigir al científico que no ceda a esas tentaciones1254 y, además, deberíamos estudiar qué sistemas de incentivos pueden implementarse para alinear, en la medida de lo posible, los intereses de los científicos con los de la generación de conocimiento. Hasta cierto punto, podría decirse que en la actualidad la mala ciencia está siendo incentivada (The natural selection of bad science).1255 Las investigaciones poco rigurosas generan con facilidad resultados positivos y llamativos que terminan favoreciendo la carrera de los investigadores con menos escrúpulos. En principio la revisión por pares debería aliviar el problema y, probablemente, esté haciéndolo, pero es un filtro insuficiente, por lo que se publican muchas conclusiones muy poco rigurosas. Incluso es posible que esta tendencia, de un tiempo a esta parte, haya ido en aumento. Resulta sospechoso, por ejemplo, que los científicos se estén esforzando por que sus artículos sean cada vez más llamativos. Desde 1974 a 2014 el uso de términos positivos en los resúmenes de los artículos científicos se ha incrementado notablemente. Por ejemplo, los términos “robusto”, “novedoso”, “innovador” y “sin precedentes” han aumentado su frecuencia un 15.000%.1256 Y algo que indica que estas tendencias pueden estar relacionadas con la calidad es que este incremento se dio, principalmente, en las revistas menos relevantes. Además, si hiciese caso a lo que leo en las notas de prensa emitidas por los centros de investigación tendría la impresión de que el cáncer se va a curar inminentemente o que la próxima batería de mi móvil sólo tendrá que cargarse una vez al mes. Creo haríamos bien en recordar a los estudiantes de ciencias el modo en el que se describió la estructura del ADN en 1953. No se nos escapa que el apareamiento concreto que hemos postulado sugiere inmediatamente un posible mecanismo de copia del material genético. Lo que Watson y Crick estaban explicando es que habían descubierto el secreto de la vida, el mecanismo molecular que permite que los seres vivos transmitan la información genética de una generación a la siguiente. Tengo la impresión de que en la actualidad el trabajo se redactaría de un modo muy distinto. La mala ciencia, hasta cierto punto, es inevitable, pero deberíamos intentar reducirla puesto que acarrea consecuencias negativas. Por un lado, detrae recursos que podrían dedicarse a hacer ciencia de mejor calidad. Además, añade ruido a la cacofonía que caracteriza a las comunidades científicas, por lo que, probablemente, reduzca la eficiencia del proceso de generación de conocimiento. Y, por si esto fuese poco, tal vez su impacto más negativo sea el social. Un mal artículo puede confundir a un experto, pero eventualmente, si el tema tiene interés, será purgado. Sin embargo, los no expertos estamos a merced de las notas de prensa de las instituciones científicas y de los artículos de la prensa generalista. Personalmente he dejado de informarme sobre ciencia en los medios no especializados. Es demasiado común que los periodistas, que en muchos casos no están especializados, sean confundidos por las notas de prensa más llamativas y acaben transmitiendo una información de muy baja calidad. Las exageraciones son tan habituales que, en muchos casos, cuando leo las noticias sobre genética en los medios generalistas llego a tener problemas para entender de qué iba la investigación. Tal vez se entienda mejor el problema con un ejemplo. En 2019, en un periódico local, se publicó un artículo que llevaba por título Un estudio valenciano resuelve el debate sobre las verduras ecológicas.1257 El debate, como es de esperar, se había resuelto en favor de la alternativa pseudoecológica. En la entradilla del artículo se detallaban las bondades de estos métodos de cultivo: Investigadores de la UPV determinan que los pimientos de este tipo de cultivo acumulan más vitamina C y antioxidantes naturales y que los resultados son extrapolables. El título de la nota de prensa emitida originalmente por la Universidad, sin embargo, era algo más cauto: “El cultivo ecológico favorece la acumulación de vitamina C y otros antioxidantes en pimiento”1258 y, además, reflejaba con mayor precisión el contenido del artículo científico que originalmente se había publicado en PLoS ONE, una revista de reconocido prestigio: Response to organic cultivation of heirloom Capsicum peppers: Variation in the level of bioactive compounds and effect of ripening.1259 En el estudio se habían analizado diversos compuestos y dos de ellos resultaron tener una concentración media superior en las condiciones de cultivo pseudoecológico: 135 vs 117 mg de ácido ascórbico por cada 100 gramos de pimiento y 232 vs 206 mg de fenólicos totales por cada 100 gramos. Dudo que el lector del artículo de la prensa generalista, que recordemos, daba el debate por zanjado, se quedase con la idea de que el supuesto descubrimiento se correspondía con una variación tan pequeña en las concentraciones de dos de los compuestos estudiados. Esta diferencia, además, no era sólo pequeña en términos absolutos, sino que también lo era cuando se comparaba con la variación en la concentración de estas sustancias en las distintas variedades ensayadas. El ácido ascórbico varió desde 47,9 mg/100g, en la peor variedad, a 208,8 mg/100 g en la mejor. De modo que, si nos basásemos en estos resultados, tal vez, la conclusión principal del artículo científico debería haber sido que distintas variedades de pimiento tienen diferentes concentraciones de ácido ascórbico en distintas condiciones de cultivo. Este no habría sido un resultado muy novedoso y supongo que habría sido más difícil de publicar en PLoS ONE. Lo que sí se mencionaba en el artículo en la prensa generalista es que para determinar las concentraciones de compuestos se habían utilizado métodos potenciométricos y espectrofotométricos, algo que un lector medio no es capaz de entender. Yo mismo, que estudié química y trabajo en un área afín, no sé que es un método potenciométrico. Conviene volver a recordar aquí el concepto de gilipollez planteado por Harry G. Frankfurt. La terminología académica debe utilizarse para comunicarnos con concisión y precisión, pero, en muchos casos, la jerga técnica termina utilizándose para disfrazar ideas pobres con ropajes prestigiosos y para impedir la crítica de los que no están en el círculo de expertos.1260 El uso de los términos técnicos en la prensa generalista me recuerda una campaña publicitaria de Volkswagen en la que afirmaba que sus nuevos coches incluían Ziritione. En aquel momento, 1999, me pareció muy gracioso que los publicistas se burlasen de su propio quehacer introduciendo un término inventado en la promoción del producto. Hoy en día, sin embargo, las notas de prensa de los centros de investigación no me parecen tan graciosas. Pero, volvamos al artículo de los pimientos. Su conclusión principal, que hay diferencias en la concentración de esos dos compuestos debidas al método de cultivo, es poco justificable. Hay que tener en cuenta que el diseño experimental consistió en cultivar unos pimientos en dos campos distintos, por lo que el titular del artículo podría haber sido: “Se cultivan unos pimientos en dos campos distintos en condiciones diferentes y se obtienen resultados ligeramente diferentes”. Es decir, el diseño experimental no permitía separar el efecto debido al tipo de cultivo del causado porque las dos parcelas sean distintas. Esta conclusión, evidentemente, no habría resuelto ningún debate, pero habría sido más precisa. Con todo esto no digo que la conclusión del estudio sea necesariamente falsa. Tal vez sea cierto que utilizar un método de cultivo más ineficiente aumente ligeramente el contenido en ácido ascórbico en algunos tipos concretos de pimientos. Lo que quiero indicar es que esta conclusión no está justificada adecuadamente por las evidencias mostradas. Recordemos: que la justificación sea inválida no implica que la conclusión sea falsa. Lo que sí es cierto es que a pesar de estos problemas graves el artículo se publicó en una revista con revisión por pares y la nota de prensa llegó al público general, contribuyendo a confundirlo sobre los valores de la mal llamada agricultura ecológica. Por cierto, una de las autoras del artículo fue durante años presidenta de la Sociedad Española de Agricultura Ecológica, algo que no fue mencionado en el apartado dedicado al conflicto de intereses. No es de extrañar que un público que no conoce los entresijos de las comunidades científicas, pero que deposita una gran confianza en la ciencia, acabe confundido por el constante bombardeo de noticias de baja calidad. Como tampoco lo es que muchos resultados científicos no puedan ser reproducidos. Sin embargo, el lector no ha de pensar que estos trabajos de baja calidad publicados en revistas más o menos reconocidas, representan el límite inferior de la mala ciencia. El fenómeno de los predatory journals es aún más escandaloso. (El término predatory journals lo he visto traducido como revistas depredadoras o espurias). Estas revistas se disfrazan de revistas más o menos respetables tomando nombres aparentemente serios como Academic Research Reviews o Botany Journal, pero publican artículos sin preocuparse en absoluto por la calidad y, en algunos casos, consiguen estar indexadas en las bases de datos que se utilizan para valorar los currículos de los investigadores. Su modelo de negocio es cobrar por publicar, algo que también hacen las revistas serias, pero, en este caso, sin controles de calidad. Los investigadores que publican en ellas se hacen con una lista de artículos con la que rellenar el currículum. Además, esta vía también se utiliza para dar una patina de legitimidad a la pseudociencia que puede emplearse para confundir al público general, que no distingue fácilmente estas revistas de las legítimas. Por ejemplo, en la semana en la que escribo estas líneas ha sido noticia que la revista Journal of Biological Regulators and Homeostatic Agents aceptó publicar el artículo: 5G Technology and induction of coronavirus in skin cells. Finalmente, en este caso, al ver el escándalo que se organizó cuando se destapó el asunto, la revista decidió retractarse. Como muestra del nivel de estas publicaciones puede bastar el caso de la uromicitosis, una enfermedad imaginaria que apareció en un legendario episodio de Seinfeld. Una de estas revistas, Urology &amp; Nephrology Open Access Journal, envió al editor John McCool un correo pidiéndole que escribiese un artículo sobre nefrología.1261 McCool, que debía de ser un gran fan de Seinfeld, decidió criticar la falta de rigor académico de la revista relatando el caso descrito en el sexto episodio de la tercera temporada de la serie: The Parking Garage. En este capítulo los protagonistas quedan atrapados en el aparcamiento de un centro comercial y Seinfeld, tras ser detenido por orinar en una esquina, decide aducir en su descargo que lo ha hecho porque padece uromicitosis. McCool escribió un artículo sobre esta enfermedad completamente inventada. Sin embargo, esto no parece que fuese un problema para los editores de Urology &amp; Nephrology Open Access Journal que, a cambio de 799$ aceptaron publicar el artículo. Por fortuna, el objetivo de McCool era honesto por lo que declinó aceptar el ofrecimiento y la uromicitosis quedó fuera de la literatura médica.1262 En 2013 John Bohannon, redactor de la revista Science, envió un artículo completamente absurdo a 304 revistas; un 60% lo aceptó. En 2015, cuatro investigadores se inventaron el currículum de una científica inexistente: Anna O. Szust (oszust significa fraude en polaco). Esta investigadora fue aceptada como editora en 360 revistas académicas a pesar de que en su currículum no constaba que hubiese publicado ni un sólo artículo científico y que no tenía experiencia editorial alguna. En este caso, al menos, nos cabe el consuelo de que ninguna de las revistas estaba incluida en las bases de datos más serias.1263 Con todo esto no estoy tratando de transmitir que todo lo que se publica sea basura, pero sí es importante tener mucho cuidado con la información que nos llega porque en las comunidades científicas no es oro todo lo que reluce. Por fortuna, lo que no parece fácil de conseguir es torcer el proceso científico lo suficiente como para conseguir que el consenso científico refleje un resultado relevante erróneo. Durante años las compañías tabaqueras consiguieron que se publicasen estudios de mala calidad sobre los efectos del tabaco, pero lo que no lograron fue que la comunidad científica alterase su consenso. En este caso la mala ciencia fue utilizada por sus departamentos de propaganda para hacer creer al público general que había un debate, pero el grueso de los expertos nunca fue confundido. Por último, debemos reconocer que la mala ciencia no es el único problema de las comunidades científicas, también nos encontramos, aunque probablemente en menor medida, fraude.1264 En ciencia también se miente, por ejemplo, hay quien se inventa los datos.1265 El fraude se distingue de la mala ciencia porque el engaño es deliberado. Aunque, de nuevo, conviene recordar que hay un continuo entre mala ciencia y fraude; un investigador puede cometer errores aun actuando con la mejor de las intenciones, pero también por desidia, por falta de rigor intelectual o, directamente, por mala fe. El fraude, no obstante, está bastante desincentivado porque las comunidades científicas suelen actuar con bastante rigor cuando es claro y el prestigio del investigador afectado suele quedar completamente destruido1266 por lo que no parece ser muy común.1267 Aun así, estoy convencido de que entre los artículos de menor calidad que rara vez llegan a formar parte de la conversación comunitaria, sí debe de haber bastante fraude de baja intensidad. Es decir, fraude disfrazado de errores que podrían ser debidos a despistes o desconocimiento. 20.5 Pseudociencias En filosofía de la ciencia hay un par de cuestiones etiquetadas como problemas de la demarcación. La primera, la de la demarcación territorial, estudia la separación del conocimiento científico de otros tipos de conocimiento, como el matemático o el filosófico. Sin embargo, cuando un filósofo de la ciencia se refiere, simplemente, al problema de la demarcación suele estar tratando el segundo problema de la demarcación, el que trata de establecer una delimitación normativa que distinga entre ciencia y pseudociencia.1268 La distinción entre ciencia y pseudociencia no tiene sólo importancia académica; socialmente resulta crítico distinguir la razón de la sinrazón, especialmente en cuestiones fundamentales para nuestra supervivencia como la salud o la producción de alimentos. El merecido prestigio social del que disfrutan las ciencias es utilizado habitualmente por personajes sin escrúpulos, o por gente simplemente equivocada, para promover creencias que terminan causando serios daños sociales.1269 La creencia en el monstruo del Lago Ness puede resultarnos más o menos simpática, pero las creencias en la homeopatía o la terapia ortomolecular matan. Proponer una definición aproximada de las pseudociencias es muy sencillo: son áreas que pretenden pasar por ciencia, pero que presentan problemas epistémicos severos.1270 El problema consiste en detallar qué entendemos por problemas epistémicos y, muy especialmente, cómo delimitar cómo de severos deben ser esos problemas. Popper, como no podía ser de otro modo, propuso la falsabilidad como criterio de demarcación. Según Popper sería científica cualquier hipótesis potencialmente falsable.1271 Sin embargo, como ya comentamos en el capítulo dedicado a la falsabilidad, este criterio es problemático. En primer lugar, hay pseudociencias que defienden propuestas falsables. Por ejemplo, la homeopatía hace predicciones empíricas claramente contrastables, de modo que es falsable.1272 No basta con que una hipótesis sea falsable, sus proponentes deberían actuar en consecuencia cuando encuentran evidencias contrarias. El problema de esta definición es que, tal y como hemos visto, no hay un criterio único ni un algoritmo perfectamente definido para elegir racionalmente entre hipótesis. Entre la ciencia y la pseudociencia existe un espectro continuo1273 y, como es típico de la mayoría fenómenos complejos, no es posible definir con absoluta precisión utilizando características necesarias y suficientes el límite entre la ciencia y la pseudociencia. En esta área es muy conocida la propuesta del filósofo de la ciencia Larry Laudan, que planteó en su The demise of the demarcation problem (1983) que el problema de la demarcación era irresoluble. Esto, por supuesto, no implica que ambos fenómenos sean equivalentes o que estén cercanos. Ya nos hemos enfrentado antes a problemas de clasificación similares. Recordemos: está claro que existen el día y la noche, lo que no es tan fácil es definir el límite exacto entre ambos. De modo que, aunque vamos a discutir sobre las características de estos fenómenos y sobre la dificultad de establecer límites precisos entre ambos, en ningún caso hemos de concluir que la existencia de casos intermedios implica una cercanía entre lo que hacía Galileo y lo que hacen los seguidores de Hahnemann. Mientras que el primero, gracias a su rigor intelectual, creaba conocimiento los segundos no hacen más que engañar o engañarse. Una posible opción sería asumir que ciencia es lo que hacen los científicos y no sólo lo que piensan los filósofos.1274 Al fin y al cabo, son los científicos quienes más saben sobre ciencia. Sin embargo, esta propuesta es muy problemática. Siempre hay que ser muy cauto cuando se eleva un es a un debe, cuando se convierte una descripción en una norma. En este caso, por ejemplo, es necesario reconocer que dentro de las comunidades científicas hay mala ciencia. De modo que, incluso aunque no podamos llegar a planear definiciones basadas en características necesarias y suficientes, sí que sería muy útil analizar algunos criterios normativos. También podríamos comenzar planteando ejemplos especialmente claros de ciencias y pseudociencias y, a partir de los mismos, derivar criterios que nos permitan caracterizar al resto de áreas en el espectro que va del conocimiento a la sinrazón. Una vez determinadas estas características diferenciadoras dispondremos de una herramienta que nos permitirá situar las distintas actividades en un espacio continuo en el que estarán localizadas tanto las ciencias, como la mala ciencia, el fraude y las distintas pseudociencias. Es posible que mientras no dispongamos de un algoritmo que codifique la racionalidad no vayamos a conseguir establecer una distinción completamente nítida, pero, al menos, esta aproximación nos permitirá enumerar características que, en general, distinguen a los investigadores rigurosos de los charlatanes. Una posible crítica a este tipo de aproximaciones es que comienzan por etiquetar algunas actividades como científicas y otras como pseudocientíficas. Sin embargo, la distancia, en cuanto a rigor intelectual y éxito operacional de estas actividades es tan enorme que no creo que en la práctica esto vaya a suponer un problema. Hay ejemplos que ilustran muy claramente la diferencia entre ciencia y pseudociencia. Por ejemplo, hay quien cree que un dios creó el universo recientemente y para mantener esta hipótesis debe responder a la existencia de los fósiles de tiranosaurios. Una opción es aducir que cuando su dios creó el universo hace unos 6000 años dejó los fósiles enterrados para probar nuestra fe. Esto es, claramente, una hipótesis ad hoc excesiva. Por cierto, que siguiendo el mismo razonamiento ese mismo dios podría haber creado el universo hace 5 minutos o el último jueves.1275 Por otro lado, algunos ejemplos claros de actividades científicas son la física fundamental experimental o la química orgánica y la homeopatía, el reiki o los cazafantasmas son, claramente, actividades pseudocientíficas. A lo largo de los años se han publicado muchas listas de criterios para ayudarnos a distinguir ciencia de pseudociencia.1276 De todos ellos, voy a tratar de exponer los que me han parecido más relevantes. La idea no es que para clasificar un área como pseudocientífica deba ser caracterizada por todos y cada uno de ellos, sino que cumpla los suficientes. La definición, como ya hemos avisado, no será sencilla. Empecemos por un criterio que sí es necesario: para que un área pueda ser calificada como pseudocientífica sus defensores deben pretender estar haciendo ciencia. Sólo un área que trate de pasar por científica puede ser pseudocientífica.1277 De hecho, este requisito se sigue de la propia etimología del término, el prefijo pseudo significa, precisamente, falso. Por lo tanto, una pseudociencia sería una falsa ciencia. Las pseudociencias se disfrazan de ciencia para arrogarse el prestigio social de la ciencia. Los pseudocientíficos suelen odiar y, al mismo tiempo, envidiar lo científico. Por un lado, les molesta la crítica que les hace la ciencia establecida, pero, por otro, les encanta el prestigio social que conlleva ponerse una bata. Al público general le es difícil, en muchos casos, distinguir las afirmaciones científicas de las pseudocientíficas y esto causa todo tipo de problemas sociales. Por ejemplo, cuando yo escuchaba a los portavoces de Greenpeace hablar sobre residuos nucleares creía estar atendiendo a razonamientos serios. Este problema se agrava todavía más por la inaccesibilidad, para el no especialista, de una gran parte del conocimiento científico. Las pseudociencias suelen ser más intuitivas que la ciencia real y las creencias más sencillas e intuitivas son más atractivas y se difunden con mayor facilidad.1278 A mí me resulta muy complejo explicarle a mi madre, que no acabó más que la educación primaria, pero que tiene una gran curiosidad e interés, qué es un anticuerpo y por qué su presencia no garantiza inmunidad ni su ausencia implica necesariamente vulnerabilidad. El sistema inmune es extraordinariamente complejo. Sin embargo, para un pseudocientífico es muy fácil argumentar que el aloe lo cura todo porque es natural. La adquisición de los conocimientos científicos es costosa, pero la transmisión de estupideces es sencilla. Además, las pseudociencias, en muchos casos, combinan la atracción por lo natural o lo tradicional con el uso de terminología aparentemente científica. Los chakras o la energía chí no sólo son milenarios, sino que están relacionados con la misteriosa mecánica cuántica (y con el Ziritione). Por si esto fuese poco, dado que prometen remedios sencillos para problemas serios, las pseudociencias suelen ser especialmente atractivas para la gente en situaciones más vulnerables.1279 Este atractivo hace que las gilipolleces pseudocientíficas se difundan mucho más rápido que el conocimiento científico. Jonathan Swift, en 1710, escribió: las mentiras vuelan mientras la verdad la sigue renqueando.1280 A este problema debemos añadirle el recogido por Brandolini en su principio: la energía requerida para desmontar una gilipollez es un orden de magnitud superior a la empleada en su generación.1281 De modo que, tal y como escribió el bloguero italiano Uriel Faneli: un embaucador puede difundir más gilipolleces de las que uno puede soñar con desmontar y, además, éstas tienden a difundirse muy rápidamente. Los ad hocs de los pseudocientíficos reflejan una resistencia absoluta a los datos, no están dispuestos a cambiar sus ideas vean lo que vean, su actitud podría resumirse por: “Yo lo tengo claro, así que no vengas a liarme con los datos.”1282 Aunque no disponemos de un criterio preciso que nos permita establecer el límite exacto entre la razón y la sinrazón, lo que está claro es que el uso que hacen de los ad hocs es muy distinto al que hizo Le Verrier al plantear la existencia de un nuevo planeta. En ciencia equivocarse no es un problema, pero empecinarse sí lo es.1283 Además, los pseudocientíficos suelen utilizar las evidencias de un modo muy sesgado, aprovechan las que confirman sus ideas previas y descartan las que les estorban. Las pseudociencias se caracterizan por utilizar metodologías muy poco rigurosas.1284 Por ejemplo, los estudios dedicados a la homeopatía que obtienen resultados positivos casi siempre implican a pocos pacientes y, en muchos casos, ignoran la recomendación del doble ciego. Esto hace que los efectos que se encuentran en estos estudios suelan deberse más a problemas estadísticos que a efectos reales. Cuando alguien trata de replicar esos resultados utilizando metodologías más robustas los efectos desaparecen.1285 Esta es una de las características típicas de la pseudociencia, se hacen afirmaciones grandiosas basándose en evidencias muy pobres.1286 La pobreza metodológica es una cualidad compartida por la pseudociencia y la mala ciencia. De hecho, en algunos casos, como en la parapsicología, es difícil distinguir entre ambas actividades. Tal vez la principal diferencia estribe en que la mala ciencia se da dentro de comunidades científicas. Las hipótesis científicas, además, suelen engarzarse con el resto de conocimientos que tenemos sobre el cosmos. Los investigadores de un área científica no suelen plantear hipótesis que entran en contradicción con conclusiones fundamentales de otras áreas.1287 Las ciencias aspiran a ofrecer una visión integrada del cosmos.1288 Sin embargo, si la parapsicología o la astrología fuesen ciertas deberíamos tirar a la basura nuestros libros de física. Las comunidades científicas están interconectadas y, en muchas ocasiones, estudian fenómenos utilizando aproximaciones multidisciplinares. Por ejemplo, mis últimos trabajos tratan aspectos botánicos, genéticos clásicos, genéticos moleculares, genómicos, estadísticos, computacionales y relacionados con los recursos fitogenéticos. Cualquier experto en estas áreas podría aportar críticas valiosas. Esto, en el fondo, es posible porque, aunque cada uno tiene un punto de vista, todos estamos estudiando un mismo fenómeno que existe en el mundo externo. Las pseudociencias, sin embargo, no sólo contradicen lo que sabemos sobre el universo, sino que se contradicen entre sí mismas. En una feria de terapias pseudocientíficas pueden promocionarse tanto la homeopatía como las terapias basadas en tomar altas dosis de vitaminas sin que a sus proponentes les extrañe lo más mínimo que ambas aproximaciones se basen en principios contradictorios. Recordemos que las gilipolleces suelen caracterizarse por su falta de coherencia. En las pseudociencias ni dentro de un área concreta ni entre áreas distintas suelen encontrarse expertos que intenten buscar evidencias contrarias a las hipótesis propuestas ni que critiquen los argumentos expuestos. Al hablar sobre las comunidades científicas me lamenté por la falta de crítica, pero el caso de los pseudocientíficos es muy distinto, esta gente no sería capaz de reconocer una crítica racional aunque estuviese pintada de rojo y les pegase en la cabeza. Es cierto que yo agradecería algo más de crítica racional en las comunidades científicas, pero ni de lejos se tolera en ellas la pasmosa falta de rigor que impera en las comunidades pseudocientíficas. De hecho, en estas últimas la norma suele ser la hostilidad a la crítica.1289 Para un pseudocientífico las hipótesis no son herramientas para entender el mundo externo, sino conclusiones que deben ser defendidas a toda costa. De hecho, una de las estrategias más habituales de los pseudocientíficos es reaccionar a las críticas aduciendo ser víctimas de campañas orquestadas por élites institucionales opuestas a su humilde búsqueda de la verdad.1290 Una de las defensas favoritas del pseudocientífico es apelar a la figura de Galileo: “a él también lo persiguieron las élites por decir la verdad.”1291 Este es signo tan distintivo que sirve prácticamente como rasgo suficiente: si lo lees en un texto, casi seguro que es pseudocientífico. Este es sólo uno de los mecanismos de defensa epistémica con el que las conclusiones pseudocientíficas tratan de blindarse contra la crítica.1292 La parapsicología, según sus proponentes, funciona, pero deja de hacerlo cuando un escéptico trata de analizar el fenómeno puesto que su negatividad interfiere. Otro recurso típico consiste en apelar a la conspiración:1293 no se han encontrado evidencias claras de visitantes extraterrestres porque todas las agencias gubernamentales de todos los gobiernos las ocultan con una efectividad absoluta. Además, dada la falta de crítica dentro de sus comunidades, las publicaciones de los pseudocientíficos no suelen dirigirse a otros expertos, sino al público general.1294 Esta es una particularidad muy distintiva de las comunidades pseudocientíficas. Como no hay discusión dentro de ellas, sus textos suelen tener como objeto la promoción de sus ideas entre el público general. En el caso de las comunidades científicas sucede todo lo contrario, los científicos suelen escribir pensando en las posibles críticas de otros expertos y sus artículos, en pocas ocasiones, pueden ser apreciados sin una extensa formación previa en el área. A los científicos se les suele acusar de estar encerrados en su torre de marfil discutiendo sobre detalles nimios, se les achaca que olviden comunicar los aspectos más relevantes de sus campos de estudio al público general. Sin embargo, los pseudocientíficos se desgañitan en la plaza del pueblo vendiendo sus bálsamos de Fierabrás. Otro modo de defensa de la pseudociencia es hablar de gilipolleces nebulosas. Recordemos que ya hemos comentado el ensayo de Harry G. Frankfurt Sobre las gilipolleces (1986). Los pseudocientíficos plantean conceptos y propuestas tan vagas que, en la práctica, no pueden ser discutidas racionalmente.1295 Parecen estar proponiendo algo, pero, en realidad, no están diciendo nada que tenga sentido. ¿Qué significan realmente el chí o la memoria del agua? Popper ya nos previno contra esta estrategia, las gilipolleces son imposibles de falsar y, por lo tanto, no son ciencia. La supuesta existencia de la energía chí no tiene efectos empíricos claros. Un investigador racional habría de preocuparse por predecir qué debería observarse tanto si sus hipótesis fuesen correctas como si no lo fuesen. Si ni tan siquiera eres capaz de hacer predicciones empíricas, tienes un problema serio. Además, si suceda lo que suceda no vas a modificar tu hipótesis, no estás siendo racional. Siempre tienes que preguntarte, por cuáles serían las evidencias que te harían abandonar tu hipótesis. Si la respuesta es que ninguna evidencia puede hacerte cambiar de opinión, te has aislado del mundo externo, estás encerrado en tu propia red de ideas y tu conocimiento no podrá progresar. La falta de rigor intelectual que caracteriza a los pseudocientíficos también se manifiesta en el uso que hacen de las citas y las referencias bibliográficas. Suelen utilizar citas de expertos fuera de contexto o citar como pretendidos expertos, para tratar una cuestión concreta, a expertos de áreas completamente distintas.1296 Por ejemplo, ha habido varias cartas abiertas en defensa del creacionismo firmadas por doctores, pero no por doctores especializados en filogenia, paleontología o geología, sino respaldadas por psicólogos, matemáticos o lingüistas. Yo soy experto en genética de poblaciones, pero te garantizo que mis afirmaciones sobre el estado del motor de tu coche no merecen ninguna atención. Otra táctica muy utilizada por los pseudocientíficos es exagerar las discusiones legítimas, que se dan dentro de las propias comunidades científicas, para deslegitimar el consenso científico.1297 Por ejemplo, los negacionistas del cambio climático o los creacionistas suelen utilizar las criticas a aspectos muy concretos hechas por expertos como prueba de que no hay acuerdo, ni siquiera, en las cuestiones más generales referentes al cambio climático o a la historia geológica del planeta. Otra diferencia entre ciencia y pseudociencia es que, mientras que las ciencias progresan y se refinan teniendo en cuenta las evidencias empíricas, las pseudociencias suelen estancarse y sus comunidades se dedican a buscar excusas que expliquen porque las evidencias nunca acaban de llegar o porque parecen indicar precisamente lo contrario. Hay muchos resultados que indican que la homeopatía no funciona, pero esto no hace mella en la mayoría de los homeópatas. 20.6 Entre el día y la noche Para terminar, volvamos a insistir en que las distinciones entre ciencia, mala ciencia, fraude científico y pseudociencia, como ya hemos comentado, no son absolutamente nítidas.1298 Dentro del mundo académico convencional se cuelan las pseudociencias. Por ejemplo, los casos en medicina o psicología son conocidos. Incluso en mi propio departamento, adscrito a la escuela de agrónomos, hay quien defiende la agricultura pseudoecológica a pesar de que sabemos que es más perjudicial para el medioambiente y de que, según la FAO, no puede alimentar a la humanidad. Normalmente, la pseudociencia en el mundo académico suele disfrazarse de ciencia haciendo mediciones cuantitativas y análisis estadísticos, es lo que Feynman, como comentamos en el capítulo anterior, denominaba cultos del cargo. En esos casos la ciencia es metodológicamente tan poco rigurosa, es tan mala ciencia que, en la práctica, casi llega a confundirse con la pseudociencia 20.7 Resumen La ciencia está formada por un conjunto de disciplinas que estudian aspectos muy diferentes del cosmos. Algunos de los fenómenos investigados, como los planos inclinados, son reproducibles y se prestan a un análisis basado en experimentos controlados, sin embargo, en otras áreas, como en la filogenética, se trata de reconstruir y comprender hechos históricos, que no volverán a ocurrir, partiendo de los vestigios que dejaron. Cuando las cuestiones investigadas tienen comportamientos relativamente sencillos es posible hacer predicciones, pero, en otros casos, como en la macroeconomía, pueden influir multitud de causas o puede haber interacciones entre distintas escalas. En el estudio de estos fenómenos la varianza de las observaciones suele deberse a variables no controladas y la predicción y la experimentación controlada, normalmente, no son posibles, por lo que hemos de conformarnos con la observación y la descripción y esto dificulta la contrastación empírica. Por otro lado, cuando los datos son escasos o cuando no son neutrales respecto a las teorías evaluadas dejan de ser testigos independientes en el juicio de esas mismas teorías. En estas áreas corremos el riesgo de que las conclusiones alcanzadas dependan más de las dinámicas sociales, de los propios investigadores, que del mundo externo. Es entonces cuando conviene extremar la precaución puesto que es más fácil confundir narrativas, que poco tienen que ver con la realidad, con conocimiento legítimo. Por el contrario, cuando el éxito operacional, como en el caso de las tecnologías, es claro, estamos menos expuestos a estas limitaciones y es más fácil evaluar el progreso del conocimiento. A estas dificultades debemos añadirles las tentaciones asociadas al merecido prestigio social de la ciencia. La pertenencia a las comunidades científicas habría de corresponderse con una integridad intelectual radical, pero este no es siempre el caso y la mala ciencia abunda. Esta ciencia metodológicamente pobre, en el límite, se confunde con el fraude científico deliberado. Además, estos problemas no son independientes de las dificultades debidas a los fenómenos estudiados ya que cuanto más difícil sea la evaluación empírica más fácil será esconder la mala ciencia. La pseudociencia también se caracteriza por ser metodológicamente pobre y, en algunos casos, es difícil distinguirla de la mala ciencia. Tal vez, en la práctica, las mayores diferencias entre ambas sean que los supuestos fenómenos estudiados por la pseudociencia han sido descartados por las comunidades científicas y que las comunidades pseudocientíficas suelen formar grupos aislados. No hay unas características necesarias y suficientes que distingan ciencia y pseudociencia, pero, aunque estos fenómenos se encuentren en un espacio multidimensional continuo, pueden ser distinguidos. Las pseudociencias constituyen un problema social importante, por ejemplo, en muchos casos plantean pseudoterapias que prometen soluciones sencillas a personas desesperadas. Además, suelen ser muy atractivas ya que son más intuitivas y esto hace que se difundan con gran facilidad entre una ciudadanía falta de una formación sólida en análisis critico. Las pseudociencias tienen la necesidad de aislarse del mundo externo y de la crítica ya que sus conclusiones, en realidad, no son conjeturas sobre el funcionamiento del mundo externo, sino creencias que deben ser defendidas a capa y espada. Un físico con una hipótesis falsada sigue siendo un físico, un homeópata que acepte los datos es una persona en la cola del paro y sin profesión. Para conseguir este blindaje epistémico utilizan distintas estrategias. Por ejemplo, se aíslan de la crítica, que debería ser bienvenida, proponiendo excusas ad hoc o aduciendo ser víctimas de campañas y conspiraciones orquestadas en su contra. Del mundo externo se aíslan, en muchos casos, planteando propuestas vagas que, en la práctica, no son falsables. Cuando sí hacen predicciones claras, como que van a curar una dolencia, además de excusar las observaciones opuestas a sus tesis, echan mano de cualquier evidencia que pueda apoyar sus conclusiones sin importarles su calidad. Las distintas pseudociencias no sólo están aisladas del mundo externo y de la ciencia, sino que están separadas entre sí. Las diferentes comunidades pseudocientíficas no tratan de ofrecer una visión integrada del mundo, como sí lo hacen las científicas. A los homeópatas y pseudoterapeutas ortomoleculares la incoherencia de recetar cantidades inexistentes de principio activo o altas dosis de vitamina no parece hacerles mella. Por último, mientras que las ciencias progresan acumulando fenómenos nuevos, descripciones más adecuadas, predicciones más precisas y creando tecnologías, las pseudociencias se estancan perdidas en una eterna contemplación de sus ombligos y en un lamentable victimismo. "],["verdad_y_metafisica_part.html", "Verdad y metafísica", " Verdad y metafísica "],["verdad.html", "21 Verdad 21.1 Correspondencia y empirismo 21.2 Es verdad lo que es coherente 21.3 Son verdaderas las conclusiones de una comunidad racional 21.4 Es verdad lo que funciona 21.5 La verdad no es para tanto 21.6 Resumen", " 21 Verdad El concepto de verdad, en principio, no parece ser muy problemático: es verdad que hay un gato junto a mí si realmente hay un gato junto a mí. Sin embargo, a pesar de la importancia del concepto y del intenso debate filosófico, todavía no se ha alcanzado un consenso filosófico sobre qué estamos diciendo cuando afirmamos que algo es verdadero.1299 Ya comentamos que el concepto de verdad es heterogéneo, que es distinto referirse a verdades matemáticas, morales o factuales. Este capítulo profundizaremos sobre la cuestión relativa a las verdades factuales, es decir, a las relacionadas con el mundo externo. Además, es necesario reconocer que la relación de la ciencia con la verdad es sutil ya que los científicos, en muchas ocasiones, se conforman con trabajar con modelos aproximados. Por ejemplo, los ingenieros que enviaron a Armstrong a la Luna utilizaron la física newtoniana a pesar de disponer de una teoría empíricamente superior. El conocimiento cotidiano tampoco está exento de este problema ya que, al fin y al cabo, cuando afirmo que hay un gato junto a mí, estoy utilizando el término “gato” para referirme a un patrón real muy complejo que podría elegir describir con una precisión mucho mayor. Pero dejemos el problema de las vacas esféricas al margen y centrémonos en el debate tal y como lo han planteado los epistemólogos y lógicos. 21.1 Correspondencia y empirismo Según la teoría de la correspondencia, la verdad reside en la relación entre la creencia y el mundo externo: son verdaderas aquellas creencias que se corresponden con la realidad.1300 Esta es una propuesta que fue planteada por Platón en el Crátilo y el Sofista y que Aristóteles describió del siguiente modo: “Es falso decir de lo que es que no es y de lo que no es que es, mientras que es verdadero decir de lo que es que es y de lo que no es que no es”. Es decir, son verdaderos aquellos aspectos del mapa que se corresponden con el territorio. Esta definición clásica continúa siendo aceptada por muchos filósofos actuales,1301 aunque, como comentaremos, los proponentes de las otras teorías sostienen que los aspectos más relevantes de esta correspondencia pueden derivarse como corolario de sus otras propuestas.1302 Además, es necesario reconocer que esta teoría implica limitaciones que son muy relevantes para la filosofía de la ciencia. Tal vez el principal problema surja al aceptar que no tenemos un acceso directo al territorio. Lo que hacemos es recibir información del mundo externo y, teniéndola en cuenta, creamos representaciones en nuestra mente.1303 Por lo tanto, si para decidir si una afirmación es verdadera hemos de recurrir a compararla con el territorio, pero éste no es accesible directamente, en realidad, lo que estaremos haciendo es comparar distintas creencias entre sí. A la tesis de que lo único que podemos percibir directamente son representaciones mentales, pero no el mundo externo, se le denomina ideismo.1304 Esta tesis fue defendida por los empiristas británicos, como Locke y Hume, y no es muy controvertida. El ideismo no es una tesis metafísica, sino, simplemente, una teoría sobre el funcionamiento de nuestra percepción y nuestra mente, no niega la existencia de los objetos externos y no debe confundirse con los idealismos filosóficos. Podemos reflexionar sobre la labor de nuestra mente haciendo una analogía con el quehacer de Eratóstenes. Uno de los cometidos del encargado del Museo consistía en cartografiar el mundo conocido. Imaginemos a un Eratóstenes, retenido en Alejandría por sus diversas responsabilidades que crearía sus mapas basándose en la información recabada por su equipo de emisarios. En este caso Eratóstenes crearía y contrastaría sus mapas sin tener un acceso directo al territorio. Esta es más o menos la posición de nuestra mente que, basándose en la información recibida a través de los sentidos, construye modelos sobre el mundo externo. ¿Cómo puede sostenerse entonces la teoría de la correspondencia si todo lo que tenemos en la cabeza son mapas? En todo caso, podríamos comparar unos mapas con otros o podríamos enviar nuevos emisarios a hacer alguna comprobación adicional, pero nunca podríamos comparar un mapa directamente con el territorio. Además, en la práctica, tampoco es trivial cotejar diferentes modelos del mundo externo. Por ejemplo, no es fácil comparar los modelos cuántico, relativista y newtoniano del mundo físico. Hemos de proceder cotejando predicciones de los mismos relativas a diferentes aspectos o, si somos capaces, evaluando la diferencia general de sus estructuras lógico-matemáticas. Sin embargo, como este es un asunto que nos desviaría del tema que nos ocupa en este capítulo, lo dejaremos apartado. Las limitaciones de la teoría de la correspondencia tienen interesantes consecuencias científicas. Por ejemplo, ¿en el tiempo de Aristarco era verdad que la Tierra se movía? Según la correspondencia, las ideas de Aristarco se correspondían con la realidad externa y, por lo tanto, eran verdaderas. Sin embargo, en aquel momento, había evidencias empíricas que parecían contradecir el modelo heliocéntrico, no se observaba ninguna consecuencia del supuesto movimiento terrestre: no había grandes vientos y no se observaba paralaje en los astros a lo largo del año. Por lo tanto, la propuesta de Aristarco no estaba más justificada que cualquiera de los otros modelos geocéntricos. Lo máximo que se podía decir en su favor es que explicaba las mismas observaciones utilizando un modelo geométricamente más sencillo; aunque, para aceptarla había que asumir un par de anomalías que se esperaba solucionar en el futuro. Por lo tanto, desde el punto de vista de alguien que dispusiese de las evidencias que se manejaban en aquel tiempo la propuesta de Aristarco no era más racional que los modelos heliocéntricos. Un defensor de la teoría de la correspondencia, sin embargo, podría aducir que, a pesar de que en la época no podía saberse el modelo de Aristarco era el verdadero puesto que la realidad externa era la que era, la Tierra, al fin y al cabo, se movía, y, por lo tanto, haciendo las investigaciones necesarias, eventualmente, se podría llegar a decidir qué modelo se correspondía con el territorio. Esto es aceptable, pero conlleva un alto precio ya que implica asumir que hay aspectos desconocidos del mundo externo. Si admitimos este problema podríamos decir que el modelo de Aristarco era tan verdadero entonces como lo es ahora porque la verdad depende del territorio, pero, al mismo tiempo, hemos de aceptar que Aristarco no podía justificar que su modelo era verdadero. En este sentido parecería que, en realidad, la teoría de la correspondencia añade poco a la admisión de que la información recibida del mundo externo ha de tener la última palabra. Simplemente estaríamos reafirmando nuestro compromiso con el empirismo, pero continuaríamos sin haber explicado qué queremos decir al afirmar que una teoría es verdadera. ¿Por qué Aristarco no estaba justificado para decir que su modelo era verdadero y ahora sí lo estamos? El lector podría pensar que sería verdadero aquello que tiene una justificación suficientemente sólida y que, por lo tanto, es aceptado por la comunidad, pero esta no es la propuesta empirista sino la pragmática. Por otro lado, la teoría de la correspondencia se asocia habitualmente con el fundacionismo. Esta propuesta sostiene que el conocimiento se asienta sobre unas bases infalibles, por ejemplo, sobre la lógica y las evidencias. El problema es que, como hemos visto, incluso las observaciones, aunque nos provean de evidencias especialmente fuertes, también son falibles. El conocimiento no se apoya sobre fundamentos graníticos infalibles, sino, más bien, sobre un cenagal que debemos pisar con sumo cuidado.1305 Tanto los pragmatistas como los coherentistas, dos de las corrientes que plantean alternativas a la correspondencia, incorporan en sus propuestas esta limitación: cualquier creencia es falible y revisable. Incluso las reglas de inferencia que se aceptaban en el pasado han tenido que refinarse. 21.2 Es verdad lo que es coherente Imaginemos que nos encomiendan la misión de detectar personas contagiadas por un virus. Disponemos de diferentes pruebas diagnósticas moleculares como Reacciones en Cadena de la Polimerasa (PCR) y pruebas de detección de anticuerpos y de antígenos. Además, por supuesto, un médico experto podría evaluar la sintomatología de cada individuo. Ahora supongamos que hacemos una PCR a un individuo completamente asintomático y obtenemos una señal positiva. ¿Debemos concluir que el resultado de la PCR es un falso positivo o, por el contrario, que la persona sí está contagiada, pero que, simplemente, no tiene síntomas? En este caso la teoría de la correspondencia no nos ayudaría demasiado, la persona estará infectada o no lo estará, pero no tenemos forma de comparar directamente nuestras ideas con la realidad externa. Lo que sí podemos hacer es repetir la PCR y encargar pruebas de detección de antígeno y anticuerpos complementarias. Una vez dispongamos de todos los resultados, podemos reevaluar la situación considerando el conjunto de evidencias. Será la red completa de evidencias y de inferencias basadas en ellas la que nos permita alcanzar una conclusión. Los coherentistas proponen que es verdad aquello que encaja en una teoría coherente, que la verdad consiste, precisamente, en la coherencia de la red de creencias.1306 El modo de saber si un pensamiento es verdadero es analizar cómo encaja con el resto de creencias de la red. La esperanza es que, eventualmente, podamos conseguir llegar a tener una red de creencias coherentes sobre el mundo externo. El coherentismo tiene la ventaja de no poner el énfasis en un territorio externo al que no podemos acceder directamente. Además, esta teoría respeta un estándar epistémico importante: es erróneo mantener creencias arbitrarias que no encajan con el resto de la red de creencias. Por ejemplo, la creencia de que el universo tiene sólo 6000 años de antigüedad es incoherente con las evidencias geológicas, con la física nuclear, con la paleontología y con la historia de las civilizaciones y esto es negativo. Otra ventaja de esta teoría es que no exige que asentemos el conocimiento sobre bases infalibles. Este es un problema que ya planteamos al comentar las impresiones cognitivas estoicas. Para el coherentista la fuerza de la creencia depende de sus conexiones con el resto de la red de creencias, no de unas observaciones infalibles concretas. Un aspecto importante a tener en cuenta es que, si estamos estudiando el mundo externo, algunas de las creencias de la red habrán de estar ancladas empíricamente con ese mundo; deben estar justificadas por información recibida desde el territorio. La coherencia, por sí misma, es un criterio excelente para sistemas formales, pero si deseamos que la estructura de la red sea útil para manejarnos en el mundo externo debe incorporar información empírica.1307 Esta influencia empírica puede permear la red de creencias gracias a que la creación de muchas percepciones y creencias está influida, fundamentalmente, por la información que nos llega del mundo externo.1308 Es decir, la red debe incluir creencias coherentes e información recabada en el mundo externo y, gracias a ello, su estructura servirá como guía para movernos por el territorio. Este anclaje empírico no estaría basado en fundaciones absolutamente sólidas. Cada uno de la multitud de hilos de unión lanzados desde distintos puntos de la red de creencias al mundo externo puede ser más o menos falible, pero la coherencia de la red aporta una gran robustez. En relación al coherentismo los filósofos suelen mencionar el problema de las múltiples posibles redes coherentes. Existen distintos posibles modelos mentales coherentes. Sin embargo, la inclusión de evidencias empíricas fuerza a que la estructura de cualquier red que aceptemos sea aproximadamente similar, por ejemplo, no habrá redes coherentes que puedan incluir unicornios rosas. Aunque es cierto que nunca conseguiremos reducir el número de redes aceptables a una sola; el problema de la subdeterminación no puede ser eliminado completamente y esto tiene una consecuencia extraña para los coherentistas, deben aceptar que, incluso aunque se asuma un único mundo externo, hay distintas posibles verdades,1309 tantas como redes coherentes puedan construirse. Aunque no es menos cierto que estas redes alternativas, en las regiones más ricas en conexiones con el mundo externo, tendrán estructuras bastante similares. Este punto volveremos a discutirlo en el capítulo dedicado al estructuralismo. 21.3 Son verdaderas las conclusiones de una comunidad racional Los pragmatistas analizaron la verdad desde otro punto de vista. Estos filósofos se centraron en el proceso de investigación y propusieron que son verdaderas aquellas conclusiones que han terminado siendo consensuadas tras una investigación rigurosa.1310 Según estos pensadores es la investigación sistemática la que hace que nuestras creencias vayan convergiendo paulatinamente con la realidad.1311 Según Charles Sanders Peirce (1839 - 1914), uno de los grandes representantes del pragmatismo, es verdadero aquello que la comunidad, eventualmente, acaba consensuando. Peirce pensaba que la verdad no puede asociarse, como propone la teoría de la correspondencia, con un punto de vista que sólo un dios omnisciente podría tener, sino que tiene que ser el resultado de un proceso de investigación cuidadoso.1312 Además, resulta notable que los pragmatistas se anticipasen a Kuhn al defender que la autoridad no reside en el individuo o en la normatividad epistémica, sino en la comunidad. El consenso es mucho más fiable que cualquier creencia individual. Esta es una idea que hemos ido encontrando repetidamente. Por ejemplo, para el científico moderno las evidencias interesantes eran las intersubjetivas: no es que yo diga que estoy viendo al gato, sino que quien lo desee puede observar el animal. Una consecuencia de esta propuesta es que para que se pueda hablar de verdad debe haberse llegado a un acuerdo mediante un diálogo racional. De esto se sigue otro resultado práctico: si deseamos saber cuál es la verdad sobre un asunto determinado hemos de investigar si la comunidad de expertos relevante ha alcanzado un consenso. Recordemos que, debido a los inevitables errores científicos, a las malas prácticas y al fraude, ningún estudio aislado es definitivo. Esta es una idea que los no expertos deberíamos hacer bien en recordar. Seguir el tráfago diario de un área científica, que es lo que suelen hacer los periodistas, puede llegar a confundir. Tal vez para el no experto sea mejor leer sobre ciencia establecida, sobre asuntos ya consensuados.1313 Yo, particularmente, prefiero leer sobre la evolución de la teoría de la relatividad desde Lorentz a Einstein que invertir mi tiempo en navegar la confusa tormenta de las noticias científicas cotidianas. Sin embargo, como no podía ser de otro modo, esta confianza en los consensos no está exenta de problemas. Por un lado, los pragmatistas asumían que el consenso puede estar equivocado, es falible y, en algún momento, puede ser reemplazado. Además, para el experto el consenso no es una guía infalible ya que es capaz de evaluar las evidencias y las inferencias e, incluso, proponer una revisión del mismo. Al fin y al cabo, muchas de las nuevas ideas aparecen gracias a voces discrepantes dentro de la comunidad. Galileo estaba menos preocupado por los consensos que por las justificaciones racionales basadas en sólidas evidencias empíricas y Kepler escribió: “prefiero la crítica aguda de una sola persona inteligente que la irreflexiva aprobación de la masa”. Eso sí, es muy importante recordar que tanto Galileo como Kepler habían hecho los deberes, formaban parte de la comunidad de expertos, conocían todos los detalles relevantes de su posición y de la de sus rivales intelectuales. Además, como ya hemos discutido, tras una corta deliberación el grueso de la comunidad asumió las justificaciones galileanas y rechazó el modelo ptolemaico. El investigador propone y la comunidad, eventualmente, tras una deliberación, que ha de ser racional, dicta sentencia. Es importante recordar que el diálogo racional está dificultado por los incentivos perversos a los que está sometida la comunidad. Si estos incentivos son capaces de convertir este diálogo en una actuación teatral vacía de contenido, el consenso comunitario valdrá menos que una flatulencia del Gran Poni Rosa. Por ejemplo, la Iglesia Católica ha conseguido mantener durante siglos amplios consensos sobre la transubstanciación de las hostias ocurrida durante la comunión, sobre la naturaleza de la santísima trinidad o sobre el pecado original y nada de esto parece estar relacionado con el mundo existente fuera de la cabeza de sus teólogos. Es importante reconocer qué consensos son puramente internos. Una buena recomendación es confiar sólo en los consensos que no han sido contradichos por otras comunidades independientes de investigadores rigurosos. En cualquier caso, es importante recordar la necesidad de defender una cierta normatividad epistémica. En esto, tal vez, haga más énfasis el coherentismo. De hecho, por mucho que una comunidad concreta se empeñe en defender una conclusión estúpida, cualquier experto ha de poder cuestionarla siguiendo la lógica y las evidencias. La justificación del conocimiento y el concepto de verdad están obligados a guardar un equilibrio entre la autoridad de las comunidades de expertos y los estándares epistémicos.1314 21.4 Es verdad lo que funciona Los pragmatistas también reflexionaron sobre otro aspecto del conocimiento, su relación con la acción sobre el mundo externo. Si deseamos conseguir buenos mapas es, precisamente, para poder movernos con éxito en el territorio.1315 El conocimiento del mundo externo implica una disposición para la acción; se obtiene con el objetivo de intervenir con éxito sobre el mundo. En este sentido sería verdad aquello que funciona. Los buenos mapas son aquellos que nos permiten planificar expediciones exitosas y aquellas creencias que conducen a acciones fallidas serían erróneas. Esta relación entre verdad y acción fue adelantada por muchos filósofos. Recordemos, por ejemplo, que esta fue, precisamente, la mayor autocrítica de los escépticos helenísticos: renunciar a la posibilidad de conocimiento implicaba renunciar a la capacidad de acción. En este momento viene bien recordar una lección del aprendizaje automático, el área a caballo entre la estadística y las ciencias de la computación que trata de crear algoritmos capaces de encontrar patrones en las evidencias. Los investigadores de esta disciplina son muy conscientes de que conviene no confiar en los modelos creados por estos algoritmos estadísticos hasta que su éxito es contrastado con conjuntos de datos independientes. El problema es que es habitual construir modelos justificados por las evidencias disponibles, pero que después carecen de valor predictivo. Esto es lo que sucede, por ejemplo, cuando en un análisis estadístico nos topamos con el problema del sobreajuste. Un modelo sobreajustado, aparentemente, refleja la estructura contenida en la información que se utilizó para crearlo, pero, en realidad, su estructura incluye detalles espurios sin valor alguno. El mejor modo de separar estos modelos sobreajustados de los útiles consiste, precisamente, en contrastar sus predicciones con información independiente. En este sentido serían verdaderos aquellos modelos capaces de hacer predicciones válidas sobre la estructura de los nuevos datos. Esta es una idea muy relacionada con la disposición para la acción del conocimiento. Sería conocimiento aquello que nos permite hacer predicciones capaces de guiar nuestras acciones con éxito. Recordemos también que esto es, precisamente, lo que hacen los seres popperianos, modelar el mundo externo para poder predecir el resultado de sus acciones. Estas ideas están también estrechamente relacionadas con el método hipotético-deductivo, así como con el éxito operacional de la ciencia. Si no contrastamos de algún modo nuestras hipótesis nos arriesgamos a tener un modelo, tal vez justificado por las evidencias disponibles, pero que, en realidad, no se corresponde con la estructura del mundo externo. Esta es otra limitación fundamental del conocimiento derivada del salto inductivo. La relación con la teoría de la correspondencia también es estrecha. Podría decirse que se corresponden con el mundo aquellos modelos que nos permiten actuar con éxito sobre la realidad externa. No tenemos un acceso directo al mundo externo, pero sí la capacidad de ir sondeándolo.1316 Además, dado que la realidad es aquello que es independiente de nuestras creencias, puede que nuestras predicciones tengan éxito o que fallen. Esta es una idea que debe ser conservada por cualquier teoría relativa al conocimiento del mundo externo. Eratóstenes no tenía en su cabeza el territorio del imperio, pero sí podía enviar emisarios para hacer comprobaciones adicionales. Esto nos permite recuperar los aspectos más valiosos de la teoría de la correspondencia sin exigir una perspectiva omnisapiente. No podemos salir de nuestras mentes, pero nuestras mentes sí pueden interaccionar con el mundo externo, de hecho, este es, precisamente, uno de los objetivos principales del conocimiento del mundo externo. Estas cuestiones volveremos a tratarlas en los capítulos siguientes, los dedicados a los aspectos más metafísicos. No tiene sentido hablar de verdades factuales si no podemos conseguir que el mundo externo y nuestros modelos interactúen de algún modo. Por ejemplo, es muy difícil justificar que es verdad que existe un dios si, al mismo tiempo, asumimos que este dios tiene la capacidad de ocultarse hasta ser completamente invisible. Este último requisito implica que hablar de verdad, en este caso, carece de sentido. Sin embargo, esta tesis también plantea un problema, ¿cuándo podemos considerar que hemos contrastado suficientemente una hipótesis? En principio, cualquier hipótesis bien justificada debería ser capaz de reflejar parte de la estructura de los datos que hemos utilizado para construirla. Sin embargo, como estamos comentando, la justificación adecuada no garantiza que vaya a funcionar el modelo en otros conjuntos de datos. En cualquier momento lo que creíamos verdad podría desmoronarse; incluso nuestras creencias mejor justificadas son falibles. Además, recordemos que Hume nos avisó de que siempre estamos expuestos al problema de la uniformidad del cosmos: nuestros modelos sólo funcionarán mientras los patrones del territorio que nos han permitido generarlos se mantengan. Hume nos previno de que es imposible llegar a estar seguros de que nuestros modelos funcionarán en cualesquiera circunstancias futuras. En cualquier caso, al menos, hemos de tratar de testar nuestras hipótesis con informaciones independientes recogidas en circunstancias variadas. Esta fue, precisamente, una de las principales innovaciones metodológicas planteadas por Galileo. Aquellos modelos que sobrevivan esta purga, al menos, habrán demostrado una cierta fiabilidad dentro del rango de circunstancias en los que los hemos comprobado. Por ejemplo, la mecánica newtoniana fue comprobada con éxito con manzanas y planetas. Esta contrastación que permitió inferir que en el futuro, probablemente, seguirá funcionando con otros objetos similares. Evidentemente, cuando tratamos de extrapolar los modelos, de aplicarlos más allá de los rangos en los que fueron contrastadas, corremos un riesgo mayor. Esto es, precisamente, lo que sucedió con la mecánica newtoniana cuando se trató de aplicar a campos gravitatorios muy intensos. Para los pragmatistas el proceso de investigación válido es aquel que conduce a generar creencias que terminan funcionando. Este es el motivo por el que, para los pragmatistas, la disposición para la acción y el proceso de investigación están relacionados.1317 La comunidad de investigadores va acumulando observaciones, haciendo experimentos y teniendo en cuenta qué predicciones son exitosas y cuales no y es esto lo que permite que su red de creencias vaya adquiriendo paulatinamente una estructura similar a la del mundo externo. Se comienza con unas ideas y capacidades previas, como en el barco de Neurath, y, poco a poco, vamos modificando tanto unas como las otras.1318 Mientras que el coherentismo ponía el acento sobre la red de creencias y su relación con las evidencias empíricas, el pragmatismo nos recuerda que esta red debe ir actualizándose en base a los éxitos y fracasos de nuestras investigaciones.1319 Además, incluir el éxito operacional nos permite comprender como es posible que podamos modificar tanto las creencias relativas al mundo externo como las metodologías que utilizamos para generarlas. Seleccionamos aquellos métodos que tienden a generar conclusiones que suelen tener un mayor éxito. Esto es, en realidad, un metamétodo. Kuhn no pudo comprender cómo podían comparase paradigmas que difiriesen en las metodologías y esta es la respuesta a su problema: hay unas metodologías más fundamentales que nos permiten comparar el desempeño de las metodologías que utilizamos para hacer ciencia. Este criterio es tan poderoso que podemos incluso prescindir de cualquier otra metodología de descubrimiento y justificación. Las evoluciones biológica y cultural son capaces de funcionar, precisamente, porque los éxitos y los fracasos de sus predicciones van haciendo que sus saberes tácitos vayan obteniendo mapas que nos permiten paulatinamente desenvolvernos mejor en el territorio. Este énfasis en la acción y el éxito operacional permite también justificar el conocimiento implícito. Si funciona es conocimiento, si no tiene éxito, no lo es. Hay autores que se resisten a denominar conocimiento a aquellas creencias que no puedan ser explicitadas puesto que consideran que hay una gran distancia entre la mecánica newtoniana y el conocimiento que permite al genoma del gato crear una máquina capaz de actuar sobre el mundo con el éxito suficiente como para reproducirse. A mí, francamente, esto no me molesta demasiado, pero estoy dispuesto a aceptar de buen grado otras propuestas terminológicas. Por ejemplo, se podría reservar la palabra conocimiento para lo explícito y el término saber para lo tácito. Aristóteles conocería, mientras que el herrero sabría. En cualquier caso, las ideas pragmatistas recogen algo importante, nuestras creencias ayudan o dificultan las acciones encaminadas a satisfacer nuestros objetivos. Este es uno de los valores fundamentales de la ciencia; el conocimiento sirve para mejorar nuestras condiciones de vida. Esta utilidad complementa al puro deleite intelectual perseguido por los filósofos clásicos. Cuanto menor sea la distancia entre la estructura de nuestros mapas y la del territorio, más difícil será que nos despeñemos por un barranco. Si nos obcecamos en no ver al virus podremos vivir tranquilos unos días más, pero eso, al virus, le dará igual y acabaremos contagiados. La realidad es eso que te pega una hostia aunque te empeñes en cerrar los ojos, de hecho, es más probable que te la pegue si te empeñas en cerrarlos. 21.5 La verdad no es para tanto En el siglo XX se planteó una nueva respuesta al problema de la verdad. Los deflacionistas argumentaron que si la pregunta es “en qué consiste la verdad” la respuesta debería ser: pues en poco. El deflacionismo sostiene que la verdad, en realidad, es redundante, que afirmar que algo es verdad no añade nada a la afirmación en sí y que, en todo caso, cualquier justificación de la proposición requerirá de argumentos extras. Según esta propuesta las otras teorías de la verdad están tratando de explicar en qué condiciones estamos justificados para afirmar que algo es verdad, pero los deflacionistas consideran que esta es una cuestión diferenciada de la del significado del propio término. Actualmente, esta es una postura muy popular, especialmente entre lógicos y filósofos analíticos.1320 No es casual que fuese Frege, uno de los grandes lógicos, quien notó está transparencia del concepto de verdad: afirmar que “hay un gato junto a mí” no es diferente que decir que “es verdad que hay un gato junto a mí.”1321 Decir que algo es verdad sería, en todo caso, una forma de asentimiento: estaríamos comunicando que nosotros creemos en el contenido de la proposición, pero esto no alteraría el significado de la proposición en sí. 21.6 Resumen Las distintas teorías sobre la verdad inciden en aspectos complementarios del estudio de la realidad. Los deflacionistas nos recuerdan que debemos distinguir entre el significado del término y los criterios de justificación. La teoría de la correspondencia nos indica que, en última instancia, es la información sobre la realidad externa la que ha de dictaminar qué creencias son verdaderas; el compromiso con el empirismo es irrenunciable, el mundo externo debe ser el factor decisivo en la justificación. El coherentismo, por otro lado, nos recuerda que debemos esforzarnos por tener creencias coherentes. Esta es una norma epistémica fundamental: no es lógicamente válido defender ideas contradictorias. Esto puede parecer trivial, pero es muy difícil mantener un conjunto de creencias coherente. Lo que podemos pedirle a un pensador racional es que se esfuerce por ser coherente, aunque dudo que pueda conseguirlo del todo. Además, este énfasis en la coherencia alivia el problema del falibilismo, la red en su conjunto es más robusta que cualquiera de las evidencias aisladas. Estas reflexiones acerca del concepto de verdad también nos han enseñado que si propusiésemos como definición que es verdad aquello que se corresponde con el mundo externo, esa verdad metafísica será inalcanzable ya que sólo podemos aspirar a crear mapas justificados, no tenemos acceso directo al territorio. Por otro lado, cabe la posibilidad de proponer que es verdad aquello que está suficientemente justificado. Sin embargo, en este caso es muy importante hacer algunas puntualizaciones. Lo que vale es el consenso de la comunidad, no la propuesta de un investigador aislado y, además no todas las comunidades son epistémicamente respetables, sólo debemos considerar aquellas que promuevan activamente el diálogo racional. También es importante insistir en que, en cualquier caso, el empirismo ha de ser determinante en la justificación: nuestras creencias tienen que estar sustentadas por evidencias empíricas y, además, si es posible, debemos comprobar si nuestros modelos funcionan, si son útiles, si son capaces de hacer predicciones acertadas. Cuando la predicción o la contrastación con datos independientes no sean posibles conviene recordar que somos más susceptibles al sobreajuste, por lo que habremos de buscar evidencias independientes que validen nuestros modelos. Por otro lado, no hay verdad sin consensos amplios, no es suficiente con que una comunidad decida aceptar una creencia: tampoco deben quedar pendientes críticas justificadas por parte de otras comunidades. También hemos aprendido que hay una tensión entre las reglas epistémicas y los actores que hacen uso de ellas. Galileo pudo enfrentarse y acabar convenciendo a la comunidad porque sus propuestas estaban bien justificadas por las observaciones y la lógica, no necesitó más, aunque, por otro lado, alguien debe juzgar las conclusiones y sus justificaciones y este juez ha de ser la comunidad. Si el resto de astrónomos no hubiese observado las fases de Venus o si hubiese considerado que ese dato no bastaba para desterrar el modelo ptolemaico, la propuesta de Galileo habría sido olvidada. Es la existencia de normas epistémicas lo que posibilita que hablemos de racionalidad, pero es la comunidad quien, eventualmente, emite el juicio en el que podemos confiar los que no somos expertos. "],["realistas_y_antirrealistas.html", "22 Realistas y antirrealistas 22.1 Realismo 22.2 El problema del progreso 22.3 Sentido y referencia 22.4 El problema social 22.5 Antirrealismo 22.6 Empiristas, científicos y antirrealistas 22.7 Antirrealistas 22.8 Verificacionismo positivista 22.9 Larga vida al verificacionismo 22.10 Empirismo constructivo 22.11 A favor del realismo 22.12 El problema de la subdeterminación 22.13 Resumen", " 22 Realistas y antirrealistas Es común pensar que los resultados científicos tratan sobre entidades reales, como los átomos y los electrones. El asunto parece sencillo: creemos que existe el gato porque lo vemos cuando abrimos los ojos y, de un modo análogo, cuando los físicos hablan de electrones, creemos que existen. Esta creencia implica una postura metafísica, es decir, una actitud sobre lo que pensamos que existe en el mundo externo. Lo habitual es asumir que las entidades que pueblan nuestros modelos del mundo, los gatos o los átomos, existen realmente en el mundo externo. A esta posición metafísica se le denomina realismo científico y, en principio, no parece demasiado problemática: ¡por supuesto que existen los gatos! Sin embargo, como veremos, aunque los gatos son aceptados por la mayoría de los filósofos, las entidades no observables y teóricas son mucho más problemáticas. ¿Existe la fuerza de la gravedad? Es indiscutible que nuestras teorías físicas clásicas la utilizan, pero ¿existe? Nadie ha visto a la fuerza de la gravedad en sí, todo lo que podemos medir es la aceleración que experimentan los cuerpos cuando están cerca de otros cuerpos. De hecho, si hubiésemos apostado por su existencia, parece que habríamos perdido ya que la relatividad general plantea que la fuerza de la gravedad, en realidad, no existe: los cuerpos son acelerados debido a la curvatura del espaciotiempo. Y si la fuerza de la gravedad no es fiable, ¿por qué habría de serlo el electrón? El grueso de este libro lo hemos dedicado a tratar cuestiones epistemológicas: ¿cómo debemos razonar? ¿Qué evidencias y qué creencias son justificables y en qué medida? Sin embargo, en estos capítulos finales vamos a plantear también cuestiones metafísicas relacionadas con la ciencia. Recordemos: la metafísica es el estudio de lo que es, de las cosas que existen en el mundo.1322 Otro término relacionado es el de ontología: la rama de la filosofía que reflexiona sobre la naturaleza de la realidad. Además, también se utiliza el término ontología para referirse al conjunto de entidades que pueblan la realidad.1323 Puede parecer extraño que los filósofos consideren como dos áreas diferenciadas a la epistemología y a la metafísica, pero recordemos que nuestras ideas más razonables pueden estar equivocadas, por lo que, incluso aunque asumamos que estamos pensando racionalmente cabe cuestionarse hasta qué punto estamos justificados para creer que una entidad utilizada en uno de nuestros modelos del mundo, de nuestros mapas, existe realmente en el territorio. 22.1 Realismo El realismo científico plantea varias tesis, más o menos, relacionadas. Una de ellas es que el objetivo de la ciencia es comprender el cosmos estableciendo qué entidades y procesos lo pueblan. Así es, por ejemplo, como lo caracterizó Van Fraassen (Países Bajos; 1941-), uno de los antirrealistas más relevantes de finales del siglo XX.1324 Si en este momento te parece extraño que alguien pueda cuestionar algo tan aparentemente evidente, me alegraré si a lo largo de este capítulo consigo que aprecies los problemas que conlleva esta tesis. Otra propuesta realista está relacionada con la aceptación de la realidad de las entidades y los procesos postulados por las teorías científicas. Por ejemplo, cuando un físico plantea que el espaciotiempo está deformado cerca de una estrella, el realista acepta esta curvatura del espaciotiempo como un aspecto real del mundo externo. El filósofo de la ciencia Larry Laudan (Estados Unidos; 1941) matizó esta propuesta: el realista defendería que las teorías científicas van aproximándose gradualmente a la realidad.1325 Este es un realismo mucho menos ambicioso ya que admite que nuestras teorías actuales tan solo son aproximadas. Para estos realistas el mapa no es exactamente igual al territorio. A este tipo de realismo se le ha criticado porque es difícil establecer en qué medida nos hemos aproximado a la realidad si no conocemos la realidad en sí. Sin embargo, en mi opinión, esta tesis adolece de un problema aún mayor: este tipo de realismo es muy débil ya que aproximadamente real puede interpretarse como no real. Yo podría defender que la Tierra es aproximadamente icosaédrica y, según estos realistas odiseicos, esto sería realista.1326 La mayoría de los filósofos, el 75% según la encuesta de Chalmers y Bourget, se definen como realistas,1327 aunque, dado que no hay una única propuesta realista, es difícil interpretar este dato. De hecho, como veremos, hay realismos, como los estructurales, que tienen mucho en común con los antirrealismos. Antes de continuar tal vez convenga aclarar que en filosofía se utiliza el término realismo metafísico en un sentido que nada tiene que ver con el realismo científico que estamos discutiendo. El realismo metafísico sostiene que existe un mundo externo independiente de nosotros y se contrapone al idealismo, que es la tesis metafísica que sostiene que todo lo que existe en el universo es mental.1328 Éstas, evidentemente, no son las cuestiones que vamos a tratar. 22.2 El problema del progreso Es evidente que la ciencia progresa, pero hemos de ser muy cautos al tratar de caracterizar ese progreso o, de lo contrario, nos podemos meter en un berenjenal metafísico. Por ejemplo, podríamos pensar que la ciencia progresa de un modo análogo al que progresa una colección de sellos o cromos: se van acumulando verdades o conocimientos que pasan a formar parte del conjunto de conocimientos científicos. Esto, obviamente, y a pesar de que muchas veces se habla de la ciencia en estos términos, es indefendible; muchas de las conclusiones científicas, con el tiempo, se revisan, e incluso, se descartan.1329 Muchos de nuestros cromos más queridos, con el tiempo, han terminado en la papelera. Duhem hizo una matización importante, hay leyes que se proponen como universales, como, por ejemplo, las relacionadas con la mecánica newtoniana, pero que más tarde aprendemos que sólo son aplicables en unos ámbitos limitados.1330 El realista se enfrenta a un problema importante ya que debe admitir que hay numerosos casos de entidades propuestas por teorías antiguas que, posteriormente, han terminado descartándose. Un ejemplo paradigmático es el éter: el medio sobre el que se suponía que se transmitían las ondas electromagnéticas. Además, en la actualidad no creo que haya muchos físicos que piensen que nuestras teorías fundamentales se vayan a mantener sin cambios en el futuro y esto plantea un problema respecto a sus ontologías. ¿Por qué habríamos de confiar en que los futuros cambios teóricos mantendrán las entidades no observables si las del pasado no lo han hecho? A este problema, en filosofía de la ciencia, se le denomina pesimismo meta-inductivo y es uno de los principales enemigos del realismo.1331 Además, las ontologías han cambiado en el pasado radicalmente, cuando se propusieron la relatividad general o la mecánica cuántica las ontologías de las teorías clásicas de Newton y Maxwell quedaron reducidas a simples quimeras que, como mucho, podríamos considerar útiles y, en el caso del éter, ni eso. Este fue uno de los motivos que llevó a Popper a plantear que cualquier propuesta teórica no es más que una conjetura y también causó quebraderos de cabeza a Kuhn, que trató de defender el progreso metafísico, pero que fue incapaz de solucionar la cuestión.1332 Kuhn se dio de bruces con el problema de que no parece que haya una dirección ontológica clara en algunas áreas de la ciencia. A veces, parece incluso que la metafísica científica va dando bandazos: como en el caso de la naturaleza de la luz, que unos días parecía ser partícula y otros una onda. A Newton la geometría de los rayos de luz le hizo pensar que ésta estaba compuesta por partículas que se movían en línea recta.1333 Por ejemplo, si uno observa la sombra de su mano verá que está bastante definida, sin embargo, si la naturaleza de la luz fuese ondulatoria y no corpuscular se esperaría ver una sombra mucho más difusa. Algo más tarde Thomas Young difractó la luz y, como este es un comportamiento característico de las ondas, propuso que la luz era una onda. Esto pareció confirmarse teóricamente cuando Maxwell predijo que las ondas electromagnéticas se movían exactamente a la velocidad de la luz. Sin embargo, el efecto fotoeléctrico volvió a poner sobre la mesa las partículas. Alguien dijo que la luz parecía ser una partícula los lunes, miércoles y viernes, una onda los martes, jueves y sábados y algo mucho más extraño los domingos. Nuestra mejor teoría actual sobre la cuestión, la cuántica, tiene una metafísica que, todavía en la actualidad, es extraordinariamente controvertida: hay quien cree ver multitud de universos en ella y quien, simplemente, renuncia a preguntarse por su metafísica y se limita a calcular usando sus descripciones matemáticas. Una posible respuesta al problema planteado por el pesimismo meta-inductivo consiste en limitar la confianza realista a la existencia de las entidades teóricas de las teorías más maduras y con mayor éxito predictivo. Es decir, podríamos confiar en las entidades de las teorías que gozan de un mayor apoyo empírico y tan sólo tendríamos que dudar de las propuestas por las hipótesis menos confirmadas. El problema de esta defensa es que los antirrealistas nos recuerdan que ha habido problemas incluso con teorías muy bien establecidas, como la gravedad newtoniana o el electromagnetismo clásico. La fuerza de la gravedad y el éter luminífero no existen. La luz no se transmite por un éter material de un modo análogo al del sonido, que se transmite mediante las vibraciones del aire, y esto demuestra claramente que una teoría con una metafísica equivocada puede llegar a hacer predicciones muy precisas. Por lo tanto, la adecuación empírica no es garantía de corrección metafísica. Otra posible defensa propone dividir las teorías en dos tipos de entidades: las que se acaban utilizando para hacer predicciones empíricas y las que no y asumir que sólo son reales las primeras. Esto habría que hacerlo teoría por teoría en cada momento histórico. Además, en la práctica, no es tan sencillo aislar términos teóricos ya que, como hemos visto, adquieren su sentido por la red de términos. 22.3 Sentido y referencia Otra defensa del realismo consiste en echar mano de la distinción entre sentido y referencia: puede que la fuerza de la gravedad no exista del modo en el que creíamos, pero hay algo en el mundo externo que se comporta de un modo muy similar a la fuerza planteada por Newton y, en realidad, eso es a lo que nos referíamos cuando hablábamos de fuerza de la gravedad. El sentido son las ideas y las descripciones asociadas con un término, mientras que la referencia es aquella entidad del mundo externo a la que nos estamos refiriendo con el término. Por ejemplo, el término “ballena” puede ser definido como animal muy grande que vive en el mar, mientras que una posible referencia es Keiko, la orca protagonista de Liberad a Willy. Un término tiene una referencia exitosa cuando hay algo en el mundo externo a lo que se refiere. Por ejemplo, unicornio no es un término con una referencia exitosa, por eso decimos que los unicornios, no existen. El termino “unicornio” tiene sentido, pero no tiene referencia. Las referencias son más estables que los sentidos y en esto se basa esta defensa del realismo. Desde Aristóteles los estudiosos de la zoología saben que las ballenas no son peces: Aristóteles cambió el sentido del término para siempre, sin embargo, Keiko sería una referencia válida tanto para los pescadores anteriores a Aristóteles como para los zoólogos posteriores. Sin embargo, esta defensa del realismo tampoco está exenta de problemas. Recordemos que los antirrealistas no dudan de la realidad de los gatos, sino de los términos no observables y teóricos. A pesar de que su taxonomía no es trivial, un gato tiene una referencia más sencilla que una entidad teórica como, por ejemplo, el espaciotiempo. En principio, los términos teóricos deberían adquirir la referencia a partir de lo que plantee la teoría y esto obliga al realista a resolver el problema de la inconmensurabilidad de las redes teóricas que plantearon Carnap o Kuhn. Además, los problemas del realista no terminan ahí. Esta defensa del realismo lo que está proponiendo es que hay una continuidad referencial entre teorías incluso en los términos teóricos. Es decir, que cuando Newton habla de fuerza de la gravedad y Einstein de curvatura del espaciotiempo, en realidad, están refiriéndose a la misma realidad externa, aquella que causa que los objetos aceleren cuando están cerca de un objeto masivo. Esta propuesta puede parecernos satisfactoria, pero, en la práctica, hemos dejado el realismo en cueros. Lo que el realista está diciendo es: no sé qué es la fuerza de la gravedad, pero es cualquier cosa del mundo externo que hace que las bolas de cañón se comporten como se comportan cuando las dejo caer desde la Torre de Pisa, eso es la gravedad. El referente es muy vago, no es como un gato al que podemos señalar y, en realidad, lo que estamos planteando es una forma de antirrealismo ya que la principal tesis antirrealista consiste, precisamente, en que aunque las teorías sean empíricamente adecuadas hemos de ser muy cautos a la hora de creer en la realidad de sus términos teóricos. Los antirrealistas no niegan que haya algo en el mundo externo que hace que las bolas de cañón aceleren hacia el suelo, no son idiotas, lo que dicen es que no debemos comprometernos con la naturaleza de ese algo, por ejemplo, con que sea una fuerza, simplemente porque una teoría empíricamente adecuada proponga que es una fuerza. El hecho de que la teoría funcione no implica que debamos creer que la fuerza de la gravedad existe a nivel fundamental, podría ser, en realidad, una curvatura del espaciotiempo o, incluso, algo mucho más extraño. Además, esta defensa desconecta lo que el científico parece estar diciendo de lo que realmente está diciendo. Puede que Newton estuviese hablando de una fuerza, pero hemos de ser caritativos e interpretarlo como si no hubiese estado hablando de una fuerza. 22.4 El problema social Todo esto no pasaría de ser una simple discusión académica si no fuese porque implica un serio problema social. Más de una vez me han dicho que lo que digan los científicos es una opinión más porque un día dicen una cosa y al siguiente sostienen lo contrario. Este es uno de los principales argumentos de quienes se oponen a la razón. Una vez un marxista me dijo en Facebook que Newton estaba obsoleto. El día que los marxistas hagan una predicción económica la mitad de fiable que las que calcula la NASA usando la mecánica newtoniana para enviar sondas a Plutón que venga y me lo cuente. Este ataque funciona porque, además, una parte importante de la sociedad cree que la ciencia acumula verdades y, por lo tanto, cuando se dan cuenta de que la ciencia no funciona así pierden la confianza en ella. Por ejemplo, muchos creen que lo que se publica en un estudio revisado por pares pasa a ser parte del corpus científico como una verdad más. Así que no es de extrañar que cuando un estudio se tumba acaben perdiendo la confianza. En un ambiente de relativismo rampante es importante explicar cómo funciona la ciencia para no fomentar los desvaríos de los constructivistas radicales. Lo que progresa claramente en las ciencias que funcionan es la adecuación empírica. Es decir, sus modelos son cada vez más precisos, tanto en sus descripciones de las evidencias disponibles como en sus predicciones. Sin embargo, esto no implica, en modo alguno, que las metafísicas de las teorías que propongan los físicos en el futuro se vayan a parecer en nada a las de las teorías actuales. Newton sigue funcionando a pesar de que las teorías más avanzadas ya no hablan de fuerzas. La relatividad general es más precisa que la newtoniana, pero esto no implica que la newtoniana dejase de funcionar cuando los revisores aceptaron el artículo de Einstein. Por eso la NASA puede seguir usando fuerzas gravitatorias, porque las predicciones, aunque no son las más precisas, son lo suficientemente precisas. De hecho, el progreso científico ni siquiera exige que los propios investigadores confíen en que sus entidades teóricas se correspondan con nada real. Ptolomeo representó un gran avance respecto a los modelos astronómicos anteriores, pero a Ptolomeo le importó bastante poco que sus ciclos y epiciclos fuesen reales o no, sólo le preocupó la precisión de las predicciones. A pesar de estos problemas parece difícil que haya conclusiones metafísicas que vayamos a abandonar en el futuro: seguiremos creyendo que los gatos existen y que el virus de la gripe es el causante de la gripe y esto plantea una cuestión interesante sobre la que se ha trabajado intensamente en tiempos recientes: qué diferencia a las entidades más fiables de las más tentativas. 22.5 Antirrealismo Los antirrealistas tienen una actitud muy cercana a la ptolemaica: lo más relevante de los modelos científicos es que sean instrumentos útiles. El estadístico británico George Box lo expresó de este modo: Todos los modelos son erróneos, pero algunos son útiles Una teoría es empíricamente adecuada cuando describe correctamente las partes observables del mundo externo1334 y está claro que las teorías pueden ser útiles incluso aunque plateen entidades, como los epiciclos de Ptolomeo, que no existen realmente. El antirrealismo surgió a finales del siglo XIX cuando se estaba discutiendo si los átomos eran reales o no.1335 Los químicos llevaban tiempo hablando de átomos, pero los físicos, dadas las evidencias empíricas disponibles en el momento, dudaban de que los átomos fuesen algo más real que los epiciclos. Cuando más tarde, a principios del siglo XX, la relatividad y la cuántica demolieron las metafísicas clásicas, los antirrealistas se vieron vindicados, había sido prudente dudar de la gravedad, y concluyeron que la ciencia debía limitarse a estudiar las regularidades empíricas que detectaba y abstenerse de tratar de asaltar los cielos metafísicos. Los antirrealistas confían en la existencia del mundo externo, esa no es su crítica, su cautela nace de su duda acerca de lo que un empirista puede llegar a conocer sobre las entidades no observables y teóricas. Según los antirrealistas los empiristas deberíamos ser ateos o, al menos, agnósticos respecto a la existencia de las entidades teóricas. Estas entidades son útiles y necesarias, pero puede que no sean reales. Mientras que el realista al usar una teoría se compromete con su metafísica, el antirrealista se conforma con utilizarla como un instrumento útil.1336 Es cierto que vemos burbujitas en una cámara de niebla, pero si están causadas por algo que se corresponde con nuestra idea de un electrón, esa es una cuestión muy distinta. Los antirrealistas tampoco pretenden que la ciencia deje de teorizar, las entidades teóricas son necesarias; tan solo discuten las implicaciones metafísicas de los modelos alcanzados. Por ejemplo, plantean que la teorización podría entenderse como una actividad que, aprovechando la estructura y la redundancia presente en la información empírica construye modelos teóricos informacionalmente compactos.1337 Ernst Mach (1838-1916), que era físico y fue el primer catedrático de filosofía de la ciencia, entendía la ciencia como un instrumento capaz de condensar la información empírica en unas cuantas leyes que reflejaban económicamente esa estructura. Esta es una idea compartida por Duhem, que planteó que la ciencia puede encontrar y analizar regularidades presentes en el mundo externo, pero que esto no implica que deba preocuparnos la naturaleza profunda de esa realidad.1338 Para los antirrealistas no resulta misterioso que la adecuación empírica progrese en las ciencias exitosas, al fin y al cabo, este debería ser, según ellos, el objetivo de las ciencias: obtener instrumentos cada vez más eficaces. Además, no les preocupa, en absoluto, que las sucesivas metafísicas parezcan no estar alineadas en una dirección progresiva. Esto es algo que podía preocupar a Kuhn, que estaba interesado por la realidad de esas metafísicas, pero Mach o van Fraassen sólo están interesados por la adecuación empírica de las teorías. En realidad, según los antirrealistas, los físicos decimonónicos habrían acertado de pleno cuando predijeron que lo único que quedaba por hacer era ajustar los últimos decimales de las predicciones de sus teorías. El cambio entre Newton y Einstein sólo parecería enorme porque se había depositado una confianza excesiva en las ontologías. Además, esto explicaba porque las teorías antiguas habían servido para desarrollar tanta tecnología útil: esos modelos eran empíricamente adecuados y, en gran parte, seguían siéndolo. Si lo que queremos es lanzar satélites, poco importa que las teorías hablen de fuerzas, campos o interacciones, lo relevante es que sirvan para hacer predicciones precisas. 22.6 Empiristas, científicos y antirrealistas Aunque nuestra primera reacción ante el debate sea prestar apoyo al ideal realista que defiende que el objetivo de la ciencia debe ser establecer cuál es la naturaleza última del cosmos, lo cierto es que el compromiso empirista con las observaciones como base del conocimiento del mundo externo puede aconsejar una mayor modestia intelectual. Mach, por ejemplo, sostenía que la ciencia debe preocuparse por describir el mundo dejando de lado las disquisiciones sobre cuál sea su verdadera naturaleza:1339 el empirista no debería comprometerse con la naturaleza y la existencia de aquello que no puede observar.1340 Esta es una postura que defendieron, por ejemplo, Hume, Comte o John Stuart Mill: el empirista ha de ser muy cauto cuando trata de llegar más allá de lo observado. Por lo tanto, la tradición empirista es más cercana del antirrealismo que del realismo.1341 James Ladyman (1969-) ha sugerido incluso sustituir el término antirrealista por el de empirista en el debate.1342 Podemos encontrar un claro reflejo de la tradición empirista y antirrealista en la división que se establecía en el mundo antiguo entre física y matemáticas. Esta división era muy diferente a la actual;1343 para Sexto Empírico, por ejemplo, las matemáticas incluían campos tan diversos como la óptica, la astronomía, la geometría, la aritmética o la teoría musical. La clave de la división entre matemáticas y física consistía, precisamente, en que mientras las matemáticas tenían un ánimo meramente descriptivo, la física pretendía explicar la esencia de la naturaleza última del cosmos. En griego física significaba crecer, dar lugar y por extensión se aplicaba a aquello que llega a existir. En latín el término se tradujo por naturaleza, de ahí la acepción que utilizamos al hablar sobre la naturaleza última de la realidad. La división entre física y matemáticas no concernía al objeto de estudio, sino a su método: las matemáticas eran cuantitativas y descriptivas. Aristóteles hacía física porque estaba interesado por las causas del movimiento de los astros, sin embargo, Ptolomeo era un mero matemático preocupado, solamente, por describir esas órbitas. Por lo tanto, los astrónomos de la antigüedad, que eran matemáticos, podían incluso plantear descripciones alternativas para un mismo fenómeno, pero los físicos debían dar con las causas reales. No fue hasta la Edad Moderna cuando esta división se replanteó. Galileo, por ejemplo, todavía asumía que la matematización de su física implicaba que sólo estaba describiendo. Por ejemplo, en su Dos nuevas ciencias (1638) admitía que las causas de la aceleración de la caída de los cuerpos no eran una parte necesaria de la investigación. Hubo muchos, como, por ejemplo, Descartes, Leibniz y Huygens que lo criticaron por ello.1344 Sin embargo, Newton, que, evidentemente, también hacia una ciencia cuantitativa y matemática, sí pretendía, al menos hasta cierto punto, estar estudiando las verdaderas causas del movimiento.1345 Newton estaba haciendo física, no matemáticas. Sin embargo, no fue hasta el descubrimiento de las geometrías no euclídeas en el siglo XIX cuando nuestra división actual entre matemáticas formales y ciencias naturales terminó de perfilase. Podríamos pensar que los científicos suelen ser realistas, que creen en la realidad de las entidades propuestas por sus teorías y este es, generalmente, el caso. Sin embargo, las actitudes de los científicos con mayor conocimiento filosófico son, en muchos casos, mucho más matizadas. El famoso Hypothesis non fingo newtoniano es un ejemplo de esta cautela metafísica. Es decir, Newton, que había propuesto una teoría gravitatoria como causa del movimiento de los astros, cuando se preguntó a sí mismo por la verdadera causa de la gravedad, como científico, se limitó a decir: no sé.1346 Partiendo de los datos empíricos podía proponerse una descripción empíricamente adecuada, pero esas evidencias no podían conducirle a descubrir la naturaleza última de la realidad y, como era consciente de ello, prefirió ser cauto, de ahí su Hypothesis non fingo. Leibniz, sin embargo, criticó esta tibieza, esta falta de ambición metafísica y Newton, cómo teólogo, añadió que la causa última debía de ser divina. Einstein siendo estudiante leyó a Mach y quedó muy influido por estas ideas empiristas y antimetafísicas y esta fue, precisamente, una de sus inspiraciones en la investigación que le condujo a su relatividad especial. Su propuesta, matemáticamente, no era muy distinta de las físicas anteriores de Lorenz o Poincaré y, sin embargo, a diferencia de estos, rechazó la idea de un espacio y un tiempo absolutos, simplemente, porque no había forma de medir esas entidades absolutas. En el planteamiento de la relatividad, Einstein partió de aquello que podía medirse, se preguntó cómo se medirían el tiempo y el espacio y esto le llevó a rechazar la idea intuitiva de un tiempo absoluto independiente del observador. Ese tiempo no podía medirse y, por lo tanto, un empirista, seguidor de Mach, no debía incluirlo en su teoría. La otra gran teoría física del siglo XX, la mecánica cuántica, también fue planteada desde postulados muy cercanos al antirrealismo positivista. Pauli, que tenía como padrino al propio Mach, afirmó que preguntarse por lo qué está sucediendo en un sistema cuando no estamos observándolo es análogo a preguntarse por cuántos ángeles caben en el ojo de una aguja.1347 A Bohr, influido por los positivistas ni siquiera parece que le preocupase demasiado la existencia del mundo cuántico. De hecho, Bohr, en la famosa conferencia de Solvay, afirmó: “Es erróneo pensar que la tarea del físico consista en averiguar qué es la naturaleza. A la física sólo le concierne lo que podemos decir sobre ella”. Es difícil plantear una actitud más antirrealista ante la ciencia. Este es el motivo por el que la interpretación de Copenhague de la física cuántica no está en absoluto preocupada por si el gato está vivo o muerto mientras la caja está cerrada. Mientras la caja esté cerrada y no podamos observar su interior poco ha de importarle a la física el estado del gato. Lo que concierne a la física es predecir la probabilidad de que lo observemos vivo o muerto una vez abramos la caja y esto puede hacerlo con absoluta precisión. El físico David Mermin resumió esta actitud con el famoso aforismo: “calla y calcula”, aunque también conviene recordar que, a continuación, añadió “pero no me callaré.”1348 Resulta curioso que fuese precisamente Einstein, el físico que descartó el tiempo absoluto, uno de los físicos que menos se callaron y que más reivindicaron el papel de la ciencia como una disciplina dedicada al estudio de la realidad más allá de su mera descripción. Sus debates con Bohr y compañía a este respecto son legendarios. Estas discusiones físico-filosóficas se materializaron en una línea de investigación muy fructífera que Einstein formuló, junto a Podolsky y Rosen, en su artículo de 1935, que más tarde, en 1964, condujo a Bell a proponer sus desigualdades y que Aspect comprobó experimentalmente en 1982. Este es un asunto apasionante que mezcla física fundamental y filosofía a partes iguales, pero, por desgracia, no cabe en este ya demasiado extenso libro. Al lector interesado le recomiendo los excelentes What is real de Adam Becker y Something Deeply Hidden de Sean Carroll. En muchos casos he oído que la filosofía de la ciencia no influye en la ciencia, me pregunto que pensarán quienes dicen esto sobre esta íntima y fecunda relación entre filosofía y física. 22.7 Antirrealistas Entre los filósofos la tradición antimetafísica resurgió en la Edad Moderna. Hume rechazó cualquier intento de llegar más allá de la experiencia empírica y recomendó a los pensadores modestia intelectual.1349 Este es el espíritu que recogieron los positivistas lógicos a principios de siglo XX. El único conocimiento válido del mundo externo es empírico y, por lo tanto, deben rechazarse las osadías metafísicas.1350 El nacimiento del positivismo lógico suele asociarse al Círculo de Viena, un grupo de científicos, filósofos y matemáticos que contaba entre sus miembros más destacados con Moritz Schlick, Rudolf Carnap, Otto Neurath, Hans Reichenbach y A. J. Ayer.1351 Schlick, que había realizado una tesis dirigida por Planck, organizó el nacimiento del Círculo en 1924 y Carnap, que terminó por convertirse en una especie de líder intelectual del grupo, estudió matemáticas, física y filosofía y fue uno de los pensadores más destacados del siglo XX. Existen dos positivismos que conviene no confundir: el decimonónico y social de Comte y el lógico del siglo XX. Comte estaba interesado en establecer las ciencias sociales como base de una reforma racional de la sociedad, mientras que los positivistas lógicos debatían, principalmente sobre cuestiones epistemológicas. El movimiento positivista del siglo XX incluyó a un gran número de pensadores que, además, desarrollaron sus ideas durante décadas por lo que, necesariamente, fue una escuela heterogénea y llena de matices. En realidad, lo más habitual es dividir a los positivistas del XX en positivistas lógicos y empiristas lógicos,1352 pero dado lo heterogéneo de ambos términos,1353 la sutileza de las distinciones y el ánimo introductorio de este texto, no creo que sea necesario aquí adoptar esta división. El positivismo, en parte debido a la diáspora causada por el horror nazi y la guerra, se convirtió en una filosofía muy influyente hasta los años 70. Todavía hoy, debemos reconocer su legado en el rigor es seguido por los filósofos analíticos. A esto conviene añadir que, como hemos ido discutiendo a lo largo de varios capítulos, una gran parte importante de la filosofía de la ciencia posterior se organizó como reacción a sus tesis, lo cual muestra que, aunque pudiesen tener una visión de la ciencia un tanto ingenua, sus aportaciones fueron muy fructíferas. Existen formas más o menos interesantes de estar equivocado. El Círculo reconocía entre los pensadores que les influyeron a Mach, Poincaré, Duhem, Boltzmann y Einstein y en su manifiesto, publicado en 1929, titulado La concepción científica del mundo reproducían la división del conocimiento planteada por Hume: el conocimiento debe ser sintético, como el científico, o analítico, como el lógico y matemático.1354 Esta división analítico-sintética fue una de las tesis positivistas fundamentales y, todavía actualmente, es aceptada sin grandes modificaciones por la mayoría de los filósofos. La justificación del conocimiento del mundo externo había de ser eminentemente empírica y lógica. Además, defendían que la ciencia tenía que utilizar un lenguaje preciso y, eminentemente, empírico para separarse de la metafísica, una disciplina que rechazaban por carecer de sentido. La lógica había experimentado un gran florecimiento en la segunda mitad del siglo XIX y se encontraba en plena efervescencia en esa época. Este es el tiempo en el que Russell y Whitehead estaban liderando el análisis de los fundamentos lógicos de las matemáticas, un programa de investigación que terminó conduciendo a Gödel y Turing. Los positivistas decidieron acometer un esfuerzo análogo en el área de las ciencias naturales. Las palabras de Russell “la lógica es la esencia de la filosofía” se convirtieron en el credo del positivismo.1355 Según los positivistas el análisis lógico del lenguaje había de permitir aclarar el contenido de las teorías científicas y, además, sería el instrumento que distinguiría con precisión la ciencia de la filosofía vaga y oscura que caracterizaba a la metafísica. 22.8 Verificacionismo positivista El verificacionismo fue otra de las tesis principales de los positivistas. La idea general es que sólo tiene sentido aquello que tiene alguna implicación empírica.1356 Siguiendo a Hume, los positivistas propusieron que aquello que no tiene consecuencias empíricas no sólo es demasiado especulativo, sino que carece de sentido porque, incluso aunque fuese falso, no podríamos observar ninguna diferencia.1357 Para un positivista lógico sólo tienen sentido aquellas proposiciones para las que pueden establecerse las condiciones observacionales que pueden llevar a determinar si son verdaderas o falsas. Una afirmación tiene sentido cuando existe un modo empírico de decidir si es verdadera o no lo es. Tiene sentido hablar de las ondas de radio, aunque no podamos verlas, porque de su existencia se derivan consecuencias empíricas que podemos llegar a detectar mediante nuestros sentidos. Este criterio del sentido lo utilizaron para luchar contra la metafísica ya que, según los positivistas, la metafísica no es más que un conjunto de ideas sin sentido.1358 Para un positivista la afirmación “existe el absoluto” no es ni verdadera ni falsa, es una pseudoafirmación sin sentido que trata de establecer algo que no está conectado, en modo alguno, con el mundo observable. La lección es que hemos de ser cautos puesto que no todo aquello que parece una proposición tiene sentido. Algunos términos metafísicos que los positivistas desterraron como carentes de sentido fueron: Dios, el Absoluto, el no-ser, la cosa en sí o la esencia.1359 Esta propuesta también asumía una distinción nítida entre el lenguaje observacional y el teórico, entre datos empíricos y teorías.1360 Defendían, además, que los términos teóricos adquieren su sentido porque pueden expresarse, en última instancia, utilizando proposiciones que utilizan sólo términos observacionales.1361 Es posible que a algunos lectores estas propuestas les parezcan muy razonables, a mí me lo parecieron, pero hay que asumir que fueron finalmente matizadas o rechazadas. Por ejemplo, el caso del plano inclinado parece indicar que, efectivamente, el lenguaje observacional es completamente neutro respecto al teórico: dos investigadores pueden establecer que una bolita está cayendo por un plano inclinado independientemente de que sean aristotélicos, newtonianos o relativistas. Sin embargo, como ya hemos comentado, esta propuesta fue matizada posteriormente. Carnap, por ejemplo, tras años de análisis, no dudó en asumir que el significado de los términos teóricos dependía del resto de términos teóricos, de los observacionales y de la relación entre ambos tipos de términos.1362 Los términos observacionales y teóricos están, desde un punto de vista estrictamente lógico, entrelazados. Otro de los problemas que rompieron el sueño positivista fue el de la inducción. Las leyes generales que plantea la ciencia, en realidad, no son verificables porque es imposible plantear un conjunto finito de observaciones que nos permitan verificar que la ley se cumple en todos los casos. Por lo tanto, estrictamente hablando, los términos teóricos no pueden ser verificados mediante la observación y según el estricto criterio de la verificación deberían ser considerados palabras carentes de sentido.1363 Los positivistas reconocieron el problema y sustituyeron la verificación por una noción menos exigente: la confirmación.1364 Carnap planteó que la confirmación debería seguir una lógica inductiva y que el resultado final habría de ser un grado de confianza. Estos detalles fueron complicando paulatinamente el análisis lógico del lenguaje sin que nunca se consiguiese alcanzar el riguroso ideal positivista. Por ejemplo, Carnap no logró terminar su proyecto de lógica inductiva. Además, aunque su primer objetivo fue distinguir los términos con sentido de los términos sin sentido, esto no fue posible y tuvieron que pasar a analizar proposiciones completas, pero esto tampoco funcionó y, por fin, hubieron de asumir que las observaciones afectan a sistemas teóricos completos.1365 Este, recordemos, fue uno de los problemas que señaló Quine al criticar el falsacionismo de Popper, pero afectaba en igual medida a los positivistas;1366 si ninguna proposición puede ser verificada por separado de las demás, la distinción entre proposiciones verificables y no verificables no es sostenible.1367 Para intentar solucionar estos problemas trataron de suavizar la distinción entre términos observacionales y teóricos, pero al hacerlo volvía a entrar la metafísica por la puerta de atrás. Es muy difícil establecer una propuesta lógico-semántica en la que tengan cabida los campos cuánticos o las supercuerdas, pero en la que no puedan colarse la metafísica que pretendían desterrar. A partir de los años 30 Carnap asumió que no habían conseguido crear un bisturí capaz de delimitar con precisión quirúrgica la ciencia de la palabrería metafísica.1368 Tal vez el mayor éxito de la aproximación positivista consistió, precisamente, en mostrar las limitaciones de este programa de investigación filosófica. Al fin y al cabo, hemos de recordar que para los lógicos-matemáticos ni siquiera fue sencillo justificar con rigor que 1 más 1 son 2: Whitehead y Russell necesitaron 362 páginas de desarrollos lógicos para hacerlo.1369 De modo que no es de extrañar que los positivistas no lograsen justificar la ciencia, que depende de observaciones empíricas mucho más dudosas que los axiomas matemáticos, con el mismo grado de rigor. En ciencia la lógica es fundamental, pero no lo es todo. 22.9 Larga vida al verificacionismo A pesar de estos problemas, la idea principal subyacente en el verificacionismo positivista continúa siendo fundamental: la percepción es la principal fuente de información sobre el mundo externo, el modo de evaluar nuestras creencias sobre el territorio debe estar necesariamente ligado al empirismo. Que fallase la formulación positivista no implica que hayamos de abandonar esta tesis.1370 Esta es también una postura que defendió Quine: aunque el verificacionismo positivista fracasó, su respeto por los datos empíricos debe ser conservado.1371 Además, el fracaso positivista tampoco implica que la metafísica especulativa sea un modo válido de estudiar la estructura fundamental del universo. La propuesta original de Hume continúa siendo válida: si lo que se propone no tiene consecuencias empíricas es sólo sofistería. La conexión informacional con la entidad postulada es un mínimo imprescindible. Si no hay modo de que nos llegue información alguna de la entidad deberíamos abstenernos de proponerla como algo relevante para el análisis del mundo externo.1372 Como dijo Schwarzenegger en Predator “si sangra podremos matarlo”, si deja un rastro podremos analizarlo, si no es mera palabrería. Lo que sí parece implicar el fracaso del verificacionismo lógico-semántico positivista es que hemos de abandonar el intento de eliminar a priori las propuestas sin sentido y tenemos que centrarnos en averiguar qué propuestas son epistemológicamente superiores e inferiores.1373 22.10 Empirismo constructivo Uno de los antirrealismos recientes más populares es el empirismo constructivo. Van Fraassen, su proponente, también es antimetafísico, pero en su propuesta ha tratado de evitar algunos de los problemas positivistas. Para Van Fraassen, como para los positivistas, no hay duda sobre la existencia de las entidades observables, pero según este autor hemos de declararnos agnósticos respecto a las entidades teóricas. Aquello que no podemos ver puede que exista, pero el empirista cauto ha de reservar el juicio. En esto el empirismo constructivo se diferencia del positivismo, puede que tenga sentido hablar sobre esas entidades, pero, simplemente, no tenemos información suficiente para estar seguros de su existencia. Además, mientras que para los positivistas los términos teóricos no son más que herramientas que sirven para resumir la estructura detectada en las observaciones, para Van Fraassen, cuando los científicos proponen una entidad no observable, como, por ejemplo, un electrón, aunque se declaren agnósticos sobre su existencia, realmente están discutiendo sobre una entidad que podría existir en el mundo externo.1374 Tal vez el punto más relevante de la propuesta del empirismo constructivo sea que las teorías deben aceptarse o rechazarse en base a su adecuación empírica, es decir, dejando de lado la realidad de las entidades teóricas y no observables que puedan proponer y obedeciendo únicamente a la precisión con la que cuadran con las observaciones. Al aceptar una teoría no tenemos la obligación de comprometernos con su corrección metafísica, sino sólo con su adecuación empírica.1375 Por supuesto, el científico utilizará la teoría como si los electrones o la fuerza gravitatoria existiesen realmente, pero esto, dado que no puede comprobarse directamente, sólo presupone una aceptación pragmática y no exige que el científico crea en la existencia de esas entidades. Por ejemplo, los físicos hablan habitualmente de la fuerza gravitatoria, pero eso no implica que hayan de aceptar su existencia. El empirismo constructivo ha conseguido que se considere perfectamente razonable que un investigador utilice una teoría sin que esto implique que deba comprometerse con su metafísica. Van Fraassen, además, critica el ánimo realista. Según su tesis el objetivo de la ciencia no debe ser llegar a la verdad, sino construir teorías empíricamente adecuadas. La interpretación estándar de la mecánica cuántica sería un buen ejemplo de esta actitud: la ciencia no debe preocuparse por si gato está vivo o muerto mientras no miramos, lo único relevante es la predicción de la probabilidad de lo que acabaremos observando y, además, es precisamente esta adecuación empírica la que nos permite construir tecnología útil. 22.11 A favor del realismo Sin embargo, a pesar de los ataques antirrealistas, continúa habiendo muchos científicos y filósofos que tienen una actitud claramente realista. Einstein, por ejemplo, no estaba, en absoluto, de acuerdo con la interpretación de Copenhague de la mecánica cuántica. Según el padre de la relatividad, la ciencia debía comprometerse con la investigación sobre la naturaleza de la realidad, no sólo con la creación de teorías empíricamente adecuadas.1376 No se trataría tan solo de crear teorías útiles, sino de obtener una descripción completa de la naturaleza, independientemente de si hay en ella aspectos no observables.1377 El realismo nos impele a ir más allá. Por otro lado, aunque es cierto que la astronomía había tenido un ánimo antirrealista desde la antigüedad, el enfrentamiento de Galileo con la Iglesia Católica se debió, precisamente, a que el pisano sostenía que la Tierra se movía de verdad. No le bastó con afirmar que el modelo copernicano era útil para calcular la posición de los planetas. No, según Galileo lo que planteaba Copérnico era verdad, no sólo empíricamente adecuado. Este es un punto que Osiander, el editor del tratado copernicano, entendió claramente y, como no quería conflictos con la autoridad, añadió un prefacio al libro en el que afirmaba que la propuesta debía ser considerada como un simple instrumento de cálculo. Incluso la Iglesia dio permiso a Galileo para defender el copernicanismo como una herramienta matemática sin implicaciones sobre la realidad física.1378 Pero Galileo era un realista convencido, la cuestión relevante era si la Tierra se movía o no se movía y no sólo si podían elaborarse calendarios o cartas astrales con mayor o menor dificultad. Además, asumir que las teorías científicas se corresponden o no con la realidad influye en la investigación. Si no te interesas por la cuestión de si la Tierra se mueve o no de verdad, no tratarás de buscar el modo de medir ese movimiento. Las entidades teóricas son un factor determinante en el diseño experimental y en la interpretación de los resultados obtenidos. Feynman, por ejemplo, sostenía que dadas dos teorías matemáticamente equivalentes no era irrelevante que el científico se comprometiese con la realidad de una u otra puesto que esto influirá en qué nuevas teorías planteará y en cómo tratará de comprobarlas.1379 Para una discusión sobre cómo la interpretación filosófica de la mecánica cuántica está influyendo actualmente en el desarrollo de nuevas teorías que tratan de unificar la gravedad con las teorías cuánticas de campos recomiendo el excelente libro de Sean Carroll Something Deeply Hidden. Sin embargo, uno de los argumentos más fuertes a favor del realismo no es la actitud de los científicos, que podría ser una equivocación, sino el denominado del “no milagro” (no miracles). Es indudable que la ciencia ha tenido un gran éxito operacional. Por ejemplo, la física ha conseguido hacer numerosas predicciones que, más tarde, han acabado por confirmarse y la explicación más sencilla de tal éxito es que algo sobre la realidad debemos de estar averiguando. Sería un milagro que las predicciones fuesen tan buenas si nuestras teorías no fuesen, al menos, parcialmente verdaderas. Por ejemplo, sería muy raro que los electrones no existiesen y que a pesar de eso pudiésemos hacer tanta tecnología basada en teorías que asumen su existencia y que los caracterizan con unas propiedades determinadas. En este caso, estamos refiriéndonos, especialmente, a un tipo muy peculiar de predicción empírica exitosa: aquellas predicciones que han propuesto nuevos fenómenos que no podrían darse sin la existencia de alguna entidad teórica previamente no observada.1380 Sería muy extraño que se hubiese confirmado la predicción de Dirac de la existencia positrón si su teoría no hubiese conseguido plasmar un aspecto de la realidad no observable. Recordemos que la predicción de Dirac se derivó de una investigación completamente teórica que tenía como objetivo unir la relatividad especial con la mecánica cuántica. Además, este no ha sido el único acierto. Los químicos propusieron los átomos a principios del siglo XIX para explicar las proporciones elementales que encontraban en distintas sustancias. Sin embargo, los físicos dudaron de su existencia durante prácticamente un siglo. Por ejemplo, Mach, el paladín del antirrealismo, se negó a aceptar su realidad porque no podían observarse.1381 Sin embargo, la existencia de los átomos quedó establecida a principios del siglo XX más allá de toda duda razonable. Ian Hacking en su Representing and intervening propuso otro argumento a favor del realismo: no sólo hemos predicho la existencia de entidades teóricas que luego ha sido confirmada, sino que somos capaces de manipular estas entidades incluso aunque no podamos observarlas directamente. Según Hacking un electrón es real porque podemos manipularlo para crear nuevos fenómenos y tecnologías.1382 Otro argumento a favor del realismo es el de la convergencia teórica o de la corroboración. A medida que la ciencia progresa, las teorías de áreas diversas tienden a converger en teorías con un mayor poder explicativo. Por ejemplo, como hemos comentado, los químicos habían propuesto los átomos y las moléculas como explicación para las relaciones elementales en sus compuestos, pero esos mismos átomos terminaron apareciendo en las teorías estadísticas que trataban de explicar a nivel microscópico las leyes termodinámicas o en el movimiento browniano. Esta convergencia teórica entre áreas científicas tan alejadas es otro argumento a favor del realismo. A Mach, como no podía ser de otro modo, la aproximación de Boltzmann a la termodinámica, basada en postular entidades no observables, no le gustó y defendió la aproximación macroscópica de Carnot y Joule.1383 Honra al pragmatismo científico que Einstein, que tenía a Mach como uno de sus referentes y que propuso una relatividad profundamente influida por sus ideas, utilizase una aproximación muy similar a la de Boltzmann para explicar el movimiento browniano dando así un importante empujón a la aceptación de los átomos por parte de los físicos. Las ondas gravitacionales ofrecen otro ejemplo reciente de esta convergencia teórica. El evento GW170817, observado por LIGO, se corresponde con la fusión de dos estrellas de neutrones. Hay pocas entidades, en principio, menos observables que el propio espaciotiempo, pero LIGO no sólo ha conseguido observar fenómenos que se derivan de la variación en su curvatura, sino que ha podido relacionar sus resultados con observaciones obtenidas utilizando técnicas astronómicas más convencionales basadas en la observación de la luz proveniente de esos objetos. A esta nueva área astronómica, al ser capaz de detectar un mismo evento utilizando diversos mensajeros, como ondas gravitacionales, neutrinos, rayos cósmicos o fotones, se la denomina astronomía multimensajero. Los antirrealistas, además, se enfrentan a un problema filosófico de difícil solución ya que, aunque se declaran ateos o agnósticos respecto a las entidades no observables, no tienen problemas en aceptar la existencia de los gatos. Pero no es trivial plantear una propuesta filosófica coherente que justifique la existencia de las entidades observables y que, al mismo tiempo, rechace las no observables. Al fin y al cabo, yo confío, en última instancia, en la existencia de mi gata por el mismo motivo en que confío en la existencia de los átomos, porque hay métodos, instrumentales o no, que me permiten estar conectado informacionalmente con ambos tipos de entidades. Los antirrealistas, que son empiristas, suelen aceptar la existencia de las entidades observables, como los gatos, limitando su escepticismo a las entidades no observables. Sin embargo, delimitar ambos tipos de entidades no resulta sencillo. La línea entre lo observable y lo no observable es vaga y ha cambiado a lo largo del tiempo.1384 El filósofo de la ciencia Grover Maxwell (1918–1981) planteó el siguiente problema a los antirrealistas:1385 un individuo puede mirar con sus ojos desnudos, pero también puede hacerlo a través de una ventana o utilizando unas gafas o con una lupa o un microscopio óptico. Esto plantea la cuestión sobre qué debe contar como no observable. ¿Son los átomos no observables ahora que disponemos de una fotografía de 35 átomos de xenón obtenida con un microscopio de efecto túnel que, previamente, había formado con ellos las siglas IBM? Estoy seguro de que mi compañera escéptica e investigadora Elena Pinilla, que es especialista en microscopios de fuerza atómica, no tendrá problemas en admitir que los átomos son, efectivamente observables. Es indudable que la observación instrumental ha difuminado la distinción entre lo observable y lo no observable y que, además, algunas entidades que originalmente fueron muy especulativas pueden, con el tiempo, llegar a ser observables y manipulables rutinariamente en el laboratorio.1386 Van Fraassen no ignoró estas críticas y aceptó que no puede distinguirse a priori entre entidades observables y no observables,1387 pero argumentó, como hemos hecho en otras secciones de este libro, que un término puede ser útil aunque refleje una distinción vaga.1388 En cualquier caso, hay entidades que nunca podrán ser observadas directamente como los quarks o los electrones. Sin embargo, aunque aceptemos esta salvaguarda, el antirrealista debería detallar qué criterios deberíamos seguir para decidir sobre qué entidades hemos de ser agnósticos y sobre cuáles no. Además, el realista puede plantear legítimamente que si el antirrealista ha dado un salto inductivo para aceptar la existencia de los gatos o de los átomos, ¿por qué no debería también admitir la existencia de las entidades no observables?1389 No es fácil dar una justificación válida que rescate a los gatos, pero no que no arrastre consigo algunas entidades teóricas. 22.12 El problema de la subdeterminación Sin embargo, aunque es justo admitir que los realistas disponen de un puñado de buenos argumentos para responder al escepticismo antirrealista, hemos de reconocer que Van Fraassen y compañía guardan un último as en la manga: la subdeterminación. Este es un problema, que como hemos comentado, está asociado al de la inducción y que no puede ser solucionado por completo. Por muy precisa que sea nuestra teoría siempre cabe la posibilidad de que haya otra que también sea empíricamente adecuada, pero que plantee una metafísica, especialmente para aquellas entidades más sumidas en el entramado teórico, completamente diferente. ¿No debería un empirista considerar estas dos teorías como equivalentes a pesar de sus diferencias teóricas? Y en ese caso: ¿por qué habríamos de preferir la ontología teórica propuesta por una de ellas? Poincaré, en parte influido por el descubrimiento de las geometrías no euclídeas, planteó el convencionalismo: cuando se dispone de varias teorías empíricamente adecuadas podemos elegir una sin comprometernos con su metafísica, simplemente, por convención o conveniencia, por ejemplo, por su facilidad de uso.1390 Poincaré defendió la elección de una teoría u otra en base a razones superempíricas, pero al hacerlo no pedía que nos comprometiésemos con que la elegida representase la realidad última. Simplemente se elegiría una de las teorías empíricamente adecuadas por convención. Además, incluso en el caso de que actualmente sólo se disponga de una teoría, siempre debemos recordar que, en el futuro, podría plantearse una nueva alternativa, hasta ahora desconocida, que podría ser mejor que la actual a pesar de plantear una metafísica radicalmente distinta. Recordemos que Planck, a finales del siglo XIX, no pensaba que la física clásica fuese a caer, que el tiempo fuese a dejar de ser absoluto o que la solidez y la identidad de las partículas se nos fuese a perder en una extraña maraña cuántica, pero, aún así, sucedió: la familiar metafísica, que Planck asumía como real, se desmoronó como un castillo de naipes. Este argumento está relacionado con el pesimismo meta-inductivo, no sólo existe la posibilidad teórica de que nuestras ontologías más queridas se desmoronen, sino que en el pasado han caído espectacularmente. 22.13 Resumen Es indudable que tanto las teorías científicas como la mayoría de nuestras creencias cotidianas tienen una relación estrecha con la realidad externa, sin embargo, establecer la naturaleza de esta relación no es trivial. Una teoría es empíricamente adecuada cuando describe correctamente las partes observables del mundo externo. Debido al problema de la subdeterminación, puede haber teorías con propuestas metafísicas muy diferentes que tengan consecuencias observables muy similares. Incluso, ha habido modelos, como el de los epiciclos de Ptolomeo que, a pesar de tener una alta adecuación empírica, no se correspondían en absoluto con la realidad: los epiciclos no existen. Lo más relevante de las teorías científicas es que son instrumentos útiles. La adecuación empírica es suficiente para actuar en el mundo y para crear tecnologías. Además, mientras que el progreso en la adecuación empírica suele ser suave, el cambio metafísico puede ser abrupto. Las teorías clásicas fueron reemplazadas por alternativas contemporáneas que sólo eran un poco más precisas en los territorios previamente explorados, pero que, al mismo tiempo, plantearon un cambio metafísico radical. Comprender esta diferencia entre adecuación empírica y metafísica es vital para la sociedad. Los cambios metafísicos pronunciados son utilizados habitualmente por los enemigos de la razón para tratar de justificar que la ciencia no tiene una relación especial con la realidad: si los científicos cambian de opinión radicalmente no tiene sentido confiar en ellos más de lo que confiamos en los brujos. Y esto lo escriben sin pudor en un portátil y se lo envían a sus editores por internet mientras la NASA envía naves a Plutón utilizando la mecánica newtoniana. Otra lección fundamental es el verificacionismo matizado. La percepción es nuestra principal fuente de información sobre el mundo externo y la evaluación de nuestras creencias relativas al mundo externo debe estar estrechamente ligada al empirismo. La conexión informacional con las entidades postuladas es crítica y cualquier propuesta que no tenga consecuencias empíricas es mera sofistería. Durante el siglo XX, y lo que llevamos del XXI, los filósofos de la ciencia han discutido estas cuestiones partiendo desde dos posiciones enfrentadas: la realista y la antirrealista. Los antirrealistas sostienen que, dado que las teorías se aceptan o se rechazan, principalmente, en base a su adecuación empírica, el empirista sólo tendría que tratar de construir teorías empíricamente adecuadas. El antirrealismo sería un simple corolario del empirismo. El empirista se limitaría a estudiar las regularidades encontradas en el cosmos y habría de asumir, con modestia intelectual, que el asalto de los cielos metafísicos, el ansia por alcanzar la naturaleza última de la realidad, nos ha dejado, en demasiadas ocasiones, un sabor amargo a quimeras rotas. La caída de teorías con un amplio soporte empírico no es una mera posibilidad filosófica, la metafísica asociada a la física clásica cayó y resultaría extraño que nuestras teorías fundamentales no vayan a sufrir un destino similar. La subdeterminación puede ser implacable y, además, no tenemos forma de predecir cuál será la dirección del cambio ontológico. Sin embargo, los realistas nos recuerdan que el objetivo de la ciencia es comprender la realidad; no se trata tan sólo de crear teorías útiles, sino de entender la naturaleza del cosmos. El ethos científico debe asumir las necesarias cautelas empíricas, pero, al mismo tiempo, ha de recordar el ejemplo de Galileo: la Tierra, en última instancia, o se mueve o no se mueve. Además, este objetivo acaba influyendo en la investigación: las críticas de Einstein al antirrealismo de Bohr se convirtieron en un programa de investigación que condujo a la confirmación experimental de las desigualdades de Bell. Y también es importante recordar que se han hecho predicciones de entidades teóricas, como los átomos y los positrones que, más tarde, no sólo se han confirmado, sino que hemos podido manipular. Podría parecer que nos encontramos en un impasse difícil de superar, pero no hay que alarmarse, hay filósofos productivos que han conseguido plantear respuestas satisfactorias. Aunque es cierto que en física fundamental no podemos anticipar una dirección ontológica clara, en otras ciencias las ontologías están mucho mejor asentadas: ni los gatos ni los átomos serán descartados por ninguna teoría futura y también seguiremos creyendo que hay enfermedades causadas por los virus. Además, conviene recordar que, en el fondo, nuestra confianza en las entidades observables y no observables surge de la misma fuente, de nuestra conexión informacional con ellas y, por otro lado, siempre es necesario hacer un salto inductivo; la aceptación de la existencia de los gatos también se basa en una información limitada del mundo externo. Por eso no es de extrañar que la línea entre lo observable y lo no observable haya sido difuminada, con el tiempo, por la observación instrumental. Lo que sí es cierto es que cuanto mayor sea el salto, más cautos habremos de ser, cuanto más nos alejemos en nuestra red de creencias de las regiones mejor ancladas empíricamente, más recomendable será la prudencia. Los átomos quedarán porque habitan una parte de la red teórica suficientemente cercana a numerosos aspectos empíricos como para que la estructura de esa región de la red pueda ser modificada significativamente por cualquier teoría futura empíricamente adecuada. Un anclaje empírico más o menos importante implica una rigidez mayor o menor en la estructura de nuestras creencias. Explicar esta propuesta constituirá el cometido del siguiente capítulo. "],["estructura.html", "23 Estructura 23.1 Teorías y estructuras 23.2 Patrones 23.3 Existe lo que es parte de una teoría útil 23.4 Existen los patrones reales 23.5 Abajo hay relaciones 23.6 Arriba y abajo 23.7 Progreso ontológico 23.8 Resumen", " 23 Estructura 23.1 Teorías y estructuras En varias ocasiones nos hemos preguntado por si la gravedad es una fuerza o una curvatura del espaciotiempo y, lo cierto, es que puede que no importe. A la hora de juzgar una teoría lo más relevante es evaluar su adecuación empírica, es decir, considerar cómo de bien se corresponde con las evidencias empíricas disponibles. En el caso de las teorías físicas las predicciones suelen hacerse utilizando fórmulas matemáticas y, por lo tanto, el aspecto más importante de la teoría es la estructura matemática de esas fórmulas. Para el caso de las teorías cualitativas el argumento será similar, aunque el lector deberá sustituir estructura matemática por estructura lógica de las proposiciones que forman el conjunto teórico.1391 Si la parte que hace el trabajo en una teoría es su estructura, tal vez deberíamos centrar nuestra atención en este aspecto y dejar de obsesionarnos con las interpretaciones que podamos dar a estas estructuras. El filósofo Roger Jones planteó en su Realism about what? una cuestión muy relevante: aunque solemos hablar sobre la física clásica como si existiese una única formulación de la misma, en realidad, los físicos trabajan con esta teoría utilizando formulaciones muy distintas, como las planteadas por Newton, Halmilton o Lagrange. Estas aproximaciones, tomadas literalmente, tienen implicaciones metafísicas muy diferentes. ¿Son más fundamentales las fuerzas, las energías o la acción? ¿La velocidad o el momento? Por ejemplo, en la formulación lagrangiana las trayectorias del sistema en el tiempo se tratan como si fuesen objetos en sí mismos y, por lo tanto, podrían ser interpretadas como soluciones en un universo bloque en el que el futuro y el pasado tienen una existencia equivalente a la del presente. En estos universos todos los instantes existirían. La extrañeza de este planteamiento llevó al autor de ciencia ficción Ted Chiang a escribir su magnífico cuento La historia de tu vida. De modo que lo que Roger Jones planteó es: si la mecánica clásica tiene varias formulaciones con ontologías claramente diferenciadas, cuando un realista nos recomienda que asumamos como reales las ontologías de la teoría, ¿respecto a cuál de las ontologías deberíamos ser realistas? ¿Debemos pensar que existe la ontología planteada por el lagrangiano, por las fuerzas o por el hamiltoniano? La respuesta de muchos de los filósofos de la ciencia actuales es que como sólo la estructura tiene implicaciones empíricas, sólo la estructura es relevante. Todas estas formulaciones alternativas de la mecánica clásica comparten una misma estructura matemática y, por lo tanto, para el estructuralista, son iguales. El estructuralismo fue propuesto por el filósofo de la ciencia John Worrall en 1989: lo relevante es la estructura matemática o lógica de las teorías1392 y no tanto la ontología. Como acabamos de comentar, a una misma estructura le podemos asignar distintas ontologías, por lo que no es de extrañar que la estructura se mantenga mucho más entre los cambios teóricos que la ontología.1393 Los cambios teóricos, que a Kuhn le parecían radicalmente revolucionarios, desde el punto de vista estructural no lo son tanto y lo son todavía mucho menos en las regiones que habían sido exploradas empíricamente antes del cambio. La estructura de esas áreas mejor conocidas varió muy poco en el cambio de Ptolomeo a Copérnico, entre la mecánica clásica y la relatividad general o entre la electrodinámica de Maxwell y la cuántica.1394 No obstante, esto no impide que la estructura de las nuevas teorías y las viejas, en algunos casos, difieran mucho en las regiones que previamente habían permanecido alejadas de la indagación empírica. Incluso puede que las propias estructuras de las nuevas teorías nos sugieran fenómenos previamente desconocidos. Independientemente de qué teorías físicas se planteen en el futuro, de lo que podemos estar seguros es de que la mecánica newtoniana seguirá funcionando en los rangos que habían sido explorados empíricamente hasta el siglo XIX y que, además, las nuevas teorías seguirán teniendo una estructura muy similar en esas regiones.1395 Esto es así porque las nuevas teorías habrán de incluir los fenómenos que se habían estudiado en su momento y porque las observaciones, aunque no son completamente independientes del conjunto de nuestro conocimiento, sí lo son lo suficiente como para que nuestra visión del mundo no vaya a cambiar tan radicalmente. Cualquier teoría futura que prediga que las bolitas dejadas caer en un plano inclinado van a flotar será una teoría errónea. Las teorías futuras seguirán siendo empíricamente adecuadas en los territorios previamente explorados y a lo máximo que podemos aspirar es a que las nuevas tengan una mayor precisión en esas regiones.1396 La relatividad general siguió prediciendo, igual que predecía la gravitación newtoniana, el movimiento de las manzanas y los planetas, aunque es cierto que consiguió una mayor precisión en el análisis de la precesión de la órbita de Mercurio y que permitió descubrir fenómenos previamente insospechados en otros rangos de masas y velocidades. Sean Carroll, que es físico teórico, explica en su The big picture que las leyes físicas que rigen nuestro mundo cotidiano son perfectamente conocidas y que no van a cambiar radicalmente.1397 De hecho, en los rangos de energía que hemos explorado no es probable que aparezcan nuevas interacciones fundamentales relevantes a añadir a la electromagnética, nuclear débil, nuclear fuerte y gravitatoria y si apareciese alguna habrá de ser extraordinariamente débil, tan débil como para que, hasta el momento, no hayamos detectado sus efectos. Podemos hacernos una idea de cómo funciona el proceso imaginando que nuestras evidencias empíricas actuales se resumen en unos cuantos puntos prácticamente alineados en un plano cartesiano. Aunque es posible que tengamos distintas formulaciones teóricas alternativas, cualquiera de ellas tendrá una estructura similar a una recta que pasará cerca de esos puntos empíricos. Un nuevo cambio teórico podría proponer una parábola para explicar esos mismos puntos. Aunque, en el rango previamente explorado empíricamente, es decir, en la región cercana a los puntos previamente medidos, la nueva teoría tendría que diferir muy poco de la antigua, ambas seguirían teniendo una estructura similar y continuarían siendo empíricamente adecuadas en esa zona. Sin embargo, esto no implica que en otras regiones las predicciones de ambas teorías hayan de ser similares, sus estructuras más allá de lo explorado previamente pueden ser muy diferentes. Por ejemplo, la relatividad general hace predicciones muy similares a la gravedad newtoniana y, sin embargo, las estructuras de ambas teorías difieren profundamente en regiones previamente inexploradas, como, por ejemplo, las regiones cercanas a objetos muy masivos. Al poner el foco en las estructuras eliminamos en gran medida el problema de la subdeterminación. Cualquier teoría futura deberá dar cuenta de las evidencias empíricas actuales y, por lo tanto, estará forzada a compartir una estructura muy similar en las regiones mejor exploradas empíricamente. Además, la estructura permite que nos abstraigamos de los cambios entre ontologías, que podrían ser radicales, para centrarnos en lo esencial, en la estructura, y nos permite explicar por qué las teorías son capaces de hacer predicciones sobre nuevos fenómenos incluso aunque sus ontologías sean erróneas. En el capítulo anterior mencionamos el éxito de la predicción de los positrones por parte de Dirac; pero lo que no comentamos es que la metafísica propuesta por su teoría fue abandonada inmediatamente.1398 Sin embargo, esto no impidió que se hiciesen predicciones exitosas relativas a territorios previamente no explorados experimentalmente o, al menos, no reconocidos como tales. Una cuestión que quedó pendiente en las primeras propuestas estructuralistas fue si eran epistemológicas o metafísicas, si se referían a lo que podemos saber o a lo que es.1399 Este es un tema que ha sido explorado, entre otros autores, por el filósofo de la ciencia James Ladyman que ha relacionado las estructuras con los patrones reales de Dennett que mencionamos en el capítulo dedicado a las taxonomías. En cualquier caso, el mundo externo es lo que es. Nuestros mapas se construyen a partir de la información empírica disponible y la adecuación empírica puede asegurarnos, en mayor o menor medida, que los mapas tendrán una estructura similar a la del territorio, pero los mapas no son, sólo el territorio es. De modo que también será relevante preguntarnos por qué queremos decir cuando aseguramos que una entidad del mapa es real. 23.2 Patrones El filósofo Wilfrid Sellars (1912-1989) propuso que utilizásemos los términos: visión científica y visión manifiesta. La manifiesta es la común, la que se manifiesta ante nuestros sentidos con tan sólo abrir los ojos, mientras que la científica es la ofrecida por nuestras mejores teorías de la naturaleza. Ambas visiones son bastante diferentes, mientras que en nuestra vida diaria percibimos gatos, colores y olores, los físicos hablan de campos cuánticos y no es trivial relacionar ambas descripciones del mundo.1400 Hay filósofos, llamados eliminitavistas, que apuestan por el fundamentalismo ontológico: sólo lo fundamental es real. Esto implica que los gatos o el olor a tortilla de patatas son una ilusión mental o, como mucho, tienen una existencia secundaria. En el otro extremo podríamos situar a los antirrealistas que, como hemos comentado, sólo aceptan como real lo que podemos observar: los gatos son reales, pero los campos cuánticos son una entidad teórica sobre la que es aconsejable mantenerse agnóstico.1401 El fundamentalismo ontológico adolece de varios problemas. En mi opinión el mayor de ellos es que ni siquiera tenemos una teoría fundamental del nivel más profundo de la realidad.1402 Todavía es peor, porque sabemos que nuestras teorías actuales más fundamentales: el modelo estándar, que está formado por un conjunto de teorías cuánticas de campos, y la relatividad general son incompatibles. De modo que el eliminitavista debería eliminar no sólo los átomos, sino considerar con suspicacia incluso las entidades fundamentales propuestas por nuestras teorías actuales. Si nos movemos en la dirección contraria también nos topamos con problemas. Para Aristóteles estaba claro que los gatos individuales existían, pero tanto él como Platón tuvieron dificultades con la especie en su conjunto. ¿Existe la especie que engloba a todos los gatos individuales? ¿Tiene esta especie una existencia real? Según Aristóteles los gatos individuales tienen una existencia primaria, mientras que la especie tendría una existencia secundaria.1403 A estos términos que engloban a varios individuos Aristóteles, y muchos filósofos posteriores, los denominaron universales. La especie gato es un universal que engloba a muchos particulares. Para Aristóteles lo que tiene una existencia primaria son los particulares, no los universales.1404 El problema de esta solución es que no explica satisfactoriamente en qué sentido existe la gatunidad. Parece claro que los gatos individuales comparten algo, una cierta gatunidad. ¿Tendrá esta gatunidad una existencia real? Sería extraño asumir que no existe en el mundo externo algo que se corresponde con la gatunidad. Si mañana desapareciesen todos los taxónomos del mundo, incluso todos los seres humanos, los gatos continuarían existiendo y seguirán reproduciéndose entre sí, pero no con los perros. Para explicar esto Platón planteó la alternativa contraria: por supuesto que existe la gatunidad, de hecho, es la gatunidad la que tiene una existencia primaria, mientras que los gatos individuales no tienen más que una existencia vicaria de esa forma universal. Tanto Platón como Aristóteles entendieron que esta propuesta tampoco estaba exenta de problemas y la cuestión quedó sin resolver satisfactoriamente. De modo que, según la imagen manifiesta mi gata, que ahora mismo está tumbada junto a mí, tiene una existencia clara, pero no es trivial compatibilizar esta existencia con el hecho de que, en realidad, este individuo es un proceso complejo formado por átomos y moléculas que, a su vez, están formadas por campos cuánticos cuya naturaleza fundamental desconocemos. Mi gata es un torbellino atómico que durante un tiempo parece ser un animal peludo. Y, además, me es más difícil aún explicar en qué sentido existen los gatos como especie, como conjunto. Tal vez podríamos avanzar algo más sobre estas cuestiones metafísicas si comentásemos algunas propuestas recientes sobre qué implica afirmar que algo existe. 23.3 Existe lo que es parte de una teoría útil En primer lugar, es necesario reconocer que hay ideas que se corresponden con entidades reales y otras que no. Los gatos existen, los unicornios no. Estos segundos son imaginarios, no se corresponden con ningún aspecto del mundo externo, forman parte de mapas imaginarios. El físico Sean Carroll, en su muy recomendable The big picture, propone que deberíamos asumir que existen aquellas entidades que son parte de una teoría que describe el mundo externo adecuadamente. Por lo tanto, los átomos existirían y también los gatos individuales y la especie gato ya que cada una de estas entidades forma parte de alguna teoría útil.1405 El mismo Sean Carroll reconoce que esta propuesta tiene la debilidad de ser epistemológica. Está proponiendo, simplemente, que debemos considerar con seriedad aquellas entidades que forman parte de un mapa útil, pero ¿qué pasa con el territorio? Además, resulta un tanto extraño que si proponemos dos teorías alternativas para explicar un mismo fenómeno, dos mapas alternativos, hayamos de aceptar la existencia de las entidades propuestas por ambas. Por ejemplo, los físicos pueden utilizar la teoría relativista o la newtoniana para explicar el movimiento planetario, ¿implica esto que debemos aceptar que tanto la curvatura del espaciotiempo como el tiempo absoluto newtoniano son reales? Responder positivamente a esta cuestión sería raro. En principio, parece razonable aceptar que, en el mundo externo, en el territorio, o bien existe un tiempo absoluto o bien no existe y no tiene mucho sentido que nuestro compromiso con esa creencia haya de depender de la teoría que estemos decidiendo utilizar en ese momento. Aunque, recordemos, sólo el territorio es, así que la existencia de entidades alternativas que aparecen en diferentes mapas aproximadamente adecuados no debería preocuparnos demasiado. Ladyman, sin embargo, para evitar este problema, ha propuesto una puntualización que considero importante: hemos de considerar como reales sólo aquellas entidades que pertenecen a teorías cuyo uso transciende a motivos meramente prácticos.1406 Esto descartaría la fuerza de la gravedad newtoniana como real. Sería real, sin embargo, la curvatura del espaciotiempo puesto que es una entidad propuesta por una teoría fundamental. La propuesta de Ladyman también podría ser criticada. Comprometerse con la existencia del espaciotiempo es muy arriesgado, hay indicios de que la relatividad general no es realmente fundamental, sino que deberá ser sustituida, en algún momento, por alguna teoría más próxima a la realidad última. Esto es cierto, pero no lo es menos que ninguna teoría llegará jamás a estar completamente exenta de este problema. Recordemos que el problema de la inducción nunca podrá ser evitado completamente. No tenemos un acceso directo al territorio, tan sólo contamos con nuestros mapas. Por lo tanto, lo que Ladyman plantea es que debemos aceptar como reales aquellas entidades que aparecen en nuestros mejores mapas, aunque, al mismo tiempo, hemos de asumir que algunas de nuestras entidades actuales, en el futuro, podrían ser descartadas. Además, recordemos que Ladyman es uno de los principales proponentes del estructuralismo, de modo que su tesis es, en realidad, algo más sutil: lo que debemos aceptar como real es la estructura asociada a la relatividad general. Esta estructura, en el futuro, sufrirá modificaciones más suaves que la ontología que Einstein asoció a esa estructura. En cualquier caso, una metafísica naturalista ha de asumir que nuestro conocimiento es limitado. No debemos aceptar esta aproximación a la metafísica porque sea infalible, sino porque nadie ha llegado nada útil haciendo ningún otro tipo de metafísica. Si queremos averiguar qué hay en el mundo hemos de mirar y, al mismo tiempo, tenemos que asumir que nuestra mirada, aunque sea cada vez más amplia y precisa, es limitada. 23.4 Existen los patrones reales Creo que la tesis más defendible es que en el mundo externo existen patrones reales. Mi gata es, en realidad, un proceso en continuo cambio y los procesos son, en última instancia, patrones reales. Dennett, que fue quien propuso el término patrón real en su Real patterns (1991) insistió en que la característica más relevante de un patrón real es su compresibilidad. La información contenida en un patrón real puede comprimirse y esto nos permite construir descripciones eficientes de esa parte de la realidad. Cuando digo que mi gata está dormida junto a mí estoy haciendo una descripción muy económica de un patrón externo y puedo hacerlo porque ese patrón no está constituido por un simple barullo de átomos localizados al azar, sino que presenta un alto grado de orden. No puede hacerse una descripción económica de un conjunto aleatorio, el azar no es comprimible, sólo podemos resumir aquello que no es completamente aleatorio. Otra característica importante de los patrones reales es que son, más o menos, estables. En biología, por ejemplo, trabajamos con patrones reales que, al menos durante un tiempo, se resisten a la continua erosión de la segunda ley de la termodinámica.1407 Estos patrones pueden ser descritos en nuestros modelos del mundo como cosas, eventos o procesos.1408 La especie gato se corresponde con un patrón y mi gata también, así como sus átomos o los campos cuánticos que permean el espaciotiempo que ocupa. Los procesos también son patrones, por ejemplo, las reacciones que escribe un químico en la pizarra son descripciones de unos patrones determinados que se dan en el mundo externo. Las estructuras de las que hablan los realistas estructurales serían las estructuras de los modelos o teorías que utilizamos para hacer descripciones, más o menos aproximadas, de estos patrones reales. Los patrones recogen el orden del territorio y las estructuras son el reflejo de ese orden en nuestros mapas. 23.5 Abajo hay relaciones A primera vista parece que el mundo está compuesto por cosas, como los gatos o las bolas de billar, que son sólidas, que ocupan un lugar. Sin embargo, los atomistas griegos ya pensaron que esta idea planteaba problemas filosóficos y propusieron que estas cosas, que componen la imagen manifiesta del mundo, en realidad, están formadas a nivel fundamental por pequeños átomos. Nuestros átomos actuales son divisibles en partes, así que no se corresponden con los átomos de Leucipo y Demócrito, pero, aun así, la mayoría de nosotros conserva la idea principal: las cosas están compuestas por cosas que, a su vez, están formadas por otras cositas más pequeñas. A esta tesis se le denomina reduccionismo ontológico. Por ejemplo, mi gata está compuesta por órganos que, a su vez, están compuestos por tejidos, células, orgánulos, macromoléculas, residuos, átomos, etcétera. Sin embargo, ya desde la antigüedad también hubo críticas a esta propuesta. Aristóteles, por ejemplo, no pensaba que el vacío pudiese existir físicamente y esto le hizo plantear que el mundo no podía estar compuesto por cositas flotando en el vacío. Según Aristóteles la materia era continua, como los campos de Maxwell. Las propuestas de la física fundamental actual comparten aspectos tanto con el atomismo como con la continuidad aristotélica, aunque, en realidad, son algo más extrañas que ambas. Hace un par de años escuché en una entrevista a Ladyman criticar el reduccionismo ontológico por lo que decidí leer sobre sus argumentos y debo confesar que me convenció. Según Ladyman, que es el proponente del realismo estructural óntico, debemos descartar la idea de que a nivel fundamental las cosas estén hechas de cosas. En realidad, si atendemos a la física actual, no podemos saber si existen objetos a nivel fundamental, lo único que podemos asegurar es que existen relaciones. Su tesis es que las relaciones son claras, pero los individuos no tanto. Esto puede parecer sorprendente: ¿cómo es posible que existan relaciones si no hay individuos? ¿Relaciones entre qué? En realidad, Ladyman no sostiene que no existan individuos a nivel fundamental, sino que de lo único que podemos estar seguros, al menos por el momento, y puede que para siempre, es de que existen relaciones y que, por lo tanto nuestras ontologías de las entidades fundamentales deberían descartar los individuos. Tanto la mecánica cuántica como la relatividad general parecen indicar que, en el caso de que existiesen individuos a nivel fundamental, no podríamos obtener información sobre ellos, sino, tan sólo, sobre sus relaciones. Estamos acostumbrados a describir los sistemas utilizando el estado de los individuos que lo componen. Por ejemplo, podemos describir el estado de una partida de billar a tres bandas describiendo la posición y velocidad de cada una de las bolas. Sin embargo, esto no es posible en el mundo cuántico. Los sistemas cuánticos se describen globalmente y cuando están compuestos por varias partículas, éstas no se individualizan.1409 El estado de un billar cuántico compuesto por tres electrones se describe por las propiedades del conjunto, no de cada electrón individual. Esta es, de hecho, la raíz de la extrañeza del comportamiento de los sistemas cuánticos. Por lo tanto, Ladyman propone que lo que podemos decir que existe a nivel fundamental son redes de relaciones1410 y que los patrones reales de Dennett están formados por estas redes de relaciones. 23.6 Arriba y abajo Nuestra descripción del mundo no es única, utilizamos distintos mapas porque los patrones reales pueden estar organizados a distintas escalas. Si quieres saber lo que hará un tigre hambriento no es necesario, ni útil, plantearte cómo se comportará cada uno de sus átomos, es suficiente con entender una mínima biología. Utilizamos teorías diferentes a distintas escalas. Además, cada uno de estos modelos tiene unas ontologías distintas.1411 Estas ontologías no son incompatibles, sino complementarias, cada una es aceptada en su ámbito.1412 No hay gatos en la escala cuántica ni montañas a escala astronómica, por lo tanto, no tiene sentido preguntarse dónde empieza el gato a escala atómica. Según Ladyman esto no es más que un pseudoproblema.1413 Por ejemplo, a veces se escucha que no existen los sentimientos porque lo único que existen son los átomos, pero esto no es cierto, para el realista estructural ambas ontologías son aceptables. La filósofa Nancy Cartwright explicó que, aunque el mundo externo está compuesto por una única realidad, las distintas ciencias lo describen de un modo complementario, cada una con un rango de aplicabilidad limitado.1414 Es cierto que las teorías han ido, poco a poco, cubriendo territorios mayores.1415 Los mapas, paulatinamente, se han ido unificando, pero esto no ha de hacernos pensar que el reduccionismo teórico absoluto es posible. Nunca tendremos una teoría cuántica de la macroeconomía. El reduccionismo teórico es la idea de que las teorías del cosmos de un nivel superior deben derivar de las del nivel inferior.1416 Este supuesto ideal es, en realidad, inalcanzable. En la práctica puede que no sepamos derivar la teoría del nivel superior a partir del inferior.1417 Por ejemplo, aunque los químicos cuánticos tratan de inferir la máxima química posible a partir del comportamiento cuántico de los núcleos y los electrones, la realidad es que a la mayoría de los químicos le trae un poco al pairo lo que digan sus compañeros cuánticos. Las reglas de la química se averiguan haciendo experimentos en el laboratorio y lo cierto es que los cuánticos no son capaces de hacer predicciones precisas de muchos de los comportamientos observados por los químicos orgánicos o inorgánicos. Además, incluso aunque conociésemos los niveles inferiores con una precisión suficiente, en la práctica, muchas veces nos encontraríamos con el problema de que no podemos calcular que debería pasar en un nivel superior.1418 Los biólogos moleculares han determinado la estructura de un gran número de proteínas, pero los físicos y los químicos cuánticos tienen graves problemas para calcular esas estructuras a partir de las leyes más elementales.1419 A estos problemas de cálculo hemos de añadirles los concernientes al caos y a la historia de los sistemas. Los sistemas caóticos no son los que se comportan azarosamente, sino aquellos cuya evolución es muy dependiente de los pequeños detalles del estado inicial del sistema. Por ejemplo, si yo dejo caer una bolita por un plano inclinado poco importa que la bolita comience su viaje con algo más o menos de velocidad, su comportamiento será muy similar en ambos casos: este sistema no es caótico. Sin embargo, en otros sistemas, como, por ejemplo, la atmósfera terrestre, la evolución depende de las condiciones iniciales exactas y dado que no podemos medir estas condiciones con infinita precisión, en estos casos, es imposible hacer buenas predicciones a medio o largo plazo. Además, imaginemos que, en algún momento, consiguiésemos solventar estas dificultades y llegásemos a construir una computadora tan potente que fuese capaz de calcular lo que haría un gato basándose en su descripción atómica. Podríamos pedirle a este ordenador que hiciese una predicción sobre el comportamiento del animal en los próximos minutos. ¿Habríamos entendido el comportamiento del gato mejor que si pensamos que está cansado y que, por lo tanto, lo que hará será dormir? Sin embargo, esto no implica que los niveles superiores obedezcan leyes que no son derivables de los inferiores, algo que se conoce como emergencia fuerte, sino, simplemente, que no tenemos por qué ser capaces de derivar estas leyes de las inferiores o que esas descripciones no serían explicaciones aceptables.1420 La realidad de los niveles superiores no es mágica, depende de la de los inferiores, es sólo que puede que nosotros no entendamos esa relación. Estas descripciones no son alternativas, sino complementarias. Cuando sí somos capaces de entender un mismo fenómeno desde distintas ciencias sus modelos deberían ser consistentes. En caso contrario nuestra comprensión de la realidad estaría rota.1421 Es una suerte que los patrones que forman el cosmos tengan una organización tal que permita ser estudiada a distintas escalas. En caso contrario sería imposible aprender nada que ocurriese a nivel superior al fundamental.1422 Aunque, en realidad, supongo que esto no ocurre por casualidad, un cosmos sin estructura sería azaroso y la vida no sería posible y, por lo tanto, no habría nadie para preguntarse sobre el por qué de la imposibilidad de conocimiento a niveles superiores al fundamental. En cualquier caso, es sorprendente que las leyes que rigen los objetos grandes sean tan sencillas y si esto ocurre es porque las leyes que gobiernan los procesos a distintas escalas están, en muchos casos desacopladas de las de las escalas inferiores. Por ejemplo, la física intranuclear es indiferente para el estudio de la química. Una idea relacionada con la anterior es la de la emergencia. Las propiedades de los niveles superiores emergen a partir de las interacciones en los niveles inferiores. Una propiedad emergente no es parte de la descripción detallada de un nivel inferior.1423 Emergencia, por cierto, proviene de emerger. El término “emergencia” no tiene un significado preciso y los filósofos tienden a evitarlo1424 y, además, en muchas ocasiones, se utiliza como sinónimo de inexplicable.1425 En los textos de filosofía veréis con más frecuencia el término superveniencia. Un nivel superior superviene en uno inferior sí y sólo sí para que algo cambie en el nivel superior debe haber un cambio en el nivel inferior.1426 Otra terminología filosófica relacionada con estos asuntos es la de ciencias fundamentales y especiales. Una ciencia especial es cualquier ciencia que no estudia el nivel fundamental de la naturaleza. La única ciencia fundamental es la física fundamental, es decir, aquella parte de la física que estudia fenómenos que pueden darse en cualquier lugar del universo en cualquier momento. Por otro lado, las especiales restringen sus ámbitos de estudio a regiones concretas.1427 La física de partículas es fundamental porque estudia fenómenos que se dan en cualquier lugar y tiempo, mientras que la biología está limitada a unas entidades que habitan unas regiones muy específicas. 23.7 Progreso ontológico De igual modo que podemos estar seguros de que las teorías futuras harán una descripción empírica muy similar a las de las teorías actuales en los rangos que ya hemos explorado empíricamente, habrá también una cierta conservación ontológica en ciertas escalas. Cualesquiera teorías biológicas que se planteen en el futuro asumirán la existencia de los gatos y las químicas y físicas la existencia de los átomos. Estas entidades están relacionadas con estructuras teóricas que están tan constreñidas por observaciones empíricas que poco podrán variar en el futuro. Ladyman lo expresa apuntando que las teorías futuras conservarán, aproximadamente, parte de la estructura modal de las teorías actuales y no sólo su adecuación empírica.1428 Por supuesto, algunas de las estructuras de nuestras teorías actuales, las menos constreñidas por las observaciones empíricas actuales, sí puede que desaparezcan de las futuras teorías. Por ejemplo, es posible que en las teorías futuras los electrones no sean considerados puntuales. De modo que el debate sobre el realismo y el antirrealismo debería darse entidad por entidad y centrarse en estudiar, dadas las restricciones empíricas conocidas, el nivel de constricción de las estructuras teóricas actuales. 23.8 Resumen Es habitual centrar la discusión sobre las teorías en sus ontologías. Por ejemplo, cuando hablamos sobre la mecánica newtoniana podemos mencionar las fuerzas, las energías o la acción. Pero para comprender mejor el cambio teórico conviene dejar de lado las ontologías y centrarnos más en la parte de las teorías que determina su adecuación empírica, su estructura matemática o lógica. Es importante recordar que podemos asignar ontologías muy distintas a una misma estructura teórica. Por ejemplo, la misma mecánica newtoniana puede ser descrita utilizando fuerzas, energías o acciones. La estructura se relaciona con el mundo real gracias a las distintas evidencias empíricas. Podemos pensar en la estructura como en una red teórica anclada en distintos puntos a observaciones empíricas. En un momento determinado habrá regiones muy bien exploradas empíricamente y otras más alejadas de las evidencias y, por lo tanto, más especulativas. En los cambios entre teorías, incluso en aquellos que le parecieron radicales a Kuhn, la estructura en las regiones mejor exploradas se mantiene ya que todas las teorías presentes y futuras tendrán que ser empíricamente adecuadas y, por lo tanto, sus estructuras, en las regiones mejor exploradas, estarán muy constreñidas. Esto, claro está, no funcionará cuando las observaciones no sean neutrales respecto a las teorías comparadas y junto con la vieja teoría desaparezcan los datos, pero esto no suele ser un problema en las ciencias naturales. Es esta rigidez de la estructura en las regiones mejor exploradas la que nos garantiza que en cualquier teoría biológica futura seguirá habiendo gatos y en cualquier química futura, átomos. El mundo externo es un cosmos, no un caos, tiene un orden, un logos. Esto implica que la información contenida en el logos es, al menos en principio, compresible y las estructuras de nuestras teorías reflejan ese orden. Es esta compresibilidad la que permite que nuestras teorías tengan capacidades explicativas tan amplias a pesar de ser tan compactas. Por otro lado, en nuestras teorías el orden del cosmos termina empaquetado en cosas, eventos o procesos. El mundo externo es y nuestras teorías son meros reflejos del mismo; el territorio es, pero los mapas son representaciones, y, por lo tanto, cabe preguntarse qué estamos diciendo al afirmar que existe una entidad presente en uno de nuestros mapas. En principio, es razonable afirmar que existen las entidades que forman parte de las teorías empíricamente adecuadas, pero conviene hacer varias matizaciones. Por un lado, las entidades más teóricas, las situadas en regiones de la red menos constreñidas por las evidencias empíricas, puede que desaparezcan en teorías futuras. Además, hay teorías que se utilizan por motivaciones estrictamente instrumentales, como los epiciclos ptolemaicos, por lo que será difícil defender que sus entidades tienen una existencia real. ¿Existe la fuerza de la gravedad o la curvatura del espaciotiempo? La pregunta, en realidad, es un tanto banal, lo que existe es el cosmos, el mundo externo y su orden; la fuerza de la gravedad y la curvatura del espaciotiempo son entidades que forman parte de teorías empíricamente adecuadas. Aunque es cierto que la relatividad general abarca territorios más amplios que la newtoniana, ¿implica esto que hemos de decir que la fuerza de la gravedad no existe? Supongo que eso deberá decidirlo cada lector. Además, hemos de reconocer que el reduccionismo teórico absoluto es imposible de alcanzar: existe un sólo territorio, pero nunca dispondremos de un único mapa. Los patrones del cosmos están organizados en distintas escalas y nuestras diferentes ciencias estudian el orden presente en esas distintas escalas. Nuestra descripción del mundo no es única y las teorías propuestas en las distintas ciencias plantean ontologías complementarias. Es cierto que, en principio, las leyes de las escalas superiores tendrían que depender de las inferiores, la biología debería depender de la química, pero en la práctica no sabemos derivar el comportamiento del gato de su química. Aunque también es importante remarcar que complementario no implica alternativo; siempre que distintas ciencias estudien el mismo fenómeno sus explicaciones deberían converger. Esto es, por ejemplo, lo que vimos con los átomos, la química y la física. Aunque podamos estudiar la estructura del cosmos presente en distintas escalas, existe un único cosmos. "],["natural.html", "24 Natural 24.1 Naturalismos 24.2 Sobrenatural 24.3 No natural 24.4 Resumen", " 24 Natural Como comentamos al inicio del camino, podría argumentarse que la tradición filosófica occidental comenzó en Mileto con Tales y compañía. Tal y como mencionamos, una de las primeras propuestas metodológicas de estos filósofos consistió en asumir que los fenómenos naturales tienen causas naturales. Esta asunción ha sido muy fructífera en ciencia, pero, tal vez, ahora que hemos discutido distintas tesis metafísicas estemos en posición de analizarla con una mayor atención. ¿Podrían los seres sobrenaturales intervenir en el mundo natural? Y si lo hiciesen, ¿podría la ciencia estudiarlos? ¿Es necesario descartar las causas sobrenaturales por principio para poder hacer ciencia? ¿Tiene sentido hablar sobre lo sobrenatural? 24.1 Naturalismos El término naturalismo, en filosofía se utiliza en distintos contextos. Por ejemplo, puede decirse que Tales había asumido el naturalismo metodológico: había decidido que en sus investigaciones sólo consideraría como posibles explicaciones naturales.1429 Esta asunción metodológica está muy relacionada con otra tesis metafísica: la clausura o el cierre causal (casual closure). En este caso los investigadores además de proponer sólo explicaciones naturales, asumen que las únicas causas posibles de un fenómeno natural son las naturales.1430 Un científico puede asumir el naturalismo metodológico, es decir, puede asumir que sólo va a estudiar causas naturales sin que esto le obligue a aceptar también que no existen seres sobrenaturales o, incluso, que esos seres puedan intervenir en el mundo físico. Uno puede elegir no estudiar ciertas cosas, por ejemplo, porque cree que será demasiado difícil. Esta parece ser la postura filosófica que, al menos implícitamente, asumen muchos científicos que son creyentes religiosos. Estos investigadores, en el laboratorio, plantean sólo explicaciones naturales, pero los domingos admiten que algunos dioses son capaces de controlar el mundo con minuciosa precisión sin que la ciencia pueda detectarlo. Sin embargo, parece difícil mantener la tesis de que para hacer ciencia haya que asumir necesariamente el naturalismo metodológico; al fin y al cabo, la ciencia ha estudiado los fenómenos paranormales.1431 Además, si, por ejemplo, Jesús decidiese en algún momento regresar a la Tierra, ¿no podrían los científicos estudiarlo? Si existiesen los fantasmas e interviniesen de algún modo en el mundo externo, ¿no podríamos examinarlos? Hemos de ser cautos puesto que en filosofía el sustantivo “naturalismo” también se utiliza en otros contextos. El término naturalismo epistemológico, por ejemplo, se refiere a la tesis de que todo el conocimiento es científico. Esta es, claramente, una idea errónea. Por ejemplo, podemos saber muchas cosas sobre el mundo natural sin echar mano de la ciencia, no necesitamos de ningún científico para averiguar que las gallinas ponían huevos. La ciencia podría definirse como el conocimiento sistemático del mundo natural y, por lo tanto, al hacerlo admitimos la posibilidad de que existan conocimientos más cotidianos, algo menos consistentes y precisos. Además, la ciencia, como ya hemos comentado en varias ocasiones, ni siquiera constituye el conjunto del conocimiento sistemático humano ya que hay numerosos conocimientos rigurosos que no se refieren al mundo externo: matemáticas, lógica, ética, o epistemología, por ejemplo.1432 Como nota personal me gustaría añadir que me molesta bastante que se utilice el término ciencia como sinónimo de conocimiento, la ciencia es conocimiento, sí, pero sistemático y del mundo natural. 24.2 Sobrenatural Es bastante común asumir que, al menos en principio, los seres sobrenaturales podrían existir y que éstos podrían interaccionar con el mundo natural, sin embargo, en realidad, es posible que esta tesis sea incoherente. Tratemos de definir “sobrenatural”. Una posibilidad sería plantear que es sobrenatural aquello que no es físico. Un fantasma sería un ente sobrenatural porque no es físico. Y, por el contrario, serían naturales aquellas entidades que pudiesen reducirse causal u ontológicamente a una entidad física.1433 El problema de esta definición es que asume que sabemos, a priori, cuál es la diferencia entre físico y sobrenatural y, por lo tanto, no aclara nada. Otra opción sería definir natural como aquello que no es material y, al mismo tiempo, podríamos definir como materiales aquellas entidades que ocupan un espacio y persisten en el tiempo. El problema es que, como hemos comentado en el capítulo anterior, a nivel fundamental los individuos no ocupan un espacio, ni siquiera sabemos, a nivel fundamental, qué es el espacio o qué son los individuos. La ciencia ha llegado a la conclusión de que si escarbamos lo suficiente la materia parece desvanecerse en una ebullición de campos cuánticos. Como la aproximación material nos ha dado problemas, podríamos plantear que es sobrenatural aquello que está más allá de las interacciones o fuerzas descritas por la física. Sin embargo, esta definición tampoco sería satisfactoria ya que cuando la física encuentra nuevas fuerzas las incorpora a su descripción del mundo. Por ejemplo, las interacciones nucleares débil y fuerte no formaban parte de nuestra descripción física del mundo a principios del siglo XX. De modo que, si se descubriese una nueva interacción, simplemente, se estudiaría y se incorporaría a las nuevas ediciones de los libros de texto. La clave está en recordar el verificacionismo matizado: la percepción es nuestra fuente de información sobre el mundo externo por lo que, en realidad, forma parte del mundo natural cualquier entidad que esté informacionalmente conectada con algo perceptible. La cuestión, por lo tanto, es si una entidad está o no está conectada informacionalmente con nosotros. Podríamos definir sobrenatural como no conectado informacionalmente con nuestro mundo. Podemos imaginar que existen entidades completamente desconectadas de nuestro mundo, como, por ejemplo, una partícula extraña que no interaccione en modo alguno, ni siquiera indirecto, con las partículas que nos constituyen. Por lo tanto, si aceptamos esta definición, sí podrían existir entidades sobrenaturales, aunque, claro está, su existencia sería completamente irrelevante para nosotros y para el mundo natural en su conjunto. De hecho, tratar de especular sobre ellas tendría tanto sentido como discutir sobre el sexo de los ángeles. Ladyman sostiene que, en el fondo, el naturalismo y el verificacionismo son equivalentes en ciencia y en metafísica.1434 Si aceptamos la conclusión anterior, y me parece difícil no hacerlo, el naturalismo metodológico es completamente innecesario y llegamos así a una conclusión que me parecía obvia desde el comienzo: la ciencia puede estudiar cualquier entidad que interaccione de algún modo con nuestro mundo. 24.3 No natural Podríamos pensar que no aceptar la existencia o la relevancia de las entidades sobrenaturales implica una metafísica naturalista, pero esto no es necesariamente cierto. En la encuesta de Chalmers y Bourget el 49,8% de los filósofos dijo ser naturalista, el 25,9% no-naturalista y el 24,3% se decantó por otra opción.1435 Por lo tanto, merece la pena explicar esto del no-naturalismo. Hay que reconocer que existen fenómenos difíciles de encajar dentro del naturalismo. Por ejemplo, ¿son los estados psicológicos parte del mundo natural? Nuestros estados psicológicos se perciben como una experiencia privada claramente diferenciada del mundo material. Las mentes no parecen ser materiales. De hecho, creo que este es el motivo por el que resulta tan intuitivo aceptar la posibilidad de que existan entidades sobrenaturales.1436 Si nuestra mente no es más que el fantasma que habita la máquina, ¿por qué no podría haber mentes libres de su atadura material? Los fantasmas o los dioses constituirían ejemplos de estas mentes libres. Una de las tesis más famosas de Descartes fue, precisamente, la del dualismo de sustancia. La mente estaría constituida por una sustancia diferenciada de lo material. Aunque nosotros no le hemos prestado atención, el término sustancia es uno de los conceptos estrella de la metafísica especulativa. Sin embargo, este término no tiene mucho interés para los metafísicos naturalistas que tratan de conocer el mundo poniendo en primer plano el conocimiento científico. En cualquier caso, el dualismo de sustancia fue criticado con severidad inmediatamente. La intelectual Isabel de Bohemia y del Palatinado (1618-1680), nada más conocer la propuesta cartesiana, escribió al filósofo francés para preguntarle por el mecanismo que haría posible que una mente inmaterial interaccionase con un cuerpo material. Además, esta interacción entre mente y materia habría de ser muy estrecha, sólo hay que tomarse un café cargado para comprobarlo. Algunos, los fisicalistas, creen que sólo existe lo físico y que la mente no es una excepción,1437 sin embargo, otros, como David Chalmers, a pesar de aceptar la íntima relación entre mente y cerebro, son no-naturalistas respecto a la mente. Para Chalmers el problema de explicar nuestra experiencia privada, nuestra vida mental, es el problema difícil. Los estados mentales que percibimos son subjetivos, no podemos tener una experiencia directa de la vida mental de otra persona y si asumimos que el resto de personas tienen una experiencia mental similar a la nuestra es sólo porque se comportan de un modo similar al nuestro. Este es un problema con implicaciones reales. Por ejemplo, no puedo saber si mi gata tiene una experiencia mental de algún tipo o si la tiene un paciente con una alteración cerebral muy severa. Tampoco podremos nunca llegar a saber realmente si una inteligencia artificial ha llegado a tener una experiencia mental similar a la nuestra. Chalmers cree que la física no puede explicar nuestros estados mentales, no es dualista de sustancia, como lo era Descartes, pero es dualista de propiedades, es decir, cree que la materia tiene propiedades que van más allá de lo físico.1438 Según Chalmers, podría concebirse un universo que fuese físicamente equivalente al nuestro, pero que no albergase propiedades mentales. Esto le lleva a plantear que las explicaciones de las ciencias naturales nunca podrán solventar el problema difícil de la conciencia. El argumento más popular de Chalmers se basa en los zombis filosóficos. Esos zombis serían seres exactamente iguales a nosotros, pero, al carecer la materia que forma su cerebro de propiedades mentales, no tendrían experiencias mentales. Por otro lado, estas propiedades mentales no influirían, en absoluto, en lo físico por lo que los zombis se comportarían de un modo indistinguible a nosotros. De hecho, para mí sería imposible saber si el resto de la humanidad está formada por zombis o no puesto que mi único indicio de que las personas que me rodean no son zombis es su comportamiento y éste, como acabo de decir, sería indistinguible. Hasta tal punto un universo completamente zombi, es decir, absolutamente privado de experiencias mentales, sería similar al nuestro que, según el propio Chalmers admite, en ese universo podría existir un David Chalmers zombi que escribiría libros que tratarían la cuestión de la experiencia privada de la consciencia, una experiencia que, evidentemente, no podría tener. Si todo esto parece extraño es porque realmente lo es. El problema del dualista es que si admite que lo mental hace algo extra a lo físico queda expuesto al problema de explicar la interacción entre lo mental y lo físico y si propone que lo mental no influye en lo físico, sino que simplemente puede acompañarlo de forma opcional, se mete en los líos que estamos comentando. Dennett sostiene que la idea del zombi filosófico es incoherente.1439 Una pregunta interesante es cómo es capaz el propio Chalmers, mediante la introspección darse cuenta de si es o no es un zombi. El problema de la consciencia sigue siendo discutido activamente en filosofía y al lector interesado le recomiendo el breve, claro e instructivo Consciousness: A Very Short Introduction de Susan Blackmore. En cualquier caso, seamos fisicalistas o no-naturalistas, creamos o no que existe la posibilidad de que Chalmers sea un zombi sin experiencias mentales que se deleita discutiendo sobre ellas, lo que nadie cuestiona es que las mentes pueden ser estudiadas por la ciencia. Incluso aunque existiese la magia, podríamos analizarla racionalmente y tanto a los que acepten esta tesis como a los que duden de ella les recomiendo el delicioso fanfic Harry Potter y los métodos de la racionalidad de Eliezer Yudkowsky. 24.4 Resumen El concepto de lo sobrenatural es incoherente, las entidades o están o no están conectadas informacionalmente con nosotros. Por lo tanto, si existiesen los fantasmas no plantearían problemas epistemológicos distintos a los planteados por las mentes de los seres humanos. Sí es posible plantear que existen entidades completamente desconectadas del cosmos, pero estas entidades no podrían ser analizadas por la ciencia y, además, serían irrelevantes para nosotros y para el mundo que habitamos. El naturalismo metodológico, la tesis que sostiene que sólo han de considerarse explicaciones naturales, es inaceptable, si hubiese entidades no-naturales también podrían ser estudiadas. La ciencia ha estudiado los milagros y, aunque algunos filósofos sostienen que las mentes son no-naturales, tampoco tiene problemas con ellas. La ciencia puede estudiar cualquier entidad conectada con nuestro mundo. "],["bayesianismo_part.html", "Bayesianismo", " Bayesianismo "],["bayesianismo.html", "25 Bayesianismo 25.1 Revolucionarios o conservadores 25.2 Creencias, probabilidades y estadística 25.3 Estadística frecuentista 25.4 Inferencia reversa 25.5 Inferencia bayesiana 25.6 Subjetividad y convergencia 25.7 Historia del bayesianismo 25.8 ¿El método? 25.9 Todas las hipótesis 25.10 Lógica inductiva 25.11 Límites del bayesianismo 25.12 Resumen", " 25 Bayesianismo A pesar de que han transcurrido milenios desde los primeros resultados deductivos aristotélicos, el estudio de los modos de razonar sigue progresando. De hecho, en las últimas décadas, el desarrollo de los métodos de inferencia racional está siendo especialmente notable. Por ejemplo, es muy destacable el trabajo que se está llevando a cabo en el área del aprendizaje automático, pero los avances que vamos a tratar, dada su relevancia filosófica, son los circunscritos al campo de la inferencia bayesiana. 25.1 Revolucionarios o conservadores La inferencia bayesiana trata de calcular el grado de confianza que habríamos de otorgar a cada una de nuestras creencias. En varias ocasiones hemos comentado la tensión existente en las comunidades racionales entre la aceptación de las teorías bien establecidas y la crítica de las mismas. El científico transita sobre la línea que separa la credulidad y la crítica: debe tener la mente abierta a las nuevas ideas, pero, al mismo tiempo, sus pies han de estar bien asentados sobre las evidencias empíricas y las teorías contrastadas. Según Kuhn, las revoluciones acaban sucediendo a pesar de los científicos porque, recordemos, los investigadores que trabajan dentro del marco de la ciencia normal han aceptado ciertas tesis que no se plantean criticar. Popper, sin embargo, consideraba que como nuestras teorías más longevas no pasan de ser nuestras mejores conjeturas actuales, las comunidades científicas deberían caracterizarse por la crítica constante a todas las hipótesis. Según Polanyi los maestros han de enseñar la rebelión controlada.1440 Es el equilibrio entre el conservadurismo y apertura lo que permite a la ciencia renovarse con eficiencia. En realidad, puede que una vez consideradas las evidencias disponibles haya un grado de confianza determinado que el pensador racional habría de asignar a cada una de sus creencias. Este es, precisamente, el objetivo de la inferencia bayesiana, establecer el grado de confianza que habría de otorgar un pensador racional a cada una de sus hipótesis. 25.2 Creencias, probabilidades y estadística Los seres humanos asignan distintos grados de confianza a diferentes creencias y es común formalizar este proceder asignando probabilidades a estas confianzas.1441 Esta es una probabilidad epistémica puesto que refleja el grado de confianza que depositamos en una de nuestras creencias. En principio, parece razonable depositar más confianza en una conclusión inductiva a medida que vayamos acumulando evidencias a su favor y, además, este grado de confianza podría ser representado por una probabilidad. Cuando hablamos del escéptico Carnéades ya comentamos que su pithanon podía traducirse por probabilidad o verosimilitud. Sin embargo, a pesar de que la probabilidad parece una buena compañera de la inducción, estas ideas no fueron formalizadas durante milenios.1442 En el siglo XX Carnap sugirió que mientras que la implicación era el concepto clave en la lógica deductiva, el grado de confirmación habría de serlo en la inductiva. Un modo de pensar en estas probabilidades es plantearnos qué apuesta estaríamos dispuestos a aceptar sobre nuestras creencias.1443 Por ejemplo, yo estaría dispuesto a apostar contra una cuota de 1 en 1 millón que si dejo un kilo de plomo a un metro del suelo caerá y no flotará, pero sólo apostaría 1 contra 10 a que el tomate se domesticó cerca del norte de Perú. Esto refleja, claramente, que mi confianza en una creencia y en la otra no es la misma. Stephen Hawking realizó a lo largo de su carrera varias apuestas de este tipo. Por ejemplo, en 1971, se apostó una subscripción a una revista con Kip Thorne sobre si el objeto Cygnus X-1 era un agujero negro. En 1990 Hawking consideró que la evidencia a favor del agujero negro era tan grande que pagó una subscripción a Penthouse a Thorne.1444 En otra ocasión, Hawking y Thorne apostaron contra el físico John Preskill a favor de que en los agujeros negros se pierde información y en 2004 Hawking consideró que debía pagar la apuesta a Preskill. En este caso el pago consistió en una enciclopedia de béisbol. A muchos lectores puede que la probabilidad les recuerde a la estadística, de hecho, estas dos cuestiones suelen estudiarse conjuntamente. Sin embargo, aunque es cierto que ambas ideas están relacionadas, en realidad, son conceptos bastante diferenciados. La estadística consiste en utilizar las evidencias disponibles para hacer inferencias sobre el comportamiento de un sistema.1445 Por lo tanto, podríamos plantearnos por qué necesitamos de la probabilidad para hacer inferencias estadísticas. La respuesta es que la probabilidad nos permite calcular qué esperamos observar si el sistema realmente se comporta tal y como dicta una hipótesis determinada, un modelo, particular.1446 Por ejemplo, si suponemos que nuestro dado de seis caras está perfectamente equilibrado podemos utilizar las reglas de la probabilidad para calcular qué esperamos obtener si lanzamos ese dado 100 veces. Este, evidentemente, es un paso necesario si queremos comprobar en qué medida el sistema estudiado se comporta según nuestra hipótesis. La teoría de la probabilidad es un típico formalismo matemático. Partiendo de unos axiomas básicos se construye un conjunto de resultados matemáticos. Esta formalización fue llevada a cabo por el matemático soviético Andrey Kolmogorov (1903–1987). Kolmogorov procedió de modo análogo a como Euclides había construido su geometría milenios antes. Es decir, creó un edificio deductivo construido sobre unos cuantos axiomas. Una vez disponemos de esta teoría formal, podemos otorgar a las probabilidades distintas interpretaciones filosóficas. Hemos comentado que hay quien asocia la probabilidad con los grados de creencia, pero esta no es la única opción. La probabilidad también puede asignarse a una propensión del mundo físico. En este caso reflejaría la medida en la que un sistema físico va a comportarse de un modo u otro.1447 Este uso es muy distinto al de grado de creencia ya que asocia la probabilidad a una característica externa a nuestra mente, a una propensión de un sistema real. La afirmación de que “la probabilidad de que salga un uno al lanzar el dado es de un sexto” puede interpretarse de distintos modos. Podemos plantear que el dado tiene una propensión objetiva de un sexto de acabar mostrando un uno, independiente de lo que nosotros pensemos o, alternativamente, podemos interpretar la afirmación como que nosotros otorgamos una probabilidad de un sexto a nuestra confianza en que el dado caerá mostrando un uno. Esto último está asociado a nuestra creencia, es parte del mapa, no del territorio. En la práctica, la noción de la propensión objetiva no puede usarse directamente ya que se refiere a una propiedad metafísica, correspondiente al territorio, que habremos de estimar de algún modo.1448 Lo que sí podemos hacer es plantear modelos teóricos en los que sus entidades tengan distintas propensiones, diferentes comportamientos. Por ejemplo, podemos imaginar dados ideales, que tengan unas propensiones asignadas por nosotros. Además, también podemos lanzar muchas veces un dado real y calcular el número de veces que sale una cara u otra. La probabilidad clásica se asigna de este último modo, calculando la frecuencia de un resultado en el límite, cuando se hacen muchos ensayos.1449 A esta noción clásica de probabilidad, propuesta por el físico y matemático francés Siméon Denis Poisson (1781-1840) se le denomina frecuentista y suele contraponerse a la de las creencias subjetivas. 25.3 Estadística frecuentista Partiendo de estas dos interpretaciones sobre la probabilidad, la frecuentista y la epistémica, se han construido dos aproximaciones a la inferencia estadística: la frecuentista y la bayesiana. La estadística frecuentista ha sido la más utilizada en el siglo XX y, todavía hoy en día, continúa siendo muy útil. Este es un debate con consecuencias muy relevantes para la ciencia actual. Los investigadores suelen desconocer las justificaciones de la estadística frecuentista y esta es una de las causas del p-hacking. Por ejemplo, los científicos suelen creer que al encontrar que algo es estadísticamente significativo están justificados para pensar que su hipótesis es verdadera. Sin embargo, el concepto frecuentista de la significación estadística no tiene una relación directa con la verdad, sino, más bien, con el rechazo de las hipótesis. La aproximación que suele seguirse en la estadística frecuentista es plantear una hipótesis, que suele denominarse nula, y haciendo la asunción de que esta hipótesis nula es cierta, se calcula cómo de probable sería obtener las evidencias que hemos obtenido. Si nuestras observaciones se encuentran dentro de las que esperaríamos ver en la mayoría de las ocasiones si la hipótesis nula fuese correcta, diríamos que no hemos rechazado la hipótesis nula. Sin embargo, si nuestras medidas son muy inusuales para esa hipótesis, se afirmaría que nuestras medidas difieren significativamente de lo esperado según la hipótesis nula y, por lo tanto, dicha hipótesis sería rechazada. Esta es la base de la inferencia estadística frecuentista. Por ejemplo, imaginemos que estamos estudiando si una moneda es justa, es decir, si la mitad de las veces cae cara y la otra mitad cruz. Podríamos hacer un experimento en el que lanzamos la moneda 100 veces y obtenemos un número determinado de caras, por ejemplo 56. Esta sería nuestra medida. A continuación, simulamos experimentos con nuestra moneda ideal. Gracias a la teoría de la probabilidad podemos calcular cuántas veces en estas simulaciones ideales obtendríamos cero caras, una, dos, tres, etcétera hasta cien. Por supuesto, obtener cero o cien caras será muy improbable, lo más habitual es que el número de caras esperado sea cercano a 50. A continuación, comparamos nuestra medida real con las expectativas y rechazamos la hipótesis original si nuestra medida es muy improbable. Es decir, en ese caso podríamos concluir que sería muy extraño que la moneda estuviese bien equilibrada puesto que de serlo el resultado obtenido habría sido muy inusual. Este procedimiento es análogo al falsacionismo de Popper. La única diferencia es que, recordemos, Popper nos instaba a rechazar la hipótesis utilizando una inferencia deductiva y que, en este caso, nuestra inferencia está siendo probabilística. Dado que en este marco frecuentista estamos trabajando con el grado en el que nuestras observaciones serían esperables si la hipótesis nula fuese cierta, es común establecer un umbral que consideraríamos intolerable. Una vez sobrepasado este umbral se concluiría que obtener unas evidencias como las observadas sería tan extraño que lo más razonable sería rechazar la hipótesis nula. A esto se le denomina significación estadística y el umbral suele situarse, por convención, en el famoso 0,05. Esto significa que si el sistema estudiado se comportase según dicta la hipótesis nula, sólo obtendríamos resultados como los que hemos observado en un 5% de los casos. Por lo tanto, es habitual concluir que, de obtenerlos, estaríamos justificados para rechazar la hipótesis nula. Un problema muy común es que los usuarios de la estadística frecuentista creen estar trabajando con las probabilidades de que la hipótesis nula sea verdadera y que al rechazar esta hipótesis lo están haciendo porque han calculado que su probabilidad es muy baja. Sin embargo, esto no es cierto. Recordemos, el rechazo de la hipótesis se ha basado en la probabilidad de haber observado el resultado que hemos obtenido asumiendo que la hipótesis es correcta. Ya sé que todo esto es extremadamente confuso. De hecho, es habitual que los usuarios de la estadística frecuentista no entiendan bien qué están haciendo. Si se trabaja de este modo es porque es más fácil calcular la probabilidad de obtener un resultado concreto si asumimos un modelo de funcionamiento del sistema estudiado que calcular la probabilidad que realmente nos gustaría saber: la probabilidad de que una hipótesis describa adecuadamente el funcionamiento del mundo teniendo en cuenta las evidencias disponibles. 25.4 Inferencia reversa Para tratar de aclarar el asunto merece la pena hablar sobre la probabilidad condicional. La probabilidad condicional es la probabilidad de que ocurra un evento sabiendo que también ha sucedido otro. Por ejemplo, cuál es la probabilidad de que en mi casa haya pelos de perro sabiendo que no tengo perro. Esta es una probabilidad condicionada que podría escribir, utilizando la nomenclatura habitual, como p(pelos perro|no perro). Esta expresión se lee como: probabilidad de pelos de perro dado que no hay perro. Las probabilidades utilizadas en estadística frecuentista suelen tener la forma p(evidencias|hipótesis). Es decir, cuál es la probabilidad de observar unas evidencias determinadas dado que hemos asumido una hipótesis como verdadera. Por ejemplo, p(obtener cara|moneda bien equilibrada). Si asumimos que nuestra moneda tiene una cara y una cruz perfectamente equilibradas podremos concluir que la probabilidad de obtener cara en un lanzamiento concreto es de un medio: en la mitad de lanzamientos de esta moneda ideal obtendremos una cara. Si planteamos un modelo de funcionamiento del mundo, en principio, hemos de poder calcular la probabilidad de encontrar un resultado concreto. Estas son las probabilidades utilizadas habitualmente por los frecuentistas: asumen una hipótesis nula y calculan la probabilidad de obtener unos resultados dados para, posteriormente, comparar lo que hemos observado con estos resultados esperados. El problema del frecuentismo es que no nos permite calcular la probabilidad en la que realmente estamos interesados, que es la reversa, es decir la probabilidad de que la hipótesis describa adecuadamente el mundo dado que hemos obtenido unos resultados concretos: p(hipótesis|evidencias). La probabilidad que nos interesa realmente no es la de obtener cara si la moneda es ideal, p(número caras|moneda equilibrada), sino la contraria, dado que hemos obtenido 54 caras y 37 cruces cuál es la probabilidad de que la moneda esté bien equilibrada: p(moneda equilibrada|número caras). Dadas las observaciones queremos asignar una probabilidad a la hipótesis. A esta probabilidad, dado que no puede ser calculada directamente a partir de nuestra hipótesis, se la denominó probabilidad reversa y puede calcularse gracias al teorema de Bayes: p(A|B) = p(A) * p(B|A) / p(B). En realidad, lo que ahora denominamos inferencia bayesiana fue conocido como probabilidad inversa o de las causas hasta los años 50.1450 Es muy común que los usuarios de los p-valores no entiendan estos problemas y que interpreten el p-valor obtenido como una probabilidad de la hipótesis, pero no lo es. En realidad, el p-valor está relacionado con la probabilidad de haber observado los datos si la hipótesis nula fuese correcta. Este es un caso de la denominada falacia del fiscal, una falacia que, dada nuestra limitada capacidad para pensar correctamente sobre probabilidades, está muy extendida tanto en el pensamiento científico como en el cotidiano. En los juzgados suele confundirse la probabilidad de que hayan aparecido las evidencias que se han presentado durante el juicio si se asume la inocencia del acusado con la probabilidad de que el acusado sea inocente dadas las evidencias que se han observado. Por ejemplo, es común que se planteen razonamientos de este tipo: el testigo vio un hombre alto de pelo rizado vestido con sudadera, además, la sangre en el lugar del crimen es cero positiva y como el acusado tiene pelo rizado, viste habitualmente con sudadera y tiene sangre de tipo cero positivo podemos concluir que el acusado es el asesino. Este razonamiento es falaz, se está utilizando la probabilidad p(evidencias|el acusado es el asesino), cuando debería utilizarse p(el acusado es el asesino|evidencias). Para calcular esta segunda probabilidad, que es la que nos interesa, hemos de echar mano del teorema de Bayes y, al hacerlo, nos daremos cuenta de que hay una información fundamental sin la cual no podemos alcanzar conclusión alguna: cuál es la proporción de hombres de pelo rizado poseedores de sudaderas que tienen tipo sanguíneo cero positivo. Si hay muy pocos hombres que cuadren con esta descripción la probabilidad de que el acusado sea culpable será alta, pero si casi todos los hombres del barrio tienen el pelo rizado, poseen sudadera y tienen sangre cero positivo estas evidencias no nos estarán diciendo prácticamente nada. Otro error, del mismo tipo, y también muy habitual, consiste en confundir la probabilidad de tener una enfermedad vírica, dado que nuestro test ha sido positivo, con la probabilidad de dar positivo si estamos contagiados. Esto le pasó a un amigo mío al que un análisis de sangre le salió positivo para HIV. Una persona normal se habría asustado mucho, pero mi amigo sabía la estadística suficiente como para comprender que lo más probable, incluso teniendo en cuenta que su test había sido positivo, era que no estuviese infectado. Esta última afirmación puede resultar sorprendente, pero voy a tratar de explicarlo con un ejemplo. Imaginemos, por simplificar, que contagio implica enfermedad y que el análisis disponible es capaz de detectar correctamente 99 de cada 100 personas sanas. Es decir, si estás sano tienes una probabilidad de 0,99 de que tu test salga negativo y sólo una probabilidad de 0,01 de que el resultado sea positivo. Es necesario asumir que siempre habrá una pequeña probabilidad de error puesto que ningún test es perfecto. De modo que la probabilidad de aparecer como positivo en el test, aun no estando infectado, es de 0,01 (1 en 100). ¿Cuál será entonces la probabilidad de que estés contagiado si te informan de un test positivo? Ante esta pregunta es bastante natural responder: 0,99. Si has respondido esto has cometido la falacia del fiscal o de la frecuencia base. De hecho, con los datos que he dado es imposible calcular la probabilidad de estar infectado sabiendo que tu análisis ha salido positivo. Recuerda, p(contagiado | test positivo) es diferente de p(test positivo | contagiado). Para poder calcular la que nos interesa necesitamos saber la prevalencia de la infección en la población. Imaginemos que la prevalencia, la proporción de individuos infectados en la población general es de 0,001, es decir, 1 de cada 1000 individuos está contagiado. Supongamos además que hemos hecho 1 millón de análisis eligiendo individuos al azar. Entre estas personas habrá unas 1000 contagiadas (1 de cada 1000) y 999.000 sanos. Dado que tenemos una tasa de falsos positivos de 1 en 100, 9.990 de estos individuos sanos obtendrán un test positivo. Supongamos además que somos capaces de detectar a todos los contagiados, a los 1000. De ser así, tendríamos 10.990 individuos que reciben un test positivo: 9.990 sanos más 1000 enfermos. Ahora sí podemos calcular cuál es la probabilidad de estar sanos a pesar de que nuestro análisis haya salido positivo: 9.990 / 10.990, es decir, 0,09. Sólo 1 de cada 10,9 personas cuyo test es positivo estará realmente enferma. Y esta probabilidad depende tanto de la tasa de falsos positivos como de la prevalencia de la enfermedad. Si la enfermedad fuese muy infrecuente, por ejemplo, si sólo la tuviese una de cada 10.000 personas sólo 1 de cada 101 positivos estará realmente contagiado. En realidad, lo que puede hacer el pensador racional al obtener el resultado positivo del test es actualizar su probabilidad de estar contagiado. Mientras que la probabilidad inicial, antes de tener el resultado del test, era de 1 en 10.000, que es la prevalencia en la población, después de tener el resultado la probabilidad pasa a ser de 1 en 101. La evidencia, el test positivo, ha modificado nuestra probabilidad inicial, nuestra probabilidad a priori. Este es uno de los motivos por los que no suele recomendarse hacer análisis masivos en poblaciones en las que las prevalencias son bajas. Por ejemplo, si se hiciesen mamografías a la población de mujeres jóvenes, muchos de los tumores detectados serían falsos positivos y un falso positivo implica bastante angustia, así como intervenciones médicas innecesarias para las personas implicadas.1451 Estos resultados son muy contraintuitivos, pero es que a los seres humanos nos cuesta pensar con probabilidades condicionales, por eso es tan importante recordar estos problemas y confiar en el teorema de Bayes. En el caso de la inferencia bayesiana el error equivalente a ignorar la importancia de la prevalencia consiste en olvidar la importancia del conocimiento previo. La probabilidad a priori debe influir en la confianza final en la hipótesis.1452 Nuestras creencias deben depender del resultado del experimento, pero también de nuestras confianzas previas, que, a su vez, recogen los resultados experimentales y teóricos previos. Uno de los problemas de la inferencia estadística frecuentista consiste, precisamente, en no incluir explícitamente el conocimiento previo en sus cálculos. Esta es una lección que, en la práctica, se aplica en ciencia continuamente. Cuando, en 2011, los físicos detectaron en el experimento OPERA neutrinos más rápidos que la luz no concluyeron que había neutrinos más rápidos que la luz. Dado que los resultados previos hacían muy improbable esta hipótesis y el nuevo resultado no era tan relevante como para superar completamente esta desconfianza inicial, prefirieron reservar el juicio. Conclusiones extraordinarias requieren evidencias extraordinarias. 25.5 Inferencia bayesiana La regla de inferencia bayesiana aparece al sustituir en el teorema de Bayes las probabilidades relativas a las confianzas en las hipótesis y las evidencias: p(Hipótesis | Evidencia) = p(Hipótesis) * p(Evidencia | Hipótesis) / p(Evidencia) Este tipo de inferencia nos permite calcular la probabilidad que queríamos calcular: el grado de confianza que hemos de asignar a una hipótesis dadas unas evidencias determinadas. Esta aproximación dicta como hemos de modificar nuestra confianza previa en una hipótesis (p(Hipótesis)) al tener noticia de nuevas evidencias. La inferencia bayesiana formaliza una parte importante del aprendizaje racional: la concerniente a la actualización de la confianza en nuestras hipótesis en base a las nuevas evidencias observadas. Lo único que queda fuera de este marco es la generación de nuevas hipótesis, la fase de descubrimiento y la investigación en busca de evidencias. En realidad, la receta bayesiana no debería resultar demasiado sorprendente: el conocimiento final depende del conocimiento previo y de las nuevas evidencias. A la probabilidad que refleja nuestra confianza previa se le suele denominar probabilidad a priori (p(Hipótesis)), mientras que a la que obtenemos tras considerar las nuevas evidencias, se le suele denominar probabilidad a posteriori de la hipótesis (p(Hipótesis | Evidencia)). En este caso a priori y a posteriori no implican momentos en el tiempo si no, tan sólo, confianzas antes y después de considerar una evidencia concreta. El uso de la inferencia bayesiana exige que partamos de un conjunto de hipótesis a evaluar, así como de una confianza previa asociada a cada una de esas hipótesis. La inferencia bayesiana dicta cómo debemos actualizar nuestra confianza en cada hipótesis al considerar las nuevas evidencias.1453 Es decir, indica al pensador racional cómo tendría que actualizar su conocimiento dada una nueva observación. En esto es análoga a la inferencia deductiva que, recordemos, también exigía partir de un conocimiento previo, de unas premisas previas. La diferencia es que la inferencia bayesiana parte de unas hipótesis que no considera ciertas, sino tan sólo probables, mientras que la deducción asume que las evidencias son completamente verdaderas o falsas. El conocimiento previo se actualiza de acuerdo a p(Evidencia | Hipótesis) / p(Evidencia). A esta razón se la conoce como factor de Bayes o fuerza de la evidencia y cuantifica cómo de probable habría sido observar la evidencia si una de las hipótesis fuese verdad frente a como de probable sería obtener la evidencia si fuese verdad cualquier hipótesis.1454 Una evidencia confirma la hipótesis si hace que aumente su probabilidad posterior y la desconfirma si la disminuye. Cuanto mayor sea la diferencia entre el numerador y el denominador más deberíamos variar nuestra confianza en la hipótesis estudiada en base a las evidencias evaluadas. Para un bayesiano la evidencia sólo es relevante si altera la probabilidad de la hipótesis. Sin embargo, hay muchas evidencias irrelevantes que no lo hacen.1455 ¿Cuánto he de cambiar mi confianza en que existan los ponis rosas si alguien me dice que se ha tomado un café? Nada, puesto que la probabilidad de esta evidencia es la misma tanto si asumo que existen los ponis rosas como si pienso que no existen. Dejo como ejercicio para el lector extender el razonamiento a la evidencia anecdótica que suele aportarse en defensa de las pseudoterapias. Del mismo modo, un pequeño ensayo clínico que arroje un resultado positivo a favor de la eficacia de la homeopatía no ha de hacernos pensar que la homeopatía funciona. Para ser racionales nuestras conclusiones deben depender necesariamente de todo el conocimiento previo disponible. No es racional asignar una confianza a la conclusión basándose sólo en las evidencias empíricas de un estudio, debemos considerar todo el cuerpo de conocimiento anterior.1456 Esto, sin embargo, no implica que el pensador racional haya de tener una mente cerrada, es sólo que debe considerar su conocimiento completo y que sólo ha de modificar la confianza en sus creencias en la medida dictada por la fuerza de las evidencias. Además, es muy importante que un pensador racional recuerde que el grado en el que una evidencia debe afectar a nuestra confianza en una creencia determinada no sólo depende de la probabilidad de que hubiésemos observado la evidencia si la hipótesis fuese cierta, sino, también, de la probabilidad de que la hubiésemos observado si la hipótesis fuese falsa. Es un error grave aumentar nuestra confianza en una hipótesis sólo por el hecho de que hayamos observado algo que hubiese ocurrido si la hipótesis fuese correcta; debemos considerar también qué predicen las hipótesis alternativas.1457 Por ejemplo, 1000 enfermos de resfriado participan en un estudio en el que se administra homeopatía, se curan los 1000 ¿deberíamos modificar nuestras ideas a priori sobre la efectividad de la homeopatía? No. Los 1000 se habrían curado tanto si la homeopatía funciona como si no funciona, por lo tanto, la fuerza de la evidencia es nula. 25.6 Subjetividad y convergencia La inferencia bayesiana nos recuerda que en el conocimiento siempre hay un aspecto subjetivo. Esta limitación se formaliza al introducir el requisito de que propongamos unas hipótesis, las que nosotros deseemos, y unas probabilidades a priori. Para el bayesiano las probabilidades representan los grados de confianza que deposita en la capacidad de que sus hipótesis modelen el funcionamiento del mundo externo y esto es, en parte, subjetivo. Este es un punto que los críticos del bayesianismo han discutido hasta la extenuación. Incluso se ha tratado, infructuosamente, de establecer un modo objetivo de fijar las probabilidades a priori. La verdad es que me llama la atención el revuelo que suele rodear a estas probabilidades cuando, al mismo tiempo, no suele cuestionarse la elección de hipótesis iniciales que, al fin y al cabo, es también subjetiva. Aunque es cierto que el problema de las hipótesis planteadas por distintos investigadores puede resolverse haciendo un nuevo análisis que las incorpore todas, pero nunca podremos resolver la cuestión de las hipótesis no planteadas. Esta limitación, sin embargo, no implica que un pensador racional pueda establecer las probabilidades a priori arbitrariamente. Por ejemplo, no es racional asignar una alta probabilidad a que un virus se transmita con una alta eficiencia en un espacio cerrado y, al mismo tiempo, creer que no se transmite en un aula cerrada. Las probabilidades que asignamos a nuestras hipótesis deberían ser coherentes.1458 Esta es una exigencia difícil de satisfacer, pero el pensador racional debería esforzarse por tratar de conseguirlo. Existen distintas formas de asignar las probabilidades a priori sistemáticamente. Por ejemplo, podríamos optar por distribuir estas probabilidades uniformemente entre todas las hipótesis, es decir, por considerar a priori todas las hipótesis igual de probables. Esta aproximación se conoce como principio de indiferencia.1459 Otra propuesta, tal vez más atractiva, consiste en establecer las probabilidades a priori en función de la complejidad de las hipótesis. En este caso estaríamos otorgando un mayor valor inicial a las hipótesis más sencillas.1460 Existen incluso formalizaciones matemáticas de esta sofisticada navaja de Ockham como, por ejemplo, la inducción de Solomonoff.1461 La idea subyacente es que si dos hipótesis predicen lo mismo deberíamos quedarnos con la más sencilla. Esto no implica que la hipótesis más sencilla tenga una probabilidad mayor de ser verdad en un sentido metafísico, sino, simplemente, que para nosotros es más útil la más sencilla ya que la más compleja no aporta un mayor poder predictivo. En cualquier caso, estas reglas, puesto que se utilizan antes de considerar la evidencia, son criterios superempíricos y no hay forma de establecer de un modo objetivo y para un caso general cuáles debemos utilizar. Por lo tanto, los bayesianos suelen aceptar un cierto grado de subjetividad en el conocimiento. Nuestra confianza en las distintas hipótesis depende del mundo exterior, pero también, en mayor o menor grado, de nuestras ideas previas.1462 Aunque este es un punto que suele discutirse cuando se habla del bayesianismo, no es algo de lo que estén exentas ni la inferencia deductiva, que depende de las premisas, ni la inferencia estadística frecuentista, que hace numerosas asunciones subjetivas y convencionales. Además, en muchas ocasiones sí tenemos motivos razonables para asignar unas probabilidades a priori determinadas. Por ejemplo, puede que estemos estudiando un sistema análogo a otros que se han estudiado antes. En este caso podríamos utilizar la distribución de resultados de esos análisis previos para fijar nuestra distribución de probabilidades a priori. Esto es, por ejemplo, lo que hacen los jugadores en un casino; asumen que los juegos que están jugando en este casino son análogos a los vistos en ocasiones previas. También proceden del mismo modo nuestros sistemas perceptuales al tener en cuenta, implícitamente, lo percibido en circunstancias análogas en ocasiones previas para sesgar lo que vamos a percibir hacia unos resultados concretos. Este es el motivo por el que yo suelo ver en muchas ocasiones, por el rabillo del ojo, a mi gata a pesar de que cuando giro la cabeza resulta no estar ahí. Mi sistema visual, a falta de un estímulo claro, a falta de la evidencia, a priori, asume que voy a ver un gato y, a continuación, actualiza esta asunción previa en base a la nueva información recibida. En cualquier caso, la inferencia bayesiana, como la deductiva, deja la puerta abierta a que dos investigaciones racionales puedan comenzar su investigación desde distintos puntos de vista. Aceptar esto ha sido un problema para mucha gente. Se asumía que el proceso científico tenía que ser completamente objetivo, por lo tanto, el bayesianismo, con sus probabilidades a priori subjetivas, no había de tener cabida.1463 Sin embargo, los bayesianos responden que lo que nos enseña la inferencia bayesiana es que estas discrepancias subjetivas son inevitables y que, por lo tanto, lo más recomendable es hacerlas explícitas. La alternativa no consiste en disponer de una inferencia completamente objetiva, sino en barrer la subjetividad debajo de la alfombra.1464 La inferencia estadística frecuentista, que ha sido la más común en la ciencia hasta el momento, también es subjetiva. Por ejemplo, la elección del umbral del p-valor es subjetiva1465 y también lo son las hipótesis a considerar. De hecho, el problema es mayor incluso en esta aproximación clásica, por eso estamos tan expuestos al p-hacking.1466 Por otro lado, este subjetivismo de las probabilidades a priori no es tan relevante como podría pensarse ya que, si las evidencias son fuertes, las probabilidades posteriores dependerán fundamentalmente de estas evidencias y aunque dos pensadores racionales partan originalmente desde distintos puntos de vista terminarán por converger. Además, la aproximación bayesiana tiene la ventaja de poder ser utilizada iterativamente. Es decir, podríamos comenzar con unas hipótesis y un conjunto de probabilidades a priori e ir repitiendo la inferencia iterativamente, con una evidencia tras otra. Esto reduce en gran medida el inevitable problema de la subjetividad inicial de las probabilidades a priori ya que, dada una cantidad suficiente de evidencias, dos investigadores racionales acabarán teniendo una confianza final en sus hipótesis muy similar.1467 De hecho, si las evidencias son fuertes, en la práctica, esta convergencia en las probabilidades a posteriori se alcanzará con prontitud. Si las evidencias son claras el grado de creencia inicial no es un problema para un pensador racional. Podría pensarse que cabe la posibilidad de que los investigadores difieran en la probabilidad que les asignen a las evidencias. Esto daría al traste con la posibilidad de que las confianzas de los investigadores en sus creencias terminen convergiendo. Sin embargo, no es tan fácil que esto suceda ni en la práctica ni en teoría. En la práctica lo más común es que se discuta sobre las conclusiones mientras que en ciencia las evidencias suelen ser mucho menos controvertidas. Además, Robert Aumann demostró un teorema que garantiza que dos investigadores racionales, siempre que tengan acceso a la misma información, no pueden diferir en la actualización de sus creencias.1468 Dos científicos racionales no deberían conformarse con estar en desacuerdo.1469 25.7 Historia del bayesianismo La cuestión de la subjetividad unida a la dificultad de cálculo han hecho que el bayesianismo haya tenido una historia bastante complicada. A pesar de lo que pudiese pensarse, Thomas Bayes (1702-1761), que fue un matemático y religioso británico, no publicó el teorema que lleva su nombre ni la inferencia bayesiana. Sabemos de su propuesta porque fue publicada por su amigo Richard Price (1723-1791), que era escritor y clérigo, y que trabajó en ella durante un par de años.1470 De todos modos, la formulación moderna no se la debemos ni a Bayes ni a Price, sino al astrónomo y matemático francés Pierre-Simon Laplace (1749-1827), el mismo que le dijo a Napoleón que no había necesitado de la hipótesis de Dios para explicar el cosmos y que nombró el metro, el centímetro y el milímetro. Laplace descubrió la regla independientemente en 1774 y trabajó en su desarrollo durante 40 años hasta darle la forma actual.1471 Laplace fue también una figura clave en el desarrollo de los métodos frecuentistas. Sin embargo, el bayesianismo, debido al problema de la subjetividad, fue ignorado durante la primera mitad del siglo XX, que es cuando se desarrolló la inferencia estadística clásica. Uno de los primeros éxitos de la aproximación bayesiana fue su uso por parte de Turing para romper la encriptación Enigma. Sin embargo, no se sabe hasta qué punto Turing desarrollo la aproximación independientemente. Lo que si está claro es que la nomenclatura utilizada por Turing fue completamente diferente y que su éxito fue secreto hasta 1973.1472 En los 60 el bayesianismo comenzó a ser considerado por algunos estadísticos que valoraban sus sólidos fundamentos lógicos frente a la abigarrada mezcla de métodos frecuentistas. La primera conferencia internacional bayesiana se celebró en Valencia en 1979 y contó la participación de casi todos los bayesianos relevantes del momento, 100 en total.1473 Aunque actualmente la estadística bayesiana, gracias a sus fundamentos lógicos, goza de un mayor prestigio entre muchos estadísticos, en la práctica el uso de los métodos frecuentistas todavía es más sencillo: requiere menos capacidad de cómputo, tiene más software disponible y sus métodos son más conocidos.1474 A pesar de estas limitaciones los métodos bayesianos se utilizan cada día más. Puede que el lector se haya quedado con la impresión de que yo favorezco el uso de métodos bayesianos en el laboratorio, pero no es así. No sería deseable que los científicos rechazasen el uso de los métodos frecuentistas. Lo ideal sería utilizar la aproximación más adecuada y más práctica para cada caso teniendo en cuenta las bases filosóficas y las limitaciones subyacentes de cada método. Normalmente, si se tienen muchos datos las aproximaciones frecuentistas funcionan tan bien como las bayesianas y su cálculo es más sencillo, aunque también es cierto que los bayesianos tienden a ser más potentes cuando se dispone de pocas evidencias.1475 En cualquier caso, lo más relevante para el investigador es hacer buenos diseños experimentales, disponer de evidencias sólidas y entender la aproximación que está utilizando. Las cuestiones planteadas por el científico y el filósofo son ligeramente diferentes, por lo tanto, no es incompatible que mi recomendación sea pragmática para el científico, pero que, al mismo tiempo, defienda el bayesianismo frente al frecuentismo como método de inferencia desde un punto de vista filosófico. 25.8 ¿El método? Para un pensador racional que desee actualizar su confianza en un conjunto de hipótesis teniendo en cuenta unas evidencias determinadas la inferencia bayesiana no es opcional, es normativa, es el estándar al que aspirar, el modo óptimo de inferencia.1476 La inferencia bayesiana no es una simple recomendación más, es la norma que tendríamos que seguir, el estándar de justificación. A lo largo de este libro hemos comentado distintos tipos de razonamientos utilizados en ciencia como, por ejemplo, el método hipotético-deductivo. Estos métodos son recomendables como guías generales, pero siempre hemos indicado que tienen limitaciones serias y que, por lo tanto, no pueden plantearse como un estándar. Sin embargo, la inferencia bayesiana sí está muy cerca del estándar de justificación hipotética. Si disponemos de varias hipótesis en juego y un conjunto de evidencias, el ideal racional consistiría en utilizar la inferencia bayesiana para asignarles las confianzas finales. En esto el bayesianismo es análogo a la lógica deductiva. Un pensador racional que partiese de unas premisas asumidas como verdaderas consideraría la lógica deductiva como el estándar a seguir, la inferencia bayesiana constituye el estándar cuando la confianza en las hipótesis no es necesariamente absoluta. El modo más común de justificar la normatividad de la inferencia bayesiana consiste en explicar el problema del libro holandés (dutch book) o de la succión financiera para el apostante. Imaginemos un individuo que decide apostar en varios partidos de fútbol. En este caso se puede demostrar que si sus confianzas en sus creencias sobre los resultados de esos partidos y, por lo tanto, sus apuestas, no siguiesen los axiomas de la teoría de la probabilidad, siempre habría un modo de apostar contra él que garantizaría que fuese cual fuese el resultado final de los partidos el apostante perdería dinero y nosotros lo ganaríamos.1477 Por lo tanto, un apostante racional debe establecer su confianza en sus creencias siguiendo la teoría de la probabilidad. Aunque, en la práctica, la inferencia bayesiana es un estándar que no resulta fácil de alcanzar lo que sí podemos hacer es utilizarla como una forma de inspiración general que nos sirva de guía en nuestros razonamientos. De hecho, muchas de las reglas y métodos que hemos propuesto a lo largo de esta obra pueden extraerse como casos particulares de la inferencia bayesiana. Por ejemplo, el método hipotético-deductivo nos recomendaba contrastar las predicciones de nuestras hipótesis con las evidencias, pero no dictaba con precisión qué debíamos concluir a partir de estas observaciones, algo que sí hace con precisión la inferencia bayesiana. Como ya comentamos, en un marco deductivo estamos expuestos a los problemas planteados por Duhem y Quine, pero estas limitaciones se solventan en gran medida al aplicar la inferencia bayesiana a la red de hipótesis, tanto principales como auxiliares.1478 Una predicción exitosa o fallida no tiene por qué influir en el mismo grado a nuestra confianza en todas estas hipótesis. Este procedimiento formaliza nuestra idea intuitiva de que, si predecimos la existencia de Vulcano, pero no conseguimos observarlo, lo más razonable es pensar que el planeta no existe, no que las teorías ópticas que han servido para construir el telescopio son erróneas. Además, la iteración bayesiana se presta de forma natural a la evaluación iterativa de nuestras hipótesis. A medida que vamos obteniendo nuevas evidencias debemos ir utilizándolas para actualizar nuestra confianza en las distintas hipótesis. Por ejemplo, imaginemos que queremos hacernos una idea de cuál es la frecuencia de personas contagiadas por un virus en una población. Inicialmente nuestra incertidumbre es absoluta, pero a medida que nos vamos encontrado con personas contagiadas y no contagiadas podemos ir incorporando esta evidencia para ir determinando la confianza que nos merecen los distintos grados de prevalencia. Si nos encontrásemos con muchos enfermos, poco a poco, iríamos concluyendo que las prevalencias más elevadas son más probables y haríamos lo contrario si vemos pocos contagiados en nuestros ensayos. Carl Sagan hizo famosa la frase: “afirmaciones extraordinarias requieren evidencia extraordinaria”. Este aforismo puede extraerse fácilmente de la regla de inferencia bayesiana. Si la confianza inicial en la hipótesis es baja necesitamos una evidencia de gran fuerza para que ésta llegue a merecer una alta confianza final. Por cierto, esta idea ya fue propuesta por Laplace: “el peso de la evidencia en favor de una afirmación extraordinaria debe ser proporcional a su improbabilidad” y, antes aún, fue utilizada por Hume para descartar los testimonios en favor de los milagros. Hume planteó que debíamos evaluar qué era más probable, que el milagro hubiese ocurrido o que el testimonio fuese equivocado y dado que la probabilidad a priori del milagro era muy baja, se necesitaría una evidencia muy alta para confiar en el milagro. Hume resumió su aproximación escribiendo: Una persona razonable evalúa sus creencias sopesando la evidencia 25.9 Todas las hipótesis La inferencia bayesiana tiene otra característica que puede llamar la atención: su objetivo no consiste en seleccionar la mejor hipótesis, sino en modificar racionalmente nuestra confianza en todas las hipótesis evaluadas. La inferencia bayesiana dicta cómo deberíamos actualizar la distribución de probabilidades a priori dada la evidencia disponible.1479 Es decir, si comenzamos planteando mil hipótesis iniciales, el resultado final será que seguimos teniendo las mismas mil hipótesis finales. Lo que habrá cambiado es nuestra confianza en cada una de ellas. Puede que ahora haya una que tenga una probabilidad final de 0,99 y el resto se repartan el 0,01 restante de probabilidad, pero también podría ocurrir que dos, tres o más hipótesis acabasen teniendo al final una probabilidad elevada. Otra aproximación muy utilizada en estadística, la máximo-verosímil, sí se plantea como objetivo elegir una sola hipótesis: aquella que hace más probable las evidencias que hemos observado (p(Evidencia|Hipótesis)). El problema de elegir una sola hipótesis es que puede que haya otra casi igual de adecuada que vamos a acabar ignorando. Sin embargo, este es un problema que no afecta al bayesiano. Además, en general, es muy buena idea evaluar todas las hipótesis y no sólo la favorita. Es común que cuando tenemos una hipótesis razonable intentemos confirmarla enumerando las evidencias que cuadran con la misma. Esta aproximación, sin embargo, no es completamente racional. Es preferible evaluar todas las hipótesis, no sólo la que nosotros creemos más probable a priori. Además, hay que utilizar en su evaluación todas las evidencias disponibles, no sólo las favorables, y debemos comprobar para cada evidencia si da o no soporte al resto de hipótesis. En cualquier caso, aunque estemos obligados a considerar todas las hipótesis puede, como ya he mencionado, que al final una de ellas acabe teniendo una probabilidad muy alta.1480 25.10 Lógica inductiva La inferencia bayesiana puede considerarse como una formalización de la inferencia inductiva no ampliativa. La probabilidad podría interpretarse como el grado en el que una afirmación es verdadera dado que otras también lo son en diverso grado. El filósofo, matemático y economista Frank Ramsey (1903–1930) indicó que la teoría de la probabilidad exige consistencia y que, por lo tanto, podría ser utilizada para extender la inferencia deductiva. Si desobedecemos las reglas de la lógica deductiva podemos acabar aceptando conjuntos de proposiciones como verdaderas que, en realidad, no pueden ser simultáneamente verdaderas, mientras que, en el caso inductivo, al violar las reglas de la probabilidad quedaríamos expuestos al problema del libro holandés.1481 La diferencia entre la inferencia bayesiana y la deductiva consiste en que mientras la deducción serviría para afirmaciones que consideramos verdaderas o falsas con certeza absoluta, este nuevo tipo de inferencia lógica nos sirve también para aquellos enunciados de los que no estamos completamente seguros.1482 La inducción simple, tal y como la consideramos en los capítulos anteriores, es ampliativa y por eso implica un salto lógico, pero la inferencia bayesiana, como la deductiva, no lo es, no crea nuevo contenido factual, simplemente transforma las premisas en conclusiones, siendo ambas, en el caso bayesiano, probabilísticas.1483 En este caso no estamos proponiendo nuevas hipótesis, como lo hacemos normalmente al inducir, sino que estamos obteniendo probabilidades a posteriori a partir de las asunciones iniciales. 25.11 Límites del bayesianismo El bayesianismo representa el estándar racional de la justificación. Si hay varias hipótesis planteadas, lo ideal sería evaluarlas a la luz de las evidencias utilizando la inferencia bayesiana, pero, por desgracia, esto no siempre es posible y, además, hay aspectos del proceso científico, como el del descubrimiento, que no están cubiertos por la aproximación bayesiana. Otro de los problemas que no soluciona el bayesianismo es el de la constancia de las regularidades del cosmos. Si mañana cambiasen las regularidades presentes en el sistema que hemos estudiado, si se violase el principio de uniformidad que discutimos en el capítulo dedicado al problema de la inducción, la inferencia bayesiana quedaría tan expuesta como cualquier otra. La inferencia bayesiana formaliza algunos aspectos de la inducción, pero no puede solventar por completo el problema de la inducción. Esto es lógicamente imposible: siempre que haya un investigador haciendo modelos sobre el funcionamiento y la constitución de un sistema a partir de información limitada estaremos expuestos a este problema. Este no es un problema que afecte sólo a la ciencia, cabe la posibilidad lógica que dentro de cinco minutos el mundo deje de existir, las esmeraldas pasen a ser rojas o que los polos Frigo Pie sepan a pollo asado. Esto, recordemos, no es una mera posibilidad teórica. Es cierto que parece improbable que las leyes del universo vayan a cambiar repentinamente, pero si estamos estudiando un sistema complejo puede que las reglas que lo rigen sean modificadas sin que nos demos cuenta. Por ejemplo, puede que tengamos un modelo epidemiológico sobre el funcionamiento de una enfermedad que nos ha funcionado muy bien durante dos décadas, pero que, de repente, falle estrepitosamente porque, sin que nos hayamos dado cuenta, la bacteria causante de la enfermedad haya adquirido una mutación que la hace mucho más contagiosa. El bayesianismo se enfrenta además a numerosos problemas prácticos. Una de las limitaciones principales suele ser la de calcular p(Evidencia | Hipótesis). Para poder hacer este cálculo nuestra hipótesis tiene que estar perfectamente determinada de un modo matemático. Sin embargo, la mayor parte del trabajo científico utiliza hipótesis que no están definidas con tanta precisión. De hecho, fuera de la física, en muchos casos, las hipótesis no son ni siquiera cuantitativas. En estos casos, aunque el bayesianismo debería ser una inspiración, un estándar que nos guiase, no podrá utilizase formalmente. Por otro lado, incluso cuando hayamos hecho el esfuerzo de plantear hipótesis cuantitativas precisas, es muy probable que no podamos utilizar la inferencia bayesiana, simplemente, porque computacionalmente es demasiado costosa. El problema general de la actualización de la confianza en nuestras creencias suele tener un coste computacional tan elevado que los cálculos son imposibles de realizar Pearl1484, location:8088]. En la práctica, para poder resolver los cálculos, hay que hacer asunciones que suelen funcionar bien en la mayoría de los casos, pero que no tienen la garantía del rigor del calculo bayesiano estricto. Es decir, en las aplicaciones habituales solemos aplicar heurísticas que, aunque en la mayoría de los casos funcionan bien, en algunos casos podrían llevarnos a conclusiones equivocadas. Existen muchas de estas aproximaciones simplificadas como, por ejemplo, las redes de creencias,1485 el muestreo de hipótesis más prometedoras por cadenas de Markov o las basadas en la energía libre.1486 Por último, debemos recordar que la aproximación formaliza la justificación de las hipótesis y que incluso existen investigaciones para ampliarla a la fase de investigación de nuevas evidencias.1487 Sin embargo, la fase de creación de hipótesis, en la mayor parte de los casos, continúa siendo un arte. Dadas unas evidencias, antes de poder evaluar las hipótesis, debemos llegar a formularlas y aquí es donde, en la práctica, solemos fallar. Si no planteamos las hipótesis correctas nuestro análisis bayesiano servirá de bien poco y, además, siempre quedaremos expuestos al problema de las hipótesis no planteadas.1488 Puede que mañana llegue otro investigador que ha encontrado un patrón que a nosotros se nos había escapado por completo. 25.12 Resumen Depositamos un grado de confianza en cada una de nuestras creencias, algunas nos parecen más seguras como representaciones del mundo externo y otras menos. Esta confianza habría de ser coherente entre distintas creencias y la asignación de probabilidades y el cálculo de probabilidades nos permiten evaluar esta coherencia. El pensador racional ha de tener en cuenta las evidencias disponibles cuando asigna una confianza a una hipótesis. Además, es importante no caer en la falacia de la frecuencia base, hemos de recordar que la probabilidad que nos interesa, la de nuestra hipótesis dado que hemos obtenido unas evidencias, es la reversa a la que podemos calcular más fácilmente: la de observar un resultado determinado si asumimos que el mundo funciona siguiendo la hipótesis. Esta probabilidad se calcula utilizando el teorema de Bayes y este es el fundamento de la inferencia bayesiana. Una consecuencia ineludible de esta aproximación es que nuestra confianza en nuestras creencias ha de depender, además de en las evidencias, del conjunto de nuestro conocimiento previo. Este conocimiento previo se introduce en el formalismo bayesiano como las hipótesis y sus confianzas previas. La inferencia bayesiana formaliza un aspecto importante del aprendizaje, cómo hemos de variar nuestra confianza en nuestras creencias cuando obtenemos una nueva evidencia. Este proceso de aprendizaje puede ser iterativo, a medida que vamos obteniendo nuevas creencias podemos ir aplicando la inferencia bayesiana para actualizar nuestras confianzas. La inferencia bayesiana es una formalización de las inferencias no ampliativas. Generaliza la lógica deductiva añadiendo la posibilidad de asignar grados de confianza a las proposiciones. Al no ser ampliativa no implica un salto lógico y, por lo tanto, evita algunos de los problemas asociados a la inducción. Aun así, no soluciona todos los problemas. Por ejemplo, que cualquier conocimiento sobre un sistema está obligado a asumir el principio de uniformidad; si el sistema cambiase el conocimiento previo adquirido quedaría obsoleto. Esta es una limitación inevitable general del conocimiento del mundo externo. Además, al no ser ampliativa acepta unas limitaciones adicionales de partida; la principal de ellas es que no nos sirve de guía durante la fase de descubrimiento de las hipótesis o sobre qué confianza inicial tenemos que depositar en ellas. Tampoco soluciona el problema de las hipótesis no planteadas, en cualquier momento podría aparecer una hipótesis rival que no hemos considerado y que podría ser mejor que cualquiera de las nuestras. Y, por último, también nos deja expuestos al problema de la carga teórica de la observación. Aunque, también se puede ver el vaso medio lleno. La inferencia bayesiana es un gran avance ya que establece un estándar para la justificación hipotética que nos sirve como guía para evaluar cualquier hipótesis disponible dadas unas evidencias. Además, al menos en teoría, es capaz de resolver el problema de Duhem-Quine. En la práctica aplicar la inferencia bayesiana no es sencillo. Por un lado, exige que asignemos probabilidades tanto a las hipótesis como a las evidencias y que los modelos sean lo suficientemente detallados como para que podamos calcular probabilidades a partir de ellos. Y, por otro, los cálculos suelen ser computacionalmente tan costosos que, en la práctica, nos obligan a usar aproximaciones. En cualquier caso, la inferencia bayesiana es un estándar que, al menos, hemos de tomar como referencia. Muchas de las reglas que hemos comentado anteriormente, como el falsacionismo o el método hipotético-deductivo pueden derivarse como casos particulares de esta aproximación general. Es importante recordar que el pensador racional debe considerar todas las hipótesis, no sólo la que trata de contrastar, y que ha de tener en cuenta todas las evidencias, no sólo las favorables. Aunque es cierto que, en la práctica, puede que algunas hipótesis tengan una confianza inicial tan ridículamente baja que no merezca la pena evaluarlas a no ser que se disponga de nuevas evidencias muy sólidas a su favor. Este es, por ejemplo, el caso de la homeopatía. Por último, no me gustaría terminar sin recordar a todos los que utilizan la inferencia estadística, sea esta bayesiana o frecuentista, que hacerlo sin entender la filosofía que hay detrás es una muestra de mala ciencia. Si no entiendes por qué estás aplicando un test y no otro y cuáles son las implicaciones filosóficas de lo que estás haciendo no deberías estar utilizando ese test sin el consejo de un especialista. "],["el_oficio_de_la_duda_part.html", "El oficio de la duda", " El oficio de la duda "],["el_oficio_de_la_duda.html", "26 El oficio de la duda 26.1 Problema y asunciones 26.2 Hija del escepticismo y el empirismo 26.3 No hay un método 26.4 Obtención de evidencias 26.5 Creación de hipótesis 26.6 Justificación 26.7 Contrastación 26.8 Elección entre hipótesis 26.9 Iteración 26.10 Progreso científico 26.11 Metafísica 26.12 Hemos de utilizar conocimiento previo 26.13 Las observaciones son limitadas, falibles y están cargadas de teoría 26.14 El problema de las inferencias ampliativas 26.15 Podría fallar, pero suele funcionar 26.16 Normas y jueces 26.17 Exigencias deontológicas 26.18 Incentivos perversos 26.19 Ágora, corte y bazar 26.20 Ciencias y ciencias 26.21 Para qué sirve la ciencia", " 26 El oficio de la duda A lo largo del libro he tratado de describir las distintas propuestas filosóficas con ecuanimidad, mostrando sus fortalezas y sus limitaciones. Sin embargo, en este capítulo, que pretendo que sirva como resumen de lo que creo haber aprendido, mostraré mi punto de vista, que es el de un científico concreto con una dilatada experiencia en genética y sin conocimientos previos de filosofía. 26.1 Problema y asunciones Acepto las tesis de que existe un mundo externo a mi mente y de que al menos algunos aspectos de ese mundo son cognoscibles. La tesis filosófica del escepticismo radical no es descartable de un modo absoluto, pero, simplemente, la considero improductiva y, además, no creo que haya ningún solipsista honesto ni tampoco tengo interés en las discusiones metafísicas relativas al idealismo (la tesis filosófica que confiere supremacía a lo mental frente a la existencia de lo material). Además, también creo que el mundo externo tiene un cierto orden, es un cosmos con un logos coherente. El cosmos está caracterizado por patrones reales comprimibles y, más o menos estables. Es decir que esos patrones pueden ser descritos utilizando menos información de la que sería necesario utilizar si habitásemos en un caos absoluto. Por ejemplo, puedo describir una bolita de hierro dando su composición, diámetro, velocidad y posición. Esta limitada información me permite anticipar gran parte de su comportamiento a pesar de que no sé cuales son las posiciones y velocidades de cada uno de sus átomos. Los patrones que comprenden el logos, el orden del cosmos, tienen estructuras a distintas escalas, desde las que se corresponden con los campos cuánticos a las galácticas, pasando por los gatos o los ecosistemas. Nosotros también formamos parte del cosmos, pero desde un punto de vista epistemológico conviene dividir el mundo en dos sistemas: el que genera y alberga conocimiento y el resto del mundo, que es lo que estoy denominando mundo externo. El investigador no tiene un acceso directo al logos, no podemos aprehender directamente el orden del cosmos, pero sí somos capaces de interaccionar con el mundo externo para obtener información sobre él. En esta información puede haber regularidades que reflejen, indirectamente, la estructura presente en los patrones que caracterizan el mundo externo. Además, disponemos de metodologías que nos permiten inferir estas regularidades. Es así como la información obtenida del mundo externo se convierte en percepciones, hipótesis, teorías, leyes, objetos, procesos, categorizaciones o clasificaciones taxonómicas, es decir, en mapas que tratan de reflejar el orden del mundo externo, del territorio. La necesidad de anticipar las regularidades presentes en el mundo externo es antigua, apareció junto a la vida. La supervivencia de un ser vivo depende de explotar los recursos presentes en el mundo externo y para ello utiliza mapas que reflejan las regularidades del territorio. Utilizamos mapas cuando percibimos un tomate en la ensalada o cuando un mejorador utiliza la genética mendeliana para crear nuevas variedades comerciales de tomate. Por supuesto, estos mapas no se han creado con el mismo rigor, unos son percepciones cotidianas y los otros son conocimiento científico, pero el principio subyacente es el mismo: existe un sistema, el conocedor, que ha utilizado una información para generar un mapa sobre la estructura del territorio. Estos modelos nos permiten predecir, hasta cierto punto, qué ocurrirá si llevamos a cabo una acción u otra. Es decir, posibilitan que actuemos con eficiencia, que nos movamos con éxito por el territorio. Somos lo que Dennett llamaba seres popperianos. El principal objetivo de los mapas es eliminar la sorpresa. El investigador trata de conocer el mundo externo lo suficiente como para anticipar lo que espera ver en el futuro. El mapa absoluto sería aquel que le permitiese anticipar con precisión completa qué información recibirá en cada momento. Esos modelos tendrían una adecuación empírica absoluta. Esto, como veremos, no implicaría tener un conocimiento metafísicamente absoluto y, además, en general, este es un objetivo inalcanzable, de modo que los investigadores se limitan a ir actualizando sus mapas basándose en la diferencia entre sus expectativas y lo percibido, es decir, en la sorpresa. La distinción entre mapa y territorio, entre modelo y mundo externo es fundamental, pero es fácil caer en el error de ignorarla. Mis ojos parecen mostrarme a la gata que duerme junto a mí tal cual es, parecen aprehender la realidad en su totalidad. Sin embargo, si queremos entender el conocimiento es necesario analizar con más detalle el proceso que me lleva a ver a mi gata. Lo que ha hecho mi sistema visual es crear una percepción teniendo en cuenta la información recibida desde el mundo externo. Además, para conseguirlo ha utilizado una metodología que, en este caso, se haya implícita en la propia estructura del sistema visual. La percepción presente en mi mente no es el patrón real que hay en el mundo externo, la gata que veo, no es la realidad en sí, sino una representación construida a partir de algunas de las regularidades presentes en la información que me ha llegado, que mi sistema visual ha considerado relevantes y que mi mente ha etiquetado automáticamente como “mi gata”. Por supuesto, esto no implica que lo que veo no tenga relación con el mundo externo, pero sí es importante recordar un par de detalles. En primer lugar, el mapa no refleja la estructura completa del territorio. De hecho, la metodología que hemos utilizado para generarlo, en este caso la estructura del sistema visual, no trata de obtener todos los detalles, sino, tan sólo aquellos que nos son relevantes. Y esto nos lleva al segundo punto: el mapa depende en parte del cartógrafo y en parte del territorio. El mapa podría ser más o menos detallado, podría contener más o menos errores e, incluso en algunos casos, podría ser una completa alucinación. No hay un absoluto filosófico que garantice el conocimiento del mundo externo: el conocimiento siempre será falible y potencialmente mejorable. Siempre cabe la posibilidad de que el mapa sea sólo aproximado o de que sea, simplemente, erróneo. Esto no es una mera posibilidad teórica, en el pasado nos hemos equivocado en incontables ocasiones y, por lo tanto, tendríamos que ser sistemáticos en nuestras investigaciones y cautos en nuestras conclusiones. Me rompe el corazón que la gente actúe como si el número de contagios detectados y registrados en una población fuese el número de casos real. En demasiados casos no comprender la distinción entre mapa y territorio produce muerte y dolor. El concepto de mapa que estoy planteando está, hasta cierto punto, relacionado con el concepto de conocimiento, pero prefiero no utilizar el mismo término para evitar confusiones. En este texto estoy asumiendo que mapa es cualquier modelo, explícito o implícito, que nos permite anticipar, al menos aproximadamente, nuevas informaciones provenientes del mundo externo. Esta es una definición metafísicamente mucho más modesta que la del conocimiento clásico, que, recordemos, exigía verdad. Esta definición no requiere de certeza absoluta y la justificación y la verdad se sustituyen por una relativa falta de sorpresa. Además, es una definición mucho más general que la de conocimiento clásico ya que engloba cualquier regularidad que un sistema conocedor genere sobre otro sistema conocido, por ejemplo: las percepciones generadas por los sistemas perceptuales, el saber del herrero que forja una espada utilizando las técnicas que le transmitió su maestro, el conocimiento científico e, incluso, las destrezas implícitas presentes en seres sin vida mental alguna. Soy consciente de que el ánimo de esta definición es muy distinto al que la definición platónica clásica, pero creo que las analogías entre los distintos ejemplos que he planteado son lo suficientemente amplias como para que sea útil considerar conjuntamente el conocimiento implícito y explicito, aunque también reconozco que las diferencias entre ambos son notables. Además, tampoco quisiera transmitir la idea de que la ciencia es equivalente a la percepción o al conocimiento cotidiano. El conocimiento científico es mayoritariamente explícito, justificado, mucho más sistemático y, además, los científicos hacen autocrítica y reflexionan sobre las metodologías que utilizan para conseguir que sea cada vez más riguroso. 26.2 Hija del escepticismo y el empirismo La ciencia moderna es rabiosamente empírica y moderadamente escéptica. El éxito científico no se asienta sobre la confianza, sino sobre la suspicacia. El ideal científico desconfía de las evidencias, duda del testimonio y sólo considera las evidencias públicas que, además, es preferible que sean reproducibles. Es decir, descarta las evidencias más endebles y acepta sólo las observaciones más sólidas, y aun así las considera falibles y revisables. Desde la revolución científica los instrumentos se han convertido en un modo de estandarizar y materializar algunas de las metodologías observacionales. Gracias a ellos hemos alcanzado una mayor intersubjetividad, un mejor acuerdo entre observadores, y, además, con el tiempo, el análisis de las fortalezas y limitaciones de cada equipo ha permitido que la observación instrumental sea cada vez más precisa. Los escépticos de la antigüedad discutieron hasta la extenuación sobre el problema de que el agua que a un observador le parecía tibia a otro le causaba escalofríos. Sin embargo, gracias a la invención del termómetro, que mide algo mucho más concreto que lo que perciben los sensores de calor de nuestra piel y que está más estandarizado, es fácil llegar a un acuerdo sobre si la temperatura es una u otra. Lo mismo sucedió, por ejemplo, con el tiempo. La sensación subjetiva de paso del tiempo puede ser muy variable, pero los relojes se estandarizan y se sincronizan para llegar a un acuerdo. Además, los instrumentos son prótesis que nos permiten acceder a rangos empíricos previamente inaccesibles para los seres humanos como la luz infrarroja, los mundos microscópicos o los neutrinos. La observación en condiciones controladas, el experimento, fue otro de los grandes avances modernos. Los experimentos permiten modificar distintas variables a nuestro antojo para observar su influencia en el sistema estudiado y, normalmente, son más reproducibles que las observaciones simples. Por desgracia, no todos los sistemas se prestan a estas manipulaciones controladas y esto dificulta su estudio. Por ejemplo, es técnicamente imposible crear estrellas y las consideraciones morales nos prohíben infectar con patógenos poblaciones humanas a sabiendas. Cuando no pueden obtenerse observaciones fiables o cuando éstas no son neutrales respecto a la hipótesis que estamos intentando contrastar perdemos nuestro mejor aliado en la generación de conocimiento científico. Esto suele ser un problema en las ciencias sociales, pero también en mi área, la genética de poblaciones, que depende de asunciones taxonómicas previas estos sesgos pueden hacer que erremos. Más adelante haré algunos comentarios sobre la necesidad de utilizar conocimiento previo y de los problemas que ello implica. El ideal científico moderno no sólo sospecha de las evidencias, sino que también desconfía de las capacidades de los investigadores y de las metodologías que emplean. Por este motivo exige rigor metodológico y justificaciones empíricas abundantes. El uso de la inferencia estadística es un ejemplo de esta desconfianza. Sabemos que el pensamiento intuitivo humano falla en estos aspectos y por eso se recomienda utilizar métodos de inferencia estadística explícitos y estandarizados. 26.3 No hay un método Es común que se caracterice a lo científico como aquel conocimiento que ha sido generado utilizando el método científico. En la mente de muchas personas éste sería un método que, de ser seguido, garantizaría conocimiento objetivo. Sin embargo, creer en la existencia del método científico es un profundo error que conlleva trágicas consecuencias sociales. No existe un algoritmo claramente definido que nos indique el camino a seguir para crear conocimiento científico. Existen recomendaciones generales que podemos tomar como guía en algunas situaciones y metodologías que podemos utilizar en distintas áreas científicas, pero hemos de pensar en ellas como en las herramientas del taller del artesano. No son tan detalladas como para crear un algoritmo óptimo con el que programar a un robot. El investigador ha de elegir qué metodología utilizar, cuánto valorar cada evidencia o cómo modificar una hipótesis cuando las observaciones no son las esperadas. La creación de conocimiento científico requiere oficio y esto implica, claro está, un cierto margen de libertad por parte del investigador y, por lo tanto, una gran responsabilidad. Los valores de los científicos son relevantes en el proceso. La falta de método no implica que la ciencia sea completamente irracional o que carezca de estándares. Ningún científico defenderá nunca que uno más uno es tres o que las bolas de plomo flotan a un metro sobre la superficie terrestre. Sin embargo, estos estándares no llegan a constituir un algoritmo detallado. Lo que sí podemos hacer es dividir la búsqueda de conocimiento científico en distintos procedimientos que, tal vez, puedan servirnos como guías para el análisis de la práctica científica. Confieso que me tienta usar el término fase de investigación, en vez de procedimiento, pero no quiero dar la impresión de estar proponiendo una serie de fases que habrían de darse necesariamente en un orden definido. 26.4 Obtención de evidencias El conocimiento del mundo externo ha de ser eminentemente empírico. Si queremos elaborar mapas del territorio, no queda más remedio que echar mano de la información proveniente del territorio. Esta, además de ser obvia, en el pasado ha demostrado ser la aproximación más fructífera; cuanto más cercanas se han mantenido las investigaciones a los datos empíricos más éxito han solido tener. Los intentos más racionalistas tienden a quedarse atascados en un marasmo de ideas que, aunque pueden parecer razonables, suelen fracasar cuando tratamos de usarlas como mapas. Esta defensa del papel preponderante de las evidencias empíricas no implica que yo defienda un inductivismo estricto. Las hipótesis científicas a veces se generan a partir de las observaciones, pero esto no siempre es así. Además, la relación entre observación y teoría puede ser muy sutil. Observamos que la Tierra parece inmóvil y que el Sol parece girar sobre nuestras cabezas, pero no es eso lo que defienden nuestras teorías. Además, en muchos casos la búsqueda de evidencias está guiada por las hipótesis previas. Por ejemplo, al buscar nuevas evidencias conviene, muy especialmente, no olvidarse de tratar de hacer observaciones que pudiesen, potencialmente, falsar nuestra hipótesis. Buscar evidencias que nos permitan distinguir entre varias hipótesis alternativas, es decir, que puedan favorecer en diferente grado a unas frente a otras es otra recomendación común. Imaginemos que disponemos de dos hipótesis, una se comporta, matemáticamente como una recta, mientras que la otra es parabólica. Puede que en el rango empírico que hemos explorado ambas hipótesis hagan predicciones muy similares y que para distinguirlas nos interese buscar nuevas evidencias en regiones en las que las predicciones de ambas hipótesis sean bastante distintas. También es habitual utilizar el conocimiento previo o, incluso, las propias hipótesis para descartar observaciones erróneas. Por ejemplo, puede que hayamos hecho cientos de observaciones, que todas se alineen, aproximadamente, en una recta, pero que una, que se hizo cuando hubo un pico en la corriente que alimentaba al aparato de medida, sea muy superior a las demás. En ese caso sería razonable eliminar esa medida del análisis por considerarla errónea. Sin embargo, hemos de tener mucho cuidado con este tipo de procedimientos puesto que podrían producir sesgos. Por ejemplo, podríamos acabar descartando observaciones robustas simplemente porque no encajan en nuestra hipótesis. Es una mala práctica científica no mostrar todas las evidencias, aunque, en la práctica, las que consideremos completamente erróneas no sean incluidas en los artículos para no distraer al lector con una avalancha de datos espurios. Esto puede ser más o menos justificable en muchos casos, pero puede llegar a convertirse en una mala práctica muy fácilmente. Esta dependencia de la búsqueda de evidencias de nuestro conocimiento previo es capaz de sesgar nuestra mirada de formas muy sutiles. Por ejemplo, podríamos someter a un mayor escrutinio a las evidencias contrarias a nuestra hipótesis preferida. Este sesgo, llevado al extremo, convertirá nuestras ideas previas en una cárcel de la que difícilmente podríamos escapar. Este es el problema que trataba de evitar la recomendación inductivista de buscar evidencias sin tener en cuenta nuestras hipótesis. En algunos casos esto tiene mucho sentido. El problema es que no siempre es fácil hacer observaciones sin hipótesis previa. Es común que las observaciones científicas sean caras y que, por lo tanto, hayamos de elegir con sumo cuidado cuáles queremos realizar. Además, las expediciones de pesca, por ejemplo, los análisis genómicos generales, tienden a crear correlaciones espurias. Estos análisis sin hipótesis previas pueden resultar útiles para generar hipótesis, pero después habrá que buscar nuevas evidencias para contrastarlas. 26.5 Creación de hipótesis La creación de hipótesis es uno de los aspectos más difíciles de codificar. Existen aproximaciones muy diferentes y, además, en muchos el planteamiento de una hipótesis exitosa exige aunar creatividad, intuición y rigor. Como acabamos de comentar, una posibilidad, la preferida por los inductivistas, consiste en acaparar un gran número de observaciones y buscar en ellas regularidades utilizando heurísticas ampliativas que hayan demostrado en el pasado generar buenas hipótesis en situaciones análogas. El área del aprendizaje automático está explorando de forma muy satisfactoria estas aproximaciones. Como ejemplo podemos pensar en el caso de un conjunto de puntos en un plano cartesiano. Podemos utilizar un procedimiento de búsqueda de rectas para localizar la que mejor se ajuste a ellos. Otras veces se procede partiendo de un número limitado de evidencias y se hace uso de la asunción de que vivimos en un universo coherente. Einstein para desarrollar la relatividad general no utilizó evidencias que fuesen mucho más allá de las ya conocidas por Galileo. Por ejemplo, fue clave el hecho de que, si se ignora la resistencia del aire, dos objetos de distinto peso experimentan la misma aceleración al caer. A partir de ahí se esforzó por crear una teoría coherente. Einstein, desoyendo completamente la recomendación inductivista, no utilizó como principal herramienta de generación de hipótesis la inducción, sino la deducción. Y esto pudo hacerlo, como ya he dicho, porque asumía que las regularidades que caracterizan el territorio deben ser coherentes y que, por lo tanto, el mapa también habría de aspirar a serlo. Es esta coherencia la que hace que el uso de la lógica y las matemáticas sea tan fructífero en la generación de conocimiento. En realidad, ni siquiera es estrictamente necesario tener en cuenta evidencia alguna para generar nuevos mapas. Por ejemplo, la evolución biológica genera nuevas formas de enfrentarse al mundo externo, nuevos genomas, simplemente, introduciendo cambios al azar. Y los artesanos de la antigüedad crearon tecnologías imprescindibles para el mantenimiento de la civilización, básicamente, mediante prueba y error. Estos mecanismos, evidentemente, son muy ineficientes e incluso puede que haya conocimientos que, en la práctica, nunca puedan llegar a ser generados de este modo, como, por ejemplo, la fundición del aluminio, pero tampoco se puede negar su éxito. Es intuitivo pensar que las hipótesis tienen que derivarse de las evidencias, pero, en realidad esto no es lo fundamental. Lo que importa es que las hipótesis estén bien justificadas y contrastadas. Imagina que viene un profeta o unos extraterrestres y nos dan una hipótesis, si funciona, si es un buen mapa, poco importa cómo haya sido generada. Cuando se asume que lo relevante es el descubrimiento implícitamente se está aceptando que disponemos de un método capaz de extraer adecuadamente las regularidades presentes en las evidencias y, por lo tanto, que una hipótesis generada por ese método tenderá a ser un buen mapa. Pero la realidad es que lo que importa es que el mapa sea adecuado, no cuál es su origen. En la práctica, es común que el proceso de generación de hipótesis consista en una serie de iteraciones en las que los investigadores van proponiendo hipótesis, haciendo experimentos para contrastarlas y modificando esas hipótesis en función de los resultados obtenidos. A una versión de esta aproximación se le suele denominar método científico, pero no olvidemos que este proceso puede ser muy libre. 26.6 Justificación En ciencia las conclusiones deben justificarse, es decir, han de aportarse evidencias y argumentos en favor de las mismas. El conocimiento científico, como el filosófico, debe ser defendido racionalmente. Además, en el caso del conocimiento sobre el mundo externo, como ya hemos dicho, las justificaciones han de incluir una parte relevante de soporte empírico. En los artículos científicos esto se traduce en que las conclusiones, hasta cierto punto y teniendo en cuenta los límites impuestos por las inferencias ampliativas, han de estar soportadas por las evidencias. Es decir, el modelo propuesto tiene que describir adecuadamente las evidencias o, al menos, debe hacerlo hasta cierto punto. De nuevo, la evaluación de estas justificaciones, aunque incluya uso de estándares epistémicos, no puede ser codificada por un algoritmo. Por ejemplo, dado que los modelos que creamos en la mayor parte de los casos son aproximados, siempre podremos aducir que las evidencias que no cuadran son espurias. Esto es lo que hizo Galileo para justificar la obvia discrepancia entre sus observaciones sobre la caída de los cuerpos y sus modelos teóricos. El pisano adujo que, en un mundo ideal, sin rozamiento ni resistencia, las bolitas caerían siguiendo sus modelos. La justificación científica debe ser eminentemente empírica, pero la relación entre observación y teoría no es, en absoluto, trivial. Estas justificaciones, además, tienen que someterse al juicio del resto de la comunidad para que ésta pueda examinar las evidencias y las inferencias en busca de posibles errores, limitaciones o matizaciones. El conocimiento científico lo valida la comunidad y, en muchos casos, lo genera también la propia comunidad. El conocimiento y la capacidad cognitiva de los investigadores individuales es muy limitada y los problemas con los que tratamos, en la mayoría de los casos, nos superan. En una comunidad comprometida, en mayor o menor grado, con el ideal del diálogo racional la exigencia de justificación permite avanzar ya que, entre todos, se fortalecen los puntos débiles de las evidencias, las hipótesis o las justificaciones. Por otro lado, conviene recordar que la justificación, de ser correcta, no podrá garantizar más que el modelo propuesto describe aproximadamente las regularidades que hemos encontrado en las evidencias. 26.7 Contrastación La contrastación consiste en comprobar el modelo con evidencias distintas a las que se utilizaron para elaborar o justificar la hipótesis originalmente. Por ejemplo, si hemos hecho un ajuste lineal para obtener una recta a partir de unos puntos concretos situados en un plano cartesiano, ¿los nuevos conjuntos de puntos se siguen pareciendo a la recta? Lo que tratamos de comprobar con la contrastación es si el modelo propuesto inicialmente tiene utilidad explicativa y predictiva real en el territorio. ¿Por qué se requiere una contrastación con evidencias distintas a las utilizadas durante la justificación? El problema es que la probabilidad de que un modelo justificado resulte ser un mal mapa cuando no se contrasta independientemente es elevada. Recordemos que las evidencias iniciales podrían haber sido parciales o erróneas y la justificación inicial, a pesar de ser razonable, podría ser errónea. Esta es una de las mayores aportaciones de Galileo: contrasta tus hipótesis con nuevas evidencias. Además, incluso aunque las evidencias iniciales fuesen correctas, representativas del fenómeno y la justificación correcta, nuestro modelo podría ser un mal mapa puesto que podría estar sobreajustado. Esta es una limitación fundamental de la generación del conocimiento sobre el mundo externo relacionada con el salto ampliativo. Un modelo está sobreajustado cuando refleja regularidades espurias que se encontraban en las evidencias originales, pero que no se corresponden con las regularidades presentes en general en el fenómeno que estamos estudiando. Cuando sucede esto el modelo resume muy bien los datos originales, pero no sirve como mapa. Cuando se generan los modelos utilizando inferencias estadísticas se trata de reducir el riesgo de sobreajuste teniendo en cuenta el incremento en el ajuste de los modelos a medida que estos se van haciendo más complejos. Lo que se trata de impedir es que los modelos lleguen a reflejar regularidades espurias a base de ir introduciendo pequeños ajustes adicionales durante su creación. El problema de esta aproximación es que, aunque, en la práctica, funciona en muchas ocasiones, no deja de ser un criterio superempírico y, por lo tanto, es mejor contrastar el modelo generado con nuevas evidencias para comprobar que, efectivamente, es un mapa adecuado. El modo más común de contrastación consiste en utilizar las conclusiones previas en el marco de nuevos estudios. Por ejemplo, si un grupo ha publicado que un gen concreto controla el tamaño del fruto, otros investigadores podrían tratar de utilizar ese gen para reducir el tamaño de los frutos en una variedad comercial concreta. El éxito de este nuevo desarrollo tecnológico sería una contrastación de las conclusiones del primer estudio. En otros casos la contrastación es más directa. Por ejemplo, cuando se buscan genes por asociación en una población concreta, como los genes de susceptibilidad a la covid19 en la población europea, los resultados pueden contrastarse comprobando la asociación de los genes encontrados en otras poblaciones. También pueden utilizarse los mapas en regiones empíricas distintas a las cubiertas por las evidencias iniciales. Las extrapolaciones exitosas son una garantía de que la estructura de nuestro mapa está reflejando, al menos en parte, algunos aspectos de las regularidades presentes en los patrones reales. Esto es, por ejemplo, lo que se hizo al contrastar la relatividad general con la observación de la curvatura de la luz por los campos gravitatorios o de las ondas gravitacionales. Ninguno de estos fenómenos se encontraba entre las evidencias que se utilizaron para justificar la teoría inicialmente. Por último, una excelente vía de contrastación es hacer predicciones y comprobar si se cumplen. Por desgracia, no todos los problemas se prestan a hacer predicciones. Por ejemplo, es difícil predecir el comportamiento exacto de los sistemas complejos. Durante la pandemia de la covid19 se ha demostrado, en repetidas ocasiones que los modelos epidemiológicos van a rebufo de la realidad. Hay demasiados factores cambiantes e incontrolables como: las mutaciones del propio virus, la actitud de la población, que está influida por la percepción del riesgo, o la instauración de distintas medidas gubernamentales. Esto no quiere decir que los modelos generados sean completamente inútiles. Incluso aunque no seamos capaces de predecir cuál será el número de casos con un mes de antelación, es útil saber que el uso de mascarillas y la ventilación de los espacios cerrados son medidas útiles y esto es algo que hemos aprendido, al menos en parte, gracias a la epidemiología. Al contrastar estamos comprobando si el mapa generado anticipa realmente la respuesta del territorio. La contrastación está relacionada con la exigencia de verdad en la definición clásica de conocimiento. Estamos comprobando que el mapa, al menos parcialmente, se corresponde con el territorio. Podríamos decir que un artículo científico es buena ciencia si está bien justificado, pero sus conclusiones sólo merecen ser consideradas como parcialmente verdaderas si han sido contrastadas. Podemos pensar también en lo justificado como lo razonable y lo contrastado como lo verdadero. Aunque no tenemos un acceso directo a las regularidades del mundo externo, al logos, al menos, podemos ir haciendo contrastaciones para ir comprobando si nuestros modelos parecen ser mapas útiles. En el límite aspiramos a disponer de mapas que nos permitan dejar de ser sorprendidos por el territorio. En la contrastación reside una de las claves del éxito operacional de la ciencia. Si eliminamos los mapas que no funcionan, iremos seleccionando, gracias a esta purga empírica, mapas cada vez más adecuados. Este era el secreto, por ejemplo, de la evolución biológica y de la evolución de las tecnologías antiguas. Evidentemente esos modos de generación de mapas no son sistemáticos y, por lo tanto, son mucho más ineficientes que la aproximación científica, pero aún así funcionan porque si se insiste en eliminar la paja lo que queda será el grano. En la medida en la que la contrastación pueda hacerse con evidencias abundantes y que sean neutrales respecto a los modelos evaluados la ciencia podrá avanzar fácilmente. En realidad, la contrastación no está claramente separada de la justificación, pero aun así creo que es interesante tener en cuenta esta distinción en la práctica científica. Por ejemplo, puede que una hipótesis haya sido ya contrastada antes de ser publicada por primera vez. La diferencia entre justificación y contrastación es útil, pero no es nítida. En cualquier caso, ni la justificación ni la contrastación serán garantías absolutas, pero lo que sí podemos ir haciendo gradualmente es aumentar o disminuir nuestro grado de confianza en que nuestras hipótesis son buenos mapas del territorio, es decir, que pueden servirnos para anticipar el comportamiento de los sistemas o fenómenos estudiados. Es muy importante ser conscientes de qué hipótesis han sido más o menos contrastadas. Esta es, al fin y al cabo, una de las principales lecciones de la inferencia bayesiana. De modo que podríamos pensar en la contrastación como una heurística derivada del marco bayesiano. O, alternativamente, podríamos pensar en ella de un modo pragmático: es verdad aquello que se ha comprobado que funciona. 26.8 Elección entre hipótesis Los principales motivos para elegir entre hipótesis deberían ser epistémicos: evidencias empíricas y coherencia lógica. Como regla general, es obvio que son más deseables las hipótesis que describen con una mayor precisión las evidencias empíricas y que son coherentes con el resto del conocimiento. Lo habitual es que, si las hipótesis hacen predicciones precisas y las observaciones son neutrales respecto a esas hipótesis, la elección entre teorías no sea demasiado conflictiva. Podríamos hacer esta elección aplicando el estándar racional bayesiano. En este caso terminaríamos asignando grados de confianza a cada una de las hipótesis en liza en función de las evidencias disponibles y de nuestras probabilidades a priori. Sin embargo, este es un estándar, muy exigente computacionalmente y que requiere hipótesis muy precisas por lo que, en muchos casos, es difícil de aplicar y, además, en la práctica, hay muchas cuestiones que la inferencia bayesiana no soluciona. Por otro lado, aunque los motivos empíricos deben prevalecer, en la práctica otros motivos superempíricos, como la sencillez o el poder explicativo, es decir, la relación entre la cantidad de aspectos explicados y el número de supuestos requeridos por la hipótesis, también pueden ser tenidos en cuenta. Sin embargo, la evaluación de las hipótesis no siempre es trivial. Por ejemplo, una hipótesis no tiene por qué ser falsada sólo por que un dato no cuadre: el dato podría ser erróneo o la predicción podría ser una equivocación incluso aunque la hipótesis fuese correcta. Además, la mayoría de nuestros modelos sólo aspiran a ser aproximados, por lo que no esperamos que su adecuación empírica sea completa. En algunas ocasiones distintos investigadores pueden llegar a valorar las bondades y las limitaciones de las distintas teorías de distinto modo, así que la comparación entre hipótesis no siempre tiene por qué ser estrictamente objetiva. Sin embargo, es importante reconocer que cuando los motivos empíricos son claros las discusiones acaban zanjándose, sólo cuando no lo son es común que no se alcancen consensos. Es en estos casos menos claros en los que los factores psicológicos y sociales pueden llegar a hacerse más relevantes; es cuando las evidencias no son suficientes cuando los motivos subjetivos y contingentes suelen hacerse más patentes. Además, recordemos que tenemos que ser especialmente cautos cuando las observaciones no sean neutras respecto a las hipótesis evaluadas. Cuando las conclusiones todavía no son claras, cuando los expertos todavía están discutiendo entre ellos, lo recomendable es que los no expertos reservemos el juicio. En cualquier caso, aunque la evaluación de las hipótesis no siempre tiene por qué ser trivial, tampoco hemos de quedarnos con la idea de que siempre será subjetiva. A veces las teorías sí se falsan con claridad. Por ejemplo, cuando Galileo estableció que Venus tenía fases incompatibles con el modelo ptolemaico y la comunidad astronómica validó la observación, el modelo ptolemaico, simplemente, se descartó. El ideal de objetividad basado en razones epistémicas es alcanzable, pero es importante recordar que no todas las conclusiones de todos los estudios científicos alcanzan este grado de solidez. Además, aunque no es posible hacer recomendaciones absolutas, sí es posible considerar algunas guías generales. Por ejemplo, la falsabilidad es una buena idea. El investigador racional ha de huir de aquellas hipótesis vagas capaces de explicarlo todo o de aquellas que no puedan ser afectadas por las evidencias empíricas. Si no puedes imaginar evidencias que puedan, al menos potencialmente, falsar tu hipótesis, no estás haciendo ciencia. Si no puedes plantear qué evidencias pueden distinguir dos hipótesis, no habrá forma de distinguirlas empíricamente. De hecho, es una muy buena recomendación plantearse antes de hacer un experimento qué esperarías observar si tu hipótesis fuese correcta y cuáles serían tus conclusiones si no se observase lo que esperas. Esto te evitará hacer un buen número de experimentos no concluyentes. Además, la falsación, al menos en primera aproximación, es otra buena idea. Si las observaciones contradicen una y otra vez tu hipótesis, habrías de abandonarla. Es lícito plantear hipótesis ad hoc para explicar una anomalía empírica, pero, sobre todo cuando estas modificaciones no implican predicciones empíricas adicionales, has de tener muy buenas razones para seguir manteniendo la hipótesis. Lo que por desgracia no podemos hacer es establecer un umbral objetivo que marque el límite entre la razón y la sinrazón. La inferencia bayesiana es una guía más general que el falsacionismo. Por ejemplo, nos permite concluir que si hacemos una observación y obtenemos el resultado esperado, debemos aumentar nuestra confianza en que nuestro mapa refleja correctamente esa región del territorio. Además, el bayesianismo nos recuerda que para ser racionales hemos de evaluar todas las evidencias, tanto las favorables a nuestra hipótesis como las contrarias y que, también hemos de sopesar todas las hipótesis y no sólo aquella que preferimos. Por otro lado, cuando buscamos nuevas evidencias es muy importante no tratar de encontrar sólo aquellos datos que confirmarían nuestra hipótesis, sino, muy especialmente, aquellos que podrían ser capaces de falsarla. 26.9 Iteración El proceso científico es iterativo: se van obteniendo evidencias, se van evaluando las hipótesis y, si todo va bien, poco a poco, vamos obteniendo mapas cada vez más adecuados. Sin embargo, no hemos de pensar que estos procedimientos o fases que acabo de describir someramente han de ocurrir en un orden fijo. En la práctica suelen alternarse de formas complejas. Por ejemplo, es común que planteemos observaciones para validar o falsar nuestras hipótesis y que los resultados obtenidos sean tan distintos a los esperados que nos obliguen a crear hipótesis completamente nuevas. En otras ocasiones, sin embargo, puede que la mayoría de las evidencias empiecen a cuadrar y que los ciclos se limiten a acumular nuevas observaciones en favor de la hipótesis. 26.10 Progreso científico Las teorías de las áreas de conocimiento que merecen plenamente el calificativo de científicas progresan paulatinamente en su adecuación empírica y en su poder explicativo hasta conseguir generar hipótesis que dan cuenta de las evidencias empíricas disponibles. El territorio cada vez nos sorprende menos y los mapas demuestran ser herramientas útiles para la acción sobre el mundo externo. También se da un progreso en la acumulación de fenómenos que han de ser explicados por cualquier teoría futura. Por ejemplo, cualquier física futura deberá dar cuenta de por qué dos objetos de distinta masa sufren la misma aceleración gravitatoria. A esto hay que añadir los nuevos fenómenos reproducibles que se van creando. Los fenómenos eléctricos que los físicos aprendieron a generar a lo largo del siglo XIX o los láseres del XX quedarán para siempre. Los estándares de justificación también progresan. En matemáticas, que no es una ciencia puesto que no estudia el mundo externo, sino una disciplina formal que es utilizada como herramienta por las ciencias, el cambio metodológico ha sido mínimo. El estándar de justificación en matemáticas es el deductivo y aunque las deducciones de Euclides, o incluso las de Newton, eran menos rigurosas que las actuales, las diferencias son pequeñas. Sin embargo, en ciencia los cambios metodológicos y las recomendaciones sobre como justificar los resultados han sido enormes. Aristóteles recomendaba hacer justificaciones estrictamente deductivas en las que, partiendo de premisas generales sobre el funcionamiento del mundo natural, había que justificar las conclusiones utilizando silogismos. Arquímedes aceptó la recomendación deductiva aristotélica, pero la hizo más general al admitir la cuantificación y las matemáticas. Este fue el estándar que Galileo, a principios de la revolución científica todavía trató de defender, con pequeñas modificaciones relativas a la contrastación, en algunos de sus trabajos. Pero las cosas cambiaron durante la revolución y el resultado final fue la adopción de un estándar de justificación mucho más inductivo: las conclusiones tenían que estar soportadas por observaciones concretas, no por reglas generales. Este es un cambio que permitió acoger de un modo más natural aquellos trabajos basados en la observación y la experimentación que en la teorización. Desde entonces los métodos de inferencia y justificación han seguido, y siguen, refinándose. Ahora, por ejemplo, se usan mucho más las inferencias estadísticas. También han progresado las técnicas instrumentales y las metodologías de observación, experimentación y descubrimiento que utilizan los científicos. La mayoría de las observaciones de los científicos del siglo XVIII les parecerían a los científicos de hoy muy rudimentarias y poco rigurosas. En la actualidad los protocolos utilizados en los laboratorios suelen ser muy detallados y los instrumentos son mucho más precisos y estandarizados. En el fondo, las metodologías científicas parten originalmente de las heurísticas que utilizamos en el pensamiento cotidiano. La evolución nos equipó con sistemas perceptuales y cognitivos capaces de generar conocimiento sobre el mundo externo y las metodologías científicas no son más que una sistematización de esas herramientas básicas. Las bases sobre las que se asienta la generación de conocimiento científico son tan elementales que resulta difícil rechazarlas: nuestros sentidos crean representaciones que tienen una relación estrecha con la estructura del mundo externo y cualquier sistema lógico debe aspirar a ser coherente. La ciencia, simplemente hace uso de sistemas epistémicos que sistematizan estos principios. Las heurísticas de inferencia lógica sufrieron una evolución similar. Nuestros razonamientos intuitivos, que en muchos casos no son conscientes, funcionan bastante bien en muchas situaciones cotidianas y han generado una gran cantidad de conocimiento, pero también tienen limitaciones importantes. Estos problemas son especialmente relevantes cuando tratamos de estudiar situaciones a las que no se enfrentaron nuestros antepasados o cuando las evidencias entran en conflicto con ideas muy queridas por nosotros o por el grupo humano con el que nos identificamos. La lógica y las matemáticas parten de intuiciones muy elementales, como que una proposición no puede ser verdadera y falsa el mismo tiempo, y sobre ellas construyen, exigiendo coherencia, edificios que superan, con mucho, nuestras limitaciones intuitivas. Es decir, el punto de partida es intuitivo, pero el esfuerzo de sistematización nos eleva a regiones inalcanzables para alguien sin formación. El problema de esta aproximación es que requiere un gran esfuerzo durante su aprendizaje y durante su uso. La ciencia, la lógica o las matemáticas no son difíciles porque partan de fundamentos extraños, sino porque gracias a la exigencia de coherencia, alcanzan una sistematización y unos resultados que terminan siendo difíciles de aprender y utilizar. La ciencia, al fin y al cabo, no es más que conocimiento sobre el mundo externo obtenido sistemáticamente. Cuando se rechaza la ciencia por principio se rechaza el conocimiento. Es legítimo criticar tal o cuál hipótesis defendida por algún experto, pero, si queremos ser racionales, esto sólo podrá hacerse justificadamente, caso por caso y asumiendo que necesitamos un nivel de conocimiento elevado. Es decir, el único modo racional de criticar el consenso de los expertos es convertirse en uno. El científico no es el único tipo de conocimiento que surge por la sistematización de nuestras capacidades naturales. La sistematización de las herramientas artesanales junto a la incorporación del conocimiento científico convirtió a los artesanos en ingenieros y la sistematización de nuestras intuiciones morales o cognitivas creó la ética, la epistemología, la lógica y las matemáticas. Toda esta evolución metodológica científica es posible porque hay una guía meta-metodológica, una meta-regla: hemos de mantener aquellas metodologías que demuestran crear mapas que, en general, tienen más éxito durante la contrastación. Es decir, se eligen las metodologías que han creado buenos mapas en el pasado. Esto, de nuevo, es una recomendación general, no un algoritmo, pero conviene recordar que en ciencia no sólo progresan los mapas, sino, también, las herramientas del cartógrafo. Las herramientas a disposición del investigador cada vez son más precisas, poderosas, estandarizadas y sistemáticas. Kuhn defendió que el cambio metodológico estaba asociado a las grandes revoluciones teóricas, pero las evidencias históricas son abundantes e indican que, en general, los cambios metodológicos son independientes de los teóricos y que, además, son graduales. El progreso en las estructuras teóricas también es mayoritariamente gradual y esto se debe principalmente a que las nuevas teorías han de acomodar la mayoría de los fenómenos que ya justificaban las antiguas. Podemos pensar en la estructura como una red teórica que se ancla a distintos puntos del mundo externo mediante la información empírica. La recta ajustada a unos puntos es un buen ejemplo. Este anclaje empírico genera en las estructuras teóricas una rigidez en las regiones mejor exploradas empíricamente. Es decir, cualquier teoría futura tendrá una estructura lógica o matemática similar en las regiones del territorio de las que disponemos de más evidencias. A medida que vamos acumulando más fenómenos, la holgura que se puede permitir a las teorías en esas regiones es cada vez menor. En algunas ciencias el cambio ontológico, es decir, el cambio en las entidades que pueblan sus teorías también suele ser pequeño. Pero, como veremos, resulta más problemático encontrar una dirección ontológica clara en las teorías físicas fundamentales. Durante un tiempo la luz pareció estar formada por partículas, luego por ondas y finalmente por algo muy extraño cuya metafísica todavía no ha sido consensuada. Sin embargo, aunque la decimonónica electrodinámica de Maxwell tenía una metafísica radicalmente distinta a la electrodinámica del modelo estándar actual, sus predicciones en los rangos empíricos conocidos en los tiempos de Maxwell son muy similares. La metafísica planteada por dos teorías puede ser muy distinta incluso aunque su adecuación empírica o sus estructuras lógicas o matemáticas sean muy similares. De hecho, como mencionamos para el caso newtoniano, una misma estructura matemática puede ser interpretada de formas muy distintas. 26.11 Metafísica La incomprensión de la relación entre el progreso gradual de la adecuación empírica y de las estructuras y el posible cambio radical de las ontologías tiene consecuencias sociales negativas puesto que genera una inmerecida desconfianza en la ciencia. Por ejemplo, suele pensarse, de algún modo más o menos vago, que Einstein demostró que las ideas newtonianas eran equivocadas cuando, en realidad, la relatividad surgió como un refinamiento de la mecánica newtoniana y, de hecho, las predicciones de ambas teorías en los rangos empíricos explorados hasta el siglo XIX eran casi idénticas. Lo que cambió más profundamente fue la metafísica asociada a las estructuras teóricas. No es que este cambio no sea relevante a nivel filosófico, al fin y al cabo, uno de los objetivos de los científicos es comprender la realidad y, por lo tanto, el debate sobre la naturaleza última de los patrones del cosmos es importante. Pero es urgente transmitir a la sociedad que otro de los objetivos del científico es construir teorías útiles, mapas adecuados, y ese es un objetivo que progresa mucho más suavemente que el de la elucidación de las ontologías de la física fundamental. Es muy importante distinguir entre adecuación empírica y metafísica. Una teoría es empíricamente adecuada cuando describe correctamente las partes observables del mundo externo. Las hipótesis se aceptan o se rechazan considerando, principalmente, su adecuación empírica. Sin embargo, la metafísica propuesta por la teoría es el conjunto de entidades o procesos que postula. Dos teorías pueden hablar de entidades muy distintas y, aún así, ambas podrían tener una adecuación similar. De hecho, la parte de la teoría que influye en su adecuación empírica es su estructura lógica o matemática y no las etiquetas ontológicas que asignamos a esa estructura. Podemos asignar ontologías distintas a una misma teoría y también podemos tener estructuras diferentes, pero con implicaciones empíricas muy similares. Además, también sería positivo que la sociedad comprendiese que una hipótesis científica puede fallar de dos formas completamente distintas y que no deben ser confundidas. 1) Como falló la mecánica newtoniana, que fue reemplazada a nivel fundamental por otras teorías que refinaron su adecuación empírica. 2) Como una hipótesis completamente errónea, es decir, como una idea que nunca fue empíricamente adecuada. Esta segunda hipótesis nunca fue un mapa bien contrastado, no fue más que un error, una mera alucinación. Es un error muy grave confundir ambos tipos de error. Que la teoría newtoniana se reemplazase no implica que la ciencia fallase, sino que sus conclusiones pueden refinarse. La mecánica newtoniana fue un gran éxito. La NASA todavía envía cohetes utilizando la mecánica newtoniana porque sigue siendo empíricamente adecuada. El segundo caso también es común en ciencia, pero no suele serlo en las hipótesis que gozan de un amplio consenso. Durante la crisis del coronavirus, por ejemplo, hemos visto numerosas conclusiones publicadas en artículos relevantes que no han resistido los intentos de contrastación más mínimos. El uso de la hidroxicloroquina para la covid19 fue un error, una alucinación, pero, aunque se consideró seriamente, nunca alcanzó un mínimo consenso entre los expertos. Así es como debe funcionar la ciencia, equivocarse no es tan grave, especialmente si el error es fruto de un intento honesto, lo trágico sería persistir en el error. Esta es, precisamente, una de las características que más diferencia a la ciencia de otras creencias mantenidas por la sociedad. Las comunidades científicas no suelen consensuar alucinaciones porque no suelen consensuar hipótesis sin una amplia contrastación. Pero volvamos a la metafísica. Tanto las teorías científicas como la mayoría de nuestras creencias cotidianas tienen una relación estrecha con la realidad. Lo que no es tan sencillo es precisar en qué consiste esa relación. En primer lugar, acepto como tesis que el mundo externo es. Es decir, existe un mundo externo y mi objetivo, tanto cotidiano como científico, es generar mapas que reflejen las regularidades existentes en ese mundo externo para poder anticipar su respuesta, pero los mapas no son el mundo externo. Sólo el territorio es, los mapas son meros reflejos de esa realidad. Podemos averiguar aspectos sobre las regularidades presentes en el mundo externo gracias a que podemos interaccionar con él y, muy especialmente, a que somos capaces de obtener información del mismo. A esta tesis podríamos denominarla verificacionismo matizado. En principio, podemos aspirar a estudiar cualquier patrón que esté conectado informacionalmente con nosotros, aunque esto no implica que vayamos a conseguir, necesariamente, obtener un buen mapa. Hay problemas que son demasiado complicados. En cualquier caso, esta tesis tiene otra consecuencia negativa obvia: si existen fenómenos o entidades que no están conectadas informacionalmente, directa o indirectamente, con nosotros no pueden ser estudiadas, incluso podría decirse que no forman parte de nuestro mundo. Podría defenderse que el empirista haría bien en olvidar el asalto a los cielos metafísicos ya que, si somos estrictos, a lo máximo que podemos aspirar es a detectar regularidades en la información obtenida del territorio. Sin embargo, creo que la actitud realista es irrenunciable en ciencia, la Tierra o se mueve o no se mueve. La ciencia también tiene por objeto comprender la naturaleza del cosmos y no sólo crear teorías útiles. Este, además, no es un problema limitado a la ciencia, estrictamente hablando es metafísicamente arriesgado afirmar que estoy observando a mi gata en el sillón ya que lo único que mi sistema visual ha podido hacer es buscar regularidades en la información recibida por mis ojos. Sin embargo, esto se ha traducido en una actualización de mis percepciones visuales y en un convencimiento claro de que mi gata está realmente en el sillón. Tal vez sería útil reflexionar sobre qué implica afirmar que mi gata está en el sillón o que la Tierra se mueve. Recordemos que el territorio es, pero el mapa es sólo una representación que nos permite anticipar lo que ocurrirá al obtener nueva información del territorio. De modo que no es trivial justificar la existencia de las entidades que pueblan nuestros mapas. Creo que la clave radica, por un lado, en que la estructura del mapa acaba reflejando, gracias a regularidades detectadas en la información recibida, las regularidades que caracterizan los patrones del mundo externo y, por otro, en que las regularidades presentes en la estructura del mapa son entendidas como entidades, procesos u objetos. El significado de un término ontológico depende en parte de la estructura lógica de nuestras creencias y en parte de la relación con el mundo externo. Dado que la estructura de las teorías está constreñida por la información empírica, podemos estar seguros de que cualquier teoría futura tendrá estructuras similares en los rangos empíricos mejor explorados y, por lo tanto, cualquier teoría futura podrá mantener las entidades que se corresponden con esas regiones de su estructura. Cualquier teoría biológica futura incluirá gatos y cualquier teoría química átomos y moléculas. Lo que es más dudoso es qué sucederá con las regiones más alejadas de la información empírica actual. Además, como los mapas no se derivan únicamente de la información empírica, sino que también podemos usar la exigencia de la coherencia lógica para llegar más allá, somos capaces de plantear teorías que hacen predicciones exitosas sobre regularidades que se encuentran en regiones inexploradas empíricamente. Por ejemplo, Mendeléyev hizo predicciones de nuevos elementos químicos haciendo interpolaciones en la estructura que había descubierto y Dirac, al unir las restricciones teóricas de la relatividad especial con las de la mecánica cuántica, predijo la existencia de algo que debía comportarse como un positrón. Además, las regularidades presentes en los patrones del mundo externo se dan en distintos niveles. Hay regularidades a nivel atómico, ecológico o galáctico. Al estudiar regiones previamente no exploradas empíricamente pueden aparecer regularidades completamente inesperadas, pero esto no implica, en absoluto, que las presentes en otras regiones o niveles vayan a ser afectadas. Puede que mañana los físicos descubran que el espaciotiempo puede derivarse de la estructura del espacio de Hilbert o puede que no lo hagan, pero de lo que podemos estar seguros es de que seguirá siendo útil hablar de espaciotiempo en teorías que tratan sobre la estructura del universo. 26.12 Hemos de utilizar conocimiento previo A pesar de que el progreso científico ha sido enorme, debemos tener muy en cuenta que el conocimiento del mundo externo está sujeto a unas limitaciones inevitables que, en algunos casos, tienen implicaciones prácticas importantes. Por otro lado, en muchos casos, incluso aunque dispongamos de las evidencias, las metodologías se aplican mal. No todos los artesanos ejercen su oficio con profesionalidad. De hecho, es casi imposible que el investigador individual no se equivoque una y otra vez. Es gracias al diálogo racional que esta limitación puede superarse parcialmente, pero, como veremos, existen en las comunidades humanas incentivos opuestos a esta racionalidad. Otro de los problemas fundamentales es que los mapas no se generan, ni deben generarse, teniendo en cuenta sólo la información empírica, sino que requieren bastante conocimiento previo y ese conocimiento podría ser erróneo y podría sesgar el resultado obtenido. El conocimiento previo es imprescindible, pero a veces resulta ser un prejuicio que nos condena a generar o mantener espejismos. Antes de empezar a estudiar filosofía de la ciencia puede que hubiese estado de acuerdo con la posición inductivista: el conocimiento debe generarse en dos fases, primero se obtienen las evidencias y más tarde se generan las conclusiones. Esta era la receta inductivista para evitar sesgos causados por nuestros prejuicios. El problema es que, por desgracia, este es un ideal ingenuo, que, aunque puede ser una guía general a tener en cuenta, estrictamente hablando es imposible de alcanzar; es imposible partir de una tabla rasa. También podríamos pensar que es irrelevante que la fase de descubrimiento sea algo confusa puesto que lo único que importa es la justificación y la contrastación y esto es cierto, pero sólo hasta cierto punto. No podemos hacer ciencia sin utilizar metodologías para hacer observaciones sistemáticas, para generar, al menos en algunos casos, hipótesis y para justificar nuestras conclusiones. Además, algunas de estas metodologías, por ejemplo, las basadas estrictamente en la lógica o las matemáticas se derivan de la asunción de coherencia del cosmos. Si aceptamos que los mapas han de ser coherentes la lógica y las matemáticas son normativas. Ningún científico puede aceptar que 1 más 1 son 3. Sin embargo, no es posible derivar las metodologías científicas sólo de la lógica y las matemáticas. En realidad, las metodologías que utilizamos son aquellas que han parecido funcionar mejor en el pasado, es decir, aquellas que nos pareció que nos ayudaban a crear mejores mapas. Y esto implica que las metodologías incluyen, explícita o implícitamente asunciones sobre el comportamiento del sistema estudiado y sobre los modos de evaluación. Por ejemplo, nuestro sistema visual asume implícitamente que estamos observando un mundo continuo tridimensional y eso le permite generar buenas representaciones en alta definición partiendo de una información limitada que por sí misma no sería suficiente para generar las representaciones que crea. Son estas asunciones las que le permiten dar saltos lógicos ampliativos con más garantías, pero también es cierto que cuando fallan aparecen las ilusiones ópticas. La situación en ciencia es completamente análoga. Por ejemplo, en genética de poblaciones utilizamos modelos estadísticos que asumen apareamientos al azar, cuando esta asunción se viola los resultados obtenidos pueden ser engañosos. Aunque tampoco es cierto que la violación de una asunción implique que la conclusión vaya a ser completamente falsa, recordemos que estamos buscando mapas aproximados. Por ejemplo, todo el campo de la reconstrucción filogenética se basa en asunciones que sabemos que, en el fondo, no se cumplen estrictamente y aún así tenemos confianza en que las reconstrucciones que hacemos recogen aspectos relevantes de los patrones históricos. Por otro lado, nuestro conocimiento está formado por redes y esto podemos aprovecharlo para plantear hipótesis a priori sobre fenómenos que no hemos estudiado empíricamente. Sean Carroll propone un ejemplo relacionado con la Luna. Antes de aterrizar en ella ya concedíamos una probabilidad muy alta a la hipótesis de que no estaba hecha de queso porque aplicábamos nuestro conocimiento sobre geología. Las teorías no están aisladas y esto, a su vez, conlleva el problema de que tampoco pueden ser evaluadas aisladamente. Por fortuna, no todo el conocimiento está relacionado con el resto en el mismo grado y esto es lo que nos permite hacer mejoras en distintas partes de la red. El filósofo positivista Otto Neurath propuso la magnífica analogía del conocimiento como un barco. Cada teoría, evidencia y metodología sería una madera del barco y nuestra misión consistiría en ir reemplazando y mejorando cada aspecto, pero sin olvidar que nos encontramos en alta mar y que, en ningún momento, podemos permitirnos el lujo de partir desde cero. En realidad, tener en cuenta los mapas y las metodologías obtenidas en el pasado, lo que los inductivistas podrían denominar nuestros prejuicios, nos ayuda a crear nuevos mapas y metodologías. Este es el modo en el que, como hemos explicado, funcionan nuestros sistemas perceptuales. Esto nos permite, por ejemplo, generar mejores mapas del territorio actual partiendo de una información limitada. El problema, claro está, es que las expectativas originales fuesen erróneas o que el territorio haya cambiado desde que se generaron. En la práctica sólo cuando dispongamos de evidencias abundantes y de buena calidad podremos limitar la influencia de la información previa y esta es una recomendación a tener en cuenta. Recordemos que el ideal científico moderno es escéptico y suspicaz así que tenderá a reservar el juicio cuando las evidencias sean limitadas. El problema se agrava cuando necesitamos tomar decisiones basándonos en información limitada. En ese caso lo racional es apoyarse más en las expectativas, pero siempre recordando que estamos corriendo un riesgo mayor; hay una fina línea entre usar el conocimiento previo y ser presa de nuestros prejuicios. 26.13 Las observaciones son limitadas, falibles y están cargadas de teoría Las evidencias empíricas también están sujetas a limitaciones fundamentales. Por ejemplo, son limitadas. En muchos casos no disponemos de evidencias que serían clave y, además, las que tenemos podrían ser erróneas. ¿Qué observaríamos si pudiésemos hacer experimentos detallados a nivel cuántico cerca de un agujero negro? No lo sabemos. ¿Cuáles son los eventos reales de infección y contagio que hacen que un virus se mueva por una comunidad? En la mayoría de los casos no tenemos información directa sobre ellas. En las ciencias sociales suele ser muy difícil disponer de la información relevante: ¿cuál es el grado de felicidad de la gente? De hecho, ¿qué significa esto de la felicidad y cómo podría cuantificarse? Es muy común que no dispongamos de las evidencias que habríamos de tener para detectar las regularidades más relevantes presentes en el territorio. En muchas ocasiones actuamos como el borracho que busca las llaves debajo de la farola. No las busca ahí porque las haya perdido en ese punto, sino porque ese es el único lugar iluminado y, por lo tanto, el sitio en el que más esperanzas tiene de encontrarlas. Además, también hemos de recordar que las observaciones son falibles, podrían ser, simplemente, erróneas o, al menos, matizables y que siempre hemos de estar abiertos a reevaluarlas. El conocimiento del mundo externo no se sostiene sobre una sólida base granítica, sino, más bien, sobre un lecho pantanoso en el que se van clavando pilares más o menos sólidos. Por ejemplo, podemos partir de percepciones elementales. Estas evidencias, a su vez, sostienen, gracias a la coherencia lógica, teorizaciones cada vez más alejadas de la percepción. En realidad, la distinción entre observación y teoría no es tan clara. Las órbitas keplerianas fueron teorías para Kepler, pero datos para Newton; en muchos casos las conclusiones de una investigación se convierten en los datos de la siguiente. Y, además, las leyes de newton terminaron contradiciendo parcialmente las observaciones keplerianas. Es fácil asumir que los datos se encuentran en el mundo externo como los champiñones y que nuestra labor consiste, simplemente, en recogerlos. Si hay un gato, veo un gato y eso es un dato, no merece la pena darle muchas más vueltas al asunto. Pero, la realidad es mucho más sutil. De hecho, como hemos visto, ni siquiera es tan trivial justificar la existencia del gato en el territorio, lo que es indudable es que yo percibo un gato, pero el territorio es mucho más complejo, el gato está formado por moléculas y átomos que yo no percibo. Las observaciones dependen, en cierto grado, de nuestro conocimiento previo y de las metodologías que las generan, están, por lo tanto, cargadas de teoría, esta es otra de las limitaciones fundamentales. Por ejemplo, un investigador ha de aprender a observar, esto le permite generar observaciones que una persona no entrenada no sería capaz de ver. Por ejemplo, un botánico volverá del campo con observaciones sobre la flora que yo nunca podré generar. Parte de esta carga teórica es debida a las categorizaciones que utilizamos. Creamos entidades y clases para reflejar la estructura que nos parece haber detectado en el territorio y nuestras observaciones hacen uso de estas categorías. Cuando en mi trabajo digo que el tomate cultivado tradicional europeo tiene una diversidad genética menor que el americano estoy haciendo uso de una taxonomía que, evidentemente, depende de mi conocimiento previo. Si, además, estoy tratando de comparar las diversidades genéticas de distintas poblaciones habré de ser muy cauto porque estos datos dependen, claramente, de las poblaciones que haya decidido utilizar. La categorización, en principio, debería reflejar las regularidades del territorio, pero, casi siempre será aproximada y dependerá, al menos en parte, de nuestra perspectiva y, en ocasiones, podría llegar a ser muy engañosa. En cualquier caso, es fundamental reconocer que las categorizaciones no dependen exclusivamente del mundo externo, sino que, en realidad, forman parte del mapa que pretende reflejar su estructura. Todas las observaciones están cargadas de teoría, pero no todas las cargas teóricas afectan por igual a la elección entre hipótesis. Este problema se hace relevante, sobre todo, cuando las observaciones no son neutrales respecto a las hipótesis que estamos evaluando. Por ejemplo, si dos astrónomos discuten sobre las trayectorias de los planetas, sus observaciones dependen de las teorías ópticas, pero esta carga teórica es neutral respecto a las hipótesis que están evaluando porque las afecta de igual modo. Sin embargo, las cosas se complican cuando las asunciones teóricas, como, por ejemplo, las clasificaciones taxonómicas, influyen desigualmente en las hipótesis evaluadas. En estos casos los datos dejan de ser evidencias imparciales en el juicio a las hipótesis evaluadas. Conviene entonces reevaluar la situación con cuidado, tal vez descendiendo a observaciones más elementales. Por ejemplo, en el caso del tomate decidí prescindir de las clasificaciones taxonómicas que estaba manejando y recopilé nuevas evidencias que utilicé para generar y justificar nuevas clasificaciones. Resumiendo, las observaciones están cargadas de teoría y esta carga puede no ser neutral. Esto no implica que las observaciones sean inútiles, recordemos que también dependen del mundo externo y, por lo tanto, contienen información sobre él. Pero sí hemos de tratar de evaluar en qué grado dependen del mundo externo y en qué medida del observador y siempre hemos de tener en cuenta que podrían encerrar sesgos debidos a nuestra perspectiva. 26.14 El problema de las inferencias ampliativas Es imposible inferir conocimiento general a partir de información limitada sin dar saltos lógicos inválidos. Esta es otra de las limitaciones fundamentales que el cartógrafo deberá asumir. Esto no implica que nuestros mapas vayan a ser necesariamente falsos, es evidente que puede generarse conocimiento útil, pero sí que hemos de considerar que, incluso aunque nos esmeremos por hacer ciencia con el máximo rigor, las conclusiones siempre serán falibles o, al menos, parciales y aproximadas. Esta limitación general se concreta en varios problemas prácticos. Por ejemplo, hemos defendido que el conocimiento del territorio se fundamenta sobre observaciones, pero estas observaciones, además de ser falibles y de ser más o menos neutrales respecto a las hipótesis evaluadas, son, irremediablemente, datos que provienen del pasado. Por lo tanto, nuestros mapas, en el mejor de los casos, serán adecuados, pero, se referirán, irremediablemente, al pasado. Mientras que el territorio no cambie esto no es problema, pero si cambiase, el mapa, como es obvio, fallaría. Este problema también afecta a nuestras metodologías que se validaban, al menos en parte, por haber demostrado funcionar en el pasado. Y, recordemos, el territorio puede cambiar sin previo aviso y sin que nos demos cuenta. Por ejemplo, nuestros sistemas perceptuales utilizan heurísticas implícitas que, en general, nos sirvieron bien en el pasado, pero cuando se enfrentan a estímulos que violan las reglas que funcionaron en el pasado producen ilusiones perceptuales. Sufrimos problemas análogos cuando tratamos de aplicar mapas generados en el pasado a territorios que han cambiado sin que nos hayamos dado cuenta. La solución parcial es asumir que no tenemos garantía de que el territorio no haya cambiado y permanecer atentos a que las nuevas evidencias puedan estar invalidando nuestro conocimiento previo. Otro problema ineludible es el de la subdeterminación. Siempre puede haber otra hipótesis que sea igual o, incluso, mejor que la nuestra. Esto no es una simple posibilidad filosófica, a principios del siglo XX los físicos vieron como sus teorías mejor contrastadas, la mecánica newtoniana y la electrodinámica de Maxwell, eran sustituidas por teorías que, al menos en el caso de la mecánica cuántica, eran radicalmente distintas. Es cierto que si nos ceñimos a las estructuras, el problema de la subdeterminación es menor puesto que las nuevas teorías tendrán estructuras similares en las regiones mejor exploradas empíricamente por las contrastaciones antiguas, pero aún así fuera de los rangos previamente conocidos pueden aparecer dragones y, además, la metafísica también tiene una cierta importancia porque es así como entendemos el mundo los seres humanos y porque, además, influye en las decisiones relativas a la investigación que toman los científicos. 26.15 Podría fallar, pero suele funcionar Estas limitaciones ineludibles impiden que disfrutemos de garantías absolutas, siempre cabe la posibilidad de que estemos terriblemente equivocados, pero esto no implica que nuestros mapas tengan que ser completamente erróneos; el escepticismo radical es una conclusión estéril. La percepción suele funcionar y la ciencia también. El conocimiento del mundo externo no disfruta de un absoluto filosófico; hay muchas cosas que podrían ir mal, pero no es menos cierto que hemos acumulado mucho conocimiento, que las ciencias clásicas funcionan bastante bien, que el éxito operacional alcanzado por esas ciencias es espectacular, que hemos enviado sondas a Plutón, que alimentamos a 7000 millones de personas, que hemos desarrollado vacunas en menos de dos meses desde la aparición de una nueva enfermedad y que disponemos de potentes computadoras de bolsillo capaces de mostrarnos vídeos de gatitos sin interrupción. No he hablado de estos problemas y limitaciones porque piense que la ciencia es una simple construcción social sin una relación especial con el territorio. Que exista la posibilidad lógica de que algo puede ir mal no implica que tenga que fallar en todos los casos. Me he detenido en las limitaciones porque es importante tener en cuenta que el camino del conocimiento es tortuoso y exige virtud metodológica y modestia intelectual. Espero que esta crítica constructiva contribuya a que permanezcamos siempre vigilantes; la ciencia no funciona gracias a la confianza, sino a la suspicacia y el rigor. No hemos de creer aquello que nos parezca haber visto, hemos de aceptar sólo aquello para lo que tengamos abundantes observaciones y aun en ese caso nuestra aceptación ha de ser tentativa. Nuestro conocimiento nunca podrá ser completo. Es imprescindible asumir una gran modestia intelectual. Con esto tampoco quiero decir que debamos asumir que no sabemos nada, no, la modestia intelectual simplemente implica que el territorio que estamos tratando de cartografiar es traicionero y que nuestras capacidades son limitadas. Tendremos que hacer acopio del mayor rigor posible y es imprescindible que contemos con colaboradores racionales dispuestos a criticarnos justificadamente. Ser conscientes de qué tarea es difícil facilita que encontremos y corrijamos los errores y eso nos permitirá solventar problemas más difíciles. 26.16 Normas y jueces En ciencia hay normas epistémicas, y aunque hay algunas absolutas, como la aritmética, la mayoría deben ser evaluadas en cada situación puesto que podrían entrar en conflicto entre sí. Por ejemplo, hemos dicho que hay que rechazar las hipótesis que no cuadran con las observaciones, pero también hemos asumido que las observaciones pueden ser erróneas o que el aparente conflicto puede ser debido a asunciones auxiliares erróneas y no a la propia hipótesis. Hay normas epistémicas, pero no un algoritmo absoluto, un método, que dicte con completa precisión cómo aplicarlas en cada ocasión. Esto implica que los investigadores tienen una cierta libertad a la hora de juzgar una cuestión concreta. Necesitamos jueces que decidan cómo interpretar y aplicar las normas epistémicas. En muchos casos el juicio será obvio, no se puede tolerar que una hipótesis requiera que 1 más 1 sean 3 o que aceptemos que los burros vuelan, pero en otros la dependencia del buen oficio y del compromiso epistémico de los jueces será mayor. En última instancia es la comunidad la que interpreta las normas y la que alcanza, o no, una decisión consensuada. Un científico puede proponer, pero, al final, lo que tendremos que valorar es que se alcance un consenso más o menos amplio entre los expertos. Además, los que no somos expertos en un área haremos bien en adoptar la postura consensuada por sus expertos y habremos de abstenernos de juzgar sobre problemas complejos. Existe una tensión entre la normatividad de las reglas epistémicas y el oficio y la libertad de los jueces que las aplican. La existencia de normas epistémicas hace posible que hablemos de racionalidad, pero esta racionalidad necesita de una comunidad que la aplique y esta aplicación dependerá, hasta cierto punto, del buen criterio de los investigadores involucrados. La racionalidad no consiste en un algoritmo, sino que, en muchos casos, requerirá de juicios complejos que dependerán, al menos en parte, de la interpretación que hagan los investigadores. Esto hace que, en un grado variable, que depende de la dificultad del problema, el resultado dependa de los valores y de la capacidad de la comunidad. El buen oficio de los investigadores es un factor relevante. Por otro lado, cuanto más fuertes sean las evidencias menos margen de interpretación habrá. Galileo pudo enfrentarse, y acabar convenciendo a la comunidad, porque sus propuestas estaban bien justificadas por las observaciones y la lógica, no necesitó más. Sin embargo, en otros casos, sobre todo cuando las evidencias escasean, las observaciones no son neutrales respecto a las teorías evaluadas y los fenómenos estudiados son complejos, la libertad epistémica de la que gozan los investigadores puede tener mucha relevancia, y es en algunos de esos casos en los que puede que sea recomendable reservar el juicio. 26.17 Exigencias deontológicas Este grado de libertad epistémica del investigador implica una gran responsabilidad y hace necesario que se consideren los valores epistémicos de los buscadores de conocimiento. Los científicos deberían actuar en todo momento tratando de optimizar la creación de conocimiento. La práctica honesta de la ciencia exige un compromiso radical con la integridad intelectual. El científico no ha de enamorarse de una hipótesis concreta, tiene que defender el proceso de generación de conocimiento; debemos ser buscadores de la verdad, no defensores de nuestras ideas. Lo contrario puede sesgar los juicios que necesariamente habremos de hacer y nos puede encerrar en círculos viciosos que favorezcan únicamente la validación de nuestras ideas previas. La cognición humana es limitada y falible, así que tenemos que esforzarnos en ser autocríticos y en buscar la crítica razonada de nuestros compañeros. Nuestros críticos racionales no son rivales, sino colaboradores que nos ayudan a reconocer el error. Y, por supuesto, hemos de devolver el favor que se nos hace participando en la construcción colectiva de conocimiento llevada a cabo mediante el diálogo racional del ágora. Este diálogo implicará crítica, pero crítica racional; el objetivo es obtener entre todos datos más fuertes, construir justificaciones más sólidas y lograr construir hipótesis mejor contrastadas. La integridad intelectual implica también la participación en las discusiones sociales que se dan en la sociedad en su conjunto. El experto íntegro tiene el deber de luchar contra los errores, relacionados con su área de conocimiento, que detecte en la sociedad. 26.18 Incentivos perversos Los científicos, al menos por el momento, son humanos y aunque no hemos de desdeñar nuestra necesidad animal de comprender el territorio, tampoco hemos de caer en la equivocación de creer que somos epistémicamente puros. Es cierto que nos interesa, en mayor o menor grado, la generación de conocimiento, pero, como mamíferos sociales que somos, la posición en la jerarquía es otro de nuestros grandes intereses. En muchas ocasiones estos dos grandes incentivos entran en conflicto y, en la práctica, no siempre vence el compromiso con la integridad intelectual. Los científicos suelen estar muy preocupados por su prestigio, tanto dentro de las comunidades científicas, como en la sociedad en general; son conscientes de que de él dependen su carrera profesional, la financiación de sus investigaciones y la atención que les presta el resto de la comunidad. Existe, por tanto, la tentación de convertirnos en propagandistas, de traicionar el ejemplo de Platón o Darwin, de no publicitar las debilidades de nuestras hipótesis y justificaciones. Un artículo científico en el que no se destaquen las limitaciones de la investigación es un ejercicio publicitario. De hecho, cada vez es más habitual que los artículos científicos no sólo oculten sus debilidades, sino que inflen sus virtudes. Hay que tener en cuenta que los investigadores piensan, probablemente con razón, que es más difícil publicar un artículo cuando se es generoso con sus virtudes y no se exponen sus limitaciones. Esta es una tentación que llega, en muchos casos, a convertir a los investigadores en malos científicos que sesgan sus juicios para defender conclusiones llamativas. Es muy importante que los no expertos entendamos que los estudios individuales no tienen utilidad para nosotros, precisamente, por estos motivos. Los científicos además de que pueden equivocarse, tienen incentivos que les llevan, en muchos casos, a inflar las conclusiones y los no expertos no somos capaces de evaluar sus justificaciones. La ciencia no avanza por una acumulación de verdades, sino gracias a un complejo proceso de discusión. Un artículo concreto no ha de considerarse como una verdad, sino como un argumento en la discusión que puede acabar siendo completamente erróneo. Los no expertos hemos de confiar en el consenso de los expertos y cuando este no se alcance lo más recomendable es que reservemos el juicio. La crítica racional del investigador a sus colegas es otra de sus obligaciones, pero hemos de recordar que un mamífero que maltrata a un compañero es un traidor. El ideal habría de ser respetar la verdad y, además, el colega tendría que agradecer nuestro interés por ayudarle a salir del error, pero en la práctica la crítica daña el prestigio del colega y, por lo tanto, sus oportunidades laborales. La crítica también implica un coste para quien la hace porque los mamíferos sociales repudiamos a los traidores. De modo que la crítica siempre implica una tensión entre traicionar a la razón o a la manada. Estamos incentivados para abandonar nuestro papel socrático para convertirnos en cortesanos que maquinan en las pausas del café de los congresos para conseguir ventajas en una próxima publicación o en la financiación de un nuevo proyecto. Y, por otro lado, es común la crítica arbitraria a los rivales intelectuales más débiles. La vitalidad de las comunidades racionales depende del compromiso de sus miembros con la verdad por encima de otras consideraciones. Respeto mis colegas y por eso me comprometo más con la verdad. También estamos tentados de traicionar nuestro deber socrático para con la sociedad en su conjunto. Suele pedirse que el científico se acerque a la sociedad y que divulgue su conocimiento. Es habitual elogiar los intentos por explicar el funcionamiento de los agujeros negros o de los cánceres. Sin embargo, no se habla tanto del papel del científico como crítico social. En la sociedad se mantienen muchas ideas erróneas y es deber de los expertos en cada área criticarlas. Por ejemplo, es común pensar que la denominada agricultura ecológica tiene un impacto medioambiental menor que la convencional a pesar de que la realidad es la contraria. Es deber de los que trabajamos en agricultura explicar este error. Pero hacerlo implica renunciar a financiación. Recordemos que los organismos públicos, que son elegidos democráticamente, eligen cómo se financia la ciencia. En la actualidad las administraciones europeas y locales llevan tiempo financiando proyectos de investigación cercanos al área de la agricultura ecológica y muchos investigadores eligen callar sus críticas razonadas para poder mantener sus laboratorios abiertos. Esto, por supuesto, nos convierte en pseudointelectuales. 26.19 Ágora, corte y bazar El ágora racional es el ideal a seguir. Debemos fomentar el diálogo racional y el compromiso con la integridad intelectual en todas las comunidades relacionadas con el conocimiento. En realidad, probablemente por estar espoleadas por la facilidad de la contrastación, las comunidades científicas suelen ser uno de los mejores ejemplos de comunidades racionales que tenemos los seres humanos. Es cierto que hay aspectos mejorables, pero el compromiso con la búsqueda de la verdad es, claramente, mucho mayor en las comunidades científicas que, por ejemplo, en las religiosas. El ejemplo del diálogo racional de Bohr y Einstein, la autocrítica de Darwin o la sumisión de Kepler a las observaciones, tal vez sea el principal legado que la ciencia pueda hacer a la sociedad en general. Por otro lado, las comunidades científicas harían bien en tomarse en serio su papel ejemplar, en fomentar el diálogo racional y en castigar a los propagandistas y cortesanos. Las comunidades en las que participo, a veces, me recuerdan demasiado a las cortes, a los reinos de taifas, a las redes clientelares y a los publicistas de las grandes agencias. La realidad, supongo, se encontrará, más bien, cercana al bazar. Hay actores comprometidos en distinto grado con la integridad intelectual y esto, en gran medida, creo que depende de la facilidad de contrastación de los problemas tratados. Si sabes que la realidad es fácil de comprobar estás incentivado para detectar el error antes de que otros lo detecten por ti. Sin embargo, cuando crees que podrás colar tu mala ciencia sin que se descubra el pastel, te sentirás más libre para convertirte en un cortesano y un publicista. 26.20 Ciencias y ciencias La ciencia es muy heterogénea y está compuesta por áreas en la que se estudian fenómenos muy diferentes utilizando metodologías muy diversas. Existe un sólo territorio, pero su estructura es tan rica a distintas escalas, que su estudio se organiza en distintas ciencias y comunidades que son, hasta cierto punto, independientes. Estas perspectivas son complementarias, no alternativas, siempre que se estudie un mismo fenómeno desde distintos puntos de vista las conclusiones obtenidas deberían ser coherentes. Por ejemplo, Carnot y Boltzmann estudiaron la termodinámica a escalas y con metodologías muy distintas, flujos de calor macroscópicos y mecánica estadística microscópica respectivamente, pero sus conclusiones fueron completamente coherentes. Lo mismo ocurrió con los átomos de los químicos, derivados de las relaciones estequiométricas de las reacciones químicas, y de los físicos, que aparecieron en multitud de fenómenos. Por otro lado, los investigadores se enfrentan a problemas con niveles de dificultad muy diferentes. Por ejemplo, hay problemas que no se prestan a la realización de experimentos. En algunos casos, como en astrofísica o epidemiología, no podemos controlar las condiciones de la observación y, en otros, como en filogenética, estudiamos fenómenos históricos que no volverán a repetirse y que queremos reconstruir a partir de los vestigios que dejaron. La contrastación es mucho más sencilla cuando podemos hacer predicciones. Por ejemplo, si mi teoría predice que la bolita tiene que caer con una aceleración determinada y se queda flotando en el aire, mi teoría tiene un problema serio. Sin embargo, si mi hipótesis no puede hacer predicciones porque se refiere a un sistema muy complejo en el que influyen múltiples causas, será más difícil falsarla. Por ejemplo, yo podría plantear un modelo para la difusión de un virus en la población y si me atreviese a predecir que su incidencia aumentará en dos semanas y, sin embargo, a las dos semanas observo que ha disminuido, podría decir que el modelo falló porque los políticos implementaron medidas adecuadas o que los ciudadanos fueron conscientes de la gravedad de la situación y aumentaron su cautela. Este no es un problema insalvable. Por ejemplo, los meteorólogos han aprendido a predecir probabilidades de distintos resultados y sus predicciones son, por lo tanto, probabilísticas. Este es un gran ejemplo, pero, por desgracia, hacer esto es difícil incluso para un área en la que se conocen perfectamente todas las leyes fundamentales. Cuando las predicciones no son posibles las hipótesis pueden contrastarse utilizando nuevas observaciones. Por ejemplo, los epidemiólogos no pueden hacer experimentos, pero sí pueden contrastar sus modelos frente a observaciones obtenidas en poblaciones muy distintas. La excesiva, e inevitable, carga teórica de la observación es otra de las dificultades principales a las que se enfrentan algunas ciencias. Por ejemplo, en psicología es difícil generar datos que estén cerca de percepciones elementales o que tengan una carga teórica neutral respecto a las hipótesis evaluadas. Esto no imposibilita completamente la contrastación, pero la hace mucho más difícil. Cuando los problemas son complejos o las evidencias tienen mala calidad o no son neutras respecto a las hipótesis evaluadas, nuestras limitaciones cognitivas, las motivaciones ideológicas y los incentivos perversos que acechan en las comunidades pueden hacerse más patentes y el progreso del área de conocimiento afectada se hará más difícil. Si no es sencillo separar el grano de la paja, elegir los mapas que funcionan y los que no, el área tendrá una mayor tendencia a quedarse atascada. Además, cuanto más difícil sea la contrastación empírica, más fácil será esconder la mala ciencia. La clave del progreso no reside en no equivocarnos, sino en ser capaces de detectar el error. Como en la selección natural, cuanto más clara sea la forma de discriminar los modelos buenos de los malos, más eficiente será la generación de conocimiento. Si, además, no hay incentivos que favorezcan el diálogo racional, la tentación de generar narrativas reconfortantes, que estaremos tentados de confundir con verdaderos mapas, será grande. Confundir una narrativa con conocimiento es el equivalente cognitivo de la alucinación colectiva. Hemos de ser muy cautos cuando nos enfrentemos a un área en las que los mapas no pueden usarse para hacer intervenciones o predicciones exitosas y en la que hay que echar mano de continuas hipótesis ad hoc para apuntalar nuestras hipótesis o en la que las hipótesis son capaces de dar cuenta de cualquier observación. En estos casos lo honesto sería reconocer la poca utilidad de los resultados obtenidos. La eficiencia y el grado de éxito dependen de la dificultad del problema, de la facilidad de contrastación y de la cultura de la comunidad; la dificultad de generación de conocimiento depende del cartógrafo y del territorio. Hay problemas que, incluso con nuestras mejores herramientas y nuestras mejores intenciones, no podremos resolver. Pero lo peor que nos puede pasar no es que no podamos saber algo, sino que creamos algo falso. Conviene recordar que tendemos a detectar regularidades incluso donde no las hay; esta es una de las principales debilidades de la cognición humana, la otra es aferrarnos a nuestras creencias más queridas. Es importante evaluar cuánto han influido en las conclusiones los factores internos, psicológicos o sociales, y cuánto los externos, la información proveniente del territorio. Si la evaluación es difícil, o el problema tiene poco interés, los aspectos internos pueden ganar protagonismo y la comunidad puede acabar dando respuestas empíricamente poco adecuadas a las que se les asigne una confianza inmerecida, es decir, puede acabar generando alucinaciones creadas por las dinámicas sociales y por los sesgos de los investigadores. En cualquier caso, los valores epistémicos y el compromiso deontológico son importantes sólo hasta cierto punto. Cuando un área no consigue progresar durante un tiempo prolongado, cuando sus hipótesis son vagas y no permiten actuar sobre el territorio, cuando los resultados obtenidos no generan tecnologías, cuando el territorio sigue sorprendiendo, debemos plantearnos el lugar de esta área de conocimiento junto al resto de ciencias. El riesgo principal es asumir que todas las ciencias merecen la misma confianza. Algunas conclusiones son más sólidas que otras y no hemos de trasladar el prestigio obtenido gracias al éxito operacional de algunas ciencias a todo el conjunto de las áreas autodenominadas científicas. Es un error trágico trasplantar el prestigio de la física del estado sólido a la macroeconomía o a algunas de las recomendaciones pedagógicas. Sin embargo, la tentación de arrogarse el prestigio social de las ciencias exitosas es grande, tanto dentro como fuera del mundo académico. La ciencia funciona bien en muchos casos, pero en ocasiones puede llegar a tener un exceso de confianza casi absurdo, similar al de una pseudociencia. Pero tampoco debemos aceptar en ningún caso el relativismo; cuando desconocemos la estructura territorio es absurdo aceptar cualquier mapa, lo racional es hacer una prudente y escéptica reserva de juicio, hemos de admitir, simplemente que no sabemos o que nuestro conocimiento es muy tentativo. 26.21 Para qué sirve la ciencia La ciencia es el fruto de nuestro mejor intento colectivo de comprender el Cosmos, nuestro mejor intento de racionalidad; falible y abierta a mejora, pero capaz de generar las tecnologías que sostienen nuestra civilización. Gracias al conocimiento científico sabemos quienes somos: mamíferos sociales con lenguaje e ínfulas que habitan un pequeño oasis fértil en un inmenso universo hostil. Por el contrario, el provinciano mito religioso que permeaba la cultura de mi infancia pretendía que éramos hijos del omnipotente y omnisapiente creador del universo y que el mundo natural estaba a nuestro servicio. No podremos comprender nuestro papel en el Cosmos mientras seamos ajenos a la realidad. Recuerdo que la primera vez que el rompecabezas encajó fue cuando, siendo niño, escuché la voz de Carl Sagan desgranando, capítulo tras capítulo, qué somos y qué es el Cosmos. Por si esto fuese poco, la ciencia nos eleva estéticamente imbuyéndonos del logos. Para el iniciado el orden del ciclo químico de la fotosíntesis y la respiración o las profundas implicaciones de los modestos planos inclinados son equivalentes a las sinfonías de Beethoven o las partitas de Bach. Si hay algo que lamento, es ser consciente de la enormidad de la belleza que todavía me es ajena. Son tantísimas las cosas que no sé. Por último, la ciencia y la filosofía señalan los límites del conocimiento, la desafiante frontera que atrapa nuestras pupilas, que nos impele a dar un paso más, que nos eleva. Un cerdo que no vuela no es más que un cerdo. Hayao Miyazaki "],["notas.html", "Notas", " Notas "],["bibliografia.html", "Bibliografía", " Bibliografía "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
